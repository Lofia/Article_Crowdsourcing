                                                                                                                     JGIM



REVIEWS


Crowdsourcing—Harnessing the Masses to Advance Health

and Medicine, a Systematic Review

                               1                            1                                           3,4
Benjamin L. Ranard, AB , Yoonhee P. Ha, MSc , Zachary F. Meisel, MD, MPH, MS                               ,
                                2,3,5,6                            6                             4
David A. Asch, MD, MBA                 , Shawndra S. Hill, PhD , Lance B. Becker, MD ,
                            7                                                2,3,4
Anne K. Seymour, MS          , and Raina M. Merchant, MD, MSHP
1                                                                       2
 Perelman School of Medicine, Uni3ersity of Pennsylvania, Philadelphia, PA, USA; Penn Medicine Center for Innovation, University of
Pennsylvania, Philadelphia, PA, USA; The Leonard Davis Institute of Health Economics, University of Pennsylvania, Philadelphia, PA, USA;
4Department of Emergency Medicine, University of Pennsylvania, Philadelphia, PA, USA; Philadelphia Veterans Affairs Medical Center,
Philadelphia, PA, USA;he Wharton School, University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania Libraries, University of

Pennsylvania, Philadelphia, PA, USA.


OBJECTIVE: Crowdsourcing research allows investiga-              should be collected and reported to provide clarity and
                                                                 comparability in methods.
tors to engage thousands of people to provide either data
or data analysis. However, prior work has not document-
ed the use of crowdsourcing in health and medical                KEY WORDS: crowdsourcing; crowd sourcing; citizen scientist; citizen
                                                                 science; human computing.
research. We sought to systematically review the litera-
ture to describe the scope of crowdsourcing in health            J Gen Intern Med 29(1):187–203
research and to create a taxonomy to characterize past           DOI: 10.1007/s11606-013-2536-8
                                                                 © Society of General Internal Medicine 2013
uses of this methodology for health and medical research.
DATA SOURCES:         PubMed, Embase, and CINAHL
through March 2013.


STUDY ELIGIBILITY CRITERIA:               Primary peer-
reviewed literature that used crowdsourcing for health                                INTRODUCTION

research.
STUDY APPRAISAL AND SYNTHESIS METHODS: Two                       
Crowdsourcing is an approach to accomplishing a task by
authors independently screened studies and abstracted            opening up its completion to broad sections of the public.

data, including demographics of the crowd engaged and            Innovation tournaments, prizes for solving an engineering
approaches to crowdsourcing.                                     problem, or paying online participants for categorizing
RESULTS: Twenty-one health-related studies utilizing
                                                                 images are examples of crowdsourcing. What ties these
crowdsourcing met eligibility criteria. Four distinct types      approaches together is that the task is outsourced with little
of crowdsourcing tasks were identified: problem solving,
data processing, surveillance/monitoring, and surveying.         restriction on who might participate. Despite the potential of
                                                                 crowdsourcing, little is known about the applications and
These studies collectively engaged a crowd of >136,395
people, yet few studies reported demographics of the             feasibility of this approach for collecting or analyzing
crowd. Only one (5 %) reported age, sex, and race
                                                                 health and medical research data where the stakes are high
statistics, and seven (33 %) reported at least one of these      for data quality and validity.
descriptors.Mostreportsincluded data on crowdsourcing
                                                                   One of the most celebrated crowdsourcing tasks was the
logisticssuchasthelength ofcrowdsourcing(n=18, 86 %)             prize established in 1714 by Britain’m tiet
and time to complete crowdsourcing task (n=15, 71 %).
All articles (n=21, 100 %) reported employing some               Longitude Act, offered to anyone who could solve the problem
                                                                 of identifying a ship’s longitudinal position. The Audubon
method for validating or improving the quality of data
reported from the crowd.                                         Society’s Christmas Bird Count began in 1900 and continues to
LIMITATIONS: Gray literature not searched and only a             this day as a way for“citizen scientists” to provide data that can
                                                                                                           2
sample of online survey articles included.                       be used for studying bird population trends.However, today
CONCLUSIONS AND IMPLICATIONS OF KEY FINDINGS:                    the world has 2.3 billion Internet users and 6 billion mobile
Utilizing crowdsourcing can improve the quality, cost, and                             3
                                                                 phone subscriptions,    providing access that facilitates
speed of a research project while engaging large segments
of the public and creating nov   el science. Standardized        crowdsourcing to a much greater extent than was available to
guidelines are needed on crowdsourcing metrics that              Britain’s Parliament and the Longitude Act. The Galaxy Zoo

                                                                 project (galaxyzoo.org) successfully classified nearly 900,000
                                                                 galaxies with the help of hundreds of thousands of online
Received February 1, 2013
Revised May 6, 2013                                              volunteers. The simple visual classification was easily
Accepted May 20, 2013                                            performed by humans but not by computers.Other examples

Published online July 11, 2013                                   include Whale.fm (whale.fm), which has almost 16,000 whale

                                                                                                                         187
188                               Ranard et al.: Crowdsourcing in Health and Medical Research                            JGIM


calls that volunteers are classifying in order to help process    authors of all papers meeting eligibility criteria. Two

large data sets that have become unmanageable for researchers     common crowdsourcing platforms used by articles meeting
alone to classify.6 The online platform eBird (ebird.org)         manuscript criteria were Amazon Mechanical Turk (AMT)

collected more than 48 million bird observations from well        (mturk.com) and Foldit (fold.it). Therefore, a literature-
over 35,000 contributors.,8                                       informed search of all three databases was performed by
   While this prior work illustrates the promise of crowd-        including the terms“mechanical turk” and “foldit.” Reference

sourcing as a research tool, little is known about the types of   lists of articles meeting eligibility criteria were reviewed to
questions crowdsourcing is best suited to answer and about the    identify additional articles, as were relevant review articles that

limitations of its use. Health research in particular requires    were returned by the database search. Project websites that
high standards for data collection and processing, tasks          were specifically cited by references were manually searched
traditionally conducted by professionals and not the public.      for relevant publications.

Furthermore, human health research often requires protections
for privacy and against physical harm. To better understand       Crowdsourced Literature Search. A crowdsourced search
                                                                  for literature was performed by psting an open call for articles
the potential of crowdsourcing methods in health research, we
conducted a systematic literature review to identify primary      on two free websites: Yahoo! Answers (answers.yahoo.com)
peer-reviewed articles focused on health-related research that    and Quora (quora.com). The title used in the question was:

used crowdsourcing of the public. Our aim was to characterize     “Crowdsourcing: published literature on crowdsourcing in
the types of health research tasks crowdsourcinghas been used     health/medicine?” and the body of the question was:“What
                                                                  scientific research articles in health/medicine have been
to address and the approaches used in order to define future
opportunities and challenges.                                     published that use crowdsourcing in part or in whole to
                                                                  achieve their research objective” Results were collected after

                                                                  seven days. Responders consented to allow use of provided
                                                                  references.

                     METHODOLOGY
                                                                  Study Selection. Studies were included if they met the
Data Sources and Searches                                         following criteria: (1) primary peer-reviewed journal article
                                                                  representing original health research; (2) methodology and
Definitions. Crowdsourcing was defined as soliciting over
the Internet from a group of unselected people, services and      results provided; and (3) citizen crowdsourcing used by
data that could not normally be provided solely by                scientists to obtain at least part of the results. Excluded were

automated sensors or computation lacking human input.             studies soliciting opinions only from other experts (i.e.,
Crowdsourcing participants had to be actively engaged in          experts collaborating with each other), abstracts, editorials,
                                                                  and wikis that existed simply to create content but not
the crowdsourcing task and not simply passively have their
data mined without their knowledge.                               to answer a specific research question with original data.
   Health research was defined as research that contrib-          Also excluded were papers that used an Internet survey

utes to the World Health Organization ’s definition of            that did not contain any of the original crowdsourcing
health: “a state of complete physical, mental and social          keywords from our Boolean search string in the title or
                                                                  abstract of the paper. Behavioral research has been conducted
well-being 9nd not merely the absence of disease or                                                                          10
infirmity.”                                                       via the Internet through Internet surveys for over 15 years,
                                                                  and therefore this is not a particularly novel research method.

Systematic Literature Search. A systematic literature search      We included the surveys returned by our database search to
was performed on March 24, 2013, by searching PubMed,             provide a few examples from the field.
Embase, and CINAHL using the following Boolean search

string: crowdsourc* OR“crowd source” OR “crowd sourcing”          Data Extraction and Quality Assessment. Two reviewers
OR “crowd sourced” OR “citizen science” OR “citizen               independently extracted data (BR and YH). The following
                                                                  data were extracted from articles (including participant
scientist” OR “citizen scientists.” Articles underwent a
multistage screening process whereby results were pooled          data items recommended by the Cochrane Handbook
and duplicates were removed. Two reviewers (BR and RM)            checklist ): study background information (title, author,

screened abstracts for relevance and then screened full-text      publication year, research field, methodology type, study
articles to confirm eligibility criteria. Two literature-informed objective, study outcome), demographic and other
                                                                  characteristics of the crowd (size of the crowd, age,
database searches were performed to identify additional
studies. Authors of published papers meeting eligibility          gender, racial/ethnic background, geographic location,
criteria are likely to be experts in their field. As a result,    occupation, education, relationship to the research problem,

PubMed was searched using the full names of first                 referral source, stated conflict of interest, motivation), and the
JGIM                            Ranard et al.: Crowdsourcing in Health and Medical Research                            189



logistics of the crowdsourcing [length of time crowdsourcing    Data Processing
was conducted, use of a web platform and/or a mobile
                                                                Crowdsourcing was used to provide data processing in 7
platform, use of individuals compared to teams, intracrowd      of 21 articles (33 %). Three papers used AMT, a service
sharing techniques (such as team wiki or forum), data
collected or processed, complexity of the task, time            from Amazon.com that allows individuals to create
                                                                accounts and sign up to do an online task in exchange
given to do the task, advertisement of project, skill set
required, monetary incentives offered, and data validation      for payment. AMT Knowledge Workers (KWs) classi-
                                                                fied polyps in computer tomography (CT) colonography
techniques]. Additional extracted data included the viewer-to-  images 28 and then were asked questions to gauge how
participant ratio, reflecting how many people saw the task                                              27
                                                                to optimize presentation of the polyps.    AMT was also
(or website with the task) to how many people completed the     used to annotate public webcam images to determine
task.
                                                                how the addition of a bike lane changed the mode of
                                                                transportation observed in the images.   31  Three manu-
Data Synthesis and Analysis. Summary statistics were used
to describe the number of studies reviewed and to               scripts reported on two independent games that used
characterize the data extracted from these studies.             crowdsourcing to either identify red blood cells (RBCs)
                                                                infected with 25,26 or thick blood smears containing    24
  This study was approved by the University of Pennsylvania
Institutional Review Board.                                     malaria parasites (Plasmodium falciparum ). The final
                                                                paper in the data processing category attempted to use

                                                                the crowd to update the literature and evidence covered
                                                                by a systematic review. 16

                         RESULTS

Systematic Literature Search
                                                                Surveillance/Monitoring
There were 231 unique articles identified from the initial
database and crowdsourced search and 209 articles identified    Surveillance/monitoring was employed in 3 of 21 (14 %)
                                                                studies. One of the papers used AMT to ask users about
in the literature-informed database search. Of the 440 articles,
76 articles underwent a full-text review. Sixteen of these      their malaria symptoms in order to assess malaria preva-
articles met eligibility criteria. Five additional articles werelence in India.0 Another used a mobile phone application
                                                                that allowed users to report potential flu-like symptoms
identified from reference lists of eligible articles (Fig. 1). The
final article cohort consisted of 21 unique health research-    along with GPS coordinates and other details, which
                                                                enabled researchers to chart incidence of flu symptoms that
related primary peer-reviewed publications that used
crowdsourcing as a methodology 12–32 (Table 1).                 matched relatively well with Centers for Disease Control
                                                                and Prevention data. 14 The last paper created a map of

                                                                automated external defibrillators (AEDs) by having users of
                                                                a mobile phone application locate and take pictures of
Study Characteristics                                           AEDs.  32

We identified four types of research tasks that articles in
our cohort employed crowdsourcing to accomplish:

problem solving, data processing, surveillance/monitor-         Surveying
ing, and surveying (Appendix       Fig. 2 and Appendix
                                                                Crowdsourcing to conduct surveys was reported in 4 of
Table 4).                                                       21 (19 %) papers. All four used AMT to administer

                                                                surveys. One study allowed surveyors to include a more
                                                                diverse population than the typical university research
Problem Solving
                                                                subject pool while maintaining reliability (as measured
Seven of 21 articles (33 %) from the final cohort employed      by Cronbach’s coefficient alpha). 15 A second study used
                                                                AMT to study the human deci sion-making process and
crowdsourcing for problem solving. Six of these used
Foldit, an online game that allows users to manipulate the      showed that AMT replicated previous laboratory find-
three-dimensional structures of proteins in order to find the   ings, indicating that it may be a good platform for
                              12,13,17–19,21                                                     22
most likely tertiary structure.            Also described       future decision-making studies.      A third study used
was the online game Phylo, where users moved colored            AMT to administer surveys about health promotional
                                                                                                 29
blocks representing different nucleotides of a gene promoter    materials and solicit feedback.     The last study used
sequence around on screen in order to make the most             KWs as subjects for cognitive behavioral tests adminis-
                               23                               tered through AMT.   30
parsimonious phylogenetic tree.
190                              Ranard et al.: Crowdsourcing in Health and Medical Research                          JGIM







































Figure 1. Results of the systematic literature search for health-related crowdsourcing studies. This figure shows the results of the systematic
                   literature search for primary peer-reviewed articles that used crowdsourcing for health research.



Crowdsourcing Logistics                                          Demographics of the Crowd

The length of the crowdsourcing study was mentioned in 18        Reporting of the demographics of the crowd varied widely,

of 21 (86 %) studies and varied from <2 hours to 10 months.      with studies reporting crowd size (16/21, 76 %), age (7/21,
Teams were used in 6 of 21 (29 %) studies, and intracrowd        33 %), gender (5/21, 24 %), race (1/21, 5 %), geographic
sharing was allowed in 7 of 21 (33 %) of studies. Monetary       location (10/21, 48 %), occupation (4/21, 19 %), education

incentives were offered in 9 of 21 (43 %) studies and            (3/21, 14 %), relationship to the research question (4/21,
ranged from $0.01 USD to $2.50 USD per task, with many           19 %), referral source (2/21, 10 %), conflict of interest (2/

studies offering bonuses for either good completion or           21, 10 %), reported motivation (3/21, 14 %), and viewer-to-
as a raffle/prize. The reported size of the crowd engaged        participant ratio (4/21, 19 %). One (5 %) study reported age,
in studies ranged from 5 to >110,000 people, with                sex, and race, and seven (33 %) studies reported at least one of

>136,395 people collectively engaged. Eleven of 21 studies       these three descriptors (Table 3).
(52 %) reported what advertising was used to attract

participants.
  All articles (100 %) reported employing some method for
validating or improving the quality of data reported from
                                                                                       DISCUSSION
the crowd. The types of validation techniques varied from
inserting random questions with known answers into the           This is the first study to identify the types of crowdsourcing

task to screen for users who were incorrectly marking            tasks used in primary peer-reviewed health research. This
answers to comparing responses among multiple users and          study has three main findings. First, we identified only 21
discarding outliers (Table 2).
                                                                 articles reflecting the use of crowdsourcing for health-
JGIM                                  Ranard et al.: Crowdsourcing in Health and Medical Research                                          191


                                                  Table 1. Study Background Information

Reference   Research field    Methodology     Objective                                       Outcome
no.                           type

1           Molecular         Observational   To evaluate whether players of the online protein Several protein structures submitted to the CASP8

               biology                         folding game Foldit could find solutions to      protein structure prediction competition ranked
                                               protein structure prediction problems            in the top 3 of all submitted entries, indicating
                                                                                                that “the game has been designed in such a way
                                                                                                that players can use it to solve scientific
                                                                                                problems”
2           Molecular         Observational   To determine whether Foldit players could solve Foldit players were able to solve “challenging
               biology                         complex protein structure prediction problems    [protein] structure refinement problems” and
                                                                                                outperform the Rosetta computer algorithm on
                                                                                                some problems
3           Epidemiology      Observational   To track an influenza outbreak by using data    Crowdsourced aggregated metric available in near
                                               submitted by users of a mobile phone             real time “correlated highly” with CDC
                                               application                                      influenza metrics available after a minimum 1
                                                                                                week lag following data collection
4           Psychology        Survey          To examine the feasibility of using AMT         “Crowdsourcing respondents were older, were
                                               respondents instead of the traditional            more ethnically diverse, and had more work
                                               undergraduate participant pool for survey         experience” and “reliability of the data…was
                                               research                                          as good as or better than the corresponding

                                                                                                 university sample”
5           Human             Observational   To determine whether a scoping systematic       A total of 6 contributions were made to the wiki,
              behavior                         review on asynchronous telehealth could be       but “none of the contributions enhanced the
                                               kept up to date through crowdsourcing            evidence base of the scoping review”
6           Molecular         Observational   To evaluate the “potential of automation in a   “Players take advantage of social mechanisms in
               biology                         social context for propagating the expert skills  the game to share, run, and modify recipes”
                                               of top Foldit players and increasing the overall  indicating “potential for using automation tools
                                               collective problem solving skills”                to disseminate expert knowledge”
7           Molecular         Observational   To determine whether Foldit players could solve Players of the online game Foldit were able to
               biology                         the structure of a retroviral protease           solve a retroviral protease structure that had
                                                                                                remained unsolved by automated methods
8           Molecular         Observational   To determine whether structured collaboration   5,400 different folding strategies were made by
               biology                         among individual Foldit players could produce    the Foldit community. By sharing and
                                               better folding algorithms                        recombining successful “recipes” two dominant
                                                                                                recipes emerged that outperformed previously
                                                                                                published methods and bore “striking similarity

                                                                                                to an unpublished algorithm developed by
                                                                                                scientists over the same period”
9           Epidemiology      Survey          To use AMT to determine whether micro-          “This methodology provides a cost-effective way
                                               monetary incentives and online reporting could    of executing a field study that can act as a
                                               be harnessed for public health surveillance of    complement to traditional public health
                                               malaria                                           surveillance methods”
10          Molecular         Observational   To determine whether crowdsourcing could be     The Foldit community was able to “successfully
               biology                         used to remodel a computationally designed       guide large-scale protein design problems” and
                                               enzyme                                           produced an “insertion, that increased enzyme
                                                                                                activity >18-fold”
11          Human             Survey          To use AMT to study the relationship between    AMT “findings were validated through the
              behavior                         delay and probability discounting in human       replication of a number of previously
                                               decision-making processes                        established relations” and the present study
                                                                                                showed that “delay and probability discounting
                                                                                                may be related, but are not manifestations of a
                                                                                                single construct (e.g., impulsivity)”
12          Comparative       Observational   To determine whether players of the online game A complex scientific problem was successfully

              genomics                         Phylo could improve the multiple sequence        embedded into the “casual” online game Phylo
                                               alignment of the promoters of disease-related    (much of the science was “hidden” leaving just
                                               genes                                            a puzzle for users to work on). Players were
                                                                                                able to improve multiple sequence alignment
                                                                                                accuracy in “up to 70 % of the alignment blocks
                                                                                                considered”
13          Pathology/        Observational   To determine whether players of the online game By combining player inputs, “nonexpert players
              hematology                       MalariaSpot could accurately identify malaria    achieved a parasite counting accuracy higher
                                               parasites in digitized thick blood smears        than 99 %”
14          Pathology/        Observational   To determine whether players of an online game  Crowdsourcing resulted in a “diagnosis of malaria
              hematology                       could accurately identify RBCs infected with     infected red blood cells with an accuracy that is
                                               malaria parasites in digitized thin blood smears within 1.25 % of the diagnostics decisions made
                                                                                                by a trained medical professional”
15          Pathology/        Observational   To expand on a prior small scale experiment by  989 previously untrained gamers from 63
              hematology                       determining whether players of a large-scale     countries made more than 1 million cell
                                               online game could identify RBCs infected with    diagnoses with a “diagnostic accuracy level that
                                               malaria parasites                                is comparable to those of expert medical

                                                                                                professionals”
192                                   Ranard et al.: Crowdsourcing in Health and Medical Research                                         JGIM


                                                              Table 1. (Continued)


 Reference   Research field   Methodology      Objective                                        Outcome
 no.                          type

 16          Radiology        Observational    To determine whether AMT could be used to        “Numerous parallels between the expert
                                                conduct observer performance studies to          radiologist and the [knowledge workers]” were
                                                optimize systems for medical imaging             observed, pointing to the potential to cheaply test
                                                applications and to find out if the results were and optimize systems on the crowd before use
                                                applicable to medical professionals              with physicians
 17          Radiology        Observational    To determine whether AMT KWs with minimal        “The performance of distributed human
                                                training could correctly classify polyps on CT   intelligence is not significantly different from
                                                colonography images                              that of [computer-aided detection] for colonic

                                                                                                 polyp classification”
 18          Public health    Survey           To determine whether crowdsourcing could be      AMT provided an “effective method for recruiting
                                                used to solicit feedback on oral health           and gaining feedback from English-speaking
                                                promotional materials                             and Spanish-speaking people” on health
                                                                                                  promotional materials
 19          Psychology       Survey           To determine whether classic behavioral          “Data collected online using AMTclosely resemble
                                                cognitive experiments that require complex       data collected in the lab under more controlled
                                                multi-trial designs could be replicated using    situations” formanyoftheexperiments
                                                AMT
 20          Public health    Observational    Todeterminewhethercrowdsourcingcouldbeused       “Publicly available web data feeds and crowd-
                                                to annotate webcam images for analysis of        sourcing have great potential for capturing

                                                behavioral modifications in active transportationbehavioral change associated with built
                                                following built-environment change               environments”
 21          Public health    Observational    To determine whether crowdsourcing could be      Crowdsourcing generated “the most
                                                used to create a map of AED locations             comprehensive AED map within a large
                                                                                                  metropolitan US region reported in the peer-
                                                                                                  reviewed literature” with 1,429 AEDs identified

 Reference number key
 1- (Cooper et al., 2010)2
 2- (Cooper et al., 2010)3
                         14
 3- (Freifeld et al., 20115
 4- (Behrend et al., 20116
 5- (Bender et al., 2011)
 6- (Cooper et al., 2011)7
 7- (Khatib et al., 2011)
 8- (Khatib et al., 2011)
                          20
 9- (Chunara et al., 20121
 10- (Eiben et al., 2012)     22
 11- (Jarmolowicz et al., 20123
 12- (Kawrykow et al., 2012)
 13- (Luengo-Oroz et al., 2012)24
 14- (Mavandadi et al., 2012)25
 15- (Mavandadi et al., 2012)26
                            27
 16- (McKenna et al., 201228
 17- (Nguyen et al., 201229
 18- (Turner et al., 2012)
 19- (Crump et al., 2013)30
 20- (Hipp et al., 2013)1
 21- (Merchant et al., 2013)2







related research. Second, we found that these studies used                  the types of questions crowdsourcing could answer and the
crowdsourcing for four different principal objectives and                   ways it could be applied has been lacking. Understanding how

that there are several advantages to utilizing crowdsourcing.               crowdsourcing has been used successfully inhealth research is

Third, we found considerable variability in how the                         crucial to understanding where crowdsourcing fits in the
methods of crowdsourcing were reported.                                     health care space, especially when there may be higher

   While citizen science has been in existence for more than a              standards or tighter regulations for data quality and validity
century and crowdsourcing has been used in science for at                   compared to the science fields that were early adopters.

least a decade, crowdsourcing has been utilized primarily by                  The limited number of articles using crowdsourcing is

non-medical fields, and little is known about its potential in              surprising given the potential benefits of this approach.
health research. Every health field from studying chronic                   Although we identified 21 articles, most of which used

diseases to global health has a potential need for human                    crowdsourcing successfully, crowdsourcing clearly is not
computing power that crowdsourcing could fill in order to                   used pervasively in health research, and it is important to

accelerate research. Prior work has heralded crowdsourcing as               understand the quality of data it provides. Even though the

a feasible method for data collection, but a clear roadmap for              use of crowdsourcing in health research is in its infancy, the
JGIM                                      Ranard et al.: Crowdsourcing in Health and Medical Research                                                    193









        DatteacvaiiduaetsionthtswrhCompared responsers                             Reports filtered for,eotrsscreeceessiatrssroeritarfpaaiuoitirlseiemesrtrastponses)






                                      padeererbradaieasuringisveso,pefyaramahtussitne,itocsny
        Mo inc(tatyNot monetary    Not monetary -ssions                            Not






        SkrilelqsueThree-resslvisulThree-resslvisulalnadtion                         smartphone








                      butoFoladsnsiteyd forpuubrcis,tflts,d, of
           of the project          Rosetta@home                                    No                     AMTe of                  None              $0.80 for survey Surveys were






                                      21tomcipmunzenttypnel,imit                     timdeurtton of          miunutis,ewlimit
        Task time  No        AdvertMean 155 to                                     N/A - unlimited        Mean 26.45






                                                                                     observation
                      proptinustuesturproptinustuesture                                                      survey questions
        Coomf tleextitaysk - solvinComplex - solving                               Moderate - report      Easy - answer
   Table 2. Logistics of the Crowdsourcing





        Dactoalrotceededoepuulzle  Game play datavosiwntdeoileyebr,iytics            obsreroottineldptnon/orpresnocleeingrspmhics






           sharing                    aspgeftraacoriaboration


                   Yes     Yes     Yes    GYes - sociala                           None None              User




                      game            game                                           phoneplication
        Plat form       Team Intra-crowd                                           Mobile




                                                                                     conmtihuforiaorfnttbliceation
        Leonfgsrorwcing




        Ren for.ence            No 2            Nostom          -ustom A      /    3 N                    4            2 days          AMT            None None               Survey
194                                      Ranard et al.: Crowdsourcing in Health and Medical Research                                                  JGIM




                             by
                             ”


                             rollbacks
        Datteacvaiiduaetsiona“iradmspnistratsrsostheedn stFcotcrri,nedpesr qualityd,ealreoeyereusovei,nforestiintestacttxetdnlaenirslyelilthoeratrrneitnytal







        Mo inc(taSyNot monetary       SpNot monetaryuNot monetarys couldIn game scoring of Successful recipes  Not monetary       Predicted enzyme






        Skrilelqsueitrededge tomkatdic  Three-resslviThree-resslvisulalnThree-rsosviiulalnadtion               Three-resslviailsualization




                        Open
                           , e-mail


                      Raapriclien,aeeFehruuletinwFasodstactcousedudiitty wastcousmedudiitty was                   actoeusedudiitty was
           of the projectletins and a                No - but already   No - but already                       No - but already






                      timderftriudyn                    timderftriudyn    timdeufftrudytn                         triepasoltdgasas
        Task time  N/A - unlAdvertisemenNo           N/A - unlimited already- unlimited   No                  AN/A - unlimited        None              $0.02 for survey Surveys were




   Table 2. (Continued)


                      evisdyteeftirc reviewproptinustecsproptinustuasagrtshlustionstiacitritzshort survey         solsvprtdrcttisloe
        Coomf tleextitaysk - edit       Complex - solComplex - solving  Complex - solving Easy - answer        Complex -






        Dactalprotceededohanges toicctifvitpuzzle resultpuzzle results  Game play andlts     responses            anrepuulzle





                      wavsieyabllle                                       the(ggoaaenolch,tid)eme
           sharing


                                        Yes     Yes  Yes     Yesame play andGame play andhin                   None None              Game play data




                                           game         game              game                                    game
        Plat form      Team Intra-crowd                                                                        Custom




                                        3 months      Custom                                                      per puzzle
        Leonfgsrorwcing                 ∼




        Renfor.ence5           10 months6      Wiki  7         Non3 weeks wiki    Custommo9ths      Cus42 days 10      AMT  1 week    None None              Survey
JGIM                                     Ranard et al.: Crowdsourcing in Health and Medical Research                                                   195






                                                                                                    ’ current

                                                                                         revRiwpleicplayerremoenadgdeesd control
        Datteavnaiiduaetsiond to haverohaphealltAnswers weregtanut,eqntGold standard wasdtraecciuacy             we(rrkkndseaaterdetnsrtilelaaslelhpowlstpese.trimage






                     surbvocus$fol.ioodg          papseredalaeiancamsieor,bnodrishscorritadble
        Mo in(UaStyv)es






        Skrilelqsueitred                        Puzzle solving    Not monetary -








                                                  pubmliecy from
           of the project                  None No - but ment$2.50 for No                      Image analysis    Not monetary -






                     secuonims,ewimit             mograemoef faeel        imlameittime
        Task time  Mean 1,47Advertisement       Timed to give          1 minute per    No                  No No                  Nomage analysis    Not mImage analysisMultNot monetary




   Table 2. (Continued)


                     survey                       puzrelersnmtinetprnbcleemsbllrioadpasitleessinhraaltrsida      RBwCiphaafaltrsida
        Coomf tleextitaysk                      Moderate - solving     Moderate - identifyerate - identify    Moderate - identify






        Dactalprotceededo                         solpulyetrsitisvity     anreguatse     andregaltse             andregaltse






           sharing


                                                None None              User puzzle     None NoGame play dataNone Noneay data         Game play data




                                                  game                    game           game                    game
        Plat form      Team Intra-crowd




                   24 hours      AMT            None None              Survey results     Easy - answer
        Leonfgsrowcing




        Renfor.ence11                           12          7 months   13   Custom  1 month        Custom     15   Custom  3 months        Custom
196                                      Ranard et al.: Crowdsourcing in Health and Medical Research                                                JGIM









        DatteavnaiiKWsneededtohaveptliKdirhighuplaolrmliiet,swdic(noet)vaer,getsuVaried acrossrtexcls,inilirciseuis,rtsa5 unique reviews






                     tasko1$05sfWrstop                                              exbeut0i1c.t$e,.1i,nirf.f0sbroonms anceannotation
        Mo in(UaSty$0.01 per           $0.01 per task     KWs needed to have






        Skrilelqsueitredrtengnition       patrtengnition









           of the project              AMTVisual picture/      AMTual picture/         None              $0.25 for survey KWs needed to have






                     20.secinmit,ftese    35tim2s0cinnittefs      milnutii,ft1s5e
        Task time  Mean 17.6AdvertisemeMean 24.1 to            Mean 4.7          5 to 30 minutes     AMT                No   None           AMTVaried across        None              $0.01 per




   Table 2. (Continued)


                     polcyomnaideoasnd    polcyomnaggrsphy        short survey      (etimmeoe.or.a,telearning)             images
        Coomf tleextitayske - classify Moderate - classify     Easy - answer     Ranged from easy                       Easy - annotate






        DactalprotceededosstatistTs from  KW usstetistTs from     resncleesnggrsphicsWussateistiTs from                    KWs






           sharing








        Plat form      Team Intra-crowd                                          AMT            None None              Results from




                                       –.5 days      AMT            None None       ∼ 4 draysotsoperiments
        Leonfgtrowcing




        Renfor.ence16          <3 month17      AMT  3         N18e None    <12 days  ResultAMTRanged from None None     20       Survey hours       AMT            None None
JGIM                                     Ranard et al.: Crowdsourcing in Health and Medical Research                                                   197









                     coArdtnostPSoaftoioiaoyefaomwahtnnrrairagcutatieiiezde
        DatteavaiiCompared GPS






        Moinc(taSy$50tofirst0ayprefieoksres1m,oiteetlthele






                     smartphone
        Skrilelqsueitred








          of the project TV, print,a







        Task time N/A - no tAdvertisement





  Table 2. (Continued)

                     ananpstrceglrctitfosrt grand
        Coomftleextitayske - locate

                                                                                                                           indicates that data were collected but not published
                                                                                                                           ”

                                                                                                                           “P

                     moabplelpbaoi,aeydttu
        Dactalrcotceeedso





          sharing


                  Yes     Yes            Data from




                                                                                            22   24 25 26
        Plat form    moTeam Intra-crowde                                                      23          27           32
                                                                      1415            20                    28 29 30
                                                                12 13      16 17 18 19   21                          31




        Leonftruowcing

                                                                                                                           indicates that data were not explicitly reported in the paper;
                                                                                                                           ”
                                                                                                                           “o
        Renfor.ence1           8 weeks         Custom         Ref1e-2- (- (-(e-(-e(nl(,h.,(e.i(-1(1a)ettllM,(-0-1trKgi,(t1ee,etl.lt)a.,)2)ta3)l)., 2013)
198                                 Ranard et al.: Crowdsourcing in Health and Medical Research                                  JGIM







          partitciiopant                 appdl>ato(d.Noson)s    visuirs0tr.5or)sut%             regutcsiplleptozzle







                     acsioialmrsti,on                  corankesdaignhly
       Motivation        Viewer to






       CoinftctitsgNo               Yes - purpose,                                                       No               No               No






                     59refersm2cirffc.ieiecr%ffic                                                          wassuracien
       Resferrcle                      No              No               No      No        >11No0No           No  No            No No            42 % of



                                                                                    s
                                                                                    ’

                                         repeltvagttonity                         recrcommunity ondsea(neh.,oanoelr)e
          totuesrisNorch            Yes - initially  No               No              No               Yes -               No               No              No

                         ”
                     “ome

                     chmapsergsram                     4-ydgreaterr                                                          colrddearrteee






  Table 3. Demographics of the Crowdationship





       Gelocationic





          ethbnaiccNoround     Yes          Yes      YesYes - >25 %es     Yes  Yes     Yes  Yes - 48 %   No     No   No    No     NPes - research Yeso



                     %< 2fl%, ale                      ma%le63 aleearoulne25ale   ma%le,37ale                                female
       Gender      Yes - >75                         Yes - 36 %es - 75 %        Yes - 62 %                     No          Yes - 53 %   No          No

                   67
                   ∼ ≤5
                     %                                 181o465+,30 to 60          18 to 62                        18 to 40   18 to 40
          (yeods)                      No         No          No           NP          No    No    No   No       Yes - outbreak  No          No           No





                                         do>w2noadsi,ssions                                     regpieps,2rrs05
       Size     NoNo  Age      NoYes - >11No000      2No      5    Nos - 33 %esNo allndN4NoNo11920,252 NoNo,000oNoNNoNPNo5NooNNoNoNooNoNNoNooYes9NoNNoNNoNoNoso




       Renfor.en1e 2                   3             4        5          6 7 8 9         101112          13    14   15161718
JGIM                                    Ranard et al.: Crowdsourcing in Health and Medical Research                                                 199







                     reported
           partitciiopant         No






                                    to anmioenertatisonal,
        Motivation          Viewer to - contribution






                                    froioin:atviparrrjctatsnpdonsors
        Coinftlctitsg







        Resferrcle                No                Yes - excluded

                                       as
                                       ”



                                    par“ticipants cite
           toqtuesrisearch








   Table 3. (Continued)


        Occupation Education         Relationship

                                                                                                                 indicates that data were collected but not published
                                                                                                                 ”
                                                                                                                 NP
                                                                                                                 “
        Gelogcrtohnic





           ethbnckground




        Gender    No Racial/   No No          Yes           Noes          Noes           No             Yes Nosome             No                 No                  Dropout rates



                                    41                                                  24
                     betnotolaedtedP≥                                              2223    25 26
           (yeods)Varied          Yes - 33 %                                                    27            32
                                                       12 13 14 15   17      20 21                 28 2930
                                                                  16    18 19                              31

                       234 per
                       –
                     (va3iexperiment)ndividuals
        Size      855 totale No313 teams and    No          No           No             No            No            No             No                 No                 No
                                                                                                                 indicates that data were not explicitly reported in the paper;
                                                                                                                 ”

                                                                                                                 “o
        Renfor.enc19           20 21                  Ref1e2- (- (-r(-(-e(nl(,(0,(.0it10l13Ke(1al,,cv(-troa(,0tnrt.eal.lt)a.,)e)ta3)l)., 2013)
200                               Ranard et al.: Crowdsourcing in Health and Medical Research                            JGIM



papers we identified successfully used crowdsourcing to           data collection (Appendix Table 5). If collected in the future,
solve protein structure problems, 18  improve alignment of        these data would provide crucial information to help the
                     23
promoter sequences,     track H1N1 influenza outbreaks in         scientific community understand how the crowd works
near real time,14 classify colonic polyps, 27,28and identify      and how to best maximize the use of crowdsourcing.
                                                        24–26
RBCs infected with Plasmodium falciparum parasites.               However, the crowdsourcing methodology for health
Furthermore, as Mavandadi et al. point out, one way around        research is in an early phase of development, and there
the problem of involving lay people in making a medical           is additional work to be done to develop these methods

diagnosis is to use crowdsourcing to distill the data for a       and related reporting standards.
medical professional, who can then make the final                    When thinking of conducting a crowdsourced study, it

decision. For example, a pathologist must look at more            may be difficult to choose or create the most appropriate
than 1,000 RBCs to rule a sample negative, but if                 platform. In some cases researchers used their own

crowdsourcing identifies RBCs that are infected, all a            custom platforms and in others they employed AMT.
pathologist has to do is officially confirm the diagnosis         We examined studies that employed the crowd to perform
                      25
with a single image.    This could be especially useful in        crowdsourced tasks; however, there are also platforms
resource-poor areas.                                              that allow one to post a “challenge” and offer a monetary
   Crowdsourcing used for health research has been                reward for the best solution. Kaggle (kaggle.com) allows

employed to accomplish one of four main categories of             scientists and others to post complex data analysis
tasks: problem solving, data processing, surveillance/mon-        problems along with monetary rewards for the best
                                                                           33
itoring, and surveying. Data from existing studies show that      solution,   and InnoCentive (innocentive.com) is a more
crowdsourcing has the potential to beneficially address the       general platform that allows prizes to be posted for any
                                                                                                                 34
following points: quality, cost, volume, speed, and novel         sort of research and development problem.         It is also
science. Crowdsourcing has been demonstrated to be a              worth noting that crowdfunding websites have become

viable way to increase the accuracy of computer recog-            popular and may be a potential way to fund research
nition of RBCs infected with malaria parasites     25 (qual-      projects. Examples include RocketHub (rockethub.com)
                                                                                                35
ity), be a low cost alterna tive to more traditiona15,20,22,30    and Petridish (petridish.org).
behavioral research and epidemiology studies                         Although we conducted a review of references and
(cost), engage over one hundred thousand people in a              review articles in addition to a crowdsourced search for
                  14
research problem     (volume), allow research to progress         literature, our results do not include all articles. Posting a
much faster than if processed by investigators alone4,15,20,22–   survey on the Internet (collecting research data about
24,26 –32
         (speed), and produce new scientific discover-            Internet users themselves by having them answer ques-
ies13,18,19,21(novel science).                                    tions or perform tasks) has been around for >15 years      10

   Additionally, there is the advantage of an untapped            and therefore is not a novel research method. Our review
expertise of the crowd. Even though these crowdsourced            only includes a sample of projects that used the Internet to

projects are not asking scientific experts to participate,        survey participants. This specifi36type of crowdsourcing
participants have been found to be experts at puzzles and         has been reviewed elsewhere.        Additionally, there are
problem solving, which would make them specifically               other types of research that are sometimes referred to as
                                                12,13,17–19,21
adept at solving protein structures in Foldit                     crowdsourcing but do not meet our definition of
and solving multiple sequence alignment with Phylo.       23      crowdsourcing. They involve investigators mining data

Presumably, among members of the public one could find            that have been generated by users, but generally not for
experts at many different tasks, especially when the task is      research purposes, such as estimating influenza activity by
                                                                                                           37
presented as a game that benefits science. Finally,               analyzing Twitter (twitter.com) posts.      Other examples
crowdsourced projects raise public awareness about the project    reviewed elsewhere include i nvestigators mining data or

and about science in general.                                     surveying online communities such as PatientsLikeMe
   The papers identified in this study varied widely in the       (patientslikeme.com) and 23andMe (23andme.com).       38 Our
amount and type of data that were reported about the crowd        search did not include gray literature or searching the

and the experimental setup. Crowdsourcing articles rarely         Internet using a search engine. The goal of the study,
reported data about the demographics of the crowd participat-     however, was to characterize primary peer-reviewed

ing, including information standard to most clinical trials such  health research. While several projects may be featured
as the size of the cohort, age, gender, and geographic            on the World Wide Web and science magazines, it is
        11
location.   These data and others such as motivation for          imperative that projects are published in academic
participation, education, and occupation are crucial for          journals so that the scientific community can validate

understanding the people involved in the research. Ideally,       the methods and demonstrate the varied, interesting, and
all papers that use crowdsourcing should include at a             successful uses of crowdsourcing in health and medical

minimum data regarding the demographics and logistics of          research.
JGIM                                  Ranard et al.: Crowdsourcing in Health and Medical Research                                           201



                                                                             9. Preamble to the Constitution of the World Health Organization as
                         CONCLUSION                                             adopted by the International Health Conference, New York, 19 –22

Crowdsourcing has been used to help answer important                            June, 1946; signed on 22 July 1946 by the representatives of 61
                                                                                States (Official Records of the World Health Organization, no. 2, p.
health-related research questions. Utilizing crowdsourcing
                                                                                100) and entered into force on 7 April 1948. [cited 2012 Jul 21].
can improve the quality, cost, and speed of a research                          Available from: http://www.who.int/about/definition/en/print.html
                                                                            10. Reips U-D, Birnbaum MH. Behavioral research and data collection via
project while engaging large segments of the public and
                                                                                the Internet. In: Proctor RW, Vu K-PL, eds. Handbook of human factors
creating novel science. This methodology serves as an                           in Web design. 2nd ed. Mahwah, New Jersey: Lawrence Erlbaum

alternative approach for studies that could benefit from                        Associates; 2011:563–85.
                                                                            11. Higgins JPT, Deeks JJ (editors). Chapter 7: Selecting studies and
large amounts of manual data processing, surveillance                           collecting data. In: Higgins JPT, Green S (editors), Cochrane Handbook

conducted by people around the world, specific skills                           for Systematic Reviews of Interventions Version 5.1.0 [Internet]. The
                                                                                Cochrane Collaboration; 2011 [updated 2011 Mar; cited 2012 Aug 1].
that members of the public may have, or diverse subject                         Available from www.cochrane-handbook.org

pools that can be surveyed at low cost. In this                             12. Cooper S, Treuille A, Barbero J, Leaver-Fay A, Tuite K, Khatib F, et
                                                                                al. The challenge of designing scientific discovery games. California:
systematic review, we identified four types of research
                                                                                Proceedings of the Fifth International Conference on the Foundations of
needs that have been addressed by crowdsourcing and                             Digital Games; Monterey; 2010:40–7. 1822354: ACM.
                                                                            13. Cooper S, Khatib F, Treuille A, Barbero J, Lee J, Beenen M, et al.
specify criteria that future studies should meet in order
to help standardize the use of crowdsourcing in health                          Predicting protein structures with a multiplayer online game. Nature.
                                                                                2010;466(7307):756 –60. doi:10.1038/nature09304 . PubMed PMID:
and medical research.                                                           20686574; PubMed Central PMCID: PMC2956414.

                                                                            14. Freifeld CC, Chunara R, Mekaru SR, Chan EH, Kass-Hout T, Ayala
                                                                                Iacucci A, et al. Participatory epidemiology: use of mobile phones for
                                                                                community-based health reporting. PLoS medicine. 2010;7(12):

Acknowledgments:                                                                e1000376. doi: 10.1371/journal.pmed.1000376    . PubMed PMID:
Contributors: The authors thank Hope Lappen, MLIS, for her                      21151888; PubMed Central PMCID: PMC2998443.
                                                                            15. Behrend TS, Sharek DJ, Meade AW, Wiebe EN.        The viability of
assistance with designing the systematic literature search.
                                                                                crowdsourcing for survey research. Behavior research methods.
Funders: NIH, K23 grant 10714038 (Merchant).                                    2011;43(3):800–13. doi:10.3758/s13428-011-0081-0. PubMed PMID:
                                                                                21437749.

Prior presentations: None                                                   16. Bender J, O'Grady L, Desphande A, Cortinois A, Saffie L, Husereau D,
                                                                                et al. Collaborative authoring: a case study of the use of a wiki as a tool
                                                                                to keep systematic reviews up to date. 2011.
Conflict of Interest: The authors declare that they do not have any
conflicts of interest.                                                      17. Cooper S, Khatib F, Makedon I, Lu H, Barbero J, Baker D, et al.
                                                                                Analysis of social gameplay macros in the Foldit cookbook. France:
                                                                                Proceedings of the 6th International Conference on Foundations of

                                                                                Digital Games; Bordeaux; 2011:9–14. 2159367: ACM.
Corresponding Author: Raina M. Merchant, MD, MSHP; Perelman                 18. Khatib F, DiMaio F, Foldit Contenders G, Foldit Void Crushers G,
School of Medicine, University of Pennsylvania, 423 Guardian Drive,             Cooper S, Kazmierczyk M, et al. Crystal structure of a monomeric

Blockley Hall, Philadelphia, PA      19104, USA (e-mail: raina.                 retroviral protease solved by protein folding game players. Nature
merchant@uphs.upenn.edu).                                                       structural & molecular biology. 2011;18(10):1175 –7. doi:10.1038/

                                                                                nsmb.2119. PubMed PMID: 21926992.
                                                                            19. Khatib F, Cooper S, Tyka MD, Xu K, Makedon I, Popovic Z, et al.
                                                                                Algorithm discovery by protein folding game players. Proceedings of the

                          REFERENCES                                            National Academy of Sciences of the United States of America.
                                                                                2011;108(47):18949 –53. doi: 10.1073/pnas.1115898108 .PubMed
 1. Sobel D. Longitude: The True Story of a Lone Genius Who Solved the          PMID: 22065763; PubMed Central PMCID: PMC3223433.
    Greatest Scientific Problem of His Time. New York: Walker Publishing
                                                                            20. Chunara R, Chhaya V, Bane S, Mekaru SR, Chan EH, Freifeld CC, et
    Company; 1995.                                                              al. Online reporting for malaria surveillance using micro-monetary
 2. National Audubon Society. History of the Christmas Bird Count               incentives, in urban India 2010–2011. Malaria journal. 2012;11:43.

    [Internet]. 2012 [cited 2012 Dec 24]. Available from:    http://            doi:10.1186/1475-2875-11-43 . PubMed PMID: 22330227; PubMed
    birds.audubon.org/history-christmas-bird-count                              Central PMCID: PMC3305483.
 3. ICT Data and Statistics Division. Measuring the Information Society     21. Eiben CB, Siegel JB, Bale JB, Cooper S, Khatib F, Shen BW, et al.

    2012 [Internet]. Geneva, Switzerland: International Telecommunication       Increased Diels-Alderase activity through backbone remodeling guided
    Union; 2012 [cited 2012 Oct 14]. Available from: http://www.itu.int/        by Foldit players. Nature biotechnology. 2012;30(2):190–2. doi:10.1038/
    ITU-D/ict/publications/idi/material/2012/MIS2012_without_
                                                                                nbt.2109. PubMed PMID: 22267011.
    Annex_4.pdf                                                             22. Jarmolowicz DP, Bickel WK, Carter AE, Franck CT, Mueller ET. Using
 4. Lintott C, Schawinski K, Bamford S, Slosar A, Land K, Thomas D, et          crowdsourcing to examine relations between delay and probability

    al. Galaxy Zoo 1: data release of morphological classifications for nearly  discounting. Behavioural processes. 2012;91(3):308–12. doi:10.1016/
    900000 galaxies. Monthly Notices of the Royal Astronomical Society.         j.beproc.2012.09.001. PubMed PMID: 22982370.
    2011;410(1):166–78. doi:10.1111/j.1365-2966.2010.17432.x.               23. Kawrykow A, Roumanis G, Kam A, Kwak D, Leung C, Wu C, et al.

 5. Sayigh L, Quick N, Hastie G, Tyack P. Repeated call types in short-         Phylo: a citizen science approach for improving multiple sequence
    finned pilot whales, Globicephala macrorhynchus. Marine Mammal              alignment. PLoS One. 2012;7(3):e31362. doi: 10.1371/journal.pone.

    Science. 2012;29(2):312–24. doi:10.1111/j.1748-7692.2012.00577.x.           0031362. PubMed PMID: 22412834; PubMed Central PMCID: PMC3296692.
 6. Nature Publishing Group. Scientific American launches Citizen Science   24. Luengo-Oroz MA, Arranz A, Frean J. Crowdsourcing malaria parasite
    Whale-Song Project, Whale FM [Internet]. 2011 [cited 2012 Oct 14].          quantification: an online game for analyzing images of infected thick

    Available from: http://www.nature.com/press_releases/sciam-                 blood smears. Journal of medical Internet research. 2012;14(6):e167.
    whale.html                                                                  doi:10.2196/jmir.2338 . PubMed PMID: 23196001; PubMed Central
 7. Sullivan BL, Wood CL, Iliff MJ, Bonney RE, Fink D, Kelling S. eBird: A
                                                                                PMCID: PMC3510720.
    citizen-based bird observation network in the biological sciences.      25. Mavandadi S, Dimitrov S, Feng S, Yu F, Sikora U, Yaglidere O, et al.
    Biological Conservation. 2009;142(10):2282    –92. doi: 10.1016/            Distributed medical image analysis and diagnosis through crowd-
                                                                                sourced games: a malaria case study. PLoS One. 2012;7(5):e37245.
    j.biocon.2009.05.006.
 8. Marris E. Supercomputing for the birds. Nature. 2010;466(7308):807.         doi:10.1371/journal.pone.0037245. PubMed PMID: 22606353; PubMed
    doi:10.1038/466807a. PubMed PMID: 20703280.                                 Central PMCID: PMC3350488.
202                                    Ranard et al.: Crowdsourcing in Health and Medical Research                                           JGIM



26. Mavandadi S, Dimitrov S, Feng S, Yu F, Yu R, Sikora U, et al. Crowd-         journal of preventive medicine. 2013;44(1):96   –7. doi: 10.1016/
    sourced BioGames: managing the big data problem for next-generation          j.amepre.2012.09.051. PubMed PMID: 23253658.

    lab-on-a-chip platforms. Lab on a chip. 2012;12(20):4102       –6.       32. Merchant RM, Asch DA, Hershey JC, Griffis HM, Hill S, Saynisch O,
    doi:10.1039/c2lc40614d. PubMed PMID: 22918378; PubMed Central                et al. A crowdsourcing innovation challenge to locate and map automat-

    PMCID: PMC3477593.                                                           ed external defibrillators. Circulation Cardiovascular quality and out-
27. McKenna MT, Wang S, Nguyen TB, Burns JE, Petrick N, Summers                  comes. 2013;6(2):229–36. doi:10.1161/CIRCOUTCOMES.113.000140.
    RM. Strategies for improved interpretation of computer-aided de-             PubMed PMID: 23481522.

    tections for CT colonography utilizing distributed human intelli-        33. CarpenterJ.May the best analyst win. Science. 2011;331(6018):698 –
    gence. Medical image analysis. 2012;16(6):1280 –92. doi:10.1016/             9. doi:10.1126/science.331.6018.698 . PubMed PMID: 21311005.

    j.media.2012.04.007 . PubMed PMID: 22705287; PubMed Central              34. Hussein A. Brokering knowledge in biosciences with InnoCentive.
    PMCID: PMC3443285.                                                           Interview by Semahat S. Demir. IEEE engineering in medicine and

28. Nguyen TB, Wang S, Anugu V, Rose N, McKenna M, Petrick N, et al.             biology magazine: the quarterly magazine of the Engineering in Medicine
    Distributed Human Intelligence for Colonic Polyp Classification in           & Biology Society. 2003;22(4):26–7. PubMed PMID: 14515687.

    Computer-aided Detection for CT Colonography. Radiology.                 35. Wheat RE, Wang Y, Byrnes JE, Ranganathan J. Raising money for
    2012;262(3):824 –33. doi:10.1148/radiol.11110938 . PubMed PMID:              scientific research through crowdfunding. Trends in ecology & evolution.

    22274839; PubMed Central PMCID: PMC3285221.                                  2013;28(2):71–2. doi:10.1016/j.tree.2012.11.00.1PubMed PMID: 23219380.
29. Turner AM, Kirchhoff K, Capurro D. Using crowdsourcing technology        36. Mason W, Suri S. Conducting behavioral research on Amazon's

    for testing multilingual public health promotion materials. Journal of       Mechanical Turk. Behavior research methods. 2012;44(1):1      –23.
    medical Internet research. 2012;14(3):e79. doi: 10.2196/jmir.2063 .          doi:10.3758/s13428-011-0124-6. PubMed PMID: 21717266.
    PubMed PMID: 22664384.                                                   37. Signorini A, Segre AM, Polgreen PM. The use of Twitter to track levels

30. Crump MJ, McDonnell JV, Gureckis TM.         Evaluating Amazon's             of disease activity and public concern in the US during the influenza A
    Mechanical Turk as a Tool for Experimental Behavioral Research. PLoS         H1N1 pandemic. PLoS One. 2011;6(5):e19467.

    One. 2013;8(3):e57410. doi:10.1371/journal.pone.0057410.PubMed           38. Swan M. Crowdsourced health research studies: an important emerging
    PMID: 23516406; PubMed Central PMCID: PMC3596391.                            complement to clinical trials in the public health research ecosystem.

31. Hipp JA, Adlakha D, Eyler AA, Chang B, Pless . merging technologies:         Journal of medical Internet research. 2012;14(2):e46. doi:10.2196/
    webcams and crowd-sourcing to identify active transportation. American       jmir.1988. PubMed PMID: 22397809.






                            APPENDIX














































                                              Figure 2. Crowdsourcing framework and categories.
 JGIM                                  Ranard et al.: Crowdsourcing in Health and Medical Research                                             203


                               Table 4. Category of Research Task Crowdsourcing was Utilized to Accomplish


Ref      Title                                                                                                              Category
no.

1        The challenge of designing scientific discovery games                                                              Problem solving
2        Predicting protein structures with a multiplayer online game                                                       Problem solving
3        Participatory epidemiology: use of mobile phones for community-based health reporting                              Surveillance/

                                                                                                                             monitoring
4        The viability of crowdsourcing for survey research                                                                 Survey
5        Collaborative authoring: a case study of the use of a wiki as a tool to keep systematic reviews up to date         Data processing
6        Analysis of social gameplay macros in the Foldit cookbook                                                          Problem solving
7        Crystal structure of a monomeric retroviral protease solved by protein folding game players                        Problem solving
8        Algorithm discovery by protein folding game players                                                                Problem solving
9        Online reporting for malaria surveillance using micro-monetary incentives, in urban India 2010-2011                Surveillance/
                                                                                                                             monitoring
10       Increased Diels-Alderase activity through backbone remodeling guided by Foldit players                             Problem solving

11       Using crowdsourcing to examine relations between delay and probability discounting                                 Survey
12       Phylo: a citizen science approach for improving multiple sequence alignment                                        Problem solving
13       Crowdsourcing malaria parasite quantification: an online game for analyzing images of infected thick blood smears Data processing
14       Distributed medical image analysis and diagnosis through crowd-sourced games: a malaria case study                 Data processing
15       Crowd-sourced BioGames: managing the big data problem for next generation lab-on-a-chip platforms                  Data processing
16       Strategies for improved interpretation of computer-aided detections for CT colonography utilizing distributed      Data processing
          human intelligence
17       Distributed human intelligence for colonic polyp classification in computer-aided detection for CT colonography    Data processing
18       Using crowdsourcing technology for testing multilingual public health promotion materials                          Survey

19       Evaluating Amazon’s Mechanical Turk as a tool for experimental behavioral research                                 Survey
20       Emerging technologies: webcams and crowd-sourcing to identify active transportation                                Data processing
21       A crowdsourcing innovation challenge to locate and map automated external defibrillators                           Surveillance/
                                                                                                                             monitoring

Reference Number Key
1- (Cooper et al., 2010)12
2- (Cooper et al., 2010)13
                        14
3- (Freifeld et al., 201015
4- (Behrend et al., 20116
5- (Bender et al., 2011)
6- (Cooper et al., 2011)17
7- (Khatib et al., 2011)8
8- (Khatib et al., 2011)9
                         20
9- (Chunara et al., 201221
10- (Eiben et al., 2012)      22
11- (Jarmolowicz et al., 2012)
12- (Kawrykow et al., 2012) 23
13- (Luengo-Oroz et al., 2012) 24
                             25
14- (Mavandadi et al., 2012) 26
15- (Mavandadi et al., 201227
16- (McKenna et al., 2012)
17- (Nguyen et al., 2012)28
18- (Turner et al., 2012)9
19- (Crump et al., 2013) 30
                       31
20- (Hipp et al., 2013)    32
21- (Merchant et al., 2013)



   Table 5. Potential Data to Report for Health Research Using

                           Crowdsourcing

Demographics of the         Logistics of the crowdsourcing
crowd

Size of crowd               Length of time crowdsourcing was
                             conducted

Age                         Web platform and the use of a mobile
                              platform
Gender                      Use of individuals versus teams and
                             intracrowd sharing techniques
Racial/ethnic background    Data collected or processed
Geographic location         Complexity of the task
Occupation                  Time given to do the task
Education                   Advertisement of project
Relationship to the         Skill set required

  research question
Referral source             Incentives offered
Conflicting interests       Data validation techniques
Motivation
Viewer to participant ratio