<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20210321</date><key>pmc.key</key><document><id>7942992</id><infon key="license">CC BY</infon><passage><infon key="alt-title">Probabilistic social learning improves the public’s judgments of news veracity</infon><infon key="article-id_doi">10.1371/journal.pone.0247487</infon><infon key="article-id_pmc">7942992</infon><infon key="article-id_pmid">33690668</infon><infon key="article-id_publisher-id">PONE-D-20-29221</infon><infon key="elocation-id">e0247487</infon><infon key="issue">3</infon><infon key="license">This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</infon><infon key="name_0">surname:Guilbeault;given-names:Douglas</infon><infon key="name_1">surname:Woolley;given-names:Samuel</infon><infon key="name_2">surname:Becker;given-names:Joshua</infon><infon key="name_3">surname:Zhao;given-names:Jichang</infon><infon key="name_4">surname:Woolley;given-names:Samuel</infon><infon key="notes">All data and code for statistical analyses are publicly available for download at https://github.com/drguilbe/misinfoCI.</infon><infon key="section_type">TITLE</infon><infon key="title">Data Availability</infon><infon key="type">front</infon><infon key="volume">16</infon><infon key="year">2021</infon><offset>0</offset><text>Probabilistic social learning improves the public’s judgments of news veracity</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>81</offset><text>The digital spread of misinformation is one of the leading threats to democracy, public health, and the global economy. Popular strategies for mitigating misinformation include crowdsourcing, machine learning, and media literacy programs that require social media users to classify news in binary terms as either true or false. However, research on peer influence suggests that framing decisions in binary terms can amplify judgment errors and limit social learning, whereas framing decisions in probabilistic terms can reliably improve judgments. In this preregistered experiment, we compare online peer networks that collaboratively evaluated the veracity of news by communicating either binary or probabilistic judgments. Exchanging probabilistic estimates of news veracity substantially improved individual and group judgments, with the effect of eliminating polarization in news evaluation. By contrast, exchanging binary classifications reduced social learning and maintained polarization. The benefits of probabilistic social learning are robust to participants’ education, gender, race, income, religion, and partisanship.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1214</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1227</offset><text>The term fake news—defined as deliberately falsified news—has proliferated since the 2016 U.S. election. The practical risks associated with fake news have become increasingly apparent amid the COVID-19 pandemic and the 2020 U.S. election. A popular assumption of fake news research is that news can be effectively categorized in binary terms as either “real” or “fake”. Social media interventions often adopt this binary logic by using human crowdsourcing or machine learning to flag media as true or false, and by directing users to fact-checking websites that apply these binary classifications. Meanwhile, binary classifications of news veracity can fuel partisan conflict, as both right and left-wing media outlets regularly accuse the other of espousing fake news.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2010</offset><text>One challenge facing policymakers is that media literacy interventions involving binary classifications of news veracity report inconsistent effects. While some studies find that individuals can accurately classify news in binary terms, other studies suggest that individuals exhibit substantial biases in their news classifications, with the popular expectation that communication in online social networks leads to the rapid spread of misinformation. Since social media users frequently discuss news in online peer networks, there is an urgent need to understand whether social influence exacerbates the spread of misinformation. Yet, prior work on misinformation relies primarily on observational data that is limited in isolating the causal effects of peer-to-peer communication on the public’s capacity to evaluate news veracity.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2847</offset><text>To the contrary, recent experimental work on collective intelligence suggests that communication in structured online networks can enable social learning, which occurs when exchanging information with peers improves belief accuracy. Importantly, this work has identified communication modality—i.e., the format through which people signal their beliefs—as a key variable in determining whether peer influence promotes social learning. Consistent with the theory that communication networks amplify the spread of misinformation, research on collective intelligence suggests that communicating judgments using coarse-grained binary terms can propagate errors and limit social learning. However, more recent experimental work suggests that these limitations can be overcome if people are given the opportunity to express their beliefs using more continuous and probabilistic response scales—e.g., by allowing people to indicate their beliefs regarding the probability that an event will occur, from 0 to 100. Indeed, experimental studies show that exchanging probabilistic judgments in online peer networks can improve belief accuracy in generic estimation tasks, and also on more politicized topics, such as public health and partisan policy.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4094</offset><text>As a mechanism, it has been found that probabilistic response scales enrich social learning by allowing individuals to explicitly signal uncertainty in their judgments. By contrast, exchanging coarse-grained binary judgments can prevent individuals from signaling their uncertainty—for example, when voting ‘yes’ or ‘no’ on whether an event will occur, different people may vote ‘no’ with either high or low confidence; the binary signal alone does not distinguish among them. Moreover, probabilistic response scales allow individuals to signal even minor belief adjustments during the communication process that can help steer the group toward a more accurate collective judgment. By contrast, binary signals can prevent individuals from indicating even minor adjustments to their beliefs during the communication process (i.e., an individual may slightly increase uncertainty but nevertheless make the same vote, thereby indicating no belief change to their peers). This points to a novel and yet simple intervention in the area of misinformation detection, which currently rests heavily on binary classifications of news veracity (true or false). Specifically, it suggests that allowing social groups to collectively evaluate the veracity of news using probabilistic response scales (e.g., by exchanging judgments regarding the probability that news is true, from 0 to 100) can significantly promote social learning, as opposed to conditions where groups collectively evaluate news veracity in binary terms (e.g., by exchanging binary judgments regarding whether news is ‘true’ or ‘false’).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5710</offset><text>In this preregistered experiment, we predict that allowing people to exchange probabilistic judgments in online peer networks will significantly improve their ability to accurately evaluate news veracity, as compared to peer networks that collectively evaluate news in binary terms, i.e., as true or false. (See Supplementary Appendix in S1 File for details on pre-registration, https://osf.io/53b7v).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>6112</offset><text>Materials and methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>6134</offset><text>This research was approved by the Institutional Review Board at Northwestern University, where the study was conducted. 900 subjects from Mechanical Turk (Mturk) participated in this experiment (Fig 1). All participants provided written, informed consent, and were legal U.S. adults. While the Mturk population can occasionally pose concerns regarding sample generalizability, methodological research has found that Mturk subjects provide high quality data for predicting online social media behavior, as compared to traditional survey methods. Additionally, the Mturk population has been widely used in both misinformation studies and collective intelligence experiments. Importantly, our analytic approach rests on the internal validity of between-condition comparisons within a randomized controlled experiment, suggesting that our reported effects are driven by our experimental manipulation and not by the demographics of our sample. As an additional robustness test, in what follows, we show that our results equally hold when controlling for the demographic attributes of participants.</text></passage><passage><infon key="file">pone.0247487.g001.jpg</infon><infon key="id">pone.0247487.g001</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>7227</offset><text>Experimental design.</text></passage><passage><infon key="file">pone.0247487.g001.jpg</infon><infon key="id">pone.0247487.g001</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>7248</offset><text>Subjects were randomly assigned to a peer network that judged the veracity of news by exchanging either (i) binary or (ii) probabilistic judgments. Fewer trials were needed in the binary condition with equivalent statistical power (“Materials and Methods”). Each group in each condition consisted of 20 unique individuals. All group-level observations are independent.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>7621</offset><text>Subjects were randomized into one of two conditions. In the “binary” condition, subjects answered the question “Is the content of this message true?” (options: yes/no). In the “probabilistic” condition, subjects answered the question: “On a scale of 0 to 100, what is the likelihood that the content of this message is true?” A single trial in each condition consisted of 20 subjects tasked with evaluating the veracity of news before and after being able to see the beliefs of the other subjects in their trial.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8150</offset><text>Subjects in both conditions provided responses three times for each news item. In Round one, subjects gave an independent response without viewing the judgments of their peers. In Rounds two and three, subjects were shown a summary of their peer network’s responses from the previous round (Fig 1). Subjects in the binary condition were shown the percentage of their peer network that evaluated the content as true and false. Subjects in the probabilistic condition were shown their network’s average estimate of the likelihood that the content is true.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8708</offset><text>Each peer network completed this process for four unique news items. The order of questions was randomized in each block of four unique news items (see S1 Fig in S1 File for design). 12 news items were used covering a range of topics including vaccines, domestic politics, and terrorism (Fig 1). The stimuli represented a range of formats, including social media posts and front-page headlines. Following recent work, we used the binary truth classifications of each news item provided by the professional fact-checking organization Snopes to determine its correct classification. Each trial evaluated two true and two false news items. Subjects received a monetary reward based on the accuracy of their final answer for each news item; this incentive scheme emulates established work in collective intelligence, and is also consistent with recent studies showing that social media users often report feeling motivated to evaluate the accuracy of news online.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9668</offset><text>To detect social learning, we measured changes in subjects’ reported beliefs along two dimensions: first, for each condition, we examined whether individuals and groups revised their veracity judgments in the correct direction with respect to Snopes’ classification. This measure indicates the extent to which participants were able to signal even minor improvements to their beliefs throughout the communication process. Secondly, we measured the actual classification accuracy of individual and group judgments. Classification accuracy in the binary condition is measured by determining whether the binary judgments—either by an individual or a group—match the binary classification (true/false) provided by Snopes (where voting ‘yes’ to the question of whether a news item is true is a correct classification in the case of true stimuli and incorrect in the case of false stimuli). To measure the accuracy of group judgments in the binary condition, we evaluated the classification accuracy of the majority vote for each group at each round via the above procedure. In the probabilistic condition, we determined the classification accuracy of individuals by binarizing their numeric estimates and comparing these binarized judgments to Snopes’ classifications: an estimate above 50% indicates that the subject believes the content to be true (i.e., more likely to be true), and an estimate below 50% indicates that the subject believed the content to be false (i.e., more likely to be false). To measure the classification accuracy of groups in the probabilistic condition, we evaluated the binarized classification accuracy of the average estimate of each group at each round. Any individual or group estimate of exactly 50% was evaluated as incorrect because it failed to provide a clear category assignment for news content that, according to Snopes, is associated with a clear truth value.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11579</offset><text>Finally, we measured whether peer networks shaped subjects’ trust in online content, which has been identified as a key source of partisan differences. In the binary condition, subjects indicated trust by voting “yes” when asked whether a news item is true. In the probabilistic condition, individuals signaled trust by providing an estimate above 50% indicating the belief that a given news item is more likely to be true. Since each trial in each condition viewed two true and two false stimuli, the accurate rate at which subjects should trust content at baseline in our experiment is 50%.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12178</offset><text>Our subject pool was 43% Democratic, 23% Republican, 26% Independent, and 7.6% without political identification. Subjects were randomized to condition regardless of partisanship, so each peer network contained a random mixture of political identifications. Importantly, we selected news items that represented a range of left-wing and right-wing perspectives (Note: while we included several left-leaning sources of false news, the majority of our false stimuli were right-leaning due to the prevalence of right-leaning disinformation that has been professionally evaluated by Snopes). S2–S13 Figs in S1 File provide each news item used in this experiment, along with crowdsourced ratings of each news item’s partisan slant and extent of political bias. Data was collected between November 30th and December 12th, 2018.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13002</offset><text>We conducted our experiment using Empirica.ly. Power tests indicated that comparable effect sizes could be detected with 15 trials in the binary condition and 30 trials in the probabilistic condition. We adopted the minimal number of trials needed in each condition to minimize the amount of exposure to misinformation, in accordance with Northwestern University’s IRB, which approved this study.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>13401</offset><text>Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>13409</offset><text>Before social interaction, there was no significant difference in the likelihood of peer networks providing the accurate judgment of news veracity in the binary and probabilistic condition (p&lt;0.43, Wilcoxon Rank Sum), as expected by randomization. However, Fig 2A shows that individuals from all partisan orientations were more likely to signal improvements in their judgments of news veracity when exchanging probabilistic rather than binary judgments (p&lt;0.001, Wilcoxon Rank Sum). These results are robust to controlling for participants’ gender, race, religiosity, income, strength of partisanship, and education, as well as the specific news items they evaluated (p&lt;0.001, OR = 7.75, N = 3190, SEs clustered by trial and condition). This finding similarly holds at the group-level (Fig 2B, p&lt;0.001, Wilcoxon Rank Sum).</text></passage><passage><infon key="file">pone.0247487.g002.jpg</infon><infon key="id">pone.0247487.g002</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>14234</offset><text>Comparing conditions in terms of the benefits of social learning for individual and collective judgments of news veracity.</text></passage><passage><infon key="file">pone.0247487.g002.jpg</infon><infon key="id">pone.0247487.g002</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>14357</offset><text>(A) The fraction of subjects signaling belief improvements (i.e., belief revisions in the correct direction), first to final round, split by partisanship and condition (averaged separately for each partisan group in each peer network). (B) The fraction of groups revising their collective judgments of news veracity in the correct direction, first to final round (measured at the question level in terms of the fraction of questions for which each group improved). (C) The probability of individuals and groups improving in their classification accuracy from first to final round (measured as the fraction of individuals and groups who were initially incorrect in their veracity classification but who became correct in their final veracity classification as a result of the communication process). (D) The gain in classification accuracy as a result of communication in the probabilistic as opposed to the binary condition, measured as the probability of an increase in classification accuracy in the probabilistic condition minus the probability of an increase in classification accuracy in the binary condition (positive values indicate that improvements were greater in the probabilistic condition). (A, N = 270; B, N = 45; C, N = 90; D, N = 90). Error bars indicate 95% confidence intervals. Prob., Probabilistic Condition.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>15686</offset><text>Furthermore, the probabilistic condition was more effective at promoting improvements in the categorical accuracy of news classifications. Fig 2C shows that the probabilistic condition significantly increased the likelihood that initially incorrect subjects would improve in the accuracy of their veracity classifications, compared to the binary condition (p = 0.05, Wilcoxon Rank Sum); and Fig 2C also shows that the probabilistic condition even more prominently increased the likelihood that initially incorrect groups would improve in the accuracy of their collective veracity classifications, compared to the binary condition (p&lt;0.01, Wilcoxon Rank Sum). Consistent with the canonical wisdom of the crowd effect, Fig 2D indicates that the benefits of probabilistic social learning are significantly more pronounced at the group-level than the individual-level (p&lt;0.05, Wilcoxon Rank Sum).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>16579</offset><text>Fig 3 shows that the group-level benefits of probabilistic social learning were replicated across all topic areas represented by our stimuli (S2–S13 Figs in S1 File). Communication in the probabilistic condition led to significantly greater improvements in the classification accuracy of groups than the binary condition across five out of the six topic areas, including politics, economics, vaccines, terrorism, and domestic news (p&lt;0.05, Wilcoxon Signed Rank Test). For the sixth topic area focusing on health, the probability of groups improving was identical in the binary and probabilistic condition. The benefits of probabilistic social learning were particularly pronounced for the topic areas of terrorism and news, where probabilistic communication led to over a 50 percentage-point increase in the likelihood of groups improving in their classification accuracy relative to the binary condition, which failed to enable any groups to improve for these topic areas (Fig 3).</text></passage><passage><infon key="file">pone.0247487.g003.jpg</infon><infon key="id">pone.0247487.g003</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>17563</offset><text>Comparing the binary and probabilistic condition in terms of the likelihood of groups increasing in the accuracy of their collective judgments, split by the topic area of news content.</text></passage><passage><infon key="file">pone.0247487.g003.jpg</infon><infon key="id">pone.0247487.g003</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>17748</offset><text>The probability of groups increasing in accuracy is measured as the probability of providing the correct veracity judgment by the final round, conditional on the majority being initially incorrect at the first round. We calculate the fraction of groups that increased in accuracy for each question in each condition, and then we average this fraction by topic area. There were 9 questions in each condition with groups that were initially inaccurate, producing 18 question-level observations. The politics and vaccines topic each contained 3 questions; all other topic areas contained a single question.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>18352</offset><text>Critically, probabilistic communication not only increased classification accuracy, but also significantly reduced partisan differences (Fig 4). Each group in each condition viewed two stimuli that were false and two stimuli that were true, such that at baseline, half of the content should have been evaluated as true and half should have been evaluated as false. At baseline, there were no significant differences between subjects in the binary and probabilistic condition in terms of their willingness to trust our experimental stimuli (S1 Table in S1 File). Meanwhile, we observed clear partisan differences in each condition. Before peer interaction, Republicans were more likely to trust online content than Democrats in both the binary (Fig 4A, median difference of 13.5 percentage points, p&lt;0.01, Wilcoxon Rank Sum) and probabilistic (Fig 4B, median difference of 7 percentage, p&lt;0.01, Wilcoxon Rank Sum) condition. Supplementary analyses show that these baseline differences in trust reflect partisan biases in media evaluation, since these differences in trust correlate with the partisan slant of stimuli (S2 and S3 Tables in S1 File).</text></passage><passage><infon key="file">pone.0247487.g004.jpg</infon><infon key="id">pone.0247487.g004</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>19499</offset><text>Partisan differences in trust toward online content, averaged across questions at the trial-level.</text></passage><passage><infon key="file">pone.0247487.g004.jpg</infon><infon key="id">pone.0247487.g004</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>19598</offset><text>Trust is measured by the rate at which subjects in each condition evaluated questions as more likely to be true. Density distributions indicate the fraction of questions that each trial collectively evaluated as true according to the communication style of each condition (binary vs. probabilistic). The rate at which questions were evaluated as true was averaged separately for both partisan groups in each trial. The data display the fraction of questions that Democrats and Republicans in each trial evaluated as true for the binary condition at the first (Panel A) and final round (Panel C), and for the probabilistic condition at the first (Panel B) and the final round (Panel D). Since each group in each condition encountered two true and two false news items, the appropriate fraction of questions that each trial should evaluate as true is 50%. Panel A &amp; C, N = 30; C &amp; D, N = 60. *p&lt;0.1; **p&lt;0.01; ***p&lt;0.001; ns., not significant.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>20540</offset><text>After communication in the binary condition, these partisan differences remained intact (Fig 4C, p&lt;0.001, Wilcoxon Rank Sum). By the end of the task in the binary condition, Republicans continued to be more likely to trust online content (Fig 4C, median difference of 14.2 percentage points, p&lt;0.001, Wilcoxon Rank Sum), leading to greater inaccuracy than Democrats (Fig 4C, p&lt;0.01, Wilcoxon Rank Sum). By comparison, communicating probabilistic judgments significantly reduced partisan biases in trust assessments (Fig 4D, reduction of 5 percentage points, p = 0.01, Wilcoxon Rank Sum), such that Republicans and Democrats no longer significantly differed in their judgments of news veracity (Fig 4D, p&lt;0.12, Wilcoxon Rank Sum). As a result, in the probabilistic condition, both Democrats and Republicans converged on the accurate rate at which the stimuli should be trusted—that is, 50% of the time, since half of the stimuli were true and half were false for all groups.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>21516</offset><text>Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21527</offset><text>In popular applications of crowdsourcing in misinformation detection, communication among human coders is frequently assumed to spread inaccurate judgments. Here we show that communication in online social networks systematically improves both individual and group judgments of new veracity. We observed these improvements both when subjects communicated using binary classifications as well as probabilistic judgments. Yet crucially, we show that the popular binary approach to classifying news as simply true or false can limit social learning when people communicate in online peer networks. We find that both individual and group-level judgments of news veracity are more likely to improve when people can signal their beliefs about news veracity using probabilistic judgments. Furthermore, we find that probabilistic signaling can reduce partisan differences in news evaluation that otherwise remain intact when news veracity is socially evaluated in binary terms.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>22497</offset><text>These results further support the established finding that exchanging probabilistic judgments is more effective at facilitating social learning than exchanging binary classifications. As is standard methodology in collective intelligence research, our study measures beliefs and belief revision via the behavioral signal that individuals provide in estimation tasks. We show that there is no significant difference in the baseline classification accuracy of individuals or groups across conditions, and yet, we find that altering the communication modality through which individuals can signal their beliefs—i.e., by enabling either binary or probabilistic signals—can significantly impact the capacity for individuals and groups to exhibit social learning in the signals they provide for evaluating news veracity. The chief contribution of this paper is to show how a critical insight of collective intelligence research—namely, that probabilistic response scales promote social learning—can directly improve social processes of news classification, which to date rely heavily on binary classifications.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>23610</offset><text>An important area of future research is to investigate the extent to which these response scale effects are a result of how communication modalities interface with the cognitive structure of individuals’ beliefs. For example, it may be that individuals’ mental representations of news veracity are probabilistic in nature, such that binary signaling prevents them from expressing improvements in their internal beliefs during communication. Future work may also find that, since individual cognition combines both categorical and probabilistic judgments, the optimal communication modality for social learning involves a combination of categorical and binary signaling. We anticipate that future research will benefit from exploring these questions.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>24364</offset><text>Relatedly, an important methodological caveat bares mentioning as concerns our study and misinformation research more broadly. This study was designed to meet both scientific and ethical constraints. In consultation with the ethics review board, we sought to minimize the number of subjects exposed to misinformation, especially since (in order to be ecologically relevant) our stimuli captured real misinformation on sensitive topics, such as politics and vaccines. For this reason, it was deemed satisfactory to proceed with the minimum sample size capable of identifying comparable effect sizes in each condition. Statistically speaking, the confidence intervals observed for the main effect in the binary and probabilistic condition are similar, indicating that these conditions captured a comparably stable effect; yet, the uneven sample size across conditions may limit the generalizability of our sample. For this reason, we hope that future research will work to identify the differential effects of probabilistic versus binary approaches to news classification in observational settings that may benefit from larger and ideally more balanced sample sizes.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>25529</offset><text>Meanwhile, a central strength of our study is that we selected stimuli and procured social groups where the partisan identity of subjects was not explicitly salient, allowing us to experimentally isolate the effect of communication modality on the capacity for social learning to improve misinformation classification. This is an appropriate set of experimental controls to impose, given that the identity of human coders is frequently anonymous in online crowdsourcing. Related work has shown that probabilistic communication is surprisingly robust at facilitating social learning across a range of partisan issues, in both politically-mixed and politically-homogeneous social networks, and even in cases where the social identity of subjects is salient. These studies suggest that a promising direction for future research is to demonstrate the ability for probabilistic social learning to improve news classification even in highly polarized political environments. Together, these results suggest that fact-checkers and social media organizations can better mitigate polarization and the spread of misinformation by using more probabilistic representations of news veracity. More broadly, these results contribute to a growing body of work on networked crowdsourcing, which identifies the conditions under which communication networks can enhance the consistency and accuracy of classification systems for a range of applications.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title_1</infon><offset>26964</offset><text>Supporting information</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>26987</offset><text>References</text></passage><passage><infon key="fpage">2521</infon><infon key="issue">19</infon><infon key="lpage">2526</infon><infon key="name_0">surname:Pennycook;given-names:G</infon><infon key="name_1">surname:Rand;given-names:D</infon><infon key="pub-id_doi">10.1073/pnas.1806781116</infon><infon key="pub-id_pmid">30692252</infon><infon key="section_type">REF</infon><infon key="source">PNAS</infon><infon key="type">ref</infon><infon key="volume">116</infon><infon key="year">2019</infon><offset>26998</offset><text>Fighting Misinformation on Social Media Using Crowdsourced Judgments of News Source Quality</text></passage><passage><infon key="fpage">240</infon><infon key="issue">5</infon><infon key="lpage">58</infon><infon key="name_0">surname:Garrett;given-names:K</infon><infon key="name_1">surname:Poulsen;given-names:S</infon><infon key="section_type">REF</infon><infon key="source">Journal of Computer-Mediated Communication</infon><infon key="type">ref</infon><infon key="volume">24</infon><infon key="year">2019</infon><offset>27090</offset><text>Flagging Facebook Falsehoods: Self-Identified Humor Warnings Outperform Fact Checker and Peer Warnings</text></passage><passage><infon key="issue">1</infon><infon key="name_0">surname:Dias;given-names:N</infon><infon key="name_1">surname:Pennycook;given-names:G</infon><infon key="name_2">surname:Rand;given-names:D</infon><infon key="section_type">REF</infon><infon key="source">Misinformation Review</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2020</infon><offset>27193</offset><text>Emphasizing Publishers Does Not Effectively Reduce Susceptibility to Misinformation on Social Media</text></passage><passage><infon key="fpage">39</infon><infon key="lpage">50</infon><infon key="name_0">surname:Pennycook;given-names:G</infon><infon key="name_1">surname:Rand;given-names:D</infon><infon key="pub-id_doi">10.1016/j.cognition.2018.06.011</infon><infon key="pub-id_pmid">29935897</infon><infon key="section_type">REF</infon><infon key="source">Cognition</infon><infon key="type">ref</infon><infon key="volume">188</infon><infon key="year">2018</infon><offset>27293</offset><text>Lazy, Not Biased: Susceptibility to Partisan Fake News Is Better Explained by Lack of Reasoning than by Motivated Reasoning</text></passage><passage><infon key="name_0">surname:Pennycook;given-names:G</infon><infon key="name_1">surname:McPhetres;given-names:J</infon><infon key="name_2">surname:Zhang;given-names:Y</infon><infon key="name_3">surname:Lu;given-names:J</infon><infon key="name_4">surname:Rand;given-names:D</infon><infon key="pub-id_doi">10.1177/0956797620939054</infon><infon key="pub-id_pmid">32603243</infon><infon key="section_type">REF</infon><infon key="source">Psychological Science</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>27417</offset><text>Fighting COVID-19 Misinformation on Social Media: Experimental Evidence for a Scalable Accuracy-Nudge Intervention</text></passage><passage><infon key="fpage">1094</infon><infon key="issue">6380</infon><infon key="lpage">96</infon><infon key="name_0">surname:Lazer;given-names:D</infon><infon key="name_1">surname:Baum;given-names:M</infon><infon key="name_2">surname:Benkler;given-names:Y</infon><infon key="name_3">surname:Berinsky;given-names:A</infon><infon key="name_4">surname:Greenhill;given-names:K</infon><infon key="name_5">surname:Menczer;given-names:F</infon><infon key="pub-id_doi">10.1126/science.aao2998</infon><infon key="pub-id_pmid">29590025</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">357</infon><infon key="year">2018</infon><offset>27532</offset><text>The Science of Fake News</text></passage><passage><infon key="fpage">1146</infon><infon key="issue">6380</infon><infon key="lpage">51</infon><infon key="name_0">surname:Vosoughi;given-names:S</infon><infon key="name_1">surname:Roy;given-names:D</infon><infon key="name_2">surname:Aral;given-names:S</infon><infon key="pub-id_doi">10.1126/science.aap9559</infon><infon key="pub-id_pmid">29590045</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">359</infon><infon key="year">2018</infon><offset>27557</offset><text>The Spread of True and False News Online</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>27598</offset><text>X Che, D Metaxa-Kakavouli, J Hancock. Fake News in the News. 2018 ACM (2018).</text></passage><passage><infon key="name_0">surname:Jamieson;given-names:K</infon><infon key="name_1">surname:Cappella;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">Echo Chamber: Rush Limbaugh and the Conservative Media Establishment</infon><infon key="type">ref</infon><infon key="year">2010</infon><offset>27676</offset></passage><passage><infon key="name_0">surname:Jamieson;given-names:K</infon><infon key="section_type">REF</infon><infon key="source">Cyberwar: How Russian Hackers and Trolls Helped Elect a President: What We Don’t, Can’t, and Do Know</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>27677</offset></passage><passage><infon key="fpage">12435</infon><infon key="issue">49</infon><infon key="lpage">40</infon><infon key="name_0">surname:Stella;given-names:M</infon><infon key="name_1">surname:Ferrara;given-names:E</infon><infon key="name_2">surname:Domenico;given-names:M</infon><infon key="pub-id_doi">10.1073/pnas.1803470115</infon><infon key="pub-id_pmid">30459270</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the National Academy of Sciences</infon><infon key="type">ref</infon><infon key="volume">115</infon><infon key="year">2018</infon><offset>27678</offset><text>Bots Increase Exposure to Negative and Inflammatory Content in Online Social Systems</text></passage><passage><infon key="fpage">4787</infon><infon key="issue">1</infon><infon key="name_0">surname:Shao;given-names:C</infon><infon key="name_1">surname:Ciampaglia;given-names:G</infon><infon key="name_2">surname:Varol;given-names:O</infon><infon key="name_3">surname:Yang;given-names:K</infon><infon key="name_4">surname:Flammini;given-names:A</infon><infon key="name_5">surname:Menczer;given-names:F</infon><infon key="pub-id_doi">10.1038/s41467-018-06930-7</infon><infon key="pub-id_pmid">30459415</infon><infon key="section_type">REF</infon><infon key="source">Nature Communications</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2018</infon><offset>27763</offset><text>The Spread of Low-Credibility Content by Social Bots</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>27816</offset><text>S Wineberg, T Ortega, J Breakstone, S McGrew. Evaluating information: the cornerstone of civic online reasoning. 2016. https://purl.stanford.edu/fv751yt5934.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>27974</offset><text>N Ferguson. The False Prophecy of Hyperconnection. Foreign Affairs, (2017).</text></passage><passage><infon key="fpage">9216</infon><infon key="issue">37</infon><infon key="lpage">21</infon><infon key="name_0">surname:Bail;given-names:C</infon><infon key="name_1">surname:Argyle;given-names:L</infon><infon key="name_2">surname:Brown;given-names:T</infon><infon key="name_3">surname:Bumpus;given-names:J</infon><infon key="name_4">surname:Chen;given-names:H</infon><infon key="name_5">surname:Hunzaker;given-names:M</infon><infon key="pub-id_doi">10.1073/pnas.1804840115</infon><infon key="pub-id_pmid">30154168</infon><infon key="section_type">REF</infon><infon key="source">PNAS</infon><infon key="type">ref</infon><infon key="volume">115</infon><infon key="year">2018</infon><offset>28050</offset><text>Exposure to Opposing Views on Social Media Can Increase Political Polarization</text></passage><passage><infon key="name_0">surname:Sunstein;given-names:C</infon><infon key="section_type">REF</infon><infon key="source">Going to Extremes: How Like Minds Unite and Divide</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>28129</offset></passage><passage><infon key="fpage">5791</infon><infon key="issue">15</infon><infon key="lpage">96</infon><infon key="name_0">surname:Dandekar;given-names:P</infon><infon key="name_1">surname:Goel;given-names:A</infon><infon key="name_2">surname:Lee;given-names:D</infon><infon key="pub-id_doi">10.1073/pnas.1217220110</infon><infon key="pub-id_pmid">23536293</infon><infon key="section_type">REF</infon><infon key="source">PNAS</infon><infon key="type">ref</infon><infon key="volume">110</infon><infon key="year">2013</infon><offset>28130</offset><text>Biased Assimilation, Homophily, and the Dynamics of Polarization</text></passage><passage><infon key="fpage">9020</infon><infon key="issue">22</infon><infon key="lpage">25</infon><infon key="name_0">surname:Lorenz;given-names:J</infon><infon key="name_1">surname:Rauhut;given-names:H</infon><infon key="name_2">surname:Schweitzer;given-names:F</infon><infon key="name_3">surname:Helbing;given-names:D</infon><infon key="pub-id_doi">10.1073/pnas.1008636108</infon><infon key="pub-id_pmid">21576485</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the National Academy of Sciences</infon><infon key="type">ref</infon><infon key="volume">108</infon><infon key="year">2011</infon><offset>28195</offset><text>How Social Influence Can Undermine the Wisdom of Crowd Effect</text></passage><passage><infon key="name_0">surname:Katz;given-names:E</infon><infon key="name_1">surname:Lazarsfeld;given-names:P</infon><infon key="section_type">REF</infon><infon key="source">Personal Influence, the Part Played by People in the Flow of Mass Communications</infon><infon key="type">ref</infon><infon key="year">1966</infon><offset>28257</offset></passage><passage><infon key="fpage">E5070</infon><infon key="issue">26</infon><infon key="lpage">76</infon><infon key="name_0">surname:Becker;given-names:J</infon><infon key="name_1">surname:Brackbill;given-names:D</infon><infon key="name_2">surname:Centola;given-names:D</infon><infon key="pub-id_doi">10.1073/pnas.1615978114</infon><infon key="pub-id_pmid">28607070</infon><infon key="section_type">REF</infon><infon key="source">PNAS</infon><infon key="type">ref</infon><infon key="volume">114</infon><infon key="year">2017</infon><offset>28258</offset><text>Network Dynamics of Social Influence in the Wisdom of Crowds</text></passage><passage><infon key="fpage">9714</infon><infon key="issue">39</infon><infon key="lpage">19</infon><infon key="name_0">surname:Guilbeault;given-names:D</infon><infon key="name_1">surname:Becker;given-names:J</infon><infon key="name_2">surname:Centola;given-names:D</infon><infon key="pub-id_doi">10.1073/pnas.1722664115</infon><infon key="pub-id_pmid">30181271</infon><infon key="section_type">REF</infon><infon key="source">PNAS</infon><infon key="type">ref</infon><infon key="volume">115</infon><infon key="year">2018</infon><offset>28319</offset><text>Social Learning and Partisan Bias in the Interpretation of Climate Trends</text></passage><passage><infon key="fpage">10717</infon><infon key="issue">22</infon><infon key="lpage">22</infon><infon key="name_0">surname:Becker;given-names:J</infon><infon key="name_1">surname:Porter;given-names:E</infon><infon key="name_2">surname:Centola;given-names:D</infon><infon key="pub-id_doi">10.1073/pnas.1817195116</infon><infon key="pub-id_pmid">31085635</infon><infon key="section_type">REF</infon><infon key="source">PNAS</infon><infon key="type">ref</infon><infon key="volume">116</infon><infon key="year">2019</infon><offset>28393</offset><text>The Wisdom of Partisan Crowds</text></passage><passage><infon key="fpage">e0227813</infon><infon key="issue">2</infon><infon key="name_0">surname:Guilbeault;given-names:D</infon><infon key="name_1">surname:Centola;given-names:D</infon><infon key="pub-id_doi">10.1371/journal.pone.0227813</infon><infon key="pub-id_pmid">32027656</infon><infon key="section_type">REF</infon><infon key="source">PLOS ONE</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2020</infon><offset>28423</offset><text>Networked Collective Intelligence Improves Dissemination of Scientific Information Regarding Smoking Risks</text></passage><passage><infon key="fpage">360</infon><infon key="issue">6079</infon><infon key="lpage">62</infon><infon key="name_0">surname:Koriat;given-names:A</infon><infon key="pub-id_doi">10.1126/science.1216549</infon><infon key="pub-id_pmid">22517862</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">336</infon><infon key="year">2012</infon><offset>28530</offset><text>When Are Two Heads Better than One and Why?</text></passage><passage><infon key="fpage">1</infon><infon key="issue">6</infon><infon key="lpage">7</infon><infon key="name_0">surname:Bang;given-names:D</infon><infon key="name_1">surname:Aitchison;given-names:L</infon><infon key="name_2">surname:Moran;given-names:R</infon><infon key="name_3">surname:Castanon;given-names:S</infon><infon key="name_4">surname:Rafiee;given-names:B</infon><infon key="name_5">surname:Mahmoodi;given-names:A</infon><infon key="section_type">REF</infon><infon key="source">Nature Human Behaviour</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2017</infon><offset>28574</offset><text>Confidence Matching in Group Decision-Making</text></passage><passage><infon key="fpage">1081</infon><infon key="issue">5995</infon><infon key="lpage">85</infon><infon key="name_0">surname:Bahrami;given-names:B</infon><infon key="name_1">surname:Olsen;given-names:K</infon><infon key="name_2">surname:Latham;given-names:P</infon><infon key="name_3">surname:Roepstorff;given-names:A</infon><infon key="name_4">surname:Rees;given-names:G</infon><infon key="name_5">surname:Frith;given-names:C</infon><infon key="pub-id_doi">10.1126/science.1185718</infon><infon key="pub-id_pmid">20798320</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">329</infon><infon key="year">2010</infon><offset>28619</offset><text>Optimally Interacting Minds</text></passage><passage><infon key="fpage">183</infon><infon key="issue">1</infon><infon key="lpage">203</infon><infon key="name_0">surname:Sorkin;given-names:R</infon><infon key="name_1">surname:Hays;given-names:C</infon><infon key="name_2">surname:West;given-names:R</infon><infon key="pub-id_doi">10.1037/0033-295x.108.1.183</infon><infon key="pub-id_pmid">11212627</infon><infon key="section_type">REF</infon><infon key="source">Psychological Review</infon><infon key="type">ref</infon><infon key="volume">108</infon><infon key="year">2001</infon><offset>28647</offset><text>Signal-Detection Analysis of Group Decision Making</text></passage><passage><infon key="fpage">399</infon><infon key="issue">4</infon><infon key="lpage">443</infon><infon key="name_0">surname:López-Pintado;given-names:D</infon><infon key="name_1">surname:Watts;given-names:D</infon><infon key="section_type">REF</infon><infon key="source">Rationality and Society</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2008</infon><offset>28698</offset><text>Social Influence, Binary Decisions and Collective Dynamics</text></passage><passage><infon key="fpage">71</infon><infon key="issue">1</infon><infon key="lpage">81</infon><infon key="name_0">surname:Vicente-Page;given-names:J</infon><infon key="name_1">surname:Pérez-Escudero;given-names:A</infon><infon key="name_2">surname:Polavieja;given-names:G</infon><infon key="section_type">REF</infon><infon key="source">Theoretical Ecology</infon><infon key="type">ref</infon><infon key="volume">11</infon><offset>28757</offset><text>Dynamic Choices Are Most Accurate in Small Groups</text></passage><passage><infon key="name_0">surname:Becker;given-names:J.</infon><infon key="name_1">surname:Guilbeault;given-names:D.</infon><infon key="name_2">surname:Smith;given-names:N</infon><infon key="section_type">REF</infon><infon key="source">Management Science</infon><infon key="type">ref</infon><offset>28807</offset><text>The Crowd Classification Problem: Social Dynamics of Binary Choice Accuracy</text></passage><passage><infon key="fpage">351</infon><infon key="issue">3</infon><infon key="lpage">68</infon><infon key="name_0">surname:Berinsky;given-names:A</infon><infon key="name_1">surname:Huber;given-names:G</infon><infon key="name_2">surname:Lenz;given-names:G</infon><infon key="section_type">REF</infon><infon key="source">Political Analysis</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2012</infon><offset>28883</offset><text>Evaluating Online Labor Markets for Experimental Research: Amazon.Com’s Mechanical Turk</text></passage><passage><infon key="fpage">433</infon><infon key="issue">2</infon><infon key="lpage">42</infon><infon key="name_0">surname:Litman;given-names:L</infon><infon key="name_1">surname:Robinson;given-names:J</infon><infon key="name_2">surname:Abberbock;given-names:T</infon><infon key="pub-id_doi">10.3758/s13428-016-0727-z</infon><infon key="pub-id_pmid">27071389</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">49</infon><infon key="year">2017</infon><offset>28973</offset><text>TurkPrime.Com: A Versatile Crowdsourcing Data Acquisition Platform for the Behavioral Sciences</text></passage><passage><infon key="pub-id_doi">10.5281/zenodo.1488413</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>29068</offset></passage><passage><infon key="fpage">1279</infon><infon key="issue">6022</infon><infon key="lpage">85</infon><infon key="name_0">surname:Tenenbaum;given-names:J</infon><infon key="name_1">surname:Kemp;given-names:C</infon><infon key="name_2">surname:Griffiths;given-names:T</infon><infon key="name_3">surname:Goodman;given-names:N</infon><infon key="pub-id_doi">10.1126/science.1192788</infon><infon key="pub-id_pmid">21393536</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">331</infon><infon key="year">2011</infon><offset>29069</offset><text>How to Grow a Mind: Statistics, Structure, and Abstraction</text></passage><passage><infon key="name_0">surname:Spivey;given-names:M</infon><infon key="section_type">REF</infon><infon key="source">The Continuity of Mind</infon><infon key="type">ref</infon><infon key="year">2008</infon><offset>29128</offset></passage><passage><infon key="fpage">1</infon><infon key="lpage">14</infon><infon key="name_0">surname:Caplan;given-names:S</infon><infon key="name_1">surname:Hafri;given-names:A</infon><infon key="name_2">surname:Trueswell;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">Psychological Science</infon><infon key="type">ref</infon><infon key="year">2021</infon><offset>29129</offset><text>Now You Hear Me, Later You Don’t: The Immediacy of Linguistic Computation and the Representation of Speech</text></passage><passage><infon key="issue">327</infon><infon key="name_0">surname:Guilbeault;given-names:D</infon><infon key="name_1">surname:Baronchelli;given-names:A</infon><infon key="name_2">surname:Centola;given-names:D</infon><infon key="pub-id_doi">10.1038/s41467-020-20037-y</infon><infon key="pub-id_pmid">33436581</infon><infon key="section_type">REF</infon><infon key="source">Nature Communications</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2021</infon><offset>29238</offset><text>Experimental Evidence for Scale-Induced Category Convergence across Populations</text></passage><passage><infon key="issue">1</infon><infon key="name_0">surname:Gorwa;given-names:R</infon><infon key="name_1">surname:Binns;given-names:R</infon><infon key="name_2">surname:Katzenbach;given-names:C</infon><infon key="section_type">REF</infon><infon key="source">Big Data &amp; Society</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2020</infon><offset>29318</offset><text>Algorithmic Content Moderation: Technical and Political Challenges in the Automation of Platform Governance</text></passage><passage><infon key="name_0">surname:Gillespie;given-names:T</infon><infon key="section_type">REF</infon><infon key="source">Custodians of the Internet: Platforms, Content Moderation, and the Hidden Decisions That Shape Social Media</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>29426</offset></passage><passage><infon key="issue">8</infon><infon key="name_0">surname:Macy;given-names:M</infon><infon key="name_1">surname:Deri;given-names:S</infon><infon key="name_2">surname:Ruch;given-names:A</infon><infon key="name_3">surname:Tong;given-names:N</infon><infon key="pub-id_doi">10.1126/sciadv.aax0754</infon><infon key="pub-id_pmid">31489373</infon><infon key="section_type">REF</infon><infon key="source">Science Advances</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2019</infon><offset>29427</offset><text>Opinion Cascades and the Unpredictability of Partisan Polarization</text></passage></document></collection>
