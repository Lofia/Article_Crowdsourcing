<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20210104</date><key>pmc.key</key><document><id>6771927</id><infon key="license">author_manuscript</infon><passage><infon key="article-id_doi">10.1109/TAFFC.2017.2678472</infon><infon key="article-id_manuscript">NIHMS1022340</infon><infon key="article-id_pmc">6771927</infon><infon key="article-id_pmid">31576202</infon><infon key="fpage">115</infon><infon key="issue">1</infon><infon key="kwd">Emotions human subjects crowdsourcing probabilistic graphical model visual stimuli</infon><infon key="license">
          This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
        </infon><infon key="lpage">128</infon><infon key="name_0">surname:Ye;given-names:Jianbo</infon><infon key="name_1">surname:Li;given-names:Jia</infon><infon key="name_2">surname:Newman;given-names:Michelle G.</infon><infon key="name_3">surname:Adams;given-names:Reginald B.;suffix:Jr.</infon><infon key="name_4">surname:Wang;given-names:James Z.</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">10</infon><infon key="year">2019</infon><offset>0</offset><text>Probabilistic Multigraph Modeling for Improving the Quality of Crowdsourced Affective Data</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>91</offset><text>We proposed a probabilistic approach to joint modeling of participants’ reliability and humans’ regularity in crowdsourced affective studies. Reliability measures how likely a subject will respond to a question seriously; and regularity measures how often a human will agree with other seriously-entered responses coming from a targeted population. Crowdsourcing-based studies or experiments, which rely on human self-reported affect, pose additional challenges as compared with typical crowdsourcing studies that attempt to acquire concrete non-affective labels of objects. The reliability of participants has been massively pursued for typical non-affective crowdsourcing studies, whereas the regularity of humans in an affective experiment in its own right has not been thoroughly considered. It has been often observed that different individuals exhibit different feelings on the same test question, which does not have a sole correct response in the first place. High reliability of responses from one individual thus cannot conclusively result in high consensus across individuals. Instead, globally testing consensus of a population is of interest to investigators. Built upon the agreement multigraph among tasks and workers, our probabilistic model differentiates subject regularity from population reliability. We demonstrate the method’s effectiveness for in-depth robust analysis of large-scale crowdsourced affective data, including emotion and aesthetic assessments collected by presenting visual stimuli to human subjects.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1635</offset><text>INTRODUCTION</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1648</offset><text>HUMANS’ sensitivity to affective stimuli intrinsically varies from one person to another. Differences in gender, age, society, culture, personality, social status, and personal experience can contribute to its high variability between people. Further, inconsistencies may also exist for the same individual across environmental contexts and current mood or affective state. The causal effects and factors for such affective experiences have been extensively investigated, as evident in the literature on psychological and human studies, where controlled experiments are commonly conducted within a small group of human subjects—to ensure the reliability of collected data. To complement the shortcomings of those controlled experiments, ecological psychology aims to understand how objects and things in our surrounding environments effect human behaviors and affective experiences, in which real-world studies are favored over those within artificial laboratory environments, . The key ingredient of those ecological approaches is the availability of large-scale data collected from human subjects, remedying the high complexity and heterogeneity that the real-world has to offer. With the growing attention on affective computing (initiated from the seminal discussion to recent communications), multiple data-driven approaches have been developed to understand what particular environmental factors drive the feelings of humans,, and how those effects differ among various sociological structures and between human groups.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3178</offset><text>One crucial hurdle for those affective computing approaches is the lack of full-spectrum annotated stimuli data at a large scale. To address this bottleneck, crowdsourcing-based approaches are highly helpful for collecting uncontrolled human data from anonymous participants. In a recent study reported in, anonymous subjects from the Internet were recruited to annotate a set of visual stimuli (images): at each time point, after being presented with an image stimulus, participants were asked to assess their personal psychological experiences using ordinal scales for each of the affective dimensions: valence, arousal, dominance and likeness (which means the degree of appreciation in our context). This study also collected demographics data to analyze individual difference predictors of affective responses. Because labeling a large number of visual stimuli can become tedious, even with crowdsourcing, each image stimulus was examined by only a few subjects. This study allowed tens of thousands of images to obtain at least one label from a participant, which created a large data set for environmental psychology and automated emotion analysis of images.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4343</offset><text>One interesting question to investigate, however, is whether the affective labels provided by subjects are reliable. A related question is how to separate spammers from reliable subjects, or at least to narrow the scope of data to a highly reliable subgroup. Here, spammers are defined as those participants who provide answers without serious consideration of the presented questions. No answer from a statistical perspective is known yet for crowdsourced affective data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4816</offset><text>A great difficulty in analyzing affective data is caused by the absence of ground truth in the first place, that is, there is no correct answer for evoked emotion. It is generally accepted that even the most reliable subjects can naturally have varied emotions. Indeed, with variability among human responses anticipated, psychological studies often care about questions such as where humans are emotionally consistent and where they are not, and which subgroups of humans are more consistent than another. Given a population, many, if not the vast majority of stimuli may not have a consensus emotion at all. Majority voting or (weighted) averaging to force an “objective truth” of the emotional response or probably for the sake of convenience, as is routinely done in affective computing so that classification on a single quantity can be carried out, is a crude treatment bound to erase or disregard information essential for many interesting psychological studies, e.g., to discover connections between varied affective responses and varied demographics.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5880</offset><text>The involvement of spammers as participating subjects introduces an extra source of variation to the emotional responses, which unfortunately is tangled with the “appropriate” variation. If responses associated with an image stimulus contain answers by spammers, the inter-annotator variation for the specific question could be as large as the variation across different questions, reducing the robustness of any analysis. An example is shown in Fig. 1. Most annotators labeling this image are deemed unreliable, and two of them are highly susceptible as spammers according to our model. Investigators may be recommended to eliminate this image or acquire more reliable labels for its use. Yet, one should not be swayed by this example into the practice of discarding images that solicited responses of a large range. Certain images are controversial in nature and will stimulate quite different emotions to different viewers. Our system acquired the reliability scores shown in Fig. 1 by examining the entire data set; the data on this image alone would not be conclusive, in fact, far from so.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6980</offset><text>Facing the intertwined “appropriate” and “inappropriate” variations in the subjects as well as the variations in the images, we are motivated to unravel the sources of uncertainties by taking a global approach. The judgment on the reliability of a subject cannot be a per-image decision, and has to leverage the whole data. Our model was constructed to integrate these uncertainties, attempting to discern them with the help of big data. In addition, due to the lack of ground truth labels, we model the relational data that code whether two subjects’ emotion responses on an image agree, bypassing the thorny questions of what the true labels are and if they exist at all.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7664</offset><text>For the sake of automated emotion analysis of images, one also needs to narrow the scope to parts of data, each of which have sufficient number of qualified labels. Our work computes image confidences, which can support off-line data filtering or guide on-line budgeted crowdsourcing practices.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7959</offset><text>In summary, systematic analysis of crowdsourced affective data is of great importance to human subject studies and affective computing, while remains an open question. To substantially address the aforementioned challenges and expand the evidential space for psychological studies, we propose a probabilistic approach, called Gated Latent Beta Allocation (GLBA). This method computes maximum a posteriori probability (MAP) estimates of each subject’s reliability and regularity based on a variational expectation- maximization (EM) framework. With this method, investigators running affective human subject studies can substantially reduce or eliminate the contamination caused by spammers, hence improve the quality and usefulness of collected data (Fig. 2).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>8721</offset><text>Related Work</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8734</offset><text>Estimating the reliability of subjects is necessary in crowdsourcing-based data collection because the incentives of participants and the interest of researchers diverge. There were two levels of assumptions explored for the crowd- sourced data, which we name as the first-order assumption (A1) and the second-order assumption (A2). Let a task be the provision of emotion responses for one image. Consider a task or test conducted by a number of participants. Their responses within this task form a subgroup of data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9252</offset><text>A1 There exists a true label of practical interest for each task. The dependencies between collected labels are mediated by this unobserved true label, of which noisy labels are otherwise conditionally independent.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9467</offset><text>A2 The uncertainty model for a subgroup of data does not depend on its actual specified task. The performance of a participant is consistent across subgroups of data subject to a single fixed effect.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9667</offset><text>Existing approaches that model the complexities of tasks or reliability of participants often require one or both of these two assumptions. Under the umbrella of assumption A1, most probabilistic approaches using the observer models,,,  focus on estimating the ground truth from multiple noisy labels. For example, the modeling of one reliability parameter per subject is an established practice for estimating the ground truth label. For the case of categorical labels, modeling of one free parameter per class per subject is a more general approach,. Our approach does not model the ground truth of labels, hence it is not viable to compare our approach with other methods in this regard. Instead, we sidestep this issue to tackle whether the labels from one subject can agree with labels from another on a single task. Agreement is judged subject to a preselected criterion. Such treatment may be more realistic as a means to process sparse ordinal labels for each task.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10641</offset><text>Assumption A2 is also widely exploited among methods, often conditioned on A1. It assumes that all of the tasks have the same level of difficulty,. Modeling one difficulty parameter per task has been explored in  for categorical labels. However, in our approach, task difficulty is modeled as a random effect without subscribing a task-specific parameter. Wisely choosing the modeling complexity and assumptions should be based on availability and purity of data. As suggested in, more complexity in a model could challenge the statistical estimation subject to the constraint of real data. Choices with respect to our model attempted to properly analyze the affective data we obtained.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11328</offset><text>If the mutual agreement rate between two participants does not depend on the actual specified task (i.e., when A2 holds), we can essentially convert the resulting problem to a graph mining problem, where subjects are vertices, agreements are edges, and the proximity between subjects is modeled by how likely they agree with each other in a general sense. Probabilistic models for such relational data can be traced back to early stochastic blockmodels,, latent space model, and their later extensions with mixed membership, and nonparametric Bayes. We adopt the idea of mixed memberships wherein two particular modes of memberships are modeled for each subject, one being the reliable mode and the other the random mode. For the random mode, the behavior is assumed to be shared across different subjects, whereas the regular behaviors of subjects in the reliable mode are assumed to be different. Therefore, we can extend this framework from graph to multigraph in the interest of crowdsourced data analysis. Specifically, data are collected as subgroups, each of which is composed of a small agreement graphs for a single task, such that the covariate within a subgroup is modeled. Our approach does not rely on A2. Instead, it models the random effects added to subjects’ performance in each task via the multigraph approach. Assumptions A1 and A2 implies a bipartite graph structure between tasks and subjects. In contrast, our approach starts from the multigraph structure among subjects that is coordinated by tasks. Finding the proper and flexible structure that data possess is crucial for modeling.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>12939</offset><text>Our Contributions</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>12957</offset><text>We developed a probabilistic multigraph model to analyze crowdsourced data and its approximate variational EM algorithm for estimation. The new method, accepting the intrinsic variation in subjective responses, does not assume the existence of ground truth labels, in stark contrast to previous work having devoted much effort to obtain objective true labels.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>13317</offset><text>Our method exploits the relational data in the construction and application of the statistical model. Specifically, instead of the direct labels, the pair-wise status of agreement between labels given by different subjects is used. As a result, the multigraph agreement model is naturally applicable to more flexible types of responses, easily going beyond binary and categorical labels. Our work serves as a proof of concept for this new relational perspective.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>13780</offset><text>Our experiments have validated the effectiveness of our approach on real-world affective data. Because our experimental setup was of a larger scale and more challenging than settings addressed by existing methods, we believe our method can fill some gaps for demands in the practical world, for instance, when gold standards are not available.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14124</offset><text>To our knowledge, this is the first attempt to connect probabilistic observer models with probabilistic graphs, and to explore modeling at this complexity from the joint perspective. We summarize our contributions as follows: </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>14351</offset><text>THE METHOD</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14362</offset><text>In this section, we describe our proposed method. Let us present the mathematical notations first. A symbol with subscript omitted always indicates an array, e.g., x = ( . . . , xi, . . .). The arithmetic operations perform over arrays in the element-wise manner, e.g., x + y = ( . . . ,xi + yi,. . .). Random variables are denoted as capital English letters. The tilde sign indicates the value of parameters in the last iteration of EM, e.g., . Given a function fθ, we denote  by  or simply , if the parameter  is implied. Additional notations, as summarized in Table 1, will be explained in more details later.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>14979</offset><text>Agreement Multigraph</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15000</offset><text>We represent the data as a directed multigraph, which does not assume a particular type of crowdsourced response. Suppose we have prepared m questions in the study, the answers can be binary, categorical, ordinal, and multidimensional. Given a subject pair (i, j) who are asked to look at the kth question, one designs an agreement protocol that determines whether the answer from subject i agrees with that from subject j. If subject i’s agrees with subject j’s on task k, then we set . Otherwise, .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15505</offset><text>In our case, we are given ordinal data from multiple channels, we define  if (sum of) the percentile difference between two answers  satisfies </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15649</offset><text>The percentile P[·] is calculated from the whole pool of answers for each discrete value, and δ = 0.2. In the above equation, we measure the percentile difference between ai and aj as well as that between ai + 1 and aj + 1 in order to reduce the effect of imposing discrete values on the answers that are by nature continuous. If the condition does not hold, they disagree and . Here we assume that if two scores for the same image are within a 20 percent percentile interval, they are considered to reach an agreement. Compared with setting a threshold on their absolute difference, such rule adapts to the non-uniformity of score distribution. Two subjects can agree with each other by chance or they indeed experience similar emotions in response to the same visual stimulus.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16432</offset><text>While the choice of the percentile threshold δ is inevitably subjective, the selection in our experiments was guided by the desire to trade-off the preservation of the original continuous scale of the scores (favoring small values) and a sufficient level of error tolerance (favoring large values). This threshold controls the sparsity level of the multi-graph, and influences the marginal distribution of estimated parameters. Alternatively, one may assess different values of the threshold and make a selection based on some other criteria of preference (if exist) applied to the final results.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>17033</offset><text>Gated Latent Beta Allocation</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17062</offset><text>This section describes the basic probabilistic graphical model we used to jointly model subject reliability, which is independent from the supplied questions, and regularity. We refrain from carrying out a full Bayesian inference because it is impractical to end users. Instead, we use the mode(s) of the posterior as point estimates.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17397</offset><text>We assume each subject i has a reliability parameter τi, ∈ [0, 1] and regularity parameters αi, βi, &gt; 0 characterizing his or her agreement behavior with the population, for i = 1, . . . ,m. We also use parameter γ for the rate of agreement between subjects out of pure chance. Let  be the set of parameters. Let Ωk be the a random sub-sample from subjects {1, . . . , m} who labeled the stimulus k, where k = 1,... ,n. We also assume sets Ωk’s are created independently from each other. For each image k, every subject pair from  i.e., ( i, j) with i ≠ j, has a binary indicator  coding whether their opinions agree on the respective stimulus. We assume  are generated from the following probabilistic process with two latent variables. The first latent variable  indicates whether subject Oj is reliable or not. Given that it is binary, a natural choice of model is the Bernoulli distribution. The second latent variable , lying between 0 and 1, measures the extent subject Oi agrees with the other reliable responses. We use Beta distribution parameterized by αi, and βi, to model  because it is a widely used parametric distribution for quantities on interval [0,1] and the shape of the distribution is relatively flexible. In a nutshell,  is a latent switch (aka, gate) that controls whether  can be used for the posterior inference of the latent variable . Hence, we call our model Gated Latent Beta Allocation (GLBA). A graphical illustration of the model is shown in Fig. 4.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18908</offset><text>We now present the mathematical formulation of the model. For k = 1,...,n, we generate a set of random variables independently via    where the last random process holds for any  and  with k = 1,...,n, and γ is the rate of agreement by chance if one of i, j turns out to be unreliable. Here  are observed data.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19223</offset><text>If a spammer is in the subject pool, his or her reliability parameter τi is zero, though others can still agree with his or her answers by chance at rate γ. On the other hand, if one is very reliable yet often provides controversial answers, his reliability τi can be one, while he typically disagrees with others, indicated by his high irregularity . We are interested in finding both types of subjects. However, most of subjects lie in between these two extremes.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19697</offset><text>As an interesting note, Eq. (4) is asymmetric, meaning that  is possible, a scenario that should never occur by definitions of the two quantities. We propose to achieve symmetry in the final model by using the conditional distribution of  and  given that , and call this model the symmetrized model. With details omitted, we state that conditioned on , and , the symmetrized model is still a Bernoulli distribution:  where </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20121</offset><text>We tackle the inference and estimation of the asymmetric model for simplicity.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>20200</offset><text>Variational EM</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20215</offset><text>Variational inference is an optimization based strategy for approximating posterior distribution in complex distributions. Since the full posterior is highly intractable, we consider to use variational EM to estimate the parameters . The parameter γ is assumed to be pre-selected by the user and does not need to be estimated. To regularize the other parameters in estimation, we use the empirical Bayes approach to choose priors. Assume the following priors  </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20680</offset><text>By empirical Bayes, τ0, s0 are adjusted. For the ease of notations, we define two auxiliary functions  and  : </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20793</offset><text>Similarly, we define their siblings </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20830</offset><text>We also define the auxiliary function rj(·) as </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20879</offset><text>Now we define the full likelihood function:  where auxiliary variables simplifying the equations are  and B(·, ·) is the Beta function. Consequently, assume the prior likelihood is LΘ(Θ) , the MAP estimate of Θ is to minimize </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21118</offset><text>We solve the estimation using variational EM method with a fixed (τ0, s0) and varying γ. The idea of variational methods is to approximate the posterior by a factorizable template, whose probability distribution minimizes its KL divergence to the true posterior. Once the approximate posterior is solved, it is then used in the E-step in the EM algorithm as the alternative to the true posterior. The usual M-step is unchanged. Each time Θ is estimated, we adjust prior (τ0, s0) to match the mean of the MAP estimates of {τi} and  respective until they are sufficiently close.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>21709</offset><text>E-Step.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21717</offset><text>We use the factorized Q-approximation with variational principle: </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21784</offset><text>Let  whose distribution can be written as  where log . As suggested by Johnson and Kotz , the geometric mean can be numerically approximated by  if both  and  are sufficiently larger than 1.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21975</offset><text>Let  whose distribution is </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22003</offset><text>Given parameter , we can compute the approximate posterior expectation of the log likelihood, which reads  where relevant statistics are defined as </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22152</offset><text>Remark B(·, ·) is the Beta function, and  is calculated from approximation Eq. (15)</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>22238</offset><text>M-Step.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22246</offset><text>Compute the partial derivatives of L with respect to αi and βi: let Δi be the set of images that are labeled by subject i. We set  and  for each i, which reads  where  is the Digamma function. The above two equations can be practically solved by Newton-Raphson method with a projected modification (ensuring α, β always are greater than zero).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22608</offset><text>Compute the derivatives of L with respect to τi and set , which reads </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22681</offset><text>Compute the derivatives of L w.r.t. γ and set to zero, which reads </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22753</offset><text>In practice, the update formula for γ needs not to be used if γ is pre-fixed. See Algorithm 1 for details.</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>22868</offset><text>Variational EM algorithm of GLBA</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;none&quot;&gt;
              &lt;colgroup span=&quot;1&quot;&gt;
                &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
                &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
              &lt;/colgroup&gt;
              &lt;tbody&gt;
                &lt;tr&gt;
                  &lt;td colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot;&gt;&lt;bold&gt;Input:&lt;/bold&gt; A
multi-graph &lt;inline-formula&gt;&lt;mml:math display=&quot;inline&quot; id=&quot;M69&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;{&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;I&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;∈&lt;/mml:mo&gt;&lt;mml:mo&gt;{&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;}&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;}&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;j&lt;/mml:mi&gt;&lt;mml:mo&gt;∈&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;Ω&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo&gt;′&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;mml:mo&gt;&amp;lt;&lt;/mml:mo&gt;&lt;mml:mi&gt;γ&lt;/mml:mi&gt;&lt;mml:mo&gt;&amp;lt;&lt;/mml:mo&gt;&lt;mml:mn&gt;0.5&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot;&gt;&lt;bold&gt;Output:&lt;/bold&gt;
subject parameters &lt;inline-formula&gt;&lt;mml:math display=&quot;inline&quot; id=&quot;M70&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;Θ&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;{&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;τ&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;}&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;γ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;italic&gt;Initialisation&lt;/italic&gt; :
&lt;italic&gt;τ&lt;/italic&gt;&lt;sub&gt;0&lt;/sub&gt; = 0.5,
&lt;italic&gt;α&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt; =
&lt;italic&gt;β&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt; =
&lt;italic&gt;τ&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt; =
1.0, &lt;italic&gt;i&lt;/italic&gt; = 1, . . . ,&lt;italic&gt;m&lt;/italic&gt;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
                    &lt;bold&gt;repeat&lt;/bold&gt;
                  &lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; &lt;bold&gt;for&lt;/bold&gt;
&lt;italic&gt;k&lt;/italic&gt; − 1 to &lt;italic&gt;n&lt;/italic&gt;
&lt;bold&gt;do&lt;/bold&gt;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;  compute statistics
&lt;inline-formula&gt;&lt;mml:math display=&quot;inline&quot; id=&quot;M71&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;mml:mo&gt;˜&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msubsup&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;mml:mo&gt;˜&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msubsup&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi&gt;τ&lt;/mml:mi&gt;&lt;mml:mo&gt;˜&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt; by &lt;xref rid=&quot;FD22&quot; ref-type=&quot;disp-formula&quot;&gt;Eq. (18)&lt;/xref&gt;;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; &lt;bold&gt;end for&lt;/bold&gt;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; &lt;bold&gt;for&lt;/bold&gt;
&lt;italic&gt;i&lt;/italic&gt; − 1 to &lt;italic&gt;m&lt;/italic&gt;
&lt;bold&gt;do&lt;/bold&gt;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;  solve
(&lt;italic&gt;α&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt;,
&lt;italic&gt;β&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt;)
from &lt;xref rid=&quot;FD23&quot; ref-type=&quot;disp-formula&quot;&gt;Eq.
(19)&lt;/xref&gt; (Newton-Raphson);&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;7:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;  compute
&lt;italic&gt;τ&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt;
by &lt;xref rid=&quot;FD24&quot; ref-type=&quot;disp-formula&quot;&gt;Eq.
(20)&lt;/xref&gt;;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;8:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; &lt;bold&gt;end for&lt;/bold&gt;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;9:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; (optional) update
&lt;italic&gt;γ&lt;/italic&gt; from &lt;xref rid=&quot;FD25&quot; ref-type=&quot;disp-formula&quot;&gt;Eq. (21)&lt;/xref&gt;;&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;until&lt;/bold&gt;
&lt;inline-formula&gt;&lt;mml:math display=&quot;inline&quot; id=&quot;M72&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;{&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;τ&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;α&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;β&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mo&gt;}&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;=&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mi&gt;m&lt;/mml:mi&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt; are all converged.&lt;/td&gt;
                &lt;/tr&gt;
                &lt;tr&gt;
                  &lt;td align=&quot;right&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;11:&lt;/td&gt;
                  &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;return&lt;/bold&gt; Θ&lt;/td&gt;
                &lt;/tr&gt;
              &lt;/tbody&gt;
            &lt;/table&gt;
</infon><offset>22901</offset><text>Input: A	 	multi-graph 	 	Output:	 	subject parameters 	 		Initialisation :	 	τ0 = 0.5,	 	αi =	 	βi =	 	τi =	 	1.0, i = 1, . . . ,m	 	1:	repeat	 	2:	 fork − 1 to ndo	 	3:	  compute statistics	 	 by Eq. (18);	 	4:	 end for	 	5:	 fori − 1 to mdo	 	6:	  solve	 	(αi,	 	βi)	 	from Eq.	 	(19) (Newton-Raphson);	 	7:	  compute	 	τi	 	by Eq.	 	(20);	 	8:	 end for	 	9:	 (optional) update	 	γ from Eq. (21);	 	10:	until are all converged.	 	11:	return Θ	 	</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>23385</offset><text>The Algorithm</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23399</offset><text>We present our final algorithm to estimate all parameters by knowing the multigraph data . Our algorithm is designed based on Eqs. (19), (20), and (21). In each EM iteration, there are two loops: one for collecting relevant statistics for each subgraph, and the other for re-computing the parameter estimates for each subject. Please refer to Algorithm 1 for details.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>23767</offset><text>EXPERIMENTS</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>23779</offset><text>Data Sets</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23789</offset><text>We studied a crowdsourced affective data set acquired from the Amazon Mechanical Turk (AMT) platform. The affective data set is a collection of image stimuli and their affective labels including valence, arousal, dominance and likeness (degree of appreciation). Labels for each image are ordinal: {1,. . .,9} for the first three dimensions, and {1,. . .,7} for the likeness dimension. The study setup and collected data statistics have been detailed in, which we describe briefly here for the sake of completeness.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24304</offset><text>At the beginning of a session, the AMT study host provides the subject brief training on the concepts of affective dimensions. Here are descriptions used for valence, arousal, dominance, and likeness.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24505</offset><text>Valence: degree of feeling happy versus unhappy</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24553</offset><text>Arousal: degree of feeling excited versus calm</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24600</offset><text>Dominance: degree of feeling submissive versus dominant</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24656</offset><text>Likeness: how much you like or dislike the image</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24705</offset><text>The questions presented to the subject for each image are given below in exact wording.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24793</offset><text>Slide the solid bubble along each of the bars associated with the 3 scales (Valence, Arousal, and Dominance) in order to indicate how you ACTUALLY FELT WHILE YOU OBSERVED THE IMAGE.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24975</offset><text>How did you like this image? (Like extremely, Like very much, Like slightly, Neither like nor dislike, Dislike slightly, Dislike very much, Dislike extremely)</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25134</offset><text>Each AMT subject is asked to finish a set of labeling tasks, and each task is to provide affective labels on a single image from a prepared set, called the EmoSet. This set contains around 40,000 images crawled from the Internet using affective keywords. Each task is divided into two stages. First, the subject views the image; and second, he/she provides ratings in the emotion dimensions through a Web interface. Subjects usually spend three to ten seconds to view each image, and five to twenty seconds to label it. The system records the time durations respectively for the two stages of each task and calculates the average cost (at a rate of about 1.4 US Dollars per hour). Around 4,000 subjects were recruited in total. For the experiments below, we retained image stimuli that have received affective labels from at least four subjects. Under this screening, the AMT data have 47,688 responses from 2,039 subjects on 11,038 images. Here, one response refers to the labeling of one image by one subject conducted in one task.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>26168</offset><text>Because humans can naturally feel differently from each other in their affective experiences, there was no gold standard criterion to identify spammers. Such a human emotion data set is difficult to analyze and the quality of data is hard to assess. Among several emotion dimensions, we found that participants were more consistent in the valence dimension. As a reminder, valence is the rated degree of positivity of emotion evoked by looking at an image. We call the variance of the ratings from different subjects on the same image the within-task variance, while the variance of the ratings from all the subjects on all the images the cross-task variance. For valence and likeness, the within-task variance accounts for about 70 percent of the cross-task variance, much smaller than for the other two dimensions. Therefore, the remaining experiments were focused on evaluating the regularity of image valences in the data.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>27095</offset><text>Baselines for Comparison</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>27120</offset><text>We discuss below several baseline methods or models with which we compare our method.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>27206</offset><text>Dawid and Skene.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>27223</offset><text>Our method falls into the general category of consensus methods in the literature of statistics and machine learning, where the spammer filtering decision is made completely based on the labels provided by observers. Those consensus methods have been developed along the line of Dawid and Skene, and they mainly deal with categorical labels by modeling each observer using a designated confusion matrix. More recent developments of the observer models have been discussed in, where a benchmark has shown that the Dawid-Skene method is still quite competitive in unsupervised settings according to a number of real-world data sets for which ground-truth labels are believed to exist albeit unknown. However, this method is not directly applicable to our scenario. To enable comparison with this baseline method, we first convert each affective dimension into a categorical label by thresholding. We create three categories: high, neural, and low, each covering a continuous range of values on the scale. For example, high valence category implies a score greater than a neural score (i.e., 5) by more than a threshold (e.g., 0.5). Such a thresholding approach has been adopted in developing affective categorization systems, e.g., ,.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>28456</offset><text>Time Duration.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>28471</offset><text>In the practice of data collection, the host filtered spammers by a simple criterion—to declare a subject spammer if he spends substantially less time on every task. The labels provided by the identified spammers were then excluded from the data set for subsequent use, and the host also declined to pay for the task. However, some subjects who were declined to be paid wrote emails to the host arguing for their cases. Under this spirit, in our experiments, we form a baseline method that uses the average time duration of each subject to red-flag a spammer.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>29033</offset><text>Filtering Based on Gold Standard Examples.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>29076</offset><text>A widely used spammer detection approach in crowdsourcing is to create a small set with known ground truth labels and use it to spot anyone who gives incorrect labels. However, such a policy was not implemented in our data collection process because as we argued earlier, there is simply no ground truth for the emotion responses to an image in a general sense. On the other hand, just for the sake of comparison, it seems reasonable to find a subset of images that evoke such extreme emotions that ground truth labels can be accepted. This subset will then serve the role of gold standard examples. We used our method to retrieve a subset of images which evoke extreme emotions with high confidence (see Section 3.7 for confidence score and emotion score calculation). For the valence dimension, we were able to identify at most 101 images with valence score ≥ 8 (on the scale of 1 . . .9) with over 90 percent confidence and 37 images with valence score ≤ 2 with over 90 percent confidence. We also looked at those images one by one (as provided in the supplementary materials, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TAFFC.2017.2678472. ) and believe that within a reasonable tolerance of doubt those images should evoke clear emotions in the valence dimension. Unfortunately, only a small fraction of subjects in our pool have labeled at least one image from this “gold standard” subset. Among this small group, their disparity from the gold standard enables us to find three susceptible spammers. To see whether these three susceptible spammers can also be detected by our method, we find that their reliability scores τ ∈ [0,1] are 0.11,0.22,0.35 respectively. In Fig. 9, we plot the distribution of τ of the entire subject pool. These three scores are clearly on the low end with respect to the scores of the other subjects. Thus the three spammers are also assessed to be highly susceptible by our model.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>31066</offset><text>In summary, while we were able to compare our method with the first two baselines quantitatively, with results to be presented shortly, comparison with the third baseline is limited due to the way the AMT data were collected.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>31292</offset><text>Model Setup</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>31304</offset><text>Since our hypotheses included a random agreement ratio γ that is pre-selected, we adjusted the parameter γ from 0.3 to 0.48 to see empirically how it affects the result in practice.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>31494</offset><text>Fig. 5 depicts how the reliability parameter τ varies with γ for different workers in our data set. Results are shown for the top 15 users who provided the most numbers of ratings. Generally speaking, a higher γ corresponds to a higher chance of agreement between workers purely out of random. From the figure, we can see that a worker providing more ratings is not necessarily more reliable. It is quite possible that some workers took advantage of the AMT study to earn monetary compensation without paying enough attention to the actual questions.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>32055</offset><text>In Table 2, we demonstrate the valence, arousal, and dominance labels for two categories of subjects. On the top, the first category contains susceptible spammers with low estimated reliability parameter τ; and on the bottom, the second category contains highly reliable subjects with high values of τ. Each subject takes one row. For the convenience of visualization, we represent the three-dimensional emotion scores given to any image by a particular color whose RGB values are mapped from the values in the three dimensions respectively. The emotion labels for every image by one subject are then condensed into one color bar. The labels provided by each subject for all his images are then shown as a palette in one row. For clarity, the color bars are sorted in lexicographic order of their RGB values. One can clearly see that those labels given by the subjects from these two categories exhibit quite different patterns. The palettes of the susceptible spammers are more extreme in terms of saturation or brightness. The abnormality of label distributions of the first category naturally originates from the fact that spammers intended to label the data by exerting the minimal efforts and without paying attention to the questions.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>33300</offset><text>Basic Statistics of Manually Annotated Spammers</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>33348</offset><text>For each subject in the pool, by observing all his or her labels in different emotion dimensions, there was a reasonable chance of spotting abnormality solely by visualizing the distribution. If one were a spammer, it often happened that his or her labels were highly correlated, skewed or deviated in an extreme manner from a neural emotion along different dimensions. In such cases, it was possible to manually exclude his or her responses from the data due to his or her high susceptibility. We applied this same practice to identifying highly susceptible subjects from the pool. We found about 200 susceptible participants.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>33976</offset><text>We studied several basic statistics of this subset in comparison with the whole population: total number of tasks completed, average time duration spent on image viewing and survey per task. The histograms of these quantities are plotted in Fig. 6. One can see that the annotated spammers did not necessarily spend less time or finish fewer tasks than the others, and the time duration has shown only marginal sensitivity to those annotated spammers (See Fig. 6). The figures demonstrate that those statistics are not effective criteria for spammer filtering.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>34536</offset><text>We will use this subset of susceptible subjects as a “pseudo-gold standard” set for quantitative comparisons of our method and the baselines in the subsequent studies. As explained previously in 3.2, other choices of constructing a gold standard set either conflict the high variation nature of emotion responses or yield only a tiny (of size three) set of spammers.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>34907</offset><text>Top-K Precision Performance in Retrieving the Real Spammers</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>34967</offset><text>We conducted experiments on each affective dimension, and evaluated whether the subjects with the lowest estimated τ were supposed to be real spammers according to the “pseudo-gold standard” subset constructed in Section 3.4. Since there was no gold standard to correctly classify whether one subject was truly a spammer or not, we have been agnostic here. Based on that subset, we were able to partially evaluate the top-K precision in retrieving the real spammers, especially the most susceptible ones.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>35477</offset><text>Specifically, we computed the reliability parameter τ for each subject and chose the K subjects with the lowest values as the most susceptible spammers. Because τ depends on the random agreement rate γ, we computed τ′s using 10 values of γ evenly spaced out over interval [0.3,0.48]. The average value of τ was then used for ranking. The Precision Recall Curves are shown in Fig. 7. Our method achieves high top-K precision by retrieving the most susceptible subjects from the pool according to the average τ. In particular, the top-20 precision is 100 percent, the top-40 precision is 95 percent, and the top-60 precision is 78 percent. Clearly, our algorithm has yielded results well aligned with the human judgment on the most susceptible ones. In Fig. 7, we also plot Precision Recall Curves by fixing γ to 0.3, 0.37,0.44 and using the corresponding τ. The result at γ = 0.37 is better than the other two across recalls, indicating that a proper level of the random agreement rate can be important for achieving the best performance. The two baseline methods are clearly not competitive in this evaluation. The Dawin- Skene method, widely used in processing crowdsourced data with objective ground truth labels, drops quickly to a remarkably low precision even at a low recall. The time duration method, used in the practice of AMT host, is better than the Dawin-Skene method, yet substantially worse than the performance of our method.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36946</offset><text>We also tested this same method of identifying spammers using affective dimensions other than valence. As shown in Fig. 8, the two most discerning dimensions were valence and arousal. It is not surprising that people can reach relatively higher consensus when rating images by these two dimensions than by dominance or likeness. Dominance is much more likely to draw on evidence from context and social situation in most circumstances and hence less likely to have its nature determined to a larger extent by the stimulus itself.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>37476</offset><text>Recall Performance in Retrieving the Simulated Spammers</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>37532</offset><text>The evaluation of top-K precision was limited in two respects: (1) the susceptible subjects were identified because we could clearly observe their abnormality in terms of the multivariate distribution of provided labels. If the participant labeled the data by acting exactly the same as the distribution of the population, we could not manually identify him/her using the aforementioned methodology. (2) We still need to determine if one is a spammer, how likely we are to spot him/her.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>38019</offset><text>In this study, we simulated several highly “intelligent” spammers, who labeled the data by exactly following the label distribution of the whole population. Every time, we generated 10 spammers, who randomly labeled 50 images. The labels of simulated spammers were not overlapping. We mixed those labels of the simulated spammers with the existing data set, and then conducted our method again to determine how accurate our approach was with respect to finding the simulated spammers. We repeated this process 10 times in order to estimate the t distribution of the simulated spammers. Results are reported Fig. 9. We drew the histogram of the estimated reliability of all real workers and compared them to the estimated reliability of simulated spammers (in the table included in Fig. 9). We noted that more than half of the simulated spammers were identified as highly susceptible based on the τ estimation (≤ 0.2), and none of them were supposed to have a high reliability score (≥ 0.6). This result validates that our method is robust enough to spot the “intelligent” spammers, even if they disguise themselves as random labelers within a population.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>39187</offset><text>Qualitative Comparison Based on Controversial Examples</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>39242</offset><text>To re-rank the emotion dimensions and likenesses of stimuli with the reliability of the subject accounted for, we adopted the following formula to find the stimuli with “reliably” highest ratings. Assume each rating αi ∈ [0,1]. We define the following to replace the usual average:  where  is the cumulative confidence score for image k. This adjusted rating bk not only allows more reliable subjects to play a bigger role via the weighted average (the first term of the product) but also modulates the weighted average by the cumulative confidence score for the image. Similarly, in order to find those with “reliably” lowest ratings, we replace  with  in the above formula and then still seek for the images with the highest bk′s.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>39988</offset><text>If bk is higher than a neutral level, then the emotional response to the image is considered high. Fig. 10 shows the histogram of image confidence scores estimated by our method. More than 85 percent of images had acquired a sufficient number of quality labels. To obtain a qualitative sense of the usefulness of the reliability parameter τ, we compared our approach with the simple average-and-rank scheme by examining controversial image examples according to each emotion dimension. Here, being controversial means the assessment of the average emotion response for an image differs significantly between the methods. Despite the variability of human nature, the majority of the population were quite likely to reach consensus for a portion of the stimuli. Therefore, this investigation is meaningful. In Figs. 2 and 3, we show example image stimuli that were recognized to clearly deviate from neutral emotions by one method but not agreed upon by the other. We skipped stimuli images that were fear inducing, visually annoying or improper. Interested readers can see the complete results in the supplementary material, available online.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>41132</offset><text>Cost/Overhead Analysis</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>41155</offset><text>There is an inevitable trade-off between the quality of the labels and the average cost of acquiring them when screening is applied based on reliability. If we set a higher standard for reliability, the quality of the labels retained tends to improve but we are left with fewer labels to use. It is interesting to visualize the trade-off quantitatively. Let us define overhead numerically as the number of labels removed from the data set when quality control is imposed; and let the threshold on either subject reliability or image confidence used to filter labels be the index for label quality. We obtained what we call overhead curve in Fig. 11. On the left plot, the result is based on filtering subjects with reliability scores below a threshold (all labels given by such subjects are excluded); on the right, it is based on filtering images with confidence scores below a threshold. As shown by the plots, if either the labels from subjects with reliability scores below 0.3 are discarded or those for images with confidence scores below 90 percent are discarded, roughly 10,000 out of 47,688 labels are deemed unusable. At an even higher standard, e.g., subject reliability ≥ .5 or image confidence level ≥ 95%, around half of the labels will be excluded from the data set. Although this means the average per label cost is doubled at the stringent quality standard, we believe the screening is worthwhile in comparison with analysis misled by wrong data. In a large-scale crowdsource environment, it is simply impractical to expect all the subjects to be fully serious. This contrasts starkly with a well-controlled lab environment for data collection. In a sense, post-collection analysis of data to ensure quality is unavoidable. It is indeed a matter of which analysis should be applied.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>42959</offset><text>DISCUSSIONS</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>42971</offset><text>Underlying Principles.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>42994</offset><text>Our approach to assess the reliability of crowdsourced affective data deviates fundamentally from the standard approaches much concerned with hunting for “ground truth” emotion stimulated by an image. An individual’s emotion response is expected to be naturally different because it depends on subjective opinions rooted in the individual’s lifetime exposure to images and concepts, a topic having been pursued long in the literature of social psychology. The new principle we adopted here focuses on the relational knowledge about the ratings of the subjects. Our analysis steps away from the use of “ground truth” by recasting the data as relational quantities.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>43670</offset><text>As pointed out by a reviewer, such a relational perspective may be intrinsic in human cognition, going beyond our specific problem here. For instance, the same spirit of exploiting relationships has already appeared in studies to understand linguistic learning. Gentner,  proposed that one should understand linguistic learning in a relational way. Instead of assuming there are well-formed abstract language concepts to grasp, the human’s cognitive ability often starts from analogical processing based on examples of a concept, and then utilizes the symbolic systems (languages) to reinforce and guide the learning, and to facilitate memory of the acquired concepts. The relationships among the examples and the abstract concept play a role in learning hand in hand, refining recursively the understanding of each other. The whole process is an interlocked and repeated improvement of one side assisted by the other. In a similar fashion, our system improves its assessment about which images evoke highly consensus emotion responses and which subjects are reliable. At the beginning, the lack of either kind of information obscures the truth about the other. Or equivalently, knowing either makes the understanding of the other easy. This is a chicken-and-egg situation. Like the proposed way of learning languages, our system pulls out of the dilemma by recursively enhancing the understanding of one side conditioned on what has been known about the other.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>45134</offset><text>Results.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>45143</offset><text>We found that the crowdsourced affective data we examined are particularly challenging for the conventional school of observer models, developed along the line of Dawid and Skene. We identified two major reasons. First, each image in our data set has a much smaller number of observers, compared with what are typically studied in the benchmarks. In our data set, most images were only labeled by 4 to 8 subjects, while many existing benchmark data sets have tens of subjects per task. Second, a more profound reason is that most images do not have a ground truth affective label at the first place. This can render ineffective many statistical methods which model the user-task confusion matrix and hence count on the existence of “true” labels and the fixed characteristics of uncertainty in responses (assumptions A1 and A2).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>45976</offset><text>Our experiments demonstrate that valence and arousal are the two most effective dimensions that can be used to analyze the reliability of subjects. Although subjects may not reach a consensus at local scales (say, an individual task) because the emotions are inherently subjective, consensus at a global scale can still be well justified.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>46315</offset><text>Usage Scenarios:</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>46332</offset><text>We would like to articulate on the scenarios under which our method or other traditional approaches (e.g., those described in Section 3.2) are more suitable.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>46490</offset><text>First, our method is not meant to replace traditional approaches that add control factors at the design stage of the experiments, for example, recording task completion time, and testing subjects with examples annotated with gold standard labels. Those methods are effective at identifying extremely careless subjects. But we argue that the reliability of a subject is often not a matter of yes or no, but can take a continum of intermediate levels. Moreover, consensus models such as Dawid-Skene methods require that each task is assigned to multiple annotators.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>47054</offset><text>Second, our method can be integrated with other approaches so as to collect data most efficiently. Traditional heuristic approaches require the host to come up with a number of design questions or procedures effective for screening spammers before executing the experiments, which can be a big challenge especially for affective data. In contrast, the consensus models support post analyses of collected data and have no special requirement for the experimental designs. This suggests we may use a consensus model to carry out a pilot study which then informs us how to best design the data collection procedure.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>47667</offset><text>Third, as a new method in the family of consensus models, our approach is unique in terms of its fundamental assumptions, and hence should be utilized in quite different scenarios than the other models. Methods based on modeling confusion matrix are more suitable for aggregating binary and categorical labels, while the agreement-based methods (ours included) are more suitable for continuous and multi-dimensional labels (or more complicated structures) that normally have no ground truth. The former are often evaluated quantitatively by how accurately they estimate the true labels, while the latter are evaluated directly by how effectively they identify unreliable annotators, a perspective barely touched in the existing literature.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>48407</offset><text>Limitations and Future Work.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>48436</offset><text>Despite the fact that we did not assume A1 or A2 and approached the problem of assessing the quality of crowdsourced data form an unusual angle, there are interesting questions left about the statistical model we employed.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>48659</offset><text>Some choices of parameters in the model are quite heuristic. The usage of our model requires pre-set values for certain parameters, e.g., γ, but we have not found theoretically pinned-down guidelines on how to choose those parameters. As a result, it is always subjective to some extent to declare a subject spammer. The ranking of reliability of subjects seems easier to accept. Where the cutoff should be will involve some manual checking on the result or will be determined by some other factors such as the desired cost of acquiring a certain amount of data.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>49226</offset><text>Although we have made great efforts to design various measures to evaluate our method, struggling to get around the issue of lacking an objective gold standard (its very existence has been questioned), these measures have limitations in one way or the other, as discussed in Section 3. We feel that due to the subjective nature of emotion responses to images, there is no simple and quick solution to this. The ultimate test of the method has to come from its usage in practice and a relatively long-term evaluation from the real-world.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>49763</offset><text>The effects of subgroup consistency, though varied from task to task, were random effects. We constructed the model this way to stretch its applicability because the number of responses collected per task in our empirical data was often small. Some related approaches (e.g., ) propose to estimate a difficulty/consistency parameter for each task, but often require a relatively large number of annotators per task. Which kind of probabilistic assumptions is more accurate or works better calls for future exploration.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>50281</offset><text>Only one “major” reliable mode was assumed at one time, and hereafter only the regularities conditioned on this mode are estimated. In another word, all the reliable users are assumed to behave consistently. One may ask whether there exist subgroups of reliable users who behave consistently within a group but differ across groups for reasons such as different demographic backgrounds. In our current model, if such “minor” reliable mode exists in a population, these subjects may be absorbed into the spammer group. Our model implicitly assumes that diversity in demography or in other aspects does not cause influential differences in emotion responses. Because of this, our method in dealing with culturally sensitive data is not well justified.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>51039</offset><text>Experimentally our method is only evaluated on one particular large data set. Evaluations on other affective data sets (when publicly available) are of interest.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>51201</offset><text>We have focused on the post analysis of collected data. As a future direction, it is of interest to examine the capacity of our approach to reduce time and cost in the practice of crowdsourcing using A/B test. We hereby briefly discuss an online heuristic strategy to dynamically allocate tasks to more reliable subjects. Recall that our model has two sets of parameters: parameter τi, indicating the reliability of subjects and parameter αi; βi, capturing the regularity. We can use the variance of distribution Beta (αi, βi) to determine how confident we are with the estimation of τi. For subject I, if the variance of Beta (αi, βi) is smaller than a threshold while τi is below a certain percentile, this subject is considered confidently unreliable and he/she may be excluded from the future subject pool.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>52039</offset><text>CONCLUSION</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>52050</offset><text>In this work, we developed a probabilistic model, namely Gated Latent Beta Allocation, to analyze the off-line consensus for crowdsourced affective data. Compared to the usual crowdsourcing settings, where reliable workers are supposed to have consensus, the consensus analysis of affective data is more challenging because of the innate variation in emotion responses even out of true feelings. To overcome this difficulty, our model estimates the reliability of subjects by exploiting the agreement relationships between their ratings at a global scale. The experiments show that the relational data based on the valence of human responses are more effective than the other emotion dimensions for identifying spammer subjects. By evaluating and comparing the new method with some standard methods in multiple ways, we find that the results have demonstrated clear advantages and the system seems ready for use in practice.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title_1</infon><offset>52975</offset><text>Supplementary Material</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">footnote</infon><offset>52998</offset><text>▷ For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>53133</offset><text>REFERENCES</text></passage><passage><infon key="name_0">surname:Barker;given-names:RG</infon><infon key="section_type">REF</infon><infon key="source">Ecological Psychology: Concepts and Methods for Studying
Environment Human Behavior</infon><infon key="type">ref</infon><infon key="year">1968</infon><offset>53144</offset></passage><passage><infon key="name_0">surname:Gibson;given-names:JJ</infon><infon key="section_type">REF</infon><infon key="source">The Senses Considered as Perceptual Systems</infon><infon key="type">ref</infon><infon key="year">1966</infon><offset>53145</offset></passage><passage><infon key="name_0">surname:Picard;given-names:RW</infon><infon key="name_1">surname:Picard;given-names:R</infon><infon key="section_type">REF</infon><infon key="source">Affective Computing</infon><infon key="type">ref</infon><infon key="volume">252</infon><infon key="year">1997</infon><offset>53146</offset></passage><passage><infon key="fpage">56</infon><infon key="issue">12</infon><infon key="lpage">67</infon><infon key="name_0">surname:Marsella;given-names:S</infon><infon key="name_1">surname:Gratch;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">Commun. ACM</infon><infon key="type">ref</infon><infon key="volume">57</infon><infon key="year">2014</infon><offset>53147</offset><text>Computationally modeling human emotion</text></passage><passage><infon key="fpage">288</infon><infon key="lpage">301</infon><infon key="name_0">surname:Datta;given-names:R</infon><infon key="name_1">surname:Joshi;given-names:D</infon><infon key="name_2">surname:Li;given-names:J</infon><infon key="name_3">surname:Wang;given-names:JZ</infon><infon key="section_type">REF</infon><infon key="source">Studying aesthetics in photographic images using a
computational approach</infon><infon key="type">ref</infon><infon key="year">2006</infon><offset>53186</offset></passage><passage><infon key="fpage">229</infon><infon key="lpage">238</infon><infon key="name_0">surname:Lu;given-names:X</infon><infon key="name_1">surname:Suryanarayan;given-names:P</infon><infon key="name_2">surname:Adams;given-names:RB</infon><infon key="name_3">surname:Li;given-names:J</infon><infon key="name_4">surname:Newman;given-names:MG</infon><infon key="name_5">surname:Wang;given-names:JZ</infon><infon key="section_type">REF</infon><infon key="source">On shape and the computability of
emotions</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>53187</offset></passage><passage><infon key="fpage">1</infon><infon key="issue">6</infon><infon key="lpage">4</infon><infon key="name_0">surname:Howe;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">Wired Mag</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2006</infon><offset>53188</offset><text>The rise of crowdsourcing</text></passage><passage><infon key="comment">Ph.D.
dissertation https://etda.libraries.psu.edu/catalog/28857</infon><infon key="name_0">surname:Lu;given-names:X</infon><infon key="section_type">REF</infon><infon key="source">Visual characteristics for computational prediction of
aesthetics and evoked emotions</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>53214</offset></passage><passage><infon key="fpage">20</infon><infon key="lpage">28</infon><infon key="name_0">surname:Dawid;given-names:AP</infon><infon key="name_1">surname:Skene;given-names:AM</infon><infon key="section_type">REF</infon><infon key="source">Appl.
Statist</infon><infon key="type">ref</infon><infon key="year">1979</infon><offset>53215</offset><text>Maximum likelihood estimation of observer error-rates using the em algorithm</text></passage><passage><infon key="fpage">167</infon><infon key="lpage">171</infon><infon key="name_0">surname:Hui;given-names:SL</infon><infon key="name_1">surname:Walter;given-names:SD</infon><infon key="pub-id_pmid">7370371</infon><infon key="section_type">REF</infon><infon key="source">Biometrics</infon><infon key="type">ref</infon><infon key="volume">36</infon><infon key="year">1980</infon><offset>53292</offset><text>Estimating the error rates of diagnostic tests</text></passage><passage><infon key="fpage">1085</infon><infon key="lpage">1092</infon><infon key="name_0">surname:Smyth;given-names:P</infon><infon key="name_1">surname:Fayyad;given-names:UM</infon><infon key="name_2">surname:Burl;given-names:MC</infon><infon key="name_3">surname:Perona;given-names:P</infon><infon key="name_4">surname:Baldi;given-names:P</infon><infon key="section_type">REF</infon><infon key="source">Proc. Adv. Neural
Inform. Process. Syst</infon><infon key="type">ref</infon><infon key="year">1995</infon><offset>53339</offset><text>Inferring ground truth from subjective labelling of venus images</text></passage><passage><infon key="fpage">469</infon><infon key="lpage">478</infon><infon key="name_0">surname:Demartini;given-names:G</infon><infon key="name_1">surname:Difallah;given-names:DE</infon><infon key="name_2">surname:Cudre-Mauroux;given-names:P</infon><infon key="section_type">REF</infon><infon key="source">Zencrowd: Leveraging probabilistic reasoning and
crowdsourcing techniques for large-scale entity linking</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>53404</offset></passage><passage><infon key="fpage">1297</infon><infon key="lpage">1322</infon><infon key="name_0">surname:Raykar;given-names:VC</infon><infon key="section_type">REF</infon><infon key="source">J. Mach. Learning Res</infon><infon key="type">ref</infon><infon key="volume">11</infon><infon key="year">2010</infon><offset>53405</offset><text>Learning from crowds</text></passage><passage><infon key="fpage">692</infon><infon key="lpage">700</infon><infon key="name_0">surname:Liu;given-names:Q</infon><infon key="name_1">surname:Peng;given-names:J</infon><infon key="name_2">surname:Ihler;given-names:AT</infon><infon key="section_type">REF</infon><infon key="source">Proc. Adv. Neural Inform.
Process. Syst</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>53426</offset><text>Variational inference for crowdsourcing</text></passage><passage><infon key="fpage">491</infon><infon key="issue">1</infon><infon key="lpage">518</infon><infon key="name_0">surname:Raykar;given-names:VC</infon><infon key="name_1">surname:Yu;given-names:S</infon><infon key="section_type">REF</infon><infon key="source">J. Mach.
Learning Res</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2012</infon><offset>53466</offset><text>Eliminating spammers and ranking annotators for crowdsourced labeling tasks</text></passage><passage><infon key="fpage">2035</infon><infon key="lpage">2043</infon><infon key="name_0">surname:Whitehill;given-names:J</infon><infon key="name_1">surname:Wu;given-names:T-F</infon><infon key="name_2">surname:Bergsma;given-names:J</infon><infon key="name_3">surname:Movellan;given-names:JR</infon><infon key="name_4">surname:Ruvolo;given-names:PL</infon><infon key="section_type">REF</infon><infon key="source">Proc. Adv. Neural Inform. Process.
Syst</infon><infon key="type">ref</infon><infon key="year">2009</infon><offset>53542</offset><text>Whose vote should count more: Optimal integration of labels from labelers of unknown expertise</text></passage><passage><infon key="fpage">156</infon><infon key="lpage">164</infon><infon key="name_0">surname:Sheshadri;given-names:A</infon><infon key="name_1">surname:Lease;given-names:M</infon><infon key="section_type">REF</infon><infon key="source">Square: A benchmark for research on computing crowd
consensus</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>53637</offset></passage><passage><infon key="fpage">8</infon><infon key="issue">397</infon><infon key="lpage">19</infon><infon key="name_0">surname:Wang;given-names:YJ</infon><infon key="name_1">surname:Wong;given-names:GY</infon><infon key="section_type">REF</infon><infon key="source">J. Amer. Stat. Assoc</infon><infon key="type">ref</infon><infon key="volume">82</infon><infon key="year">1987</infon><offset>53638</offset><text>Stochastic blockmodels for directed graphs</text></passage><passage><infon key="fpage">1077</infon><infon key="issue">455</infon><infon key="lpage">1087</infon><infon key="name_0">surname:Nowicki;given-names:K</infon><infon key="name_1">surname:Snijders;given-names:TAB</infon><infon key="section_type">REF</infon><infon key="source">J. Amer. Stat.
Assoc</infon><infon key="type">ref</infon><infon key="volume">96</infon><infon key="year">2001</infon><offset>53681</offset><text>Estimation and prediction for stochastic blockstructures</text></passage><passage><infon key="fpage">1090</infon><infon key="issue">460</infon><infon key="lpage">1098</infon><infon key="name_0">surname:Hoff;given-names:PD</infon><infon key="name_1">surname:Raftery;given-names:AE</infon><infon key="name_2">surname:Handcock;given-names:MS</infon><infon key="section_type">REF</infon><infon key="source">J. Amer. Stat. Assoc</infon><infon key="type">ref</infon><infon key="volume">97</infon><infon key="year">2002</infon><offset>53738</offset><text>Latent space approaches to social network analysis</text></passage><passage><infon key="fpage">33</infon><infon key="lpage">40</infon><infon key="name_0">surname:Airoldi;given-names:EM</infon><infon key="name_1">surname:Blei;given-names:DM</infon><infon key="name_2">surname:Fienberg;given-names:SE</infon><infon key="name_3">surname:Xing;given-names:EP</infon><infon key="section_type">REF</infon><infon key="source">Proc. Advances Neural
Inform. Process. Syst</infon><infon key="type">ref</infon><infon key="year">2009</infon><offset>53789</offset><text>Mixed membership stochastic blockmodels</text></passage><passage><infon key="fpage">1719</infon><infon key="lpage">1726</infon><infon key="name_0">surname:Kim;given-names:M</infon><infon key="name_1">surname:Leskovec;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">Latent multi-group membership graph
model</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>53829</offset></passage><passage><infon key="fpage">381</infon><infon key="lpage">388</infon><infon key="name_0">surname:Kemp;given-names:C</infon><infon key="name_1">surname:Tenenbaum;given-names:JB</infon><infon key="name_2">surname:Griffiths;given-names:TL</infon><infon key="name_3">surname:Yamada;given-names:T</infon><infon key="name_4">surname:Ueda;given-names:N</infon><infon key="section_type">REF</infon><infon key="source">Learning systems of concepts with an infinite
relational model</infon><infon key="type">ref</infon><infon key="year">2006</infon><offset>53830</offset></passage><passage><infon key="comment">10 687–10 692</infon><infon key="issue">31</infon><infon key="name_0">surname:Kemp;given-names:C</infon><infon key="name_1">surname:Tenenbaum;given-names:JB</infon><infon key="section_type">REF</infon><infon key="source">Proc. Nat. Academy Sci. United States
America</infon><infon key="type">ref</infon><infon key="volume">105</infon><infon key="year">2008</infon><offset>53831</offset><text>The discovery of structural form</text></passage><passage><infon key="fpage">183</infon><infon key="issue">2</infon><infon key="lpage">233</infon><infon key="name_0">surname:Jordan;given-names:MI</infon><infon key="name_1">surname:Ghahramani;given-names:Z</infon><infon key="name_2">surname:Jaakkola;given-names:TS</infon><infon key="name_3">surname:Saul;given-names:LK</infon><infon key="section_type">REF</infon><infon key="source">Mach. Learning</infon><infon key="type">ref</infon><infon key="volume">37</infon><infon key="year">1999</infon><offset>53864</offset><text>An introduction to variational methods for graphical models</text></passage><passage><infon key="fpage">453</infon><infon key="lpage">464</infon><infon key="name_0">surname:Bernardo;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">Bayesian Stat</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2003</infon><offset>53924</offset><text>The variational Bayesian em algorithm for incomplete data: With application to scoring graphical model structures</text></passage><passage><infon key="name_0">surname:Johnson;given-names:NL</infon><infon key="name_1">surname:Kotz;given-names:S</infon><infon key="name_2">surname:Balakrishnan;given-names:N</infon><infon key="section_type">REF</infon><infon key="source">Continuous Univariate
Distributions</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">1995</infon><offset>54038</offset></passage><passage><infon key="fpage">752</infon><infon key="issue">5</infon><infon key="lpage">775</infon><infon key="name_0">surname:Gentner;given-names:D</infon><infon key="section_type">REF</infon><infon key="source">Cognitive Sci</infon><infon key="type">ref</infon><infon key="volume">34</infon><infon key="year">2010</infon><offset>54039</offset><text>Bootstrapping the mind: Analogical processes and symbol systems</text></passage><passage><infon key="fpage">261</infon><infon key="issue">2</infon><infon key="lpage">283</infon><infon key="name_0">surname:Gentner;given-names:D</infon><infon key="name_1">surname:Christie;given-names:S</infon><infon key="section_type">REF</infon><infon key="source">Language
Cognition</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2010</infon><offset>54103</offset><text>Mutual bootstrapping between language and analogical processing</text></passage><passage><infon key="file">nihms-1022340-f0001.jpg</infon><infon key="id">F1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>54167</offset><text>An example illustrating one may need to acquire more reliable labels,
ensuring the image confidence is more than 0.9.</text></passage><passage><infon key="file">nihms-1022340-f0002.jpg</infon><infon key="id">F2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>54285</offset><text>Images shown are considered of lower valence than their average valence
ratings (i.e., evoking a higher degree of negative emotions) after processing
the data set using our proposed method. Our method eliminates the contamination
introduced by spammers. The range of valence ratings is between 0 and 8.</text></passage><passage><infon key="file">nihms-1022340-f0003.jpg</infon><infon key="id">F3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>54588</offset><text>Images shown are considered of higher valence than their average
valence ratings (i.e., evoking a higher degree of positive emotions) after
processing the data set using our propose method. Our method again eliminates
the contamination introduced by spammers. The range of valence ratings is
between 0 and 8.</text></passage><passage><infon key="file">nihms-1022340-f0004.jpg</infon><infon key="id">F4</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>54897</offset><text>Probabilistic graphical model of the proposed Gated Latent Beta
Allocation.</text></passage><passage><infon key="file">nihms-1022340-f0005.jpg</infon><infon key="id">F5</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>54973</offset><text>(a) Reliability scores versus γ ∈
[0.3,0.48] for the top 15 users who provided the most numbers of ratings. (b)
Visualization of the estimated regularity parameters of each worker at a given
γ. Green dots are for workers with high reliability
and red dots for low reliability. The slope of the red line equals
γ.</text></passage><passage><infon key="file">nihms-1022340-f0006.jpg</infon><infon key="id">F6</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>55298</offset><text>Normalized histogram of basic statistics including total number of
tasks completed and average time duration spent at each of the two stages per
task.</text></passage><passage><infon key="file">nihms-1022340-f0007.jpg</infon><infon key="id">F7</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>55449</offset><text>The agnostic Precision-Recall curve (by valence) based on manually
annotated spammers. The top 20, top 40 and top 60 precision is 100, 95, 78
percent respectively (black line). It is expected that precision drops quickly
with increasing recalls, because the manually annotation process can only
identify a special type of spammers, while other types of spammers can be
identified by the algorithm. The PR curves at γ =
0.3,0.37,0.44 are also plotted. Two baselines are compared: the Dawid and Skene
(DS) approach and the time duration based approach.</text></passage><passage><infon key="file">nihms-1022340-f0008.jpg</infon><infon key="id">F8</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>56004</offset><text>The agnostic Precision-Recall curve based on manually annotated
spammers computed from different affective dimensions: valence, arousal,
dominance, and likeness.</text></passage><passage><infon key="file">nihms-1022340-f0009.jpg</infon><infon key="id">F9</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>56166</offset><text>The histogram distribution of estimated worker reliabilities
τ and statistics of simulated spammers based on 10
repeated runs, each with 10 spammers injected.</text></passage><passage><infon key="file">nihms-1022340-f0010.jpg</infon><infon key="id">F10</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>56327</offset><text>The histogram of image confidences estimated based on our method. About
85 percent of images have a confidence scores higher than 90 percent.</text></passage><passage><infon key="file">nihms-1022340-f0011.jpg</infon><infon key="id">F11</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>56469</offset><text>Left: Overhead curve based on subject filtering; Right: overhead curve
based on image filtering. The overhead is quantified by the number of labels
discarded after filtering.</text></passage><passage><infon key="file">T2.xml</infon><infon key="id">T2</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>56644</offset><text>Symbols and Descriptions of Parameters, Random Variables, and
Statistics</text></passage><passage><infon key="file">T2.xml</infon><infon key="id">T2</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Symbols&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Descriptions&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;italic&gt;O&lt;sub&gt;i&lt;/sub&gt;&lt;/italic&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;subject &lt;italic&gt;i&lt;/italic&gt;&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;italic&gt;τ&lt;/italic&gt;
              &lt;sub&gt;
                &lt;italic&gt;i&lt;/italic&gt;
              &lt;/sub&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;rate of subject reliability&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;italic&gt;α&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt;,
&lt;italic&gt;β&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt;&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;shape of subject regularity&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;italic&gt;γ&lt;/italic&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;rate of agreement by chance&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Θ&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;union of parameters&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;inline-formula&gt;
                &lt;mml:math display=&quot;inline&quot; id=&quot;M78&quot; overflow=&quot;scroll&quot;&gt;
                  &lt;mml:mrow&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mi&gt;T&lt;/mml:mi&gt;
                      &lt;mml:mi&gt;j&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                  &lt;/mml:mrow&gt;
                &lt;/mml:math&gt;
              &lt;/inline-formula&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;whether
&lt;italic&gt;O&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;j&lt;/italic&gt;&lt;/sub&gt; reliably
response&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;inline-formula&gt;
                &lt;mml:math display=&quot;inline&quot; id=&quot;M79&quot; overflow=&quot;scroll&quot;&gt;
                  &lt;mml:mrow&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mi&gt;J&lt;/mml:mi&gt;
                      &lt;mml:mi&gt;i&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                  &lt;/mml:mrow&gt;
                &lt;/mml:math&gt;
              &lt;/inline-formula&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;rate of
&lt;italic&gt;O&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt; agreeing with
other reliable responses&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;inline-formula&gt;
                &lt;mml:math display=&quot;inline&quot; id=&quot;M80&quot; overflow=&quot;scroll&quot;&gt;
                  &lt;mml:mrow&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mi&gt;I&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mi&gt;i&lt;/mml:mi&gt;
                        &lt;mml:mo&gt;,&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;j&lt;/mml:mi&gt;
                      &lt;/mml:mrow&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                  &lt;/mml:mrow&gt;
                &lt;/mml:math&gt;
              &lt;/inline-formula&gt;
            &lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;whether
&lt;italic&gt;O&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt; agrees with the
responses from &lt;italic&gt;O&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;j&lt;/italic&gt;&lt;/sub&gt;&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;inline-formula&gt;
                &lt;mml:math display=&quot;inline&quot; id=&quot;M81&quot; overflow=&quot;scroll&quot;&gt;
                  &lt;mml:mrow&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mi&gt;ω&lt;/mml:mi&gt;
                      &lt;mml:mi&gt;i&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                    &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                    &lt;mml:mo&gt;⋅&lt;/mml:mo&gt;
                    &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                  &lt;/mml:mrow&gt;
                &lt;/mml:math&gt;
              &lt;/inline-formula&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;cumulative degree of responses agreed by
&lt;italic&gt;O&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;i&lt;/italic&gt;&lt;/sub&gt;&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;inline-formula&gt;
                &lt;mml:math display=&quot;inline&quot; id=&quot;M82&quot; overflow=&quot;scroll&quot;&gt;
                  &lt;mml:mrow&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mi&gt;ψ&lt;/mml:mi&gt;
                      &lt;mml:mi&gt;i&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                    &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                    &lt;mml:mo&gt;⋅&lt;/mml:mo&gt;
                    &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                  &lt;/mml:mrow&gt;
                &lt;/mml:math&gt;
              &lt;/inline-formula&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;cumulative degree of responses&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;inline-formula&gt;
                &lt;mml:math display=&quot;inline&quot; id=&quot;M83&quot; overflow=&quot;scroll&quot;&gt;
                  &lt;mml:mrow&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mi&gt;r&lt;/mml:mi&gt;
                      &lt;mml:mi&gt;j&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                    &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                    &lt;mml:mo&gt;⋅&lt;/mml:mo&gt;
                    &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                  &lt;/mml:mrow&gt;
                &lt;/mml:math&gt;
              &lt;/inline-formula&gt;
            &lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;a ratio amplifies or discounts the
reliability of &lt;italic&gt;O&lt;/italic&gt;&lt;sub&gt;&lt;italic&gt;j&lt;/italic&gt;&lt;/sub&gt;&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;inline-formula&gt;
                &lt;mml:math display=&quot;inline&quot; id=&quot;M84&quot; overflow=&quot;scroll&quot;&gt;
                  &lt;mml:mrow&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mover accent=&quot;true&quot;&gt;
                        &lt;mml:mi&gt;τ&lt;/mml:mi&gt;
                        &lt;mml:mo&gt;˜&lt;/mml:mo&gt;
                      &lt;/mml:mover&gt;
                      &lt;mml:mi&gt;i&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                  &lt;/mml:mrow&gt;
                &lt;/mml:math&gt;
              &lt;/inline-formula&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;sufficient statistics of posterior
&lt;inline-formula&gt;&lt;mml:math display=&quot;inline&quot; id=&quot;M85&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;T&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;, given &lt;inline-formula&gt;&lt;mml:math display=&quot;inline&quot; id=&quot;M86&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;Θ&lt;/mml:mi&gt;&lt;mml:mo&gt;˜&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;inline-formula&gt;
                &lt;mml:math display=&quot;inline&quot; id=&quot;M87&quot; overflow=&quot;scroll&quot;&gt;
                  &lt;mml:mrow&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mover accent=&quot;true&quot;&gt;
                        &lt;mml:mi&gt;α&lt;/mml:mi&gt;
                        &lt;mml:mo&gt;˜&lt;/mml:mo&gt;
                      &lt;/mml:mover&gt;
                      &lt;mml:mi&gt;i&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                    &lt;mml:mo&gt;,&lt;/mml:mo&gt;
                    &lt;mml:msubsup&gt;
                      &lt;mml:mover accent=&quot;true&quot;&gt;
                        &lt;mml:mi&gt;β&lt;/mml:mi&gt;
                        &lt;mml:mo&gt;˜&lt;/mml:mo&gt;
                      &lt;/mml:mover&gt;
                      &lt;mml:mi&gt;i&lt;/mml:mi&gt;
                      &lt;mml:mrow&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;
                        &lt;mml:mi&gt;k&lt;/mml:mi&gt;
                        &lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;
                      &lt;/mml:mrow&gt;
                    &lt;/mml:msubsup&gt;
                  &lt;/mml:mrow&gt;
                &lt;/mml:math&gt;
              &lt;/inline-formula&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;sufficient statistics of posterior
&lt;inline-formula&gt;&lt;mml:math display=&quot;inline&quot; id=&quot;M88&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msubsup&gt;&lt;mml:mi&gt;J&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;mml:mo stretchy=&quot;false&quot;&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msubsup&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;, given &lt;inline-formula&gt;&lt;mml:math display=&quot;inline&quot; id=&quot;M89&quot; overflow=&quot;scroll&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mover accent=&quot;true&quot;&gt;&lt;mml:mi mathvariant=&quot;normal&quot;&gt;Θ&lt;/mml:mi&gt;&lt;mml:mo&gt;˜&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>56717</offset><text>Symbols	Descriptions	 	Oi	subject i	 	τi	rate of subject reliability	 	αi,	 	βi	shape of subject regularity	 	γ	rate of agreement by chance	 	Θ	union of parameters	 		whether	 	Oj reliably	 	response	 		rate of	 	Oi agreeing with	 	other reliable responses	 		whether	 	Oi agrees with the	 	responses from Oj	 		cumulative degree of responses agreed by	 	Oi	 		cumulative degree of responses	 		a ratio amplifies or discounts the	 	reliability of Oj	 		sufficient statistics of posterior	 	, given 	 		sufficient statistics of posterior	 	, given 	 	</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>57285</offset><text>Oracles in the AMT Data Set</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; frame=&quot;void&quot; rules=&quot;none&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot;&gt;
              &lt;graphic xlink:href=&quot;nihms-1022340-t0012&quot;/&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>57313</offset><text>	 	</text></passage></document></collection>
