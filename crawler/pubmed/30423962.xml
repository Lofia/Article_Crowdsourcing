<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20201221</date><key>pmc.key</key><document><id>6263868</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.3390/s18113845</infon><infon key="article-id_pmc">6263868</infon><infon key="article-id_pmid">30423962</infon><infon key="article-id_publisher-id">sensors-18-03845</infon><infon key="elocation-id">3845</infon><infon key="issue">11</infon><infon key="kwd">smartphone sensors road surface anomaly crowdsourcing</infon><infon key="license">Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).</infon><infon key="name_0">surname:Sattar;given-names:Shahram</infon><infon key="name_1">surname:Li;given-names:Songnian</infon><infon key="name_2">surname:Chapman;given-names:Michael</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">18</infon><infon key="year">2018</infon><offset>0</offset><text>Road Surface Monitoring Using Smartphone Sensors: A Review</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>59</offset><text>Road surface monitoring is a key factor to providing smooth and safe road infrastructure to road users. The key to road surface condition monitoring is to detect road surface anomalies, such as potholes, cracks, and bumps, which affect driving comfort and on-road safety. Road surface anomaly detection is a widely studied problem. Recently, smartphone-based sensing has become increasingly popular with the increased amount of available embedded smartphone sensors. Using smartphones to detect road surface anomalies could change the way government agencies monitor and plan for road maintenance. However, current smartphone sensors operate at a low frequency, and undersampled sensor signals cause low detection accuracy. In this study, current approaches for using smartphones for road surface anomaly detection are reviewed and compared. In addition, further opportunities for research using smartphones in road surface anomaly detection are highlighted.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1018</offset><text>1. Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1034</offset><text>Recently, the monitoring of road surface conditions has become considerably important. Well-maintained road surfaces increase road user safety and comfort levels. Therefore, it is essential to monitor road conditions continuously to enhance the transportation system in terms of driving safety and comfort. For instance, in Canada, authorities responsible for road surface maintenance have to deal with complaints concerning the poor surface conditions of roadways, particularly during the winter months. One of the main indicators used to determine road surface conditions is the density of road surface anomalies. Municipalities typically rely on statistical data derived from collected road surface information, visual field inspections, or vehicles outfitted with special instruments which measure and monitor road surface conditions. For example, ARAN (Automated Road Analyzer), which is widely used for road monitoring in Canada, and ROMDAS (Road Measurement Data Acquisition System), which is used to monitor road surfaces in New Zealand, both use lasers combined with ultrasonic and video sensors for high-level road quality assessment. However, these methods are labor-intensive, costly, and often suffer from insufficient data coverage to generate a complete picture of road surface conditions in large cities, such as Toronto, Canada. For the above reasons, road maintenance authorities are looking for a low-cost, higher-efficiency detection method. They also desire a centralized information system able to monitor the road status in real time. Traditionally, there have been three main approaches for road surface monitoring: 3D reconstruction, vibration, and vision-based.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2722</offset><text>A 3D reconstruction approach relies on 3D laser scanning to create accurate surface models. These models are then compared to a base model to detect road surface anomalies. In this approach, a 3D laser scanner uses reflected laser pulses, which create accurate 3D digital models of existing objects, such as road surface anomalies. Subsequently, the distress features (road surface anomalies) are extracted from the created point clouds (i.e., a collection of points that represent a 3D shape of road surface distress). This approach was widely investigated by Kelvin, Vijay and Arya, Salari et al., Moazzam et al., Hou et al., Kim and Ryu, Wang et al., and Yan et al.. However, the aforementioned approaches require high-cost laser scanners and are very costly when monitoring large-scale road networks.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3527</offset><text>A vision-based approach relies on image processing analysis, such as texture extraction and comparison using captured photographs depicting pavement distress features. The principle of this approach primarily utilizes geotagged images captured by a camera/video system mounted facing downward toward the road surface on a moving vehicle. Any suspicious road surface distress features, including potholes and cracks, can be automatically detected from the collected geotagged video images by applying, for example, a Canny edge detection process. Vision-based approaches were extensively evaluated by Koch et al., Jog et al., Huidrom et al., Lokeshwor et al., and Yan and Yuan. Even though these approaches are cost-effective compared to 3D reconstruction approaches, they depend on certain environmental conditions, such as lighting and shadow influence, etc.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4387</offset><text>With a vibration-based approach, road surface anomalies are detected from the rate of moving vehicles’ vibrations captured by motion sensors (e.g., accelerometers or gyroscopes). Theoretically, a vehicle, when passing over any road surface anomaly, such as a pothole, crack, manhole, or expansion joint, will vibrate more than when passing over smooth road surfaces.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4756</offset><text>Over the last few years, smartphone-based sensing has become an important supplemental technique for detecting road surface anomalies in order to monitor the surface of the road segments or the surface of bicycle and pedestrian lanes. Participatory sensing is anticipated to be an emerging area in which smartphone-based measurements seem to be particularly attractive, as they are not only widespread but also equipped with several sensing capabilities. Measuring and analyzing motion sensors’ signal data from various types of moving smartphones may diverge depending on many factors, including the sensor’s characteristics and quality, smartphone device’s position, vehicle’s suspension system, and speed.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5473</offset><text>This paper aims to provide a comprehensive review of the existing studies that investigate how smartphone sensors may help detect road surface anomalies by synthesizing the problems, major issues, and challenges in current development, as well as identifying the existing research voids for further research studies. Therefore, the inclusion criteria for the articles in this paper were the evaluation of existing approaches using smartphone sensor data for road surface anomaly detection. In addition, articles that have no focus on the application of smartphone sensors or those using handheld computer devices other than smartphones, such as PDAs (personal digital assistants), or those using low-end accelerometer kits were excluded from this review. It is important to note that there are other studies that also address the application of monitoring road and traffic conditions using smartphones. However, only the parts of these studies that relate to the scope of this paper are considered and reviewed.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6485</offset><text>This paper is organized as follows. Section 2 compares related work according to the overall workflow of detecting road surface anomalies from smartphone sensors, followed by a review of parameters affecting the performance of the detection and integration approaches. Section 3 presents a brief discussion of the reviewed articles and their limitations as a comprehensive approach. Conclusions and the challenges of detecting road surface anomalies from smartphone sensors, as well as potential future research areas, are given in Section 4.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>7028</offset><text>2. Related Work</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7044</offset><text>Measuring the signals from smartphone sensors is challenging due to dissimilar sensor properties between various models of smartphones, as well as differences in vehicle size, weight, length, and suspension systems. There is also a difference in a vehicle’s vertical motion induced by road surface anomalies—the length, depth, and shape of the potholes on the road surface and the road curvature’s effect on the vertical movement rate of different vehicles. In fact, different vehicles passing over a specific pothole would not generate an identical signal pattern. In addition, vehicle velocities affect the vertical movement rate, which then leads to different patterns of the vibration response to any road surface anomaly.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7777</offset><text>Road surface anomaly detection approaches consist mainly of five steps: (1) sensing (data collection), (2) preprocessing, (3) processing for feature extraction, (4) post-processing, and (5) performance evaluations. Figure 1 illustrates the overall process for road surface anomaly detection using smartphone sensors.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8094</offset><text>There are different kinds of sensor data that can be obtained from smartphone sensors. Motion sensor types include: accelerometer, gyroscope, linear accelerometer, and rotation. Position sensor types include: GPS, manometer, and rotation. The next step is the preprocessing of sensor data, with the aim of filtering noises that contaminated the sensor data. The other goal of preprocessing sensor data is to reorient them from the device coordinate system to another geographic coordinate system. The preprocessed sensor data are then analyzed to discover and extract desired information based on predefined rules (feature extraction). After that, the processed sensor data should be transferred to the central server for data post-processing, including integration with other data from different sources (concept of crowdsourcing). Finally, the performance of the proposed process should be evaluated to determine its functionality and reliability.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9044</offset><text> Sensor Data Collection </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9069</offset><text>The smartphone sensor framework has open access to many types of built-in sensors. Some of these sensors are hardware-based (physical) and some are software-based (virtual). Hardware-based sensors are the physical, built-in sensors, such as accelerometers, gyroscopes, magnetometers, light, temperature, etc. Physical sensors measure motion, orientation, and environmental conditions, such as acceleration force, physical position of device, illumination, etc. In contrast, software-based sensors use data from one or more of the hardware-based sensors and virtually calculate real-time values based on the desired outcome, such as linear acceleration, rotation, gravity, etc. In general, smartphone sensors can be categorized into three different types: motion sensors, position sensors, and environmental sensors.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9885</offset><text>Motion sensors are suitable for monitoring a device’s movement and vibration, tilt, shake, rotation, or swing. The movements can directly reflect user interaction, as typically happens in game applications (i.e., a user steering a car or a controlling a ball in a game). However, they can also reflect where the device is sitting (i.e., moving with the occupant while they drive their car). With direct user interaction, device movement is monitored relative to the device’s coordinate system or a defined local application frame. With physical environmental conditions, the device movement is monitored relative to the local-level coordinate system (Figure 2).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10551</offset><text>Position sensors are suitable for specifying a device’s physical position in the local-level coordinate system. In fact, the geomagnetic field sensor, in combination with accelerometer sensor data, can determine a device’s position relative to the local-level coordinate system. Environmental sensors measure the environmental properties of the surrounding area, such as temperature, humidity, ambient pressure, and illuminance. This type of sensor has a very limited contribution to road surface anomaly detection, since there does not seem to be any direct relationship/impact between these factors and the formation of road surface anomalies.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11201</offset><text>For each smartphone-based application, various combinations of sensors (physical or virtual) may be used depending on the desired application criteria. To develop an application for road surface anomaly detection, motion sensor data can be tracked to detect any possible shake or tilt caused by road surface anomalies in a moving vehicle. Previous studies investigating road surface anomaly detection using smartphone sensors have widely employed motions sensors (accelerometers and gyroscopes). Accelerometer sensors measure acceleration force, including gravity force, applied to a device on all three physical axes (m/s2). Gyroscope sensors measure a device’s rate of rotation around each of the three physical axes (rad/s). Previous studies have frequently used accelerometer sensor data to detect anomalies because road surface anomalies have more influence on and are mainly detectable from the acceleration force applied to the vehicles, rather than the rotation rate caused by vehicles’ vibration. Only a few studies, including Yagi and Douangphachanh and Oneyama, have investigated gyroscope sensor data, particularly frequency domain combined with accelerometer sensor data, which increases the accuracy of detection (as complementary sensor data).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>12464</offset><text>To determine the current location information of smartphone or mobile devices, including latitude, longitude, bearing of moving direction, and velocity of movement, the location API (application program interface) provides the best available location information of the devices based on the currently available location providers, such as GPS (Global Positioning System) and/or Wi-Fi (Global Positioning System). In addition, the API provides the accuracy for each provided location information data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>12965</offset><text>Table 1 summarizes and compares a list of sensors commonly found in smartphones for the application of road surface anomalies. These sensors are used either directly or indirectly for road surface anomaly detection.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>13181</offset><text> Pre-Processing </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>13198</offset><text>The data preprocessing step involves transforming raw data derived from smartphone sensors into a clean and organized data set prior to analysis. One of the goals of preprocessing is to smooth the raw sensor data and filter the noise. There are three major types of smoothing and filtering approaches: moving-average filtering, low-/high-pass filtering, and band-pass filtering. Moving-average filtering is the most common filter in digital signal processing, mainly because it is the easiest to understand and implement since there is no need to have any prior information regarding the sensor data. Despite its simplicity, this kind of filter is ideal for some common tasks, such as reducing random noise while retaining major information content. Low-/high-pass filters remove some undesired parts of signals based on a predetermined cut of frequencies. A band-pass filter passes portions of the signals within a certain range of frequencies and removes the other parts of signals that are outside of that range.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14214</offset><text>Preprocessing may also aim to reorient sensor data values from a device coordinate system (Figure 2c) to the local-level coordinate system (Figure 2a). An example would be a body-frame (i.e., moving platform) coordinate system (Figure 2b). This process can be accomplished by completing a rotation (using Euler angles) around each of the three axes. The reorientation process reduces issues related to smartphone placement.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14638</offset><text> Processing </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14651</offset><text>The threshold-based approach uses simple predefined threshold values based on experiments to detect road surface anomalies from sensor data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14792</offset><text>The machine learning approach uses more advanced techniques to detect road surface anomalies. Studies Bhoraskar et al. have investigated unsupervised approaches, such as k-means clustering, in which a predetermined number of clusters are identified, and data are classified to the same number of clusters. Some other studies, including Perttunen et al. and Jain et al., have explored supervised approaches, such as support vector machine (SVM) clustering. In the case of supervised approaches, some training data sets should be collected to train the algorithm. The test data are then classified based on the trained data set.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15419</offset><text>Another approach that was recently investigated is dynamic time warping (DTW). This approach is predominantly employed in speech recognition studies. DTW compares incoming signal data with predefined templates and measures the similarity between the data sets.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15680</offset><text>The processing step analyzes the preprocessed sensor values to detect road surface anomalies. The signal pattern is tracked to detect any abnormal changes in sensor values using three main approaches:</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15881</offset><text>Regarding smartphone applications, the preprocessing and processing steps can be accomplished using two different modes: online and offline. In an offline mode, sensor data are collected, and the preprocessing and processing steps are applied locally on computers. In fact, any application developed for sensor data collection is able to collect and store sensor data while a car is passing over potholes or bumps. Next, the sensor data are extracted for further processing. In an online mode, data collection, preprocessing, and processing are performed simultaneously as the car is passing over potholes or bumps. Ideally, a specific smartphone application should be designed and developed to collect, preprocess, and process the sensor data in an online mode.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>16644</offset><text> Post-Processing </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>16662</offset><text>Post-processing includes crowdsourcing and integrating data from multiple sources (users’ collaborations, geographic datasets) to increase the accuracy of detection and scalability. Detection results from various users can be integrated (data fusion), enabling more reliable and precise detection. Due to the dynamic behavior of road surface anomalies, integrating the detection results from various users at different times can help evaluate a road surface anomaly’s condition more precisely than in the spatiotemporal domain. Moreover, other geographic data, such as road networks, manhole, and catchment basin location data, can be integrated through filtration or data analysis to increase the accuracy of the results. As an example, manholes and road joints behave similarly to road surface anomalies in sensor data. Therefore, if the geolocation of man-made anomalies is integrated, sensor-detected road surface anomalies (i.e., the manholes or joints in this case) are subsequently able to be filtered.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>17676</offset><text>The central server stores incoming data while also processing parallel incoming data from multiple sources. The completed central processed data can be presented as a geospatial information system (GIS) web-based map to the general users or authorities dealing with road surface maintenance.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>17968</offset><text>2.1. Sensor Data Collection</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>17996</offset><text>A major step in developing a viable approach that can detect road surface anomalies is the collection of sample sensor data from smartphones’ sensors. As discussed earlier, motion sensors, such as accelerometers and gyroscopes, have been widely used in the collection and processing of data for road surface anomaly detection. Data collection from previous studies (refer to Table 2) differ in terms of the types of sensors being employed, sampling rates, variety of vehicle, and devices considered for the data collection. These indicated factors are the most critical parameters that impact the performance of a smartphone’s ability to detect road surface anomalies. Table 2 summarizes the sensor data collection properties reviewed in the selected studies.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>18760</offset><text>According to Table 2, accelerometer sensors have been widely investigated as a means to develop an approach to detect road surface anomalies. In most previous studies, accelerometer sensor data were investigated in the time domain for detecting road surface anomalies. However, gyroscope sensor data were transformed to the frequency domain for feature extraction (road surface anomaly detection). Moreover, most of the previous studies only employed accelerometer sensors to detect road surface anomalies. However, Yagi, Douangphachanh and Oneyama, and Mohamed et al. attempted to combine gyroscope and accelerometer sensor data to increase detection accuracy using a data fusion technique.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>19452</offset><text>Data sampling rates play a significant role in the processing of any detected event. Choosing an appropriate sampling rate is a design decision affected by multiple factors, such as: available resources, required accuracy, and the type of data being used for event recognition. As an example, if only frequency domain features are used for monitoring road anomalies, the sampling rate should be high enough to capture all relevant frequencies. According to Douangphachanh and Oneyama, the road anomalies most likely have the frequency range of 40–50 Hz are captured in accelerometer data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>20043</offset><text>A higher sampling rate increases the chances of capturing and detecting road surface distress features. However, it also increases the battery usage of a smartphone, as well as the required capacity to store and process data. Finding proper sampling rates is related to the speed of movement, as well as the mechanical properties of a vehicle. Sinharay et al. investigated the use of a low sampling rate to develop their approach to road surface anomaly detection.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>20508</offset><text>Various models of vehicles and smartphone devices are factors considered by previous studies when collecting data. According to Table 2, Douangphachanh and Oneyama and Jain et al. studied both different vehicles (e.g., sedan, SUV, trucks) and smartphones (i.e., different manufactures) to ensure their approaches functioned equally in different circumstances.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>20868</offset><text>2.2. Sensor Data Preprocessing</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>20899</offset><text>The preprocessing of sensor data values is important for two major reasons: filtering noise that distorts parts of the signal; data cleaning and sensor data reorientation. Not all the reviewed studies preprocessed the sensor data. Some reviewed studies only conducted noise filtering and data smoothing approaches as their preprocessing step while some other studies only conducted signal data transformation before processing them. Sebestyen et al. and Seraj et al. utilized two different filters: one for eliminating noise, and one for amplifying acceleration variation caused by road anomalies. Douangphachanh and Oneyama used a high-pass filter to detect low-frequency information, such as changing speed and vehicle maneuvering and turning, which have lower frequencies than road surface anomalies from sensor data. Mohamed et al. applied the second order high-pass butterworth filter proposed by Butterworth. Harikrishnan and Gopi collected data segmented into groups of n-samples. Then, a filtering process was conducted to preserve data samples induced by potholes or speed bumps, as well as to minimize the parts of sensor data corresponding to normal roads. To smooth the signal data, Singh et al. (2017) applied a simple moving-average and band-pass filter to smooth accelerometer sensor data values before processing them. The approaches proposed by Mohan et al., Bhoraskar et al., Vittorio et al., Sebestyen et al., Wang et al., and Singh et al. entailed the application of Euler angles (rotation angles) calculated from accelerometer sensor data to transform the signal data values from device coordinate systems to the local-level coordinate system orientation using a coordinate transformation technique. Silva et al. applied a data cleaning process by eliminating all null sensor data values and inconsistent timestamp data values before processing them.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>22771</offset><text>2.3. Sensor Data Processing</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>22799</offset><text>Processing sensor values for the application of road surface anomaly detection has three main approaches: threshold-based, machine learning, and DTW. Table 3 summarizes the approaches used by previous studies when processing sensor data and detecting abnormal changes in signal data. Data processing in this application can be reviewed in terms of the feature extraction approach (e.g., threshold-based, machine learning, and DTW), ability to classify road surface anomalies (anomaly classification capability), smartphone orientation dependency in detection, and speed dependency in detection.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>23394</offset><text>2.3.1. Feature Extraction Approach</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>23429</offset><text> Threshold-Based Approach </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>23456</offset><text>In order to detect road surface anomalies using threshold-based approaches, sensors’ changing data value patterns or statistical values (e.g., standard deviations) taken from sensor data values were analyzed. The amplitude of the accelerometer signal was monitored and the anomaly’s patterns in the signal were identified (an anomaly’s patterns in digital signals occur when the power of the signal exceeds a specific value). Threshold-based approaches were reviewed from three different perspectives: length of interval for a window function, fixed vs. flexible threshold determination, and amplitude of signal vs. other properties of signal amplitude (e.g., mean and standard deviation).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>24152</offset><text>Determining the interval length for a window function in spectral analysis is challenging, as it is related to various factors, such as the speed of vehicles and the distance from the front to rear wheels. A window function considers predefined intervals of the signal data for analysis and feature extraction as opposed to looking at signal data individually. Table 3 summarizes the length of interval for a window function for each of the studies that explored window functions. Defining proper threshold values in a statistical approach is an intensive process since road anomaly data values are affected by variable conditions. The suspension system of a car, sensor properties of smartphones, and smartphone placement all affect how smartphones sense a single anomaly. Studies conducted by Mohan et al., Mednis et al., Sinharay et al., and Yi et al. determined fixed-threshold values from experiments studying road surface anomaly detection. However, studies conducted by Sebestyen et al., Wang et al., and Harikrishnan and Gopi utilized dynamic threshold values to overcome unsteady signal patterns caused by various sensor and mechanical properties. Dynamically assigned threshold values are desirable when creating methods for detecting road surface anomalies, as they can be adapted to different circumstances.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>25472</offset><text>Mohan et al., Mednis et al., Sebestyen et al., Wang et al., and Harikrishnan and Gopi determined thresholds based on the amplitude of the signal. However, other studies, such as Yagi, Nomura and Shiraishi, Vittorio et al., and Yi et al. determined thresholds based on the statistical values (such as the standard deviation) derived from signal values. Mednis et al. confirmed that the standard deviation is the most important parameter for detecting road surface anomalies from accelerometer sensor data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>25977</offset><text> Machine Learning Approach </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>26005</offset><text>There are two prevalent approaches using machine learning techniques: supervised learning and unsupervised learning. The reviewed studies that involved machine learning techniques can also be categorized based on these two approaches. Bhoraskar et al. used k-means, an unsupervised method, to classify sensor data on smooth and bumpy roads, as well as to train the SVM algorithm. In this approach, the classes (bumpy or smooth) were manually labeled. Moreover, Mohamed et al. utilized the proposed threshold-based approach to label classes (smooth or speed bump) and train an SVM algorithm with three different kernel functions to distinguish between bumps and smooth road. Perttunen et al., Jain et al., Seraj et al., and Mohamed et al. employed SVM to classify sensor data. Captured videos, images, sounds, or field inspection were utilized to collect the ground truth and label the anomalies for classification purposes. Silva et al. investigated the performance of various supervised machine learning approaches, such as gradient boosting (GB), decision tree (DT), multilayer perceptron classifier (MPL), Gaussian Naive Bayes (GNB), and linear SVC to classify road surface distresses into different classes, including short bump, long bump, unleveled manholes, and others. Although these methods successfully classified the sensor data, a sample of labeled data was required to train the supervised algorithm first, which is impractical for real-time or near real-time applications.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>27492</offset><text> Dynamic Time Warping Approach (DTW) </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>27530</offset><text>In time series signal processing, the DTW approach measures the similarity between any two patterns of signals and extracts features from signal data. For example, Singh et al. proposed a DTW-based approach to detect road surface anomalies from accelerometer sensor data. In this approach, time series values captured accelerometer sensor data for every pothole and bump, and the data were then stored in a central server as templates. Next, incoming sensor data were compared with the stored templates to detect similarities. The accuracy of this approach was greatly correlated to the quality of the reference template. Therefore, this approach was both computationally intensive and unreliable, as it required reference templates for each different condition (i.e., various vehicles, road conditions, speed of driving).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>28353</offset><text>2.3.2. Differentiating Various Forms of Road Surface Anomalies</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>28416</offset><text>Actual road surface anomalies, including potholes and cracks;</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>28478</offset><text>Man-made road surface anomalies, including manholes, road joints, catchment basins, and speed bumps.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>28579</offset><text>Anomalies existing on road surfaces can be categorized into two major forms:</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>28656</offset><text>A comprehensive pothole detection approach should be able to differentiate actual road surface anomalies (such as potholes and cracks) successfully from a variety of man-made anomalies (such as manholes and speed bumps). However, this is challenging as they both generate similar signal patterns, especially in the case of manholes and catchment basins.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>29010</offset><text>In an approach proposed by Sebestyen et al., potholes can be distinguished from man-made speed bumps. If a car runs over a pothole, the car first drops and then climbs back up. Conversely, if a car runs over a man-made bump, the car first climbs and then drops. Therefore, by setting these rules within the signal pattern, these anomalies were detected and separated. Sinharay et al. suggested that the standard deviation of values calculated from sensor data can be used to distinguish potholes from bumps. Seraj et al. classified detected road surface anomalies to three different classes: severe anomalies, mild anomalies, and spans. Harikrishnan and Gopi used an X-Z filter proposed by Eriksson et al. to differentiate between potholes and speed bumps. Eriksson et al. claimed that potholes are mainly caused by an impact on one side of the vehicle, resulting in a relatively large variation on the x-direction of the accelerometer sensor data. However, speed bumps cause an impact on both sides of a vehicle, leading to small variations on the x-direction of accelerometer sensor data values. Such a mechanism can then be used to distinguish between potholes and speed bumps.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>30191</offset><text>2.3.3. Smartphone Orientation Dependency</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>30232</offset><text>Signal transformation: In this method, the sensors’ values are transferred from the device coordinate system to another geometric coordinate system (e.g., local-level coordinate system or body-frame coordinate system).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>30453</offset><text>Orientation-independent features: In this method, the magnitude of the sensor data values on all three axes is considered instead of considering their individual values on three separate axes.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>30646</offset><text>Road anomaly detection results are sensitive to the sensors’ orientation. Most of the reviewed studies, such as Yagi, Mednis et al., Perttunen et al., and Sinharay et al., assumed fixed and predetermined positions for analyzing smartphone sensor data. They required users to place their mobile device at a specific orientation and restricted them from using their mobile devices freely. As such, the smartphones had a lack of orientation independence. In order to find a practical road surface anomaly detection solution, smartphones should be freely placed. To develop an approach independent from smartphone orientation, two methods have been investigated:</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>31307</offset><text>The methods proposed by Mohan et al., Bhoraskar et al., Vittorio et al., Sebestyen et al., Wang et al., and Singh et al. applied a signal transformation method, which uses the Euler angles computed from accelerometer sensor data for coordinate transformations. Conversely, the approaches proposed by Jain et al., Sinharay et al., and Yi et al. utilized orientation-independent features of acceleration data (i.e., vector sum, mean, standard deviation) to become independent from smartphone orientation.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>31810</offset><text>2.3.4. Speed Dependency</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>31834</offset><text>Another factor that influences road anomaly detection using smartphone sensors is the speed of the vehicle. Douangphachanh and Oneyama demonstrated that average speed plays an important role in road roughness estimation. When a car passes over a specific road anomaly, such as a pothole, at different speeds, the amplitude of the collected acceleration signal reacts in a different manner, which should be modeled. Fox et al. investigated the effect of velocity as a component for detecting road surface anomalies from an onboard accelerometer sensor. Their investigations revealed that at high speeds, discriminating between normal roads and pothole regions was difficult. Sebestyen et al. collected sensor data at three different speeds: 15, 30, and 60 km/h. All values from the different speeds were normalized to a value of 30 km/h to develop and verify the proposed approach. Yi et al. examined the effect of vehicle velocity discussed in their approach by creating a lookup table, as well as categorizing the speed into different ranges. Then, each event was indexed according to the ratio of standard deviation, as well as the standard deviation of stable periods of the speed interval during which the event had been detected. Seraj et al. used speed data logged from the GPS sensor to demodulate accelerometer sensor data and amplify part of the signal caused by anomalies by considering the speed of the vehicles. Sinharay et al. normalized the feature values based on the speed of the vehicle. Speed was categorized in three ways: lower than 2 km/h, between 2 and 30 km/h, and more than 30 km/h. In addition, Perttunen et al. adopted an approach by Tanaka et al. that removed the effects of speed on signal data. Mednis et al. used different algorithms for different speeds. For instance, for a speed of less than 25 km/h, the z-sus algorithm was implemented. For the speed of more than 25 km/h, the z-peak algorithm was implemented. Mohan et al. used the z-sus method for speeds of less than 25 km/h and z-peak for speeds of more than 25 km/h. To minimize the false positive detection rate, Harikrishnan and Gopi proposed specifying a velocity-dependent variable. This variable was adjusted to the threshold value based on the current velocity of the vehicle. Different studies have used various methods to deal with the effects of vehicle speed on the performance of their approaches to road anomaly detection. However, none of them provided a technique robust enough to account for the effect of a vehicle’s velocity.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>34368</offset><text>2.4. Post-Processing of Detected Events (Road Surface Anomalies)</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>34433</offset><text>In this section, studies that investigated data integration and approaches used to process detected road surface anomalies from various users (i.e., data fusions) are reviewed and discussed. Chen et al. and Fox et al. transferred identified potholes’ information for each selected region in their study to the cloud for further analysis in their proposed approach. Then, a voting algorithm was applied to the study area for final decision making. In fact, the voting algorithm counts the number of reports made for each phenomenon from different sources. If the number of reported anomalies from various sources, for each predefined slice of the road, is more than a predefined threshold, those anomalies are considered true detection. Otherwise, they are rejected and assumed false detection. Fox et al. considered a sliding window of 10 m for evaluating the number of reports from smartphones on-board vehicles in order to minimize the false positive rate of detection.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>35407</offset><text>Unfortunately, for both studies, this simple voting algorithm ignores the fact that sources have different degrees of trustworthiness. In addition, this binary-based algorithm does not consider the temporal and probabilistic nature of the anomalies. Results conducted by Fox et al. indicated that at least 10 vehicles operating at a speed of 50 km/h were required for data collection in order to reach an accuracy of 90%. Furthermore, Chen et al. claimed 90% accuracy with nearly zero false positive alarms for their crowdsourcing-based road surface monitoring (CRSM) system.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>35983</offset><text>Yi et al. adopted a grid-based clustering algorithm called DENCLUE (DENsity CLUstering) to filter out false detections using the reporting frequency of events in a 5-m grid zone. Neighboring grids were grouped together if the frequency of the reported anomalies for each neighbor grid was more than three. Otherwise, the grid was assumed to be noisy and was removed. The drawback of this strategy is that some anomalies close to each other were treated as a single anomaly. In addition, threshold-based approaches for classifications are similar to the voting algorithm, which suffers as a result of considering the temporal and probabilistic nature of any road surface anomaly detecting by smartphones. Moreover, there is always a trade-off between reducing the false detection rate and missing the detection of anomalies at the same time. In this study, only the position accuracy of detected road surface anomalies was investigated, and the overall accuracy of detection was not studied.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>36974</offset><text>Alessandroni et al. proposed the “SmartRoadSense” system. Roughness information was collected in a central server. Then, the average of all roughness values within the predefined buffers of the detected location was considered to be the roughness value for that region. Sebestyen et al. proposed a method in which an average was taken to combine incoming information from multiple users. In this method, a weighted sum between the available evaluations was computed, as well as integrated multiple surveys from various incidents. This method, similar to the voting algorithm, suffers from the ignorance of the temporal aspect of road surface anomalies and the inherent uncertainty of incoming data. In addition, defining the proper buffer distance is challenging because it significantly affects the detection rate.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>37794</offset><text>2.5. Performance Evaluations</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>37823</offset><text>To evaluate the performance of road surface anomaly detection approaches, performance metrics are required, including accuracy ratio, precision, false positives ratio, and false negatives ratio. The choice of a specific performance metric or a combination of different performance metrics depends on the type of application needed, as well as its performance requirements. Table 4 summarizes overall performance evaluations for each approach based on the provided performance metrics. In addition to the overall accuracy of the analysis, some studies investigated performance evaluations with different smartphone placements.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>38449</offset><text> Smartphone Placement </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>38472</offset><text>One of the challenges in road surface anomaly detection is that smartphone sensors are sensitive to the placement of the device. In most studies, the location of mobile phones was considered to be fixed to a mount on the windshield or attached to the dashboard. However, few studies have investigated the performance of their approaches with smartphones in different locations in the vehicle, such as in the driver’s pocket or in the console near the gearbox. Different drivers have different habits, and the ideal approach should consider any circumstance that could result in a change in the location of a smartphone and its impact on the loss of recognition performance. Table 5 indicates that only three studies investigated the performance of their respective approaches with different smartphone placements in moving vehicles, namely,. Douangphachanh and Oneyama confirmed that smartphones located in a driver’s pocket or in the console caused lower detection rates.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>39449</offset><text>3. Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>39463</offset><text>In this review, the existing research investigating approaches for road surface anomaly detection using smartphone sensors is reviewed and compared. The existing approaches are compared using five primary criteria: sensor data collection, preprocessing, processing, post-processing, and performance evaluations.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>39775</offset><text>Data collection is one of the most important considerations when developing any approach to road surface anomaly detection with smartphone sensors. It is essential that the detection process considers all relevant aspects, including smartphone sensor properties, smartphone mounting location, vehicle suspension system, driving behavior, and speed. Therefore, to guarantee that an approach is compatible with different conditions, sensor data should be collected in various situations: various models of cars, smartphones, and speeds. However, due to the limitation of resources, only certain vehicles and smartphone devices have been selected and used for data collection in the reviewed research studies.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>40482</offset><text>To smooth the sensor data, to amplify the parts of the sensor data caused by the event (road surface anomaly), and to attenuate or remove parts of sensor data caused by noise or undesired input.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>40677</offset><text>To reorient the sensor data from a device coordinate system to the body-frame (vehicle coordinate system) or local-level coordinate system.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>40817</offset><text>Preprocessing is also an important task for any application using sensor data to extract features such as road surface anomalies. Preprocessing has two major objectives:</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>40987</offset><text>In fact, the preprocessing step can increase the accuracy of detection and decrease the false detection rate. In most reviewed studies, it was assumed that the general location of a smartphone was in a rigid holder. It was also assumed to be fixed, both position- and rotation-wise, with respect to the body-frame (vehicle) coordinate system. Unfortunately, when the smartphone is positioned in its holder or placed on the dashboard, there is no guarantee that the direction of the sensor data measurements will align with the vehicle’s body-frame coordinate system. The relative direction between the device’s coordinate system and the body frame’s coordinate system is therefore considered unknown. In fact, the desired approach should give freedom to users concerning smartphone placement. Several studies have considered sensor data reorientation using accelerometer sensor data to approximate rotation angles (employing Euler angles). However, the calculated rotation angles from accelerometer sensor data are both biased and contaminated by variant noise caused by thermal and mechanical fluctuations inside the sensor. Most modern smartphones using microelectromechanical sensors (MEMS), such as inertial measurement units (IMU), which contain a three-axis gyroscope for measuring angular velocities around three axes (i.e., pitch, roll, and heading), a three-axis accelerometer for measuring acceleration, and a three-axis magnetometer for measuring magnetic fields. The data from the IMU can be fused to obtain unbiased rotation angles that can then be applied for the purpose of coordinate system transformations.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>42617</offset><text>Developing processing algorithms to detect road surface anomalies from smartphone sensor data is quite challenging. Smartphone sensor properties, car suspension systems, driving behavior, and speed affect the signal pattern when passing over any road anomaly since they are contaminated with biases and noise. Threshold-based approaches have been examined to minimize these problems, and they have been evaluated in several studies. The results of these studies were not reliable as a robust and inclusive detection approach. The machine-learning approach, which has been applied by some studies, was able to overcome some limitations encountered by threshold-based approaches. However, the proposed methods were not inclusive and did not yield a robust solution. For example, supervised approaches, such as SVM, required many trained data sets to cover all possible scenarios for classification. However, by integrating both approaches (threshold-based and machine learning-based approaches), a hybrid approach is developed which can potentially overcome the limitations of each individual approach to detect road surface anomalies from smartphone sensors.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>43775</offset><text>Additionally, as seen in Table 1, most of the studies employed a single sensor (e.g., an accelerometer) to detect road surface anomalies. Figure 3 illustrates all available motion sensors on currently trending smartphones. Linear acceleration and gravity are the new software-based (virtual) sensors which have been recently integrated into high-end smartphone devices. To improve the system’s performance, sensor fusion techniques can be used. For example, gyroscope or gravity sensors can be combined with accelerometer sensor data to strengthen the detection of road surface anomalies. In addition, accelerometer, magnetic, and gyroscope sensor data are combined in order to derive the isolated gravity vector and to exclude it from accelerometer data. Most new and high-end smartphone devices are capable of calculating linear acceleration from their sensors. Linear acceleration is the effect of acceleration on the smartphone devices excluding the earth’s gravity. As a result, the actual acceleration of the device can be determined irrespective of the device orientation.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>44859</offset><text>Most studies reviewed have implemented and verified their methods in an offline mode. However, with the continued release of powerful smartphones, few studies have both developed and verified their approaches in an online mode. Mednis et al. and Wang et al. implemented the proposed method on an Android OS for real-time pothole detection. However, in major studies, entire preprocessing and processing steps which have been done on computers and smartphones have only been used for sensor data collection. Due to the popularity of smartphones embedded with high-performance sensors, as well as the recent increase in the enhanced capability of smartphones, complex analysis and processing of streamed data from smartphone sensors in real time are now possible and practical. For online road surface anomaly detection approaches, the feasibility of implementing an online mode for smartphones should be investigated. In addition, a proper evaluation of implemented approaches for road surface monitoring on smartphones is desirable. Smartphone resource consumption analysis, such as CPU, memory, and battery usage are topics of further interest.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>46005</offset><text>Due to the complexity of the processing step, post-processing using multiple sources is able to increase both the detection accuracy and decrease the rate of false detection. Some studies investigated data crowdsourcing techniques for road surface monitoring and achieved considerable improvement of the detection accuracy rate. Unfortunately, their recommended approaches were in the very early stages of development, and they suffered from the unreliability of smartphone detection and the variable nature of road surface anomalies.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>46540</offset><text>Moreover, the participatory sensing from smartphone applications presents challenges, such as flawed client-server communication due to unreliable vehicular networks, limited connectivity time, and high packet rate. GPS errors also complicate data accumulation because of erratic sampling. In fact, the detected location derived from the GPS sensors of smartphones have uncertainty. For instance, some existing studies proved that the cellular and/or GPS positioning can result in errors ranging from several meters to 100 m (MOK et al.; Zandbergen; Pun-Cheng et al.). Therefore, the detected location from various smartphone users for any road surface anomaly varies due to the data uncertainty. As a result, the best approach to crowdsourcing road surface anomalies from multiple sources would be a probabilistic and spatiotemporal-based approach that would overcome both the uncertainty and variability in road surface anomalies. In addition, novel technologies of data transferring, such as the RESTful (representational state transfer) architecture and data formats such as the JSON (JavaScript object notation) data format, can be utilized to minimize the packet rate and overcome the challenges in participatory sensing using smartphones.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>47786</offset><text>4. Conclusions and Challenges</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>47816</offset><text>Efforts have been made to implement various methods which detect road surface anomalies using data from smartphone sensors. However, these approaches continue to face some challenges. Regarding the performance of the associated algorithms, it is difficult to compare the accuracy and performance of various approaches due to restricted availability of the reported algorithms and data sets. For many threshold-based approaches, the manner in which the threshold was set remains unclear. In addition, methods that use supervised or unsupervised learning methods need large amounts of data to train their detection model.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>48436</offset><text>Therefore, a hybrid approach, which would be able to continually detect and distinguish various road surface anomalies using real-time data streaming from smartphone sensors and other geographic data, should be developed. Sensor data values should be smoothed and reoriented to allow smartphone users more freedom, as well as to increase the accuracy of detection. The ideal approach should be self-adapting and self-learning; it would be able to reconcile itself to any platform, the dynamic behavior of different vehicles, as well as various road surface conditions.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>49005</offset><text>A free, cross-platform smartphone application must be developed. This application would be fully automatic and not require any user interaction, as well as allow the driver to maintain focus on the road. In addition, the power consumption of the proposed application should be minimized, perhaps by reducing the usage of GPS sensors. Specific techniques, such as robust sensor calibration readings, should also be investigated because the amount of sensor noise and accessibility of the sensor data vary in different smartphones.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>49535</offset><text>Due to the increase in the number of smartphone holders, continuous monitoring and reporting of road surface anomaly events are achievable by the public. In fact, the effectiveness of road monitoring systems could be substantially improved with effective data-crowdsourcing techniques. Smartphones generally are embedded by various wireless interfaces, such as Bluetooth, Wi-Fi, and cellular networks, making them ideal for crowdsourcing purposes and pushing notifications to road users. In fact, detected anomalies can be transferred to the central server through Wi-Fi or cellular networks for further processing and driver/authority awareness. Data integration in the server would increase system accuracy by training the machine learning algorithms and data classification operations. It would also provide further opportunities to notify drivers about the road surface anomalies ahead, and government agencies about the current road surface condition for potential maintenance and rehabilitation.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>50537</offset><text>Moreover, vehicular network technologies, including V2V (vehicle to vehicle) and C-V2V (Cellular-V2V) communication technologies, are trending nowadays and can play a critical role in transportation management and specifically on driving safety. By more vehicles being connected to the Internet and to each other, there is potential for enhancing the processes of (1) data collection by obtaining the most updated information regarding the road surface conditions from all connected vehicles and (2) data exchange among road users by notifying drivers approaching to road surface anomalies detected by other road users beforehand through V2V and C-V2V technologies. However, these technologies are still under investigation and are not widely deployed on vehicles due to the absence of a road infrastructure.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title</infon><offset>51346</offset><text>Author Contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>51367</offset><text>S.S. conceived of the review study, collected the materials and wrote the paper. S.L. contributed the review, writing and revision of the manuscript. M.C. reviewed the study plan, and edited the manuscript.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>51574</offset><text>Funding</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>51582</offset><text>This research work is supported by the Discovery Grant from the Natural Sciences and Engineering Research Council of Canada (NSERC) grant number [RGPIN-2017-05950].</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title</infon><offset>51747</offset><text>Conflicts of Interest</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>51769</offset><text>The authors declare no conflict of interest.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>51814</offset><text>References</text></passage><passage><infon key="fpage">630</infon><infon key="lpage">634</infon><infon key="name_0">surname:Strutu;given-names:M.</infon><infon key="name_1">surname:Stamatescu;given-names:G.</infon><infon key="name_2">surname:Popescu;given-names:D.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2013 17th International Conference on System Theory, Control and Computing (ICSTCC)</infon><infon key="type">ref</infon><offset>51825</offset><text>A mobile sensor network based road surface monitoring system</text></passage><passage><infon key="fpage">48</infon><infon key="lpage">53</infon><infon key="name_0">surname:Buza;given-names:E.</infon><infon key="name_1">surname:Omanovic;given-names:S.</infon><infon key="name_2">surname:Huseinovic;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2nd International Conference on Information Technology and Computer Networks</infon><infon key="type">ref</infon><offset>51886</offset><text>Pothole detection with image processing and spectral clustering</text></passage><passage><infon key="comment">Technical Report of Highway IDEA Project</infon><infon key="name_0">surname:Kelvin;given-names:C.</infon><infon key="section_type">REF</infon><infon key="source">Automated Pavement Distress Survey through Stereovision</infon><infon key="type">ref</infon><infon key="year">2004</infon><offset>51950</offset></passage><passage><infon key="name_0">surname:Vijay;given-names:S.</infon><infon key="name_1">surname:Arya;given-names:K.</infon><infon key="section_type">REF</infon><infon key="source">Master’s Thesis</infon><infon key="type">ref</infon><infon key="year">2006</infon><offset>51951</offset><text>Low Cost—FPGA Based System for Pothole Detection on Indian Roads</text></passage><passage><infon key="comment">Technical Report</infon><infon key="name_0">surname:Salari;given-names:E.</infon><infon key="name_1">surname:Chou;given-names:E.</infon><infon key="name_2">surname:Lynch;given-names:J.J.</infon><infon key="section_type">REF</infon><infon key="source">Pavement Distress Evaluation Using 3d Depth Information from Stereo Vision</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>52018</offset></passage><passage><infon key="fpage">1284</infon><infon key="lpage">1291</infon><infon key="name_0">surname:Moazzam;given-names:I.</infon><infon key="name_1">surname:Kamal;given-names:K.</infon><infon key="name_2">surname:Mathavan;given-names:S.</infon><infon key="name_3">surname:Usman;given-names:S.</infon><infon key="name_4">surname:Rahman;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2013 16th International IEEE Conference on Intelligent Transportation Systems-(ITSC)</infon><infon key="type">ref</infon><offset>52019</offset><text>Metrology and visualization of potholes using the microsoft kinect sensor</text></passage><passage><infon key="fpage">376</infon><infon key="lpage">381</infon><infon key="name_0">surname:Hou;given-names:Z.</infon><infon key="name_1">surname:Wang;given-names:K.C.</infon><infon key="name_2">surname:Gong;given-names:W.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the International Conference on Transportation Engineering 2007</infon><infon key="type">ref</infon><offset>52093</offset><text>Experimentation of 3D pavement imaging through stereovision</text></passage><passage><infon key="fpage">603</infon><infon key="lpage">608</infon><infon key="name_0">surname:Kim;given-names:T.</infon><infon key="name_1">surname:Ryu;given-names:S.K.</infon><infon key="section_type">REF</infon><infon key="source">J. Emerg. Trends Comput. Inf. Sci.</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2014</infon><offset>52153</offset><text>Review and analysis of pothole detection methods</text></passage><passage><infon key="fpage">869627</infon><infon key="name_0">surname:Wang;given-names:H.W.</infon><infon key="name_1">surname:Chen;given-names:C.H.</infon><infon key="name_2">surname:Cheng;given-names:D.Y.</infon><infon key="name_3">surname:Lin;given-names:C.H.</infon><infon key="name_4">surname:Lo;given-names:C.C.</infon><infon key="pub-id_doi">10.1155/2015/869627</infon><infon key="section_type">REF</infon><infon key="source">Math. Probl. Eng.</infon><infon key="type">ref</infon><infon key="volume">2015</infon><infon key="year">2015</infon><offset>52202</offset><text>A real-time pothole detection approach for intelligent transportation system</text></passage><passage><infon key="fpage">295</infon><infon key="lpage">310</infon><infon key="name_0">surname:Yan;given-names:W.Y.</infon><infon key="name_1">surname:Shaker;given-names:A.</infon><infon key="name_2">surname:El-Ashmawy;given-names:N.</infon><infon key="pub-id_doi">10.1016/j.rse.2014.11.001</infon><infon key="section_type">REF</infon><infon key="source">Remote Sens. Environ.</infon><infon key="type">ref</infon><infon key="volume">158</infon><infon key="year">2015</infon><offset>52279</offset><text>Urban land cover classification using airborne LiDAR data: A review</text></passage><passage><infon key="fpage">376</infon><infon key="lpage">389</infon><infon key="name_0">surname:Yan;given-names:W.Y.</infon><infon key="name_1">surname:Yuan;given-names:X.X.</infon><infon key="pub-id_doi">10.1080/15472450.2017.1366320</infon><infon key="section_type">REF</infon><infon key="source">J. Intell. Transp. Syst.</infon><infon key="type">ref</infon><infon key="volume">22</infon><infon key="year">2018</infon><offset>52347</offset><text>A low-cost video-based pavement distress screening system for low-volume roads</text></passage><passage><infon key="fpage">697</infon><infon key="lpage">698</infon><infon key="name_0">surname:Canny;given-names:J.</infon><infon key="pub-id_doi">10.1109/TPAMI.1986.4767851</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Pattern Anal. Mach. Intell.</infon><infon key="type">ref</infon><infon key="volume">PAMI-8</infon><infon key="year">1986</infon><offset>52426</offset><text>A computational approach to edge detection</text></passage><passage><infon key="fpage">370</infon><infon key="lpage">378</infon><infon key="name_0">surname:Koch;given-names:C.</infon><infon key="name_1">surname:Jog;given-names:G.</infon><infon key="name_2">surname:Brilakis;given-names:I.</infon><infon key="pub-id_doi">10.1061/(ASCE)CP.1943-5487.0000232</infon><infon key="section_type">REF</infon><infon key="source">J. Comput. Civ. Eng.</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2013</infon><offset>52469</offset><text>Pothole detection with image processing and spectral clustering</text></passage><passage><infon key="fpage">553</infon><infon key="lpage">560</infon><infon key="name_0">surname:Jog;given-names:G.</infon><infon key="name_1">surname:Koch;given-names:C.</infon><infon key="name_2">surname:Golparvar-Fard;given-names:M.</infon><infon key="name_3">surname:Brilakis;given-names:I.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2012 ASCE International Workshop on Computing in Civil Engineering</infon><infon key="type">ref</infon><offset>52533</offset><text>Pothole properties measurement through visual 2D recognition and 3D reconstruction</text></passage><passage><infon key="fpage">312</infon><infon key="lpage">321</infon><infon key="name_0">surname:Huidrom;given-names:L.</infon><infon key="name_1">surname:Das;given-names:L.K.</infon><infon key="name_2">surname:Sud;given-names:S.</infon><infon key="pub-id_doi">10.1016/j.sbspro.2013.11.124</infon><infon key="section_type">REF</infon><infon key="source">Procedia Soc. Behav. Sci.</infon><infon key="type">ref</infon><infon key="volume">104</infon><infon key="year">2013</infon><offset>52616</offset><text>Method for automated assessment of potholes, cracks and patches from road surface video clips</text></passage><passage><infon key="fpage">31</infon><infon key="lpage">41</infon><infon key="name_0">surname:Lokeshwor;given-names:H.</infon><infon key="name_1">surname:Das;given-names:L.K.</infon><infon key="name_2">surname:Goel;given-names:S.</infon><infon key="pub-id_doi">10.1061/(ASCE)TE.1943-5436.0000564</infon><infon key="section_type">REF</infon><infon key="source">J. Transp. Eng.</infon><infon key="type">ref</infon><infon key="volume">140</infon><infon key="year">2013</infon><offset>52710</offset><text>Robust method for automated segmentation of frames with/without distress from road surface video clips</text></passage><passage><infon key="elocation-id">914</infon><infon key="name_0">surname:Zang;given-names:K.</infon><infon key="name_1">surname:Shen;given-names:J.</infon><infon key="name_2">surname:Huang;given-names:H.</infon><infon key="name_3">surname:Wan;given-names:M.</infon><infon key="name_4">surname:Shi;given-names:J.</infon><infon key="pub-id_doi">10.3390/s18030914</infon><infon key="pub-id_pmid">29562731</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2018</infon><offset>52813</offset><text>Assessing and mapping of road surface roughness based on GPS and accelerometer sensors on bicycle-mounted smartphones</text></passage><passage><infon key="name_0">surname:Estrin;given-names:D.</infon><infon key="name_1">surname:Hansen;given-names:M.</infon><infon key="name_2">surname:Parker;given-names:A.</infon><infon key="name_3">surname:Ramanathan;given-names:N.</infon><infon key="name_4">surname:Burke;given-names:J.A.</infon><infon key="name_5">surname:Reddy;given-names:S.</infon><infon key="name_6">surname:Srivastava;given-names:M.B.</infon><infon key="section_type">REF</infon><infon key="source">Participatory Sensing</infon><infon key="type">ref</infon><infon key="year">2006</infon><offset>52931</offset></passage><passage><infon key="name_0">surname:Sinharay;given-names:A.</infon><infon key="name_1">surname:Bilal;given-names:S.</infon><infon key="name_2">surname:Pal;given-names:A.</infon><infon key="name_3">surname:Sinha;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Computer Society of India (CSI) Annual Convention, Theme: Intelligent Infrastructure</infon><infon key="type">ref</infon><infon key="volume">Volume 1</infon><offset>52932</offset><text>Low computational approach for road condition monitoring using smartphones</text></passage><passage><infon key="fpage">515</infon><infon key="lpage">523</infon><infon key="name_0">surname:Fox;given-names:A.</infon><infon key="name_1">surname:Kumar;given-names:B.V.</infon><infon key="name_2">surname:Chen;given-names:J.</infon><infon key="name_3">surname:Bai;given-names:F.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2015 12th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)</infon><infon key="type">ref</infon><offset>53007</offset><text>Crowdsourcing undersampled vehicular sensor data for pothole detection</text></passage><passage><infon key="name_0">surname:Yagi;given-names:K.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 17th ITS World Congress (ITS Japan and ITS America ERTICO)</infon><infon key="type">ref</infon><offset>53078</offset><text>Extensional smartphone probe for road bump detection</text></passage><passage><infon key="fpage">783</infon><infon key="lpage">787</infon><infon key="name_0">surname:Douangphachanh;given-names:V.</infon><infon key="name_1">surname:Oneyama;given-names:H.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)</infon><infon key="type">ref</infon><infon key="volume">Volume 1</infon><offset>53131</offset><text>Exploring the use of smartphone accelerometer and gyroscope to study on the estimation of road surface roughness condition</text></passage><passage><infon key="comment">Available online: https://developer.android.com/docs/</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>53254</offset><text>Documentation for App Developers</text></passage><passage><infon key="name_0">surname:Data;given-names:M.C.</infon><infon key="section_type">REF</infon><infon key="source">Secondary Analysis of Electronic Health Records</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>53287</offset></passage><passage><infon key="name_0">surname:Smith;given-names:S.W.</infon><infon key="section_type">REF</infon><infon key="source">The Scientist and Engineer’s Guide to Digital Signal Processing</infon><infon key="type">ref</infon><infon key="year">1997</infon><offset>53288</offset></passage><passage><infon key="fpage">21</infon><infon key="lpage">63</infon><infon key="name_0">surname:Noureldin;given-names:A.</infon><infon key="name_1">surname:Karamat;given-names:T.B.</infon><infon key="name_2">surname:Georgy;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">Fundamentals of Inertial Navigation, Satellite-Based Positioning and Their Integration</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>53289</offset><text>Basic Navigational Mathematics, Reference Frames and the Earth’s Geometry</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">6</infon><infon key="name_0">surname:Bhoraskar;given-names:R.</infon><infon key="name_1">surname:Vankadhara;given-names:N.</infon><infon key="name_2">surname:Raman;given-names:B.</infon><infon key="name_3">surname:Kulkarni;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2012 Fourth International Conference on Communication Systems and Networks (COMSNETS)</infon><infon key="type">ref</infon><offset>53365</offset><text>Wolverine: Traffic and road condition estimation using smartphone sensors</text></passage><passage><infon key="fpage">64</infon><infon key="lpage">78</infon><infon key="name_0">surname:Perttunen;given-names:M.</infon><infon key="name_1">surname:Mazhelis;given-names:O.</infon><infon key="name_2">surname:Cong;given-names:F.</infon><infon key="name_3">surname:Kauppila;given-names:M.</infon><infon key="name_4">surname:Leppänen;given-names:T.</infon><infon key="name_5">surname:Kantola;given-names:J.</infon><infon key="name_6">surname:Collin;given-names:J.</infon><infon key="name_7">surname:Pirttikangas;given-names:S.</infon><infon key="name_8">surname:Haverinen;given-names:J.</infon><infon key="name_9">surname:Ristaniemi;given-names:T.</infon><infon key="section_type">REF</infon><infon key="source">International Conference on Ubiquitous Intelligence and Computing</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>53439</offset><text>Distributed road surface condition monitoring using mobile phones</text></passage><passage><infon key="name_0">surname:Jain;given-names:M.</infon><infon key="name_1">surname:Singh;given-names:A.P.</infon><infon key="name_2">surname:Bali;given-names:S.</infon><infon key="name_3">surname:Kaul;given-names:S.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the NSDR: 6th USENIX/ACM Workshop on Networked Systems for Developing Regions</infon><infon key="type">ref</infon><offset>53505</offset><text>Speed-Breaker Early Warning System</text></passage><passage><infon key="fpage">377</infon><infon key="lpage">387</infon><infon key="name_0">surname:Mohamed;given-names:A.</infon><infon key="name_1">surname:Fouad;given-names:M.M.M.</infon><infon key="name_2">surname:Elhariri;given-names:E.</infon><infon key="name_3">surname:El-Bendary;given-names:N.</infon><infon key="name_4">surname:Zawbaa;given-names:H.M.</infon><infon key="name_5">surname:Tahoun;given-names:M.</infon><infon key="name_6">surname:Hassanien;given-names:A.E.</infon><infon key="section_type">REF</infon><infon key="source">Intelligent Systems 2014</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>53540</offset><text>RoadMonitor: An intelligent road surface condition monitoring system</text></passage><passage><infon key="fpage">2059</infon><infon key="lpage">2085</infon><infon key="name_0">surname:Shoaib;given-names:M.</infon><infon key="name_1">surname:Bosch;given-names:S.</infon><infon key="name_2">surname:Incel;given-names:O.D.</infon><infon key="name_3">surname:Scholten;given-names:H.</infon><infon key="name_4">surname:Havinga;given-names:P.J.</infon><infon key="pub-id_doi">10.3390/s150102059</infon><infon key="pub-id_pmid">25608213</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2015</infon><offset>53609</offset><text>A survey of online activity recognition using mobile phones</text></passage><passage><infon key="fpage">433</infon><infon key="lpage">439</infon><infon key="name_0">surname:Douangphachanh;given-names:V.</infon><infon key="name_1">surname:Oneyama;given-names:H.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2013 13th International Conference on ITS Telecommunications (ITST)</infon><infon key="type">ref</infon><offset>53669</offset><text>Estimation of road roughness condition from smartphones under realistic settings</text></passage><passage><infon key="fpage">458</infon><infon key="lpage">464</infon><infon key="name_0">surname:Sebestyen;given-names:G.</infon><infon key="name_1">surname:Muresan;given-names:D.</infon><infon key="name_2">surname:Hangan;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2015 16th International Carpathian Control Conference (ICCC)</infon><infon key="type">ref</infon><offset>53750</offset><text>Road quality evaluation with mobile devices</text></passage><passage><infon key="fpage">128</infon><infon key="lpage">146</infon><infon key="name_0">surname:Seraj;given-names:F.</infon><infon key="name_1">surname:van der Zwaag;given-names:B.J.</infon><infon key="name_2">surname:Dilo;given-names:A.</infon><infon key="name_3">surname:Luarasi;given-names:T.</infon><infon key="name_4">surname:Havinga;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Big Data Analytics in the Social and Ubiquitous Context</infon><infon key="type">ref</infon><infon key="year">2014</infon><offset>53794</offset><text>RoADS: A road pavement monitoring system for anomaly detection using smart phones</text></passage><passage><infon key="fpage">536</infon><infon key="lpage">541</infon><infon key="name_0">surname:Butterworth;given-names:S.</infon><infon key="section_type">REF</infon><infon key="source">Wirel. Eng.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">1930</infon><offset>53876</offset><text>On the theory of filter amplifiers</text></passage><passage><infon key="fpage">5192</infon><infon key="lpage">5197</infon><infon key="name_0">surname:Harikrishnan;given-names:P.</infon><infon key="name_1">surname:Gopi;given-names:V.P.</infon><infon key="pub-id_doi">10.1109/JSEN.2017.2719865</infon><infon key="section_type">REF</infon><infon key="source">IEEE Sens. J.</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2017</infon><offset>53911</offset><text>Vehicle vibration signal processing for road surface monitoring</text></passage><passage><infon key="fpage">323</infon><infon key="lpage">336</infon><infon key="name_0">surname:Mohan;given-names:P.</infon><infon key="name_1">surname:Padmanabhan;given-names:V.N.</infon><infon key="name_2">surname:Ramjee;given-names:R.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 6th ACM Conference on Embedded Network Sensor Systems</infon><infon key="type">ref</infon><offset>53975</offset><text>Nericell: Rich monitoring of road and traffic conditions using mobile smartphones</text></passage><passage><infon key="fpage">242</infon><infon key="lpage">251</infon><infon key="name_0">surname:Vittorio;given-names:A.</infon><infon key="name_1">surname:Rosolino;given-names:V.</infon><infon key="name_2">surname:Teresa;given-names:I.</infon><infon key="name_3">surname:Vittoria;given-names:C.M.</infon><infon key="name_4">surname:Vincenzo;given-names:P.G.</infon><infon key="name_5">surname:Francesco;given-names:D.M.</infon><infon key="pub-id_doi">10.1016/j.sbspro.2014.01.057</infon><infon key="section_type">REF</infon><infon key="source">Procedia Soc. Behav. Sci.</infon><infon key="type">ref</infon><infon key="volume">111</infon><infon key="year">2014</infon><offset>54057</offset><text>Automated sensing system for monitoring of road surface quality by mobile devices</text></passage><passage><infon key="fpage">71</infon><infon key="lpage">88</infon><infon key="name_0">surname:Singh;given-names:G.</infon><infon key="name_1">surname:Bansal;given-names:D.</infon><infon key="name_2">surname:Sofat;given-names:S.</infon><infon key="name_3">surname:Aggarwal;given-names:N.</infon><infon key="pub-id_doi">10.1016/j.pmcj.2017.06.002</infon><infon key="section_type">REF</infon><infon key="source">Pervasive Mob. Comput.</infon><infon key="type">ref</infon><infon key="volume">40</infon><infon key="year">2017</infon><offset>54139</offset><text>Smart patrolling: An efficient road surface monitoring using smartphone sensors and crowdsourcing</text></passage><passage><infon key="fpage">415</infon><infon key="lpage">422</infon><infon key="name_0">surname:Silva;given-names:N.</infon><infon key="name_1">surname:Soares;given-names:J.</infon><infon key="name_2">surname:Shah;given-names:V.</infon><infon key="name_3">surname:Santos;given-names:M.Y.</infon><infon key="name_4">surname:Rodrigues;given-names:H.</infon><infon key="pub-id_doi">10.1016/j.procs.2017.11.056</infon><infon key="section_type">REF</infon><infon key="source">Procedia Comput. Sci.</infon><infon key="type">ref</infon><infon key="volume">121</infon><infon key="year">2017</infon><offset>54237</offset><text>Anomaly detection in roads with a data mining approach</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">6</infon><infon key="name_0">surname:Mednis;given-names:A.</infon><infon key="name_1">surname:Strazdins;given-names:G.</infon><infon key="name_2">surname:Zviedris;given-names:R.</infon><infon key="name_3">surname:Kanonirs;given-names:G.</infon><infon key="name_4">surname:Selavo;given-names:L.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2011 International Conference on Distributed Computing in Sensor Systems and Workshops (DCOSS)</infon><infon key="type">ref</infon><offset>54292</offset><text>Real time pothole detection using android smartphones with accelerometers</text></passage><passage><infon key="fpage">29</infon><infon key="lpage">36</infon><infon key="name_0">surname:Nomura;given-names:T.</infon><infon key="name_1">surname:Shiraishi;given-names:Y.</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Inf. Soc.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2015</infon><offset>54366</offset><text>A method for estimating road surface conditions with a smartphone</text></passage><passage><infon key="fpage">1905</infon><infon key="lpage">1917</infon><infon key="name_0">surname:Yi;given-names:C.W.</infon><infon key="name_1">surname:Chuang;given-names:Y.T.</infon><infon key="name_2">surname:Nian;given-names:C.S.</infon><infon key="pub-id_doi">10.1109/TITS.2014.2378511</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Intell. Transp. Syst.</infon><infon key="type">ref</infon><infon key="volume">16</infon><infon key="year">2015</infon><offset>54432</offset><text>Toward crowdsourcing-based road pavement monitoring by mobile sensing technologies</text></passage><passage><infon key="name_0">surname:Bishop;given-names:C.M.</infon><infon key="section_type">REF</infon><infon key="source">Pattern Recognition and Machine Learning (Information Science and Statistics)</infon><infon key="type">ref</infon><infon key="volume">Volume 1</infon><infon key="year">2011</infon><offset>54515</offset></passage><passage><infon key="fpage">1</infon><infon key="lpage">23</infon><infon key="name_0">surname:Senin;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Dynamic Time Warping Algorithm Review</infon><infon key="type">ref</infon><infon key="volume">Volume 855</infon><infon key="year">2008</infon><offset>54516</offset></passage><passage><infon key="fpage">29</infon><infon key="lpage">39</infon><infon key="name_0">surname:Eriksson;given-names:J.</infon><infon key="name_1">surname:Girod;given-names:L.</infon><infon key="name_2">surname:Hull;given-names:B.</infon><infon key="name_3">surname:Newton;given-names:R.</infon><infon key="name_4">surname:Madden;given-names:S.</infon><infon key="name_5">surname:Balakrishnan;given-names:H.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 6th International Conference on Mobile Systems, Applications, and Services</infon><infon key="type">ref</infon><offset>54517</offset><text>The pothole patrol: Using a mobile sensor network for road surface monitoring</text></passage><passage><infon key="elocation-id">305</infon><infon key="name_0">surname:Alessandroni;given-names:G.</infon><infon key="name_1">surname:Carini;given-names:A.</infon><infon key="name_2">surname:Lattanzi;given-names:E.</infon><infon key="name_3">surname:Freschi;given-names:V.</infon><infon key="name_4">surname:Bogliolo;given-names:A.</infon><infon key="pub-id_doi">10.3390/s17020305</infon><infon key="pub-id_pmid">28178224</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2017</infon><offset>54595</offset><text>A study on the influence of speed on road roughness sensing: The SmartRoadSense case</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">11</infon><infon key="name_0">surname:Tanaka;given-names:N.</infon><infon key="name_1">surname:Okamoto;given-names:H.</infon><infon key="name_2">surname:Naito;given-names:M.</infon><infon key="pub-id_doi">10.1016/S0167-2789(00)00159-7</infon><infon key="section_type">REF</infon><infon key="source">Phys. D Nonlinear Phenom.</infon><infon key="type">ref</infon><infon key="volume">147</infon><infon key="year">2000</infon><offset>54680</offset><text>Detecting and evaluating intrinsic nonlinearity present in the mutual dependence between two variables</text></passage><passage><infon key="fpage">2151</infon><infon key="lpage">2158</infon><infon key="name_0">surname:Chen;given-names:K.</infon><infon key="name_1">surname:Lu;given-names:M.</infon><infon key="name_2">surname:Tan;given-names:G.</infon><infon key="name_3">surname:Wu;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2013 IEEE 10th International Conference on High Performance Computing and Communications &amp; 2013 IEEE International Conference on Embedded and Ubiquitous Computing (HPCC_EUC)</infon><infon key="type">ref</infon><offset>54783</offset><text>CRSM: Crowdsourcing based road surface monitoring</text></passage><passage><infon key="fpage">1741</infon><infon key="lpage">1752</infon><infon key="name_0">surname:Zhang;given-names:L.</infon><infon key="name_1">surname:Qi;given-names:G.J.</infon><infon key="name_2">surname:Zhang;given-names:D.</infon><infon key="name_3">surname:Tang;given-names:J.</infon><infon key="pub-id_doi">10.1109/ACCESS.2017.2780182</infon><infon key="section_type">REF</infon><infon key="source">IEEE Access</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2018</infon><offset>54833</offset><text>Latent Dirichlet Truth Discovery: Separating Trustworthy and Untrustworthy Components in Data Sources</text></passage><passage><infon key="fpage">210</infon><infon key="lpage">215</infon><infon key="name_0">surname:Alessandroni;given-names:G.</infon><infon key="name_1">surname:Klopfenstein;given-names:L.</infon><infon key="name_2">surname:Delpriori;given-names:S.</infon><infon key="name_3">surname:Dromedari;given-names:M.</infon><infon key="name_4">surname:Luchetti;given-names:G.</infon><infon key="name_5">surname:Paolini;given-names:B.</infon><infon key="name_6">surname:Seraghiti;given-names:A.</infon><infon key="name_7">surname:Lattanzi;given-names:E.</infon><infon key="name_8">surname:Freschi;given-names:V.</infon><infon key="name_9">surname:Carini;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the UBICOMM-2014 IARIA</infon><infon key="type">ref</infon><offset>54935</offset><text>Smartroadsense: Collaborative road surface condition monitoring</text></passage><passage><infon key="name_0">surname:Wallin;given-names:J.</infon><infon key="name_1">surname:Zachrisson;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">Sensor Fusion in Smartphones: With Application to Car Racing Performance Analysis</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>54999</offset></passage><passage><infon key="fpage">1</infon><infon key="lpage">6</infon><infon key="name_0">surname:Dunkel;given-names:J.</infon><infon key="name_1">surname:Bruns;given-names:R.</infon><infon key="name_2">surname:Stipkovic;given-names:S.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2013 IEEE Eleventh International Symposium on Autonomous Decentralized Systems (ISADS)</infon><infon key="type">ref</infon><offset>55000</offset><text>Event-based smartphone sensor processing for ambient assisted living</text></passage><passage><infon key="fpage">3</infon><infon key="lpage">14</infon><infon key="name_0">surname:Fernandez;given-names:J.A.</infon><infon key="name_1">surname:Borries;given-names:K.</infon><infon key="name_2">surname:Cheng;given-names:L.</infon><infon key="name_3">surname:Kumar;given-names:B.V.</infon><infon key="name_4">surname:Stancil;given-names:D.D.</infon><infon key="name_5">surname:Bai;given-names:F.</infon><infon key="pub-id_doi">10.1109/TVT.2011.2164428</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Veh. Technol.</infon><infon key="type">ref</infon><infon key="volume">61</infon><infon key="year">2012</infon><offset>55069</offset><text>Performance of the 802.11 p physical layer in vehicle-to-vehicle environments</text></passage><passage><infon key="fpage">23</infon><infon key="lpage">30</infon><infon key="name_0">surname:Mok;given-names:E.C.M.</infon><infon key="name_1">surname:Shea;given-names:G.Y.K.</infon><infon key="name_2">surname:Yan;given-names:W.Y.</infon><infon key="section_type">REF</infon><infon key="source">Hong Kong Inst. Surv. J.</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2004</infon><offset>55147</offset><text>Geolocation positioning with wireless cellular network in Hong Kong</text></passage><passage><infon key="fpage">5</infon><infon key="lpage">25</infon><infon key="name_0">surname:Zandbergen;given-names:P.A.</infon><infon key="pub-id_doi">10.1111/j.1467-9671.2009.01152.x</infon><infon key="section_type">REF</infon><infon key="source">Trans. GIS</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2009</infon><offset>55215</offset><text>Accuracy of iPhone locations: A comparison of assisted GPS, WiFi and cellular positioning</text></passage><passage><infon key="fpage">545</infon><infon key="lpage">556</infon><infon key="name_0">surname:Pun-Cheng;given-names:L.S.C.</infon><infon key="name_1">surname:Mok;given-names:E.C.M.</infon><infon key="name_2">surname:Shea;given-names:G.Y.K.</infon><infon key="name_3">surname:Yan;given-names:W.Y.</infon><infon key="section_type">REF</infon><infon key="source">Location Based Services and Telecartography</infon><infon key="type">ref</infon><infon key="year">2007</infon><offset>55305</offset><text>EASYGO—A public transport query and guiding LBS</text></passage><passage><infon key="name_0">surname:Silva;given-names:C.M.</infon><infon key="name_1">surname:Masini;given-names:B.M.</infon><infon key="name_2">surname:Ferrari;given-names:G.</infon><infon key="name_3">surname:Thibault;given-names:I.</infon><infon key="pub-id_doi">10.1155/2017/6123868</infon><infon key="section_type">REF</infon><infon key="source">Mob. Inf. Syst.</infon><infon key="type">ref</infon><infon key="volume">2017</infon><infon key="year">2017</infon><offset>55355</offset><text>A survey on infrastructure-based vehicular networks</text></passage><passage><infon key="elocation-id">2207</infon><infon key="name_0">surname:Masini;given-names:B.</infon><infon key="name_1">surname:Bazzi;given-names:A.</infon><infon key="name_2">surname:Zanella;given-names:A.</infon><infon key="pub-id_doi">10.3390/s18072207</infon><infon key="pub-id_pmid">29987254</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2018</infon><offset>55407</offset><text>A Survey on the Roadmap to Mandate on Board Connectivity and Enable V2V-Based Vehicular Sensor Networks</text></passage><passage><infon key="file">sensors-18-03845-g001.jpg</infon><infon key="id">sensors-18-03845-f001</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>55511</offset><text>Road surface anomaly detection process.</text></passage><passage><infon key="file">sensors-18-03845-g002.jpg</infon><infon key="id">sensors-18-03845-f002</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>55551</offset><text>(a) Local-level coordinate system. (b) Body-frame coordinate system. (c) Device coordinate system.</text></passage><passage><infon key="file">sensors-18-03845-g003.jpg</infon><infon key="id">sensors-18-03845-f003</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>55650</offset><text>Available motion sensors on current smartphones.</text></passage><passage><infon key="file">sensors-18-03845-t001.xml</infon><infon key="id">sensors-18-03845-t001</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>55699</offset><text>List of sensors used for road surface anomaly detection.</text></passage><passage><infon key="file">sensors-18-03845-t001.xml</infon><infon key="id">sensors-18-03845-t001</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sensor Name&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Type&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Unit&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Physical&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;m/s&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Measures the acceleration force&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Gyroscope&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Physical&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;rad/s&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Measures a device’s rate of rotation&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Linear Acceleration&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Virtual&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;m/s&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Measures the acceleration force, excluding the force of gravity&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Magnetometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Physical&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;μT (T stands for Tesla)&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Measures the ambient geomagnetic field&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Gravity&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Virtual&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;m/s&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Measures the force of gravity&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Rotation&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Virtual&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;rad&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Measures the orientation of a device&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;GPS&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Physical&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Degree&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Obtain location information&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>55756</offset><text>Sensor Name	Type	Unit	Description	 	Accelerometer	Physical	m/s2	Measures the acceleration force	 	Gyroscope	Physical	rad/s	Measures a device’s rate of rotation	 	Linear Acceleration	Virtual	m/s2	Measures the acceleration force, excluding the force of gravity	 	Magnetometer	Physical	μT (T stands for Tesla)	Measures the ambient geomagnetic field	 	Gravity	Virtual	m/s2	Measures the force of gravity	 	Rotation	Virtual	rad	Measures the orientation of a device	 	GPS	Physical	Degree	Obtain location information	 	</text></passage><passage><infon key="file">sensors-18-03845-t002.xml</infon><infon key="id">sensors-18-03845-t002</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>56271</offset><text>List of sensors used for road surface anomaly detection.</text></passage><passage><infon key="file">sensors-18-03845-t002.xml</infon><infon key="id">sensors-18-03845-t002</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Proposed Method&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Employed Sensor(s)&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Data Sampling Rate (Hz)&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vehicle&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Smartphone Model&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Distance of Experiment&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Location of Data Sampling&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mohan et al. &lt;xref rid=&quot;B37-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;37&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;310&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Toyota Qualis&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Windows smartphone&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;622 km&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Bangalore and Seattle&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yagi &lt;xref rid=&quot;B21-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;21&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer/Gyroscope&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Toyota PRIUS&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;iPhone&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Kashiwazaki, Japan&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mednis et al. &lt;xref rid=&quot;B41-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;41&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;BMW 323 touring&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Samsung i5700, Samsung Galaxy s, HTC Desire HTC HD2,&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;174 km&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vairoga iela, Riga, Latvia&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Perttunen et al. &lt;xref rid=&quot;B28-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;28&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;38&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Nokia N95 8GB&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;25 km&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Finland&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Jain et al. &lt;xref rid=&quot;B29-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;29&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Bus, Auto rickshaw, cycle rickshaw, motorcycle and car (models were not mentioned)&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4 different Android-based smartphones (models were not mentioned)&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;678 km&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;New Delhi, India&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Bhoraskar et al. &lt;xref rid=&quot;B27-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;27&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;50&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Suzuki access 125, Auto rickshaw&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Google Nexus S, HTC Wildfire S&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;IIT Bombay campus&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Douangphachanh and Oneyama &lt;xref rid=&quot;B32-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;32&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Toyota Vigo 4WD, pick up, Toyota Camry, Toyota Vigo 2WD, Toyota Yaris&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Samsung Galaxy Note 3, Galaxy S3, LG 4X HD&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vientiane, Laos&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sinharay et al. &lt;xref rid=&quot;B19-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;19&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4–6&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Google Nexus S&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Kolkata, India&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Douangphachanh and Oneyama &lt;xref rid=&quot;B22-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;22&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer/Gyroscope&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Toyota Vigo 4WD, pick up, Toyota Camry, Toyota&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Samsung Galaxy Note 3, Galaxy S3, LG 4X HD&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vientiane, Laos&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Seraj et al. &lt;xref rid=&quot;B34-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;34&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;14 km&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vittorio et al. &lt;xref rid=&quot;B38-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;38&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer/Gyroscope&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;47 and 93&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Five different types of cars&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Samsung Galaxy S2&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100.3 km&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vlora, Albania&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sebestyen et al. &lt;xref rid=&quot;B33-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;33&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;90&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Wang et al. &lt;xref rid=&quot;B9-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;9&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;60&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Nomura and Shiraishi &lt;xref rid=&quot;B42-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;42&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yi et al. &lt;xref rid=&quot;B43-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;43&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Toyota Camry&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sony Xperia, HTC Desire, HTC Hero&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mohamed et al. &lt;xref rid=&quot;B30-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;30&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer/Gyroscope&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Volkswagen Jetta, Chevrolet Aveo&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Lumia 820&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Harikrishnan and Gopi &lt;xref rid=&quot;B36-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;36&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;50&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Maruti swift&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;India&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Singh et al. &lt;xref rid=&quot;B39-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;39&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Toyota Etios&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Nexus 5, Samsung S5, Samsung Note 3, Moto E, Samsung S4 mini&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;220 km&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Chandigrah, India&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Silva et al. &lt;xref rid=&quot;B40-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;40&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accelerometer&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;50&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Three different models&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Two different models&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Braga-Portugal&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>56328</offset><text>Proposed Method	Employed Sensor(s)	Data Sampling Rate (Hz)	Vehicle	Smartphone Model	Distance of Experiment	Location of Data Sampling	 	Mohan et al. 	Accelerometer	310	Toyota Qualis	Windows smartphone	622 km	Bangalore and Seattle	 	Yagi 	Accelerometer/Gyroscope	100	Toyota PRIUS	iPhone	N/A	Kashiwazaki, Japan	 	Mednis et al. 	Accelerometer	100	BMW 323 touring	Samsung i5700, Samsung Galaxy s, HTC Desire HTC HD2,	174 km	Vairoga iela, Riga, Latvia	 	Perttunen et al. 	Accelerometer	38	N/A	Nokia N95 8GB	25 km	Finland	 	Jain et al. 	Accelerometer	N/A	Bus, Auto rickshaw, cycle rickshaw, motorcycle and car (models were not mentioned)	4 different Android-based smartphones (models were not mentioned)	678 km	New Delhi, India	 	Bhoraskar et al. 	Accelerometer	50	Suzuki access 125, Auto rickshaw	Google Nexus S, HTC Wildfire S	N/A	IIT Bombay campus	 	Douangphachanh and Oneyama 	Accelerometer	100	Toyota Vigo 4WD, pick up, Toyota Camry, Toyota Vigo 2WD, Toyota Yaris	Samsung Galaxy Note 3, Galaxy S3, LG 4X HD	N/A	Vientiane, Laos	 	Sinharay et al. 	Accelerometer	4–6	N/A	Google Nexus S	N/A	Kolkata, India	 	Douangphachanh and Oneyama 	Accelerometer/Gyroscope	100	Toyota Vigo 4WD, pick up, Toyota Camry, Toyota	Samsung Galaxy Note 3, Galaxy S3, LG 4X HD	N/A	Vientiane, Laos	 	Seraj et al. 	Accelerometer	5	N/A	N/A	14 km	N/A	 	Vittorio et al. 	Accelerometer/Gyroscope	47 and 93	Five different types of cars	Samsung Galaxy S2	100.3 km	Vlora, Albania	 	Sebestyen et al. 	Accelerometer	90	N/A	N/A	N/A	N/A	 	Wang et al. 	Accelerometer	60					 	Nomura and Shiraishi 	Accelerometer	100	N/A	N/A	N/A	N/A	 	Yi et al. 	Accelerometer	80	Toyota Camry	Sony Xperia, HTC Desire, HTC Hero	N/A	N/A	 	Mohamed et al. 	Accelerometer/Gyroscope	N/A	Volkswagen Jetta, Chevrolet Aveo	Lumia 820	N/A	N/A	 	Harikrishnan and Gopi 	Accelerometer	50	Maruti swift	N/A	N/A	India	 	Singh et al. 	Accelerometer	10	Toyota Etios	Nexus 5, Samsung S5, Samsung Note 3, Moto E, Samsung S4 mini	220 km	Chandigrah, India	 	Silva et al. 	Accelerometer	50	Three different models	Two different models	N/A	Braga-Portugal	 	</text></passage><passage><infon key="file">sensors-18-03845-t003.xml</infon><infon key="id">sensors-18-03845-t003</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>58405</offset><text>List of sensors used for road surface anomaly detection.</text></passage><passage><infon key="file">sensors-18-03845-t003.xml</infon><infon key="id">sensors-18-03845-t003</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Proposed Method&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Employed Technique(s)&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Approaches&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Length of Analyzing Window&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mohan et al. &lt;xref rid=&quot;B37-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;37&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;For speed &amp;gt;25 km = 0.8 g and for speed &amp;lt;25 z-sus (sustained dip in vertical component of accelerometer data&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;seven samples for speed of less than 25 km/h&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yagi &lt;xref rid=&quot;B21-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;21&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Standard deviation of z-values with different window time&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;50 ms&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mednis et al. &lt;xref rid=&quot;B41-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;41&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Z-THERESH = 0.4 g, Z-DIFF = 0.2 g, STDEV(Z) = 0.2 g, and G-ZERO = 0.8 g&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;one sample&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Perttunen et al. &lt;xref rid=&quot;B28-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;28&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Machine learning&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Support Vector Machine (SVM)&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5 s∼2 s&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Jain et al. &lt;xref rid=&quot;B29-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;29&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Machine learning&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Support Vector Machine (SVM)&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Bhoraskar et al. &lt;xref rid=&quot;B27-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;27&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Machine learning&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;K-means Clustering and Support Vector Machine (SVM)&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Douangphachanh and Oneyama &lt;xref rid=&quot;B32-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;32&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Machine learning&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Linear Regression&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sinharay et al. &lt;xref rid=&quot;B19-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;19&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The rate change of z values in acceleration values&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1 s&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Douangphachanh and Oneyama &lt;xref rid=&quot;B22-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;22&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Machine learning&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Linear Regression&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vittorio et al. &lt;xref rid=&quot;B38-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;38&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Comparing the difference of maximum value and minimum value of vertical acceleration impulse in the defined unit of time with an adaptive threshold&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5 samples&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Seraj et al. &lt;xref rid=&quot;B34-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;34&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Machine learning&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Features extracted in time domain, frequency domain and wavelet decomposition and SVM used for feature classification&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;256 samples and 170 samples&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sebestyen et al. &lt;xref rid=&quot;B33-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;33&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Adaptive threshold based on the lowest, highest and average values of accelerometer data in predefined window length&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;one sample&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Wang et al. &lt;xref rid=&quot;B9-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;9&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Approach proposed by Mednis et al.&lt;xref rid=&quot;B41-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;41&lt;/xref&gt; with adaptive threshold&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;one sample&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Nomura and Shiraishi &lt;xref rid=&quot;B42-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;42&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0 &amp;lt; roughness index (RI) &amp;lt; 1 for &lt;inline-formula&gt;&lt;mml:math id=&quot;mm6&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt; = 0.0190 m/s&lt;sup&gt;2&lt;/sup&gt; and 0 &amp;lt; RI &amp;lt; 2 for &lt;inline-formula&gt;&lt;mml:math id=&quot;mm8&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt; = 0.0428 m/s&lt;sup&gt;2&lt;/sup&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;one sample&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yi et al. &lt;xref rid=&quot;B43-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;43&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Two steps of pothole verification based on the standard deviation of sensor data &lt;inline-formula&gt;&lt;mml:math id=&quot;mm10&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt; &amp;lt; 2 × &lt;inline-formula&gt;&lt;mml:math id=&quot;mm11&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt; and &lt;inline-formula&gt;&lt;mml:math id=&quot;mm12&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;1&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt; &amp;lt; 2.5 × &lt;inline-formula&gt;&lt;mml:math id=&quot;mm13&quot;&gt;&lt;mml:mrow&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;σ&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mi&gt;v&lt;/mml:mi&gt;&lt;mml:mi&gt;e&lt;/mml:mi&gt;&lt;mml:mi&gt;n&lt;/mml:mi&gt;&lt;mml:mi&gt;t&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5 s&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mohamed et al. &lt;xref rid=&quot;B30-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;30&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Machine learning&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;SVM with three different kernel functions (RBF, MLP, and polynomial).&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Harikrishnan and Gopi &lt;xref rid=&quot;B36-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;36&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Threshold-based&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Fitting Gaussian models to the normal roads and comparing the accelerometer sensor data value in the z direction with the mean of fitted model.&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Singh et al. &lt;xref rid=&quot;B39-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;39&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;DWT&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Measuring signal pattern similarity&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;N/A&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Silva et al. &lt;xref rid=&quot;B40-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;40&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Machine learning&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Using different supervised classification approaches (gradient boosting (GB), decision tree (DT), multilayer perceptron classifier (MPL), Gaussian Naive Bayes, and linear SVC) and comparing the detection accuracy&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;125 samples&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>58462</offset><text>Proposed Method	Employed Technique(s)	Approaches	Length of Analyzing Window	 	Mohan et al. 	Threshold-based	For speed &gt;25 km = 0.8 g and for speed &lt;25 z-sus (sustained dip in vertical component of accelerometer data	seven samples for speed of less than 25 km/h	 	Yagi 	Threshold-based	Standard deviation of z-values with different window time	50 ms	 	Mednis et al. 	Threshold-based	Z-THERESH = 0.4 g, Z-DIFF = 0.2 g, STDEV(Z) = 0.2 g, and G-ZERO = 0.8 g	one sample	 	Perttunen et al. 	Machine learning	Support Vector Machine (SVM)	0.5 s∼2 s	 	Jain et al. 	Machine learning	Support Vector Machine (SVM)	N/A	 	Bhoraskar et al. 	Machine learning	K-means Clustering and Support Vector Machine (SVM)	N/A	 	Douangphachanh and Oneyama 	Machine learning	Linear Regression	N/A	 	Sinharay et al. 	Threshold-based	The rate change of z values in acceleration values	1 s	 	Douangphachanh and Oneyama 	Machine learning	Linear Regression	N/A	 	Vittorio et al. 	Threshold-based	Comparing the difference of maximum value and minimum value of vertical acceleration impulse in the defined unit of time with an adaptive threshold	5 samples	 	Seraj et al. 	Machine learning	Features extracted in time domain, frequency domain and wavelet decomposition and SVM used for feature classification	256 samples and 170 samples	 	Sebestyen et al. 	Threshold-based	Adaptive threshold based on the lowest, highest and average values of accelerometer data in predefined window length	one sample	 	Wang et al. 	Threshold-based	Approach proposed by Mednis et al. with adaptive threshold	one sample	 	Nomura and Shiraishi 	Threshold-based	0 &lt; roughness index (RI) &lt; 1 for  = 0.0190 m/s2 and 0 &lt; RI &lt; 2 for  = 0.0428 m/s2	one sample	 	Yi et al. 	Threshold-based	Two steps of pothole verification based on the standard deviation of sensor data  &lt; 2 ×  and  &lt; 2.5 × 	0.5 s	 	Mohamed et al. 	Machine learning	SVM with three different kernel functions (RBF, MLP, and polynomial).	N/A	 	Harikrishnan and Gopi 	Threshold-based	Fitting Gaussian models to the normal roads and comparing the accelerometer sensor data value in the z direction with the mean of fitted model.	N/A	 	Singh et al. 	DWT	Measuring signal pattern similarity	N/A	 	Silva et al. 	Machine learning	Using different supervised classification approaches (gradient boosting (GB), decision tree (DT), multilayer perceptron classifier (MPL), Gaussian Naive Bayes, and linear SVC) and comparing the detection accuracy	125 samples	 	</text></passage><passage><infon key="file">sensors-18-03845-t004.xml</infon><infon key="id">sensors-18-03845-t004</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>60924</offset><text>Performance evaluation of reviewed studies investigating road surface anomalies from smartphone sensors.</text></passage><passage><infon key="file">sensors-18-03845-t004.xml</infon><infon key="id">sensors-18-03845-t004</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Proposed Method&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Performance Evaluation&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mohan et al. &lt;xref rid=&quot;B37-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;37&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;For a speed of less than 25 km/h, the rate of the false negatives is 29% (well-oriented sensor) and 37% (virtually oriented). However, for a speed of more than 25 km/h, the rate of false negatives is 41% (well-oriented sensor) and 51% (virtually oriented).&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yagi &lt;xref rid=&quot;B21-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;21&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not provided.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mednis et al. &lt;xref rid=&quot;B41-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;41&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The accuracy of the overall system is approximately 90%. However, the outcome of Z-DIFF and STDEV-Z approaches are highly dependent on the frequency and timing of data.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Perttunen et al. &lt;xref rid=&quot;B28-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;28&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The confusion matrix for the best result indicates that this approach has approximately 80% accuracy.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Jain et al. &lt;xref rid=&quot;B29-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;29&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The results indicate approximately 75% accuracy.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Bhoraskar et al. &lt;xref rid=&quot;B27-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;27&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;For bump detection, the algorithm gets zero false positives and 10% false negatives.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Douangphachanh and Oneyama &lt;xref rid=&quot;B32-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;32&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The R&lt;sup&gt;2&lt;/sup&gt; values in their estimation were between 0.721 and 0.869 for different cars when the smartphones were located in the box near gearshift.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sinharay et al. &lt;xref rid=&quot;B19-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;19&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The accuracy of the system is 80% with 20% false positives.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Douangphachanh and Oneyama &lt;xref rid=&quot;B22-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;22&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The R&lt;sup&gt;2&lt;/sup&gt; values in their estimation indicated significant improvement compared to the previous study.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vittorio et al. &lt;xref rid=&quot;B38-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;38&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Right positive rate was higher than 80% whereas the false positive rate was lower than 15%.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Seraj et al. &lt;xref rid=&quot;B34-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;34&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;90% accuracy ratio for detecting severe anomalies regardless of vehicle type and road location.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sebestyen et al. &lt;xref rid=&quot;B33-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;33&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The accuracy of the anomaly detection algorithm implemented in this study is about 80%.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Wang et al. &lt;xref rid=&quot;B9-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;9&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;In experiments, the results indicate the accuracy of the proposed approach is 100% without false positives.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Nomura and Shiraishi &lt;xref rid=&quot;B42-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;42&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94% accuracy rate for classifying road segments into different roughness levels (detection rate for road surface anomaly detection was not provided).&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yi et al. &lt;xref rid=&quot;B43-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;43&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Numerically, compared with z-component, the RMSEs (root mean square deviation) are 0.01 m/s&lt;sup&gt;2&lt;/sup&gt; of the batch mode and 0.03 m/s&lt;sup&gt;2&lt;/sup&gt; of online mode.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mohamed et al. &lt;xref rid=&quot;B30-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;30&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75.76% by applying RBF kernel function, 66.67% by applying MLP kernel function, and 87.88% by applying polynomial kernel function.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Harikrishnan and Gopi &lt;xref rid=&quot;B36-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;36&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The estimation error is 34.8% for the speed of 15 km/h and 1.6% for the speed of 20 km/h. The estimation error increases as the speed goes above 20 km/h.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Singh et al. &lt;xref rid=&quot;B39-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;39&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;88.66% detection rate for potholes and 88.89% detection rate for bumps.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Silva et al. &lt;xref rid=&quot;B40-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;40&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Scores of GB = 0.8705, DT = 0.8071, MLP = 0.7868, GNB = 0.7385, and linear SVC = 0.4619.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>61029</offset><text>Proposed Method	Performance Evaluation	 	Mohan et al. 	For a speed of less than 25 km/h, the rate of the false negatives is 29% (well-oriented sensor) and 37% (virtually oriented). However, for a speed of more than 25 km/h, the rate of false negatives is 41% (well-oriented sensor) and 51% (virtually oriented).	 	Yagi 	Not provided.	 	Mednis et al. 	The accuracy of the overall system is approximately 90%. However, the outcome of Z-DIFF and STDEV-Z approaches are highly dependent on the frequency and timing of data.	 	Perttunen et al. 	The confusion matrix for the best result indicates that this approach has approximately 80% accuracy.	 	Jain et al. 	The results indicate approximately 75% accuracy.	 	Bhoraskar et al. 	For bump detection, the algorithm gets zero false positives and 10% false negatives.	 	Douangphachanh and Oneyama 	The R2 values in their estimation were between 0.721 and 0.869 for different cars when the smartphones were located in the box near gearshift.	 	Sinharay et al. 	The accuracy of the system is 80% with 20% false positives.	 	Douangphachanh and Oneyama 	The R2 values in their estimation indicated significant improvement compared to the previous study.	 	Vittorio et al. 	Right positive rate was higher than 80% whereas the false positive rate was lower than 15%.	 	Seraj et al. 	90% accuracy ratio for detecting severe anomalies regardless of vehicle type and road location.	 	Sebestyen et al. 	The accuracy of the anomaly detection algorithm implemented in this study is about 80%.	 	Wang et al. 	In experiments, the results indicate the accuracy of the proposed approach is 100% without false positives.	 	Nomura and Shiraishi 	94% accuracy rate for classifying road segments into different roughness levels (detection rate for road surface anomaly detection was not provided).	 	Yi et al. 	Numerically, compared with z-component, the RMSEs (root mean square deviation) are 0.01 m/s2 of the batch mode and 0.03 m/s2 of online mode.	 	Mohamed et al. 	75.76% by applying RBF kernel function, 66.67% by applying MLP kernel function, and 87.88% by applying polynomial kernel function.	 	Harikrishnan and Gopi 	The estimation error is 34.8% for the speed of 15 km/h and 1.6% for the speed of 20 km/h. The estimation error increases as the speed goes above 20 km/h.	 	Singh et al. 	88.66% detection rate for potholes and 88.89% detection rate for bumps.	 	Silva et al. 	Scores of GB = 0.8705, DT = 0.8071, MLP = 0.7868, GNB = 0.7385, and linear SVC = 0.4619.	 	</text></passage><passage><infon key="file">sensors-18-03845-t005.xml</infon><infon key="id">sensors-18-03845-t005</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>63532</offset><text>Smartphone placement dependency considerations for each approach.</text></passage><passage><infon key="file">sensors-18-03845-t005.xml</infon><infon key="id">sensors-18-03845-t005</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Proposed Method&lt;/th&gt;&lt;th align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin;border-top:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Considering Smartphone Mounting Dependency&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mohan et al. &lt;xref rid=&quot;B37-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;37&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Back and middle seats, dashboard, and hand-rest of vehicle&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yagi &lt;xref rid=&quot;B21-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;21&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Front dashboard&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mednis et al. &lt;xref rid=&quot;B41-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;41&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Front dashboard&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Perttunen et al. &lt;xref rid=&quot;B28-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;28&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Windshield rack&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Jain et al. &lt;xref rid=&quot;B29-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;29&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Pants pocket, front dashboard, near the gearbox, near the rear car speakers&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Bhoraskar et al. &lt;xref rid=&quot;B27-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;27&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not defined&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Douangphachanh and Oneyama &lt;xref rid=&quot;B32-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;32&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Front dashboard, near the gearshift, inside driver’s pocket&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sinharay et al. &lt;xref rid=&quot;B19-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;19&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Front dashboard&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Douangphachanh and Oneyama &lt;xref rid=&quot;B22-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;22&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;On the dashboard, in the box near the gearshift, and inside driver’s pocket&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vittorio et al. &lt;xref rid=&quot;B38-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;38&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Front dashboard&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Seraj et al. &lt;xref rid=&quot;B34-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;34&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Fixed on the windshield&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sebestyen et al. &lt;xref rid=&quot;B33-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;33&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Front dashboard&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Wang et al. &lt;xref rid=&quot;B9-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;9&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not defined&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Nomura and Shiraishi &lt;xref rid=&quot;B42-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;42&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Front dashboard&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yi et al. &lt;xref rid=&quot;B43-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;43&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Front dashboard and windshield rack&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mohamed et al. &lt;xref rid=&quot;B30-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;30&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not defined&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Harikrishnan and Gopi &lt;xref rid=&quot;B36-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;36&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not defined&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Singh et al. &lt;xref rid=&quot;B39-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;39&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not defined&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Silva et al. &lt;xref rid=&quot;B40-sensors-18-03845&quot; ref-type=&quot;bibr&quot;&gt;40&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not defined&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>63598</offset><text>Proposed Method	Considering Smartphone Mounting Dependency	 	Mohan et al. 	Back and middle seats, dashboard, and hand-rest of vehicle	 	Yagi 	Front dashboard	 	Mednis et al. 	Front dashboard	 	Perttunen et al. 	Windshield rack	 	Jain et al. 	Pants pocket, front dashboard, near the gearbox, near the rear car speakers	 	Bhoraskar et al. 	Not defined	 	Douangphachanh and Oneyama 	Front dashboard, near the gearshift, inside driver’s pocket	 	Sinharay et al. 	Front dashboard	 	Douangphachanh and Oneyama 	On the dashboard, in the box near the gearshift, and inside driver’s pocket	 	Vittorio et al. 	Front dashboard	 	Seraj et al. 	Fixed on the windshield	 	Sebestyen et al. 	Front dashboard	 	Wang et al. 	Not defined	 	Nomura and Shiraishi 	Front dashboard	 	Yi et al. 	Front dashboard and windshield rack	 	Mohamed et al. 	Not defined	 	Harikrishnan and Gopi 	Not defined	 	Singh et al. 	Not defined	 	Silva et al. 	Not defined	 	</text></passage></document></collection>
