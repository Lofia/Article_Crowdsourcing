<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20210812</date><key>pmc.key</key><document><id>8347513</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.3390/s21155007</infon><infon key="article-id_pmc">8347513</infon><infon key="article-id_pmid">34372243</infon><infon key="article-id_publisher-id">sensors-21-05007</infon><infon key="elocation-id">5007</infon><infon key="issue">15</infon><infon key="kwd">annotation crowdsourcing classification neural networks quality control time-series</infon><infon key="license">Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).</infon><infon key="name_0">surname:Al-Qershi;given-names:Fattoh</infon><infon key="name_1">surname:Al-Qurishi;given-names:Muhammad</infon><infon key="name_2">surname:Aksoy;given-names:Mehmet Sabih</infon><infon key="name_3">surname:Faisal;given-names:Mohammed</infon><infon key="name_4">surname:Algabri;given-names:Mohammed</infon><infon key="name_5">surname:Pławiak;given-names:Paweł</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">21</infon><infon key="year">2021</infon><offset>0</offset><text>A Time-Series-Based New Behavior Trace Model for Crowd Workers That Ensures Quality Annotation</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>95</offset><text>Crowdsourcing is a new mode of value creation in which organizations leverage numerous Internet users to accomplish tasks. However, because these workers have different backgrounds and intentions, crowdsourcing suffers from quality concerns. In the literature, tracing the behavior of workers is preferred over other methodologies such as consensus methods and gold standard approaches. This paper proposes two novel models based on workers’ behavior for task classification. These models newly benefit from time-series features and characteristics. The first model uses multiple time-series features with a machine learning classifier. The second model converts time series into images using the recurrent characteristic and applies a convolutional neural network classifier. The proposed models surpass the current state of-the-art baselines in terms of performance. In terms of accuracy, our feature-based model achieved 83.8%, whereas our convolutional neural network model achieved 76.6%.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1091</offset><text>1. Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1107</offset><text>Crowdsourcing, a concept first coined by Howe, refers to numerous people being involved in computing tasks to solve problems that are more difficult for computers than humans. It is an alternative mechanism for solving such problems at a lower cost. Therefore, many researchers have resorted to crowdsourcing as a preferable labeling choice in different domains, such as natural language processing and image labeling. Moreover, many researchers have incorporated crowdsourcing into studies on the COVID-19 pandemic, disasters, fake news, and preprocessing for deep learning applications. Such studies leverage the availability of crowdsourcing platforms such as Amazon Mechanical Turk (AMT), as well as the abundant ordinary Internet users (i.e., crowd workers). Due to the heterogeneous nature of such workers, crowdsourcing is prone to quality concerns.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1964</offset><text>Crowd workers have different motivations, expertise, and backgrounds. Moreover, human-specific factors (e.g., boredom, laziness, and inexperience), identity, and bias are other sources of quality errors. Notably, numerous crowd workers are untrustworthy. The percentage of spammers among crowd workers could be as high as 50%. Moreover, crowd workers may attempt to maximize their monetary rewards by cheating using quick submission or copy and pasting. There are also sophisticated spammers who can evade certain anti-cheating crowdsourcing tests. Others such as Sybil attackers can attack crowdsourcing tasks using pseudo accounts to submit similar answers. All of these problems can lead to deceptive results from such workers or high variability in quality due to variance in their effort or skills. In 2016 at least 20 million adults in the U.S. earned money by working from crowdsourcing like those found on Amazon Mechanical Turk (AMT), a number that is expected to rise with the growth of AI. Furthermore, crowdsourced data processing is performed at scale at many tech companies, with tens of millions of dollars spent every year, so the quality improvement is a critical issue for those companies. To attain high-quality results from crowdsourcing, various approaches have been proposed. A common technique is to evaluate crowd workers’ output using gold standards. Unfortunately, many crowd workers may be rejected just due to bad luck on gold set questions. Moreover, spammers are aware of the use of such questions. Another widely used approach involves studying the relationship between crowd workers’ answers based on consensus methods such as majority voting. One limitation of such a method is the high costs due to redundancy. Moreover, such methods fail against collusion attacks by malicious workers. Another approach uses motivations such as reputation in advanced quality measures.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3872</offset><text>An alternative way to cope with these problems is to study crowd workers’ behavior rather than their output. Compared with gold standard and consensus methods, behavior-based approaches can be generalized across tasks and do not only target closed questions. Moreover, these approaches are free from the cold-start problem, and they do not require workers’ historical annotation information.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4268</offset><text>Regrettably, only a few studies have targeted crowd workers’ behavior. Gadiraju et al. studied different workers’ behavior limited to online surveys. Hirth et al. examined different time aspects of worker behavior to find the most crucial features related to worker qualifications. Rzeszotarski and Kittur estimated the labeling quality and accuracy of workers on different tasks based on task fingerprints and a set of statistical behavior features. Similarly, Kazai and Zitouni collected experts’ behavior and trained a supervised classifier to detect poor crowd workers. However, none of these works have shared their source code or dataset. Leveraging from the open source of, Goyal et al. are the only researchers who have shared their collected dataset. The present study benefited from this dataset and works.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5091</offset><text>It proposes novel time-series-based models in the field of crowdsourcing quality control.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5181</offset><text>It introduces two new models with various experiments. The first was based on time-series feature generation, showing the important features of crowd workers’ behavior. The other model was based on converting time series into heatmaps and then leveraging from their recurring characteristics to classify the tasks of crowd workers. The latter model establishes a baseline for research in the application of a lightweight deep learning model in the field of crowdsourcing workers’ assessment control.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5685</offset><text>The proposed models possess superior performance. We demonstrated that our models outperform time-series state-of-the-art models such as dynamic time warping (DTW) and time-series support vector classifier (TS-SVC), as well as leading research works by Rzeszotarski and Kittur and Goyal et al..</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5980</offset><text>The contributions of this paper can be summarized as follows:</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6042</offset><text>The remainder of this paper is organized as follows. Section 2 presents the related work. Section 3 describes the methodology and the proposed models. Section 4 illustrates the experiment details and results as well as provides the discussion. Finally, Section 5 presents the conclusion and recommendations for future works.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>6367</offset><text>2. Related Work</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6383</offset><text>Generally, at least two types of approaches have been explored by researchers to obtain high-quality data from crowd workers, traditional and behavior-tracing approaches.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>6554</offset><text>2.1. Traditional Approaches</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6582</offset><text>In this line of research, quality control is applied to crowd workers’ responses. This can be based on other independent human evaluators, who are employed to assess the answers of other crowdsourcing workers. Other studies have implemented consensus algorithms, where multiple answers are gathered for each task. These answers are then aggregated into the most likely answer or the so-called majority vote. Unfortunately, this approach can greatly inflate costs due to the needed redundancy. Furthermore, it is vulnerable to gaming, the majority effect, or at worst Sybil attacks. Another traditional approach is to use gold standard data for filtering workers. These gold data can be created by injecting a few ground truth labels from experts in rich crowd labeling or by gathering a set of experts. These standard data can also be generated automatically from just a few gold unit seeds. A real-time system can evaluate crowd workers’ reliability using a collected reference set. A shortcoming of such gold standard data is that they are not always available or applicable in some generative tasks, such as tagging and summarization. Both majority voting and gold data approaches assume that the response spaces are structured (i.e., the tasks have closed questions).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7858</offset><text>Other researchers have applied social motivations such as reputation as a pre-quality filtering approach. A social norm and welfare framework was simulated in to mitigate the “free-riding” problem in crowdsourcing. Such an approach entails the drawback of evasion by malicious workers. Such workers can even acquire high reputation scores by accepting tasks that are unlikely to be rejected.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>8254</offset><text>2.2. Behavior Tracing Approaches</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8287</offset><text>A different line of research is focused in tracing the behavior of crowd workers when performing tasks. Kazai and Zitouni stored experts’ behavior as behavior features (e.g., mouse movements, clicks, scrolls, and key-presses) of three different tasks. They applied it to training a gradient boosted decision tree classifier to detect poor crowd workers. Rzeszotarski and Kittur proposed a task fingerprinting prototype that was mainly based on the recording of sequential logs of interface events. They collected statistical features related to time and browsing events, and then applied the prototype in different tasks and investigated decision trees to classify passing versus failing workers. Both of the aforementioned studies applied or necessitated expert behavioral data, which are difficult and costly to acquire in practice. In, the authors developed and applied the behavior approach of application layer monitoring. They studied three time aspects (i.e., completion, working phases, and consideration) using very fine-grained interaction level features to feed a support vector machine. One of their main findings was that a robust correlation existed between task interaction time and workers’ qualifications. They focused only on time features and neglected other behavior features. A visualization tool called CrowdScape was introduced in. The researchers visualized both worker behavior and output information. They traced workers by analyzing and showing a highly granular user interface interaction level such as mouse movements, clicks, and focus changes. An analysis of search engine result pages was presented in, which studied the behavior of the assessors working on these pages. The authors defined different patterns based on time analysis and ratings accordingly and reported the possibilities of cheating and noncheating behaviors according to those patterns. Another work was limited to an online survey, and collected data from two pre-defined workers. They presented five different groups of workers differentiated by their behavior. Restricted to a questionnaire, the researchers in studied behavior in terms of five personality traits and observations of workers’ interactions with some task parameters, and defined another five types of workers.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10572</offset><text>A recent study leveraged from to generate richer behavior features investigated the feasibility of using these features of crowd workers for classifying the correctness of labels and predicting the labeling accuracy of workers. They applied a random forest classifier and a k-means clustering classifier for transforming sequence-like features. Next, they combined the random forest classifier with a co-training supervised naïve Bayes model for the sequence features. Lastly, some crowdsourcing quality research has focused on the consistency behavior of crowd workers, such. Different from the aforementioned studies, the present study aimed to enrich the research by manipulating data as time-series data. This new angle of data manipulation will create opportunities for enhancing the performance of machine learning (ML) models, either by feeding ML models with spacious features as in our feature-based model or by leveraging deep learning models as in our second image-convolutional neural network (image-CNN) model.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>11597</offset><text>3. Method and Materials</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>11621</offset><text>3.1. Dataset</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11634</offset><text>To evaluate the performance of the proposed models against baselines and for experimental evaluation, we used the public dataset by Goyal et al.. Its behavior data include 3984 HIT records. The data used for crowdsourcing tasks were collected from the 2014 NIST TREC Web Track.1. AMT workers were asked with judging the relevance of documents on 50 predefined topics. The judgment scale for those HITs was multiscale. For our experiments, we used a binary scale; that is, each record was either labeled as 1 if the worker correctly answered the task or 0 if he or she did not. The behavior features of these workers during their annotation were collected. The features were action-based, such as mouse movement, clicking, and scrolling, as well as time-based, such as total time and dwell time. We focused on action-based and converted them into time-series–based features as we will describe later.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>12536</offset><text>3.2. Proposed Models</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12557</offset><text>Human intelligent tasks (HITs) are tasks performed by crowd workers in crowdsourcing markets. For each HIT, the browsing behavior events of the worker are recorded. In our methodology, these browsing events were: e ∈ {mouse movement, key click, focus change, scroll, paste}.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12834</offset><text>In general, time series can be sampled regularly or irregularly through time and can therefore be represented as a vector of time stamps , and associated measurements . Let the sampling times be . If the time points are equally spaced, that is,  then the time series is regularly sampled; otherwise, it is an irregularly sampled time series.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13176</offset><text>In our case, the timestamps of the samples were not equally spaced, which meant that our samples were irregularly sampled time series. For each sample, the representation is an ordered vector of events  with  measurements, where the associated measurement  is the time at which the associated browsing action occurred. The HIT vectors have variable lengths depending on the number of actions a worker performed for each HIT. Finally, our two models were based on the manipulation of these samples as irregular time-series-like data. For example, consider a simple HIT log listing four browsing events over a 30-s period: ((, mouse-move), (, click), (, focus-change), (, click)). We recorded such an example as time-series data. This simple HIT is represented as vector ; such vectors are the input samples for our two models, namely the feature-based model and the image-CNN model.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14058</offset><text>Figure 1 depicts the two proposed models. First, the browsing behaviors of the crowd workers are captured as sets of events . Then, the timestamps of these events are stored for each HIT as time-series samples. These time-series are the inputs for both models. Whereas the feature-based model receives these samples as time-series features and uses an ML model, the image-CNN model receives them as sets of recurrence plot (RP) images/heatmaps. Finally, for both models, the output is a binary class that predicts whether the worker will label the HIT correctly or incorrectly.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>14636</offset><text>3.2.1. Feature-Based Model</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14663</offset><text>In this model, we used feature generation and selection approaches to enhance the ML performance. Leveraging from transformed time-series samples, we generated a huge number of features to train ML models. Then, we selected and shed light on those features that remarkably enhanced the ML models’ performance and the most important features.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>15007</offset><text>Feature Generation</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15026</offset><text>For each time-series sample (workers’ HIT browsing behavior), we generated a set of global time-series features (such as measures of its trend, entropy, and distribution). Then, we applied an ML classifier using these features to classify the samples (HITs). Global features of the time-series samples refer to algorithms that quantify patterns in time series across the full sample (rather than capturing subsequences). These global features are divided into different categories, which are described in the following four subsections.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15565</offset><text>Statistical:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15578</offset><text>In this category, there are some simple statistical features, such as mean, median, variance, standard deviation, and sets of quantiles (where a quantile determines how many values in a distribution are above or below a certain limit). Others include count below the mean and ratio beyond sigma. Other more advanced features such as skewness and kurtosis are measures that define how far the distribution differs from a normal distribution. Another one is Benford correlation, which is a correlation resulting from the Newcomb-Benford’s Law distribution.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16135</offset><text>Transformed:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16148</offset><text>This category contains two popular transformations. The first is the generation of Fourier transform coefficients. We generated the Fourier coefficients of one-dimensional discrete Fourier transform for real input using the fast Fourier transformation (FFT) algorithm as follows: where  is the returned coefficients and  is the time series. Furthermore, we leveraged FFT to extract statistical features of the absolute Fourier transform spectrum, such as spectral centroid (mean), variance, skew, and kurtosis. The second transformation is continuous wavelet transformation (CWT). We applied Mexican hat wavelet, which is the negative normalized second derivative of a Gaussian function: where  is the width parameter of the wavelet function .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16892</offset><text>Information theory/entropy:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16920</offset><text>Different entropy measures were generated, such as sample and approximate entropy and permutation entropy. Other entropy measures were generated from the transformed one such as the binned entropy of the FFT.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17129</offset><text>Time-series-related/others:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17157</offset><text>We also generated simple features related to the time-series, such as the sum, length, maximum, and minimum. Other specific time-series features were generated, including absolute energy, which is the sum over the squared values of the samples; energy ratio by chunks, which is the sum of squares or chunk  out of  chunks, and it is a ratio over the whole series; complexity estimation, which estimates how complex the time series is (e.g., whether it has more peaks or valleys); and symmetry, which checks whether the distribution of the sample is symmetrical.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>17719</offset><text>Feature Selection/Reduction</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17747</offset><text>Many features from the previous step have many sub-features. For example, there are nine quantiles and many coefficients for CWT and FFT, and many Fourier entropy bins. For each event , there are approximately hundreds of generated features. As a result, the number of features returned from the generation step is huge. Therefore, we applied a feature selection/reduction approach to shed light on the most important features, and those remarkable features enhanced the ML models’ performance. We selected the extremely randomized trees classifier (ExtraTreeClassifier) for the feature selection/reduction. In our case, the HIT events in terms of time stamps were the vector samples. These samples were the input feature for this approach. The tsfresh module was used for feature generation. In this step, the number of features generated was enormous. There were 3896 features, including the features in the section above, as well as others. These features were divided into training and testing sets for training a random forest (RF) model. Moreover, due to the huge number of features generated, we applied a feature selection approach to find the important features that mainly affect the ML model; then, we shed light on the most important features. We applied the ExtraTreesClassifier for feature selection and then trained and tested the same RF model using these resulting features. We experimented with different thresholds for this step and investigated how they would affect the performance of the model. The list of 78 important features that returned from a mean threshold are shown in Table A1 at Appendix A.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>19373</offset><text>3.2.2. Image-CNN Model</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19396</offset><text>In this model, we first converted the input time-series data into other behavior recurrent samples and then used the CNN model to train and test the new samples.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>19558</offset><text>Recurrence Plot</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19574</offset><text>Time series can be characterized by a featured recurrent behavior such as irregular periodicities. The recurrence plot (RP) is a famous tool for studying and visualizing such behaviors. It provides a graphical representation of the recurrent patterns in time-series signals. Eckmann et al. proposed the RP as a matrix of pairwise recurrences of phase-space states. For a given trajectory  and , the RP is defined as follows:where  is the Heaviside function,  is the norm, and ε is a distance threshold. Basically,  if time  recurs to a former (or later) state at , and  otherwise. In our case, we used a gray level instead of binarization to preserve much information (i.e., to which level  is close to )). The distance between two states  was calculated using the Euclidean distance:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20365</offset><text>Regarding , we ignored the distance threshold.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20412</offset><text>After calculating the distances, the recurrence matrices were stored as gray-level images (heatmaps) to be inputs for the model.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>20541</offset><text>CNN Model</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20551</offset><text>Compared with traditional ML methods, deep learning (DL) recently achieved great success in many computer science fields. CNNs are one of the most popular DL models. CNNs have achieved excellent performance in the image classification field. We used a CNN to classify the images formed from the RP step as introduced in. We used an enhancement of the model by concatenating the feature outputs from the CNN with auxiliary features to optimize the classifier. The details of CNN model are as follows.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21051</offset><text>The input to our network is an observation set  containing N instances of  (gray-scale image as the d-dimensional vector, d = 2 and number of channels = 1) with corresponding labels  (i.e.,  for binary classification) annotated by the workers. The goal is to learn the CNN model, represented by , from the labels that generalized well on unseen data: where  is the predicted label for an unseen image , and  is the learned model parameter.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21491</offset><text>The 2D convolution layer has the images  masked by a kernel  as follows: where  are dimensions of the image and  are dimensions of the kernel.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21634</offset><text>Now, we consider a kernel  of size , and  is a  patch of the image. The activation is obtained by sliding the  window and computing  where  is a bias and  is the activation function. The rectified linear unit (ReLU) is used as follows:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21870</offset><text>Then, a sub-sampling is used by adding a pooling layer (MaxPooling). After that, the flattening of the output is concatenated with a set of auxiliary features that are entered in two layers. These layers are the multilayer perceptron (or neural network). First, the fully connected hidden layer is followed by the output layer as follows.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22209</offset><text>For  (hidden layer): </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22231</offset><text>For  (output layer):  where  that was calculated in (7);  is the weight vector  and  is the ReLU activation function for the fully connected layer. Finally,  is the activation function of the output layer, which is Sigmoid, and its output is the classification label .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22500</offset><text>At each step,  is a matrix for which the number of rows is the number of neurons (features ) in layer  and the number of columns is the number of neurons in layer . Regarding the architecture of our model, we defined the startup architecture and then we optimized it by tuning different hyper-parameters. The CNN model had one input channel of size 32 × 32, which represents the height and width of the gray images (the reason being that the time-series data had variable length, the longest sample being 128 and the smallest being 28; the average length was 32, so we selected the average length). These images were generated from RP mapping; 3985 samples were converted into gray images with variable dimensions. All were resized to the fixed 32 × 32 dimensions. The number of filters was 32; these filters had a 3 × 3 window size. Regarding the activation function, ReLU Equation (8) was implemented. The model had a subsampling step using the MaxPooling layer. To prevent the model from overfitting, a dropout with a 0.2 rate value was used. The model was flattened after that to enable the concatenation with auxiliary features. These auxiliary features were used to enhance our CNN model. They are shown in Table 1 (adapted from). A fully connected layer with 64 neurons was used, followed by another dropout with a 0.5 rate. The last layer in the model is a single neuron with sigmoid activation to classify the images into two classes. For learning, we applied the Adam optimizer. Binary cross entropy was used as the loss function. The number of epochs started with 200 and a batch size of 25. The validation ratio was 20% of the data.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24148</offset><text>For added details, we now describe the output dimensions of the layers. We have image  with dimensions of , one channel  (grayscale), and a filter size of . The default stride  of filter movement was 1. Furthermore, the convolution padding  was zero. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24400</offset><text>Therefore, the output dimension =. This was put into the pooling layer. In the MaxPooling2D layer in Keras, the default stride equals the pooling size, and our pooling size was ; thus, = 2. Using Equation (13) again,. Consequently, the pooling output dimension =, and we had 32 filters, so the number of features was  = 7200. These features, concatenated with 11 auxiliary features, give the total number of features—7211. This means that  in Equation (13) has dimensions of , namely the features multiplied by the number of neurons of the fully connected layer. The last sigmoid layer produces a label of either 0 or 1. The detailed architecture of this model is presented in Figure 2.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>25089</offset><text>4. Experimental Results and Evaluation</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>25128</offset><text>4.1. Experimental Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>25154</offset><text>4.1.1. Evaluation Metrics</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25180</offset><text>To evaluate the classification, we adopted accuracy as the comparison evaluation metric. Moreover, since the dataset had imbalance classes, we used the area under the curve (AUC) of the receiver operating characteristics (ROC) curve scores.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>25421</offset><text>4.1.2. Features-Based Model</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25449</offset><text>Parameters tuning:</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25468</offset><text>One of the most common techniques for hyperparameters tuning in machine learning models is cross-validation (CV) using k number of folds. Random forests are not an exception. So, we first tuned the model hyperparameters using 10-fold CV to ensure that the model train and test 10 different data samples. We then calculated the average performance of these divided data samples. We further tuned the hyperparameters by randomizing search of optimized parameters. We defined a grid of hyperparameter ranges and random samples from the grid, performing 10-fold CV with each combination of values. We tuned different parameters using this method and the results were: no bootstrapping, no maximum depth, 131 features as maximum number, 7 minimum number of samples split, and 408 estimators. This optimization improved the performance for feature generation model by 1.7% in terms of accuracy and by non-noticeable improvement for AUC-ROC. Approximately, the feature selection model enhanced accuracy by 1% and it seems like the first model in terms of AUC-ROC.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26525</offset><text>Feature generation and selection:</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26559</offset><text>For the first model, 3896 features were generated. Therefore, we used ExtraTreesClassifier for feature selection and to demonstrate the important features from among the numerous features. Using ExtraTreesClassifier, we retrieved the importance of each feature. The importance represents the mean decrease in the Gini-impurity. Mean decrease in Gini is a famous measure of variable importance for estimating a target variable in decision trees, random forests, ExtraTrees models. The variable is the feature, and the target is the class. Different means of importance of all features are considered as importance thresholds. The higher the number, the more important the feature. Moreover, we used different thresholds to show how many important features were reduced by the model, as well as the accuracy and AUC-ROC score for each threshold. The thresholds are different means of the importance threshold that resulted from the ExtraTreesClassifier, as presented in Table 2. It reveals that both the accuracy and AUC-ROC fluctuated between 83% and 80% until the number of features reached 41, when they began to decrease to approximately 78%.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>27704</offset><text>4.1.3. Image-CNN Model</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27727</offset><text>Parameter tuning:</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27745</offset><text>In this subsection, we outline the results of our CNN model using various hyper-parameters. Since the learning rate is one of the most important hyper-parameters to tune for training deep neural networks, we implemented an experiment to select the most suitable learning rate. We fixed the number of epochs to 300 and the dropout rate for the convolutional layer and dense layer to 0.5 and 0.25, respectively; consequently, the batch size was set to 50. Leveraging from, we set the learning rate range as base_lr = 0.1 and max_lr = . We started from a low learning rate and increased it exponentially for every batch using the step size, which we set to step_size = 20.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>28415</offset><text>As Figure 3 shows, there was a continuous decrease until reaching a stable state. The point of stability estimates the most suitable learning rate. We approximated it as . We fixed this learning rate for all subsequent hyper-parameters experiments. Regarding the number of epochs, we experimented with the training/validation loss and accuracy against 300 epochs, as shown in Figure 4. We found that at approximately 150 epochs, the validation accuracy and loss started to be fixed. This meant that the model started to be stable around 150 epochs and it seemed to enter in overfitting just after that. Therefore, we fixed the number of epochs to 150 for the following experiments.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29097</offset><text>Therefore, our initial hyper-parameters were as follows: learning rate:, epochs: 150, input dimensions 32 × 32, and dropout rates for the convolutional layer and dense layer = 0.5 and 0.25, respectively. Table 3 presents the use of different hyper-parameters and the corresponding training, validation accuracy, and loss. We selected the best validation accuracy and loss for fixing the hyper-parameters and then started to tune the next one.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29541</offset><text>First, we used batch sizes of 25, 50, and 75 and found that the optimal validation accuracy and loss were achieved with a batch size of 50. Second, for the convolutional layer, we used dropout rates of 0.25, 0.50, and 0.75. We noticed that the model attained the optimal validation accuracy and loss with the 0.25 dropout rate. The same was found with the fully connected layer where the 0.25 dropout rate achieved the best results. Finally, we tried some different dimensions for the images, namely 56 × 56, 28 × 28, and 32 × 32, as recommended in. Regarding the training, validation loss, and accuracy across the epochs, since we conducted a k-folding experiment with k = 10, we only present two folds (the third and eighth epochs) in Figure 5.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>30291</offset><text>4.1.4. Baselines</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30308</offset><text>The proposed models’ performances were compared with different baselines using the dataset of Goyal et al.. The first baseline was a decision tree with aggregate features (DT-AF) classifier, which is a classifier model from Rzeszotarski and Kittur. It uses behavior features in addition to updated aggregated behavior features of Goyal et al.. The second baseline was a random forest with the same aggregate features (RF-AF) classifier, which was a generalization of the DT-AF classifier. We applied some optimization for these two baselines like the parameters tuning in Section 4.1.2. Same parameters for RF-AF with our feature-based models, which are random forest algorithms. However, we tuned the parameters less with DT-AF since decision trees had fewer parameters to be tuned. In spite of that, DT-AF had noticeable enhancement compared to no improvement for RF-AF.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>31183</offset><text>The third and fourth baselines were popular classifiers in time-series field. The third was k-nearest neighbor classifier using dynamic time warping (DTW) as a distance measure. This classifier has received enduring interest and been shown to be effective for time-series classification. DWT is a popular comparison algorithm in time-series analysis that finds an optimal alignment between two given (time-dependent) sequences under certain restrictions, rather than measuring similarity or dis-similarity between two input times series using Euclidian distance between the corresponding points of the inputs. DTW is a very robust method to compare them using a sliding window instead of pair comparison. This is to ignore any phase shifts and speed between the inputs. We consider this simple approach, since it often produces better results than more complex classifiers.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>32057</offset><text>The fourth and final baseline was a support vector classifier SVC for the time series data (TS-SVC). Support vector classifier (SVC) is an algorithm that searches for the optimal separating surface between classes using hyperplane. When there is a non-linearity relation between the data, such as in our case, SVC needs to apply a suitable kernel. In the domains that frequently use time-series data such as bioinformatics, there is increasing domain-kernels usage. We applied SVC with such time-series called global alignment kernel. This kernel implements a maximum smoothed DTW score across all possible alignments between the two compared time-series samples. TS-SVCs are promising methods for predicting different time-series domains such as financial or biomedicine. No dedicated optimization is applied for these models. We tried some parameter tuning like the number of neighbors, but no noticeable enhancement occurred. This, unfortunately, came with a large increase in time complexity.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>33054</offset><text>4.1.5. Parameters and Software</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>33085</offset><text>For the DT-AF baseline, we used the default settings. For the RF-AF model, we used an ensemble of 100 trees in the forest. We used the scikit-learn module for these baselines. For DTW, we used two neighbors for distance calculations. For both the DTW and TS-SVC baselines, we implemented the corresponding Tslearn libraries. For the division of data, we used 10-fold cross-validation and the test size was 20% for all models. The experiments were conducted on a machine with the following criteria: a GeForce GTX 980 GPU with 47 GB RAM, using Python 3.8 and Keras API in the Ubuntu 20.04 operating system.4.2.6. Comparison with baselines:</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>33724</offset><text>In this subsection, we present the classification metrics and results of the proposed methods and baselines. Our models achieved optimal accuracy. The two feature-based models attained accuracies of 83.8% and 81.8%, followed by the image-CNN model, which attained 76.6%. Furthermore, in terms of AUC-ROC, the two feature-based models won, achieving accuracies of 82% and 80.9%, followed by the image-CNN model, which achieved 72.3%. We believe that the image-CNN model was able to achieve better results; however, the number of samples was small, and such CNN deep networks require a huge amount of data. For DTW, we only used two neighbors since any increase in neighbors would increase the time complexity of the model without any noticeable enhancement in performance. TS-SVC had the same time complexity challenge, and the same observations were noted; specifically, any increase in the comparison numbers led to increased quadratic time complexity without a remarkable improvement in the results. Table 4 presents the results of the performance comparison against baselines in terms of accuracy and AUC-ROC with an average 10-fold cross-validation.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>34878</offset><text>5. General Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>34900</offset><text>5.1. Feature-Based Models</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>34926</offset><text>The feature-based models achieved superior performance over analogous models such as. A significant factor is the large number of features generated from our time-series transformation. Rather than having around twenty features in the baselines, our model has around 4k features in the first feature-based model and 41 features for the worst performance of the second model. The results showed that the feature-based models classified the workers well when their browsing events in HITs were captured as time-series samples. This gives the indication about the good consideration of crowd behavior as a time-series representation. Regarding the optimization of these models, we found that cross validation with main hyperparameter tuning raised the performance around 2%. This is a fine percentage. However, we did not expect more noticeable improvement for further optimization. These models have limited options in the optimizations. Regarding the most important features affecting the performance, as Appendix A shows, the majority were related to either mouse movement or focus change events. Mouse movement was the most significant event followed by focus change and then key clicks. In addition, scrolling and paste events seemed not to exhibit any noticeable enhancement in the ML models. This seems reasonable, since the workers in the HIT used more mouse movements than other events. The focus change gives a good indication about the intention of the workers to do a good work. Generally, among 78 features, we found that 41 features were related to mouse movement, followed by 20 related to focus change and only 16 related to key clicks. In particular, significant features were the transformed ones such as the CWT and FFT coefficients for both focus change and mouse movement. In addition, large sets of quantiles had significant impacts in the ML models. Other statistics such as mouse movement and focus change maximum, minimum, and mean were also important. This indicated that the statistical features of mouse movement and focus change remarkably affected the classifier performance. Mouse movement absolute energy and energy ratio by chunks were other important features. Moreover, especially for mouse movement, approximate entropy was returned as an important feature. This could be reasonable since approximate entropy is designed to work for small data samples (n &lt; 50 points), and we had n = 32.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>37347</offset><text>5.2. Image-CNN Model</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>37368</offset><text>Differently, we selected a new model in this research scope compared to saturated ones such as random forest, decision trees. Our image-CNN model archived comparable performance results despite the small number of behavior traces. Such shortage in data samples does not yield competitive performance using such neural networks models. Therefore, one of the factors of such performance is the transformation of the numeric data into heatmap images. CNN is the most widely used deep learning model in the areas of image processing. Many researchers used variations of CNNs for image classification and achieved superior performance such as. Another factor is the intensive optimization for this model. We deepened the optimization in this model to enhance the performance because such models are rare/nonexistent in the research of classifying crowdsourcing workers using their behavior. This model presents a prospective beginning for further research on neural models such as deep CNN and long short-term memory (LSTM) models. For the optimization we implemented hyperparameter optimization HPO. It consists in fixing the various hyperparameters of the model. We optimized global hyperparameters like learning rate, epochs, and regularization parameters such as dropout rates. We started the tuning from the learning rate since it is one of the most important factors. Then, we gradually tuned other significance hyperparameter like number of epochs, batch size, dropout rate, and dimensions. The accuracy and loss monitoring are the key for such tuning. In terms of the number of epochs and the dropout rate, overfitting was alarming. We selected 150 epochs and dropout rates as 0.25 in both layers since other values for epochs and dropout rates led to overfitting. Regarding the image dimension, as expected, 32 × 32 provided the best results since it was equal to our average time-series sample length, which is 32.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>39289</offset><text>5.3. Baselines</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>39304</offset><text>The baselines are of two types: (a) state-of-the-art models such as dynamic time warping (DTW) and time-series support vector classifier (TS-SVC). (b) Leading research works by Rzeszotarski and Kittur and Goyal et al.. Regarding their optimizations, for both DT-AF and RF-AF, in terms of accuracy, only DT-AF model achieved considerable enhancement. It reached the performance adjacent to RF-AF model. This could be interpreted based on the small number of features. A small number of features did not result in any performance disparity between decision trees and random forests. However, decision trees needed some more optimization. RF-AF model did not achieve any noticeable enhancement. In terms of AUC-ROC, there was no enhancement for either model. Even after optimizations, DT-AF and RF-AF models still achieved lower performance compared to the proposed models. Alternatively, we did not make any considerable optimizations for DTW or TS-SVC models. For DTW, we only used two neighbors since any increase in neighbors would increase the time complexity of the model without any noticeable enhancement in performance. TS-SVC had the same time complexity challenge, and the same observations were noted; specifically, any increase in the comparison numbers led to increased quadratic time complexity without a remarkable improvement in the results.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>40660</offset><text>6. Conclusions</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>40675</offset><text>In this study, two new models were proposed to deal with the quality problems related to crowdsourcing. These models depended on time-series data. These data represented the browsing behavior of crowd workers. Each model dealt with the data differently. The feature-based model generated a huge number of features that fed an ML classifier. The richness of the features enhanced the classifier’s performance. Our experiments shed light on which features were the most important, and, consequently, on the remarkable browsing events that determine crowdsourced work quality. The image-CNN model gathered the time-series data as recurrent heatmaps and fed a CNN model. The two models provided a classification for HITs that predicted whether a HIT would be performed correctly by a worker based on his or her browsing behavior. Both models significantly outperformed the state-of-the-art and leading classifiers.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>41588</offset><text>There are some limitations in our work. The training data are limited in this study regarding models such as image-CNN model. The performance of new promising AI approaches, such as deep learning, is strongly correlated with the amount of training data available. Therefore, further research is needed to exploit larger training data. This could be carried out either by creating an extensive dataset and then using this dataset as time series with recent models such as LSTM, or, alternatively, by implementing data augmentation for the generated recurrent images in this study. Undoubtedly, this will enhance the CNN performance, specially with extending the CNN model into deep CNN with more deep layers and more hyperparameter tuning. Another limitation is the transformation into irregular time series samples. Although the performance of the proposed models is noteworthy, having a likely regular time series sample will enhance the models remarkably. Therefore, in future work, we plan to resample time-series using different techniques. Rather than primitive methods such as shifting and imputing, we will exploit more advanced resampling approaches such as periodic identification and causality analysis. One more limitation is the performance of DTW and TS-SVC models. We did not perform an optimization for these models due to the time complexity of such models. However, a window of further research is possible using Faster DWT algorithms similar to. This will feasibly optimize these time series models.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">footnote</infon><offset>43106</offset><text>Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title</infon><offset>43232</offset><text>Author Contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>43253</offset><text>Conceptualization, F.A.-Q. and M.A.-Q.; methodology, F.A.-Q. and M.A.-Q.; software, F.A.-Q., M.A.-Q. and M.A.; validation, M.A.-Q., M.A. and M.F.; investigation, F.A.-Q., M.S.A. and M.F.; resources, F.A.-Q., M.A.-Q. and M.A.; data curation, F.A.-Q. and M.A.-Q.; writing—original draft preparation, F.A.-Q. and M.A.-Q.; writing—review and editing, F.A.-Q., M.F. and M.S.A.; visualization, F.A.-Q. and M.A.-Q.; supervision, M.S.A. and M.A.-Q.; funding acquisition, F.A.-Q. All authors have read and agreed to the published version of the manuscript.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>43805</offset><text>Funding</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>43813</offset><text>The Deanship of Scientific Research at King Saud University, Riyadh, Saudi Arabia, through a research group program under Grant RG-1441-503.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>43954</offset><text>Institutional Review Board Statement</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>43991</offset><text>Not applicable. </text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>44008</offset><text>Informed Consent Statement</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>44035</offset><text>Not applicable. </text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title</infon><offset>44052</offset><text>Data Availability Statement</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>44080</offset><text>Not applicable.</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title</infon><offset>44096</offset><text>Conflicts of Interest</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>44118</offset><text>The authors declare no conflict of interest.</text></passage><passage><infon key="section_type">APPENDIX</infon><infon key="type">title</infon><offset>44163</offset><text>Appendix A</text></passage><passage><infon key="section_type">APPENDIX</infon><infon key="type">paragraph</infon><offset>44174</offset><text>In this appendix, we present the details of the features that result from the feature selection stage of the feature-based model at Table A1.</text></passage><passage><infon key="file">sensors-21-05007-t0A1.xml</infon><infon key="id">sensors-21-05007-t0A1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>44316</offset><text>The features of the feature-based model.</text></passage><passage><infon key="file">sensors-21-05007-t0A1.xml</infon><infon key="id">sensors-21-05007-t0A1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Feature Name&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Feature Description&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Action Name&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Importance&lt;break/&gt;Order&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Parameters&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;15&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Continuous Wavelet Transform coefficients&lt;/td&gt;&lt;td rowspan=&quot;15&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The Continuous Wavelet Transform for the Mexican hat wavelet&lt;/td&gt;&lt;td rowspan=&quot;8&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;MMT *&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;15&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;18&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 20&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;63&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2nd Coefficient width 5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;68&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2nd Coefficient width 20&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;71&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2nd Coefficient width 10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;72&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2nd Coefficient width 2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;FCT *&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;28&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;33&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;36&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 20&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;38&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;CST *&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;64&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;66&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;77&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1st Coefficient width 5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;24&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Quantile&lt;/td&gt;&lt;td rowspan=&quot;24&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The q quantile of the sample (10 quantiles)&lt;/td&gt;&lt;td rowspan=&quot;9&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 9th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 1st quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;7&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 2nd quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 3rd quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 6th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;11&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 7th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;12&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 8th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;14&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 4th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 5th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;8&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;FCT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;22&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 1st quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;23&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 9th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;25&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 8th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;26&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 4th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;27&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 6th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;29&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 7th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;32&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 3rd quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;34&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 2nd quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;7&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;CST&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;48&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 9th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;52&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 8th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;57&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 4th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;59&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 2nd quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;73&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 6th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;74&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 7th quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The 1st quantile&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;5&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Fast Fourier Transform coefficient&lt;/td&gt;&lt;td rowspan=&quot;5&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The fourier coefficients of the one-dimensional discrete Fourier Transform&lt;/td&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;16&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Real 1st coefficient&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;17&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Absolute 1st coefficient&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Absolute 2nd coefficient&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;FCT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;30&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Absolute 1st coefficient&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;35&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Real 1st coefficient&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Sum values&lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The sum over the sample values&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;19&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FCT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;37&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Benford correlation&lt;/td&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The correlation resulted from the Newcomb-Benford’s Law distribution&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;39&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FCT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;40&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CST&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;56&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Absolute energy&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The absolute energy of the sample which is the sum over the squared values&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;41&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Energy ratio by chunks&lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt; The sum of squares of chunk i out of N chunks expressed as a ratio with the sum of squares over the whole series. (10 segments)&lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;43&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;First segment&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;42&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Second segment&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Fast Fourier Transform aggregated &lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The spectral centroid (mean), variance, skew, and kurtosis of the absolute fourier transform spectrum.&lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;44&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Centroid&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;61&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Variance&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Change quantiles&lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The average, absolute value of consecutive changes of the series x inside the corridor of quantiles q-low and q-high.&lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;45&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean without absolute difference of (the higher quantile and the lower quantile)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;55&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean with absolute difference of (the higher quantile and the lower quantile)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Variation coefficient&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The variation coefficient (standard error/mean, give relative value of variation around mean) of x&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;46&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean absolute change&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The mean over the absolute differences between subsequent sample values&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;47&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean change&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The mean over the differences between subsequent sample values.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;49&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Linear trend&lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The linear least-squares regression for the values of the sample versus the sequence from 0 to length of the sample minus one.&lt;/td&gt;&lt;td rowspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;50&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Slope&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;60&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Intercept&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Complexity Estimator&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The estimation for a sample complexity (A more complex sample has more peaks, valleys etc.).&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;53&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Without normalization&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Standard deviation&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The standard deviation of the sample x.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;69&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Absolute sum of changes&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The sum over the absolute value of consecutive changes in the series x.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;62&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Maximum&lt;/td&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The largest value of the sample x.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FCT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CST&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;70&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Minimum&lt;/td&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The smallest value of the sample x.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FCT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;21&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CST&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;58&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Mean&lt;/td&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The mean of the sample x&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FCT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;24&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CST&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;54&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Median&lt;/td&gt;&lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;The median of the sample x&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;MMT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;13&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;FCT&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;31&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CST&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;65&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>44357</offset><text>Feature Name	Feature Description	Action Name	ImportanceOrder	Parameters	 	Continuous Wavelet Transform coefficients	The Continuous Wavelet Transform for the Mexican hat wavelet	MMT *	1	1st Coefficient width 2	 	8	1st Coefficient width 5	 	15	1st Coefficient width 10	 	18	1st Coefficient width 20	 	63	2nd Coefficient width 5	 	68	2nd Coefficient width 20	 	71	2nd Coefficient width 10	 	72	2nd Coefficient width 2	 	FCT *	28	1st Coefficient width 10	 	33	1st Coefficient width 2	 	36	1st Coefficient width 20	 	38	1st Coefficient width 5	 	CST *	64	1st Coefficient width 2	 	66	1st Coefficient width 10	 	77	1st Coefficient width 5	 	Quantile	The q quantile of the sample (10 quantiles)	MMT	2	The 9th quantile	 	6	The 1st quantile	 	7	The 2nd quantile	 	9	The 3rd quantile	 	10	The 6th quantile	 	11	The 7th quantile	 	12	The 8th quantile	 	14	The 4th quantile	 	78	The 5th quantile	 	FCT	22	The 1st quantile	 	23	The 9th quantile	 	25	The 8th quantile	 	26	The 4th quantile	 	27	The 6th quantile	 	29	The 7th quantile	 	32	The 3rd quantile	 	34	The 2nd quantile	 	CST	48	The 9th quantile	 	52	The 8th quantile	 	57	The 4th quantile	 	59	The 2nd quantile	 	73	The 6th quantile	 	74	The 7th quantile	 	75	The 1st quantile	 	Fast Fourier Transform coefficient	The fourier coefficients of the one-dimensional discrete Fourier Transform	MMT	16	Real 1st coefficient	 	17	Absolute 1st coefficient	 	76	Absolute 2nd coefficient	 	FCT	30	Absolute 1st coefficient	 	35	Real 1st coefficient	 	Sum values	The sum over the sample values	MMT	19		 	FCT	37		 	Benford correlation	The correlation resulted from the Newcomb-Benford’s Law distribution	MMT	39		 	FCT	40		 	CST	56		 	Absolute energy	The absolute energy of the sample which is the sum over the squared values	MMT	41		 	Energy ratio by chunks	 The sum of squares of chunk i out of N chunks expressed as a ratio with the sum of squares over the whole series. (10 segments)	MMT	43	First segment	 	42	Second segment	 	Fast Fourier Transform aggregated 	The spectral centroid (mean), variance, skew, and kurtosis of the absolute fourier transform spectrum.	MMT	44	Centroid	 	61	Variance	 	Change quantiles	The average, absolute value of consecutive changes of the series x inside the corridor of quantiles q-low and q-high.	MMT	45	Mean without absolute difference of (the higher quantile and the lower quantile)	 	55	Mean with absolute difference of (the higher quantile and the lower quantile)	 	Variation coefficient	The variation coefficient (standard error/mean, give relative value of variation around mean) of x	MMT	46		 	Mean absolute change	The mean over the absolute differences between subsequent sample values	MMT	47		 	Mean change	The mean over the differences between subsequent sample values.	MMT	49		 	Linear trend	The linear least-squares regression for the values of the sample versus the sequence from 0 to length of the sample minus one.	MMT	50	Slope	 	60	Intercept	 	Complexity Estimator	The estimation for a sample complexity (A more complex sample has more peaks, valleys etc.).	MMT	53	Without normalization	 	Standard deviation	The standard deviation of the sample x.	MMT	69		 	Absolute sum of changes	The sum over the absolute value of consecutive changes in the series x.	MMT	62		 	Maximum	The largest value of the sample x.	MMT	3		 	FCT	20		 	CST	70		 	Minimum	The smallest value of the sample x.	MMT	4		 	FCT	21		 	CST	58		 	Mean	The mean of the sample x	MMT	5		 	FCT	24		 	CST	54		 	Median	The median of the sample x	MMT	13		 	FCT	31		 	CST	65		 	</text></passage><passage><infon key="file">sensors-21-05007-t0A1.xml</infon><infon key="id">sensors-21-05007-t0A1</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>47877</offset><text>* MMT: Mouse Movement Time, FCT: Focus Changes Time, CST: Clicks Specific Time.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>47957</offset><text>References</text></passage><passage><infon key="comment">Available online: https://www.wired.com/2006/06/crowds/</infon><infon key="name_0">surname:Howe;given-names:J.</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>47968</offset><text>Wired Magazine 2006, The Rise of Crowdsourcing</text></passage><passage><infon key="fpage">277</infon><infon key="lpage">295</infon><infon key="name_0">surname:Poesio;given-names:M.</infon><infon key="name_1">surname:Chamberlain;given-names:J.</infon><infon key="name_2">surname:Kruschwitz;given-names:U.</infon><infon key="name_3">surname:Ide;given-names:N.</infon><infon key="name_4">surname:Pustejovsky;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">Handbook of Linguistic Annotation</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>48015</offset><text>Crowdsourcing</text></passage><passage><infon key="fpage">319</infon><infon key="lpage">326</infon><infon key="name_0">surname:Von Ahn;given-names:L.</infon><infon key="name_1">surname:Dabbish;given-names:L.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2004 Conference on Human factors in Computing Systems—CHI’04</infon><infon key="type">ref</infon><infon key="year">2004</infon><offset>48029</offset><text>Labeling images with a computer game</text></passage><passage><infon key="name_0">surname:Zong;given-names:S.</infon><infon key="name_1">surname:Baheti;given-names:A.</infon><infon key="name_2">surname:Xu;given-names:W.</infon><infon key="name_3">surname:Ritter;given-names:A.</infon><infon key="pub-id_arxiv">2006.02567</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>48066</offset><text>Extracting COVID-19 events from Twitter</text></passage><passage><infon key="fpage">1221</infon><infon key="lpage">1232</infon><infon key="name_0">surname:Zhang;given-names:D.</infon><infon key="name_1">surname:Zhang;given-names:Y.</infon><infon key="name_2">surname:Li;given-names:Q.</infon><infon key="name_3">surname:Plummer;given-names:T.</infon><infon key="name_4">surname:Wang;given-names:D.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)</infon><infon key="type">ref</infon><infon key="volume">Volume 2019</infon><infon key="year">2019</infon><offset>48106</offset><text>CrowdLearn: A crowd-AI hybrid system for deep learning-based damage assessment applications</text></passage><passage><infon key="fpage">5196</infon><infon key="lpage">5205</infon><infon key="name_0">surname:Olivieri;given-names:A.</infon><infon key="name_1">surname:Shabani;given-names:S.</infon><infon key="name_2">surname:Sokhn;given-names:M.</infon><infon key="name_3">surname:Cudré-Mauroux;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 52nd Hawaii International Conference on System Sciences</infon><infon key="type">ref</infon><infon key="volume">Volume 6</infon><offset>48198</offset><text>Creating task-generic features for fake news detection</text></passage><passage><infon key="fpage">1313</infon><infon key="lpage">1321</infon><infon key="name_0">surname:Albarqouni;given-names:S.</infon><infon key="name_1">surname:Baur;given-names:C.</infon><infon key="name_2">surname:Achilles;given-names:F.</infon><infon key="name_3">surname:Belagiannis;given-names:V.</infon><infon key="name_4">surname:Demirci;given-names:S.</infon><infon key="name_5">surname:Navab;given-names:N.</infon><infon key="pub-id_doi">10.1109/TMI.2016.2528120</infon><infon key="pub-id_pmid">26891484</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Med. Imaging</infon><infon key="type">ref</infon><infon key="volume">35</infon><infon key="year">2016</infon><offset>48253</offset><text>AggNet: Deep learning from crowds for mitosis detection in breast cancer histology images</text></passage><passage><infon key="name_0">surname:Chen;given-names:X.</infon><infon key="name_1">surname:Zhang;given-names:Y.</infon><infon key="name_2">surname:Xu;given-names:H.</infon><infon key="name_3">surname:Cao;given-names:Y.</infon><infon key="name_4">surname:Qin;given-names:Z.</infon><infon key="name_5">surname:Zha;given-names:H.</infon><infon key="pub-id_arxiv">1801</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>48343</offset><text>Visually explainable recommendation</text></passage><passage><infon key="fpage">1403</infon><infon key="lpage">1412</infon><infon key="name_0">surname:Quinn;given-names:A.J.</infon><infon key="name_1">surname:Bederson;given-names:B.B.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</infon><infon key="type">ref</infon><offset>48379</offset><text>Human Computation: A Survey and Taxonomy of a Growing Field</text></passage><passage><infon key="fpage">1941</infon><infon key="lpage">1944</infon><infon key="name_0">surname:Kazai;given-names:G.</infon><infon key="name_1">surname:Kamps;given-names:J.</infon><infon key="name_2">surname:Milic-Frayling;given-names:N.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 20th ACM International Conference on Information and Knowledge Management—CIKM’11</infon><infon key="type">ref</infon><offset>48439</offset><text>Worker types and personality traits in crowdsourcing relevance labels</text></passage><passage><infon key="fpage">999</infon><infon key="lpage">1014</infon><infon key="name_0">surname:Hung;given-names:N.Q.V.</infon><infon key="name_1">surname:Thang;given-names:D.C.</infon><infon key="name_2">surname:Weidlich;given-names:M.</infon><infon key="name_3">surname:Aberer;given-names:K.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2015 ACM International Conference on Manage. of Data—SIGMOD’15</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>48509</offset><text>Minimizing efforts in validating crowd answers</text></passage><passage><infon key="fpage">901</infon><infon key="lpage">911</infon><infon key="name_0">surname:Garcia-Molina;given-names:H.</infon><infon key="name_1">surname:Joglekar;given-names:M.</infon><infon key="name_2">surname:Marcus;given-names:A.</infon><infon key="name_3">surname:Parameswaran;given-names:A.</infon><infon key="name_4">surname:Verroios;given-names:V.</infon><infon key="pub-id_doi">10.1109/TKDE.2016.2518669</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Knowl. Data Eng.</infon><infon key="type">ref</infon><infon key="volume">28</infon><infon key="year">2016</infon><offset>48556</offset><text>Challenges in data crowdsourcing</text></passage><passage><infon key="fpage">823</infon><infon key="lpage">834</infon><infon key="name_0">surname:Nakatsu;given-names:R.T.</infon><infon key="name_1">surname:Grossman;given-names:E.B.</infon><infon key="name_2">surname:Iacovou;given-names:C.L.</infon><infon key="pub-id_doi">10.1177/0165551514550140</infon><infon key="section_type">REF</infon><infon key="source">J. Inf. Sci.</infon><infon key="type">ref</infon><infon key="volume">40</infon><infon key="year">2014</infon><offset>48589</offset><text>A taxonomy of crowdsourcing based on task complexity</text></passage><passage><infon key="fpage">20</infon><infon key="lpage">27</infon><infon key="name_0">surname:Vuurens;given-names:J.B.P.</infon><infon key="name_1">surname:De Vries;given-names:A.P.</infon><infon key="pub-id_doi">10.1109/MIC.2012.71</infon><infon key="section_type">REF</infon><infon key="source">IEEE Internet Comput.</infon><infon key="type">ref</infon><infon key="volume">16</infon><infon key="year">2012</infon><offset>48642</offset><text>Obtaining high-quality relevance judgments using crowdsourcing</text></passage><passage><infon key="fpage">121</infon><infon key="lpage">137</infon><infon key="name_0">surname:Eickhoff;given-names:C.</infon><infon key="name_1">surname:de Vries;given-names:A.P.</infon><infon key="pub-id_doi">10.1007/s10791-011-9181-9</infon><infon key="section_type">REF</infon><infon key="source">Inf. Retr. Boston.</infon><infon key="type">ref</infon><infon key="volume">16</infon><infon key="year">2013</infon><offset>48705</offset><text>Increasing cheat robustness of crowdsourcing tasks</text></passage><passage><infon key="name_0">surname:Gadiraju;given-names:U.</infon><infon key="name_1">surname:Kawase;given-names:R.</infon><infon key="name_2">surname:Dietze;given-names:S.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</infon><infon key="type">ref</infon><offset>48756</offset><text>Understanding Malicious Behavior in Crowdsourcing Platforms: The Case of Online Surveys</text></passage><passage><infon key="fpage">530</infon><infon key="lpage">543</infon><infon key="name_0">surname:Mok;given-names:R.K.P.</infon><infon key="name_1">surname:Chang;given-names:R.K.C.</infon><infon key="name_2">surname:Li;given-names:W.</infon><infon key="pub-id_doi">10.1109/TMM.2016.2619901</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Multimed.</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2017</infon><offset>48844</offset><text>Detecting Low-Quality Workers in QoE Crowdtesting: A Worker Behavior-Based Approach</text></passage><passage><infon key="name_0">surname:Wang;given-names:G.</infon><infon key="name_1">surname:Mohanlal;given-names:M.</infon><infon key="name_2">surname:Wilson;given-names:C.</infon><infon key="name_3">surname:Wang;given-names:X.</infon><infon key="name_4">surname:Metzger;given-names:M.</infon><infon key="name_5">surname:Zheng;given-names:H.</infon><infon key="name_6">surname:Zhao;given-names:B.Y.</infon><infon key="pub-id_arxiv">1205.3856</infon><infon key="pub-id_doi">10.1109/ICASSP.2017.7952656</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>48928</offset><text>Social Turing Tests: Crowdsourcing Sybil Detection</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">22</infon><infon key="name_0">surname:Rivera;given-names:V.A.</infon><infon key="name_1">surname:Lee;given-names:D.T.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the ACM on Human-Computer Interaction</infon><infon key="type">ref</infon><infon key="volume">Volume 5</infon><offset>48979</offset><text>I Want to, but First I Need to: Understanding Crowdworkers’ Career Goals, Challenges, and Tensions</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">161</infon><infon key="name_0">surname:Marcus;given-names:A.</infon><infon key="name_1">surname:Parameswaran;given-names:A.</infon><infon key="pub-id_doi">10.1561/1900000044</infon><infon key="section_type">REF</infon><infon key="source">Found. Trends® Databases</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2015</infon><offset>49080</offset><text>Crowdsourced Data Management: Industry and Academic Perspectives</text></passage><passage><infon key="fpage">829</infon><infon key="lpage">840</infon><infon key="name_0">surname:Jain;given-names:A.</infon><infon key="name_1">surname:Sarma;given-names:A.D.</infon><infon key="name_2">surname:Parameswaran;given-names:A.</infon><infon key="name_3">surname:Widom;given-names:J.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the VLDB Endowment</infon><infon key="type">ref</infon><infon key="volume">Volume 10</infon><offset>49145</offset><text>Understanding workers, developing effective tasks, and enhancing marketplace dynamics: A Study of a Large Crowdsourcing Marketplace</text></passage><passage><infon key="fpage">17</infon><infon key="lpage">20</infon><infon key="name_0">surname:Le;given-names:J.</infon><infon key="name_1">surname:Edmonds;given-names:A.</infon><infon key="name_2">surname:Hester;given-names:V.</infon><infon key="name_3">surname:Biewald;given-names:L.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the SIGIR 2010 Workshop on Crowdsourcing for Search Evaluation—(CSE 2010)</infon><infon key="type">ref</infon><offset>49277</offset><text>Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution</text></passage><passage><infon key="fpage">43</infon><infon key="lpage">48</infon><infon key="name_0">surname:Oleson;given-names:D.</infon><infon key="name_1">surname:Sorokin;given-names:A.</infon><infon key="name_2">surname:Laughlin;given-names:G.</infon><infon key="name_3">surname:Hester;given-names:V.</infon><infon key="name_4">surname:Le;given-names:J.</infon><infon key="name_5">surname:Biewald;given-names:L.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence</infon><infon key="type">ref</infon><offset>49385</offset><text>Programmatic gold: Trargeted and scalable quality assurance in crowdsourcing</text></passage><passage><infon key="fpage">374</infon><infon key="lpage">388</infon><infon key="name_0">surname:Burmania;given-names:A.</infon><infon key="name_1">surname:Parthasarathy;given-names:S.</infon><infon key="name_2">surname:Busso;given-names:C.</infon><infon key="pub-id_doi">10.1109/TAFFC.2015.2493525</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Affect. Comput.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2016</infon><offset>49462</offset><text>Increasing the Reliability of Crowdsourcing Evaluations Using Online Quality Assessment</text></passage><passage><infon key="fpage">21</infon><infon key="lpage">26</infon><infon key="name_0">surname:Vuurens;given-names:J.</infon><infon key="name_1">surname:de Vries;given-names:A.</infon><infon key="name_2">surname:Eickhoff;given-names:C.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the ACM SIGIR Workshop on Crowdsourcing for Information Retrieval (CIR’11)</infon><infon key="type">ref</infon><offset>49550</offset><text>How much spam can you take? An analysis of crowdsourcing results to increase accuracy</text></passage><passage><infon key="fpage">1355</infon><infon key="lpage">1368</infon><infon key="name_0">surname:Sheng;given-names:V.S.</infon><infon key="name_1">surname:Zhang;given-names:J.</infon><infon key="name_2">surname:Gu;given-names:B.</infon><infon key="name_3">surname:Wu;given-names:X.</infon><infon key="pub-id_doi">10.1109/TKDE.2017.2659740</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Knowl. Data Eng.</infon><infon key="type">ref</infon><infon key="volume">31</infon><infon key="year">2019</infon><offset>49636</offset><text>Majority Voting and Pairing with Multiple Noisy Labeling</text></passage><passage><infon key="fpage">108</infon><infon key="lpage">113</infon><infon key="name_0">surname:Nazariani;given-names:M.</infon><infon key="name_1">surname:Barforoush;given-names:A.A.</infon><infon key="pub-id_doi">10.1109/CJECE.2019.2898260</infon><infon key="section_type">REF</infon><infon key="source">Can. J. Electr. Comput. Eng.</infon><infon key="type">ref</infon><infon key="volume">42</infon><infon key="year">2019</infon><offset>49693</offset><text>Dynamic weighted majority approach for detecting malicious crowd workers</text></passage><passage><infon key="fpage">2521</infon><infon key="lpage">2538</infon><infon key="name_0">surname:Tao;given-names:F.</infon><infon key="name_1">surname:Jiang;given-names:L.</infon><infon key="name_2">surname:Li;given-names:C.</infon><infon key="pub-id_doi">10.1007/s10115-020-01475-y</infon><infon key="section_type">REF</infon><infon key="source">Knowl. Inf. Syst.</infon><infon key="type">ref</infon><infon key="volume">62</infon><infon key="year">2020</infon><offset>49766</offset><text>Label similarity-based weighted soft majority voting and pairing for crowdsourcing</text></passage><passage><infon key="fpage">267</infon><infon key="lpage">276</infon><infon key="name_0">surname:Kazai;given-names:G.</infon><infon key="name_1">surname:Zitouni;given-names:I.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Ninth ACM International Conference on Web Search and Data Mining</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>49849</offset><text>Quality Management in Crowdsourcing using Gold Judges Behavior</text></passage><passage><infon key="fpage">2140</infon><infon key="lpage">2148</infon><infon key="name_0">surname:Zhang;given-names:Y.</infon><infon key="name_1">surname:Van der Schaar;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the INFOCOM</infon><infon key="type">ref</infon><offset>49912</offset><text>Reputation-based Incentive Protocols in Crowdsourcing Applications</text></passage><passage><infon key="fpage">510</infon><infon key="lpage">515</infon><infon key="name_0">surname:Hirth;given-names:M.</infon><infon key="name_1">surname:Scheuring;given-names:S.</infon><infon key="name_2">surname:Hossfeld;given-names:T.</infon><infon key="name_3">surname:Schwartz;given-names:C.</infon><infon key="name_4">surname:Tran-Gia;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2014 IEEE 5th International Conference on Communications and Electronics, IEEE ICCE</infon><infon key="type">ref</infon><offset>49979</offset><text>Predicting result quality in crowdsourcing using application layer monitoring</text></passage><passage><infon key="fpage">13</infon><infon key="lpage">22</infon><infon key="name_0">surname:Rzeszotarski;given-names:J.M.</infon><infon key="name_1">surname:Kittur;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 24th Annual ACM Symposium on User interface Software and Technology</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>50057</offset><text>Instrumenting the crowd: Using implicit behavioral measures to predict task performance</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">3</infon><infon key="name_0">surname:Dang;given-names:B.</infon><infon key="name_1">surname:Hutson;given-names:M.</infon><infon key="name_2">surname:Lease;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 4th AAAI Conference on Human Computation and Crowdsourcing (HCOMP)</infon><infon key="type">ref</infon><offset>50145</offset><text>MmmTurkey: A Crowdsourcing Framework for Deploying Tasks and Recording Worker Behavior on Amazon Mechanical Turk</text></passage><passage><infon key="fpage">41</infon><infon key="lpage">49</infon><infon key="name_0">surname:Goyal;given-names:T.</infon><infon key="name_1">surname:Mcdonnell;given-names:T.</infon><infon key="name_2">surname:Kutlu;given-names:M.</infon><infon key="name_3">surname:Elsayed;given-names:T.</infon><infon key="name_4">surname:Lease;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Sixth AAAI Conference on Human Computation and Crowdsourcing</infon><infon key="type">ref</infon><offset>50258</offset><text>Your Behavior Signals Your Reliability: Modeling Crowd Behavioral Traces to Ensure Quality Relevance Annotations</text></passage><passage><infon key="fpage">889</infon><infon key="lpage">901</infon><infon key="name_0">surname:Hata;given-names:K.</infon><infon key="name_1">surname:Krishna;given-names:R.</infon><infon key="name_2">surname:Li;given-names:F.-F.</infon><infon key="name_3">surname:Bernstein;given-names:M.S.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing—CSCW’17</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>50371</offset><text>A glimpse far into the future: Understanding long-term crowd worker quality</text></passage><passage><infon key="fpage">614</infon><infon key="lpage">622</infon><infon key="name_0">surname:Sheng;given-names:V.S.</infon><infon key="name_1">surname:Provost;given-names:F.</infon><infon key="name_2">surname:Ipeirotis;given-names:P.G.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining—KDD 08</infon><infon key="type">ref</infon><infon key="year">2008</infon><offset>50447</offset><text>Get another label? Improving data quality and data mining using multiple, noisy labelers</text></passage><passage><infon key="fpage">1063</infon><infon key="lpage">1072</infon><infon key="name_0">surname:Scholer;given-names:F.</infon><infon key="name_1">surname:Turpin;given-names:A.</infon><infon key="name_2">surname:Sanderson;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 34th International ACM SIGIR Conference Research and Development in Information Retrieval—SIGIR’11</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>50536</offset><text>Quantifying test collection quality based on the consistency of relevance judgements</text></passage><passage><infon key="fpage">26</infon><infon key="lpage">30</infon><infon key="name_0">surname:Difallah;given-names:D.E.</infon><infon key="name_1">surname:Demartini;given-names:G.</infon><infon key="name_2">surname:Cudré-Mauroux;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the CrowdSearch Workshop</infon><infon key="type">ref</infon><offset>50621</offset><text>Mechanical cheat: Spamming schemes and adversarial techniques on crowdsourcing platforms</text></passage><passage><infon key="fpage">1529</infon><infon key="lpage">1538</infon><infon key="name_0">surname:Yuan;given-names:D.</infon><infon key="name_1">surname:Li;given-names:G.</infon><infon key="name_2">surname:Li;given-names:Q.</infon><infon key="name_3">surname:Zheng;given-names:Y.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>50710</offset><text>Sybil Defense in Crowdsourcing Platforms</text></passage><passage><infon key="name_0">surname:Hettiachchi;given-names:D.</infon><infon key="name_1">surname:Schaekermann;given-names:M.</infon><infon key="name_2">surname:McKinney;given-names:T.</infon><infon key="name_3">surname:Lease;given-names:M.</infon><infon key="pub-id_arxiv">2105.09457</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2021</infon><offset>50751</offset><text>The Challenge of Variable Effort Crowdsourcing and How Visible Gold Can Help</text></passage><passage><infon key="fpage">646</infon><infon key="lpage">649</infon><infon key="name_0">surname:Lee;given-names:W.</infon><infon key="name_1">surname:Huang;given-names:C.H.</infon><infon key="name_2">surname:Chang;given-names:C.W.</infon><infon key="name_3">surname:Wu;given-names:M.K.D.</infon><infon key="name_4">surname:Chuang;given-names:K.T.</infon><infon key="name_5">surname:Yang;given-names:P.A.</infon><infon key="name_6">surname:Hsieh;given-names:C.C.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Advances in Database Technology—EDBT</infon><infon key="type">ref</infon><offset>50828</offset><text>Effective quality assurance for data labels through crowdsourcing and domain expert collaboration</text></passage><passage><infon key="fpage">55</infon><infon key="lpage">62</infon><infon key="name_0">surname:Rzeszotarski;given-names:J.</infon><infon key="name_1">surname:Kittur;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology—UIST’12</infon><infon key="type">ref</infon><offset>50926</offset><text>CrowdScape: Interactively visualizing user behavior and output</text></passage><passage><infon key="fpage">17</infon><infon key="lpage">20</infon><infon key="name_0">surname:Zhu;given-names:D.</infon><infon key="name_1">surname:Carterette;given-names:B.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the SIGIR 2010 Workshop on Crowdsourcing for Search Evaluation</infon><infon key="type">ref</infon><offset>50989</offset><text>An analysis of assessor behavior in crowdsourced preference judgments</text></passage><passage><infon key="fpage">168381</infon><infon key="lpage">168393</infon><infon key="name_0">surname:Alqershi;given-names:F.</infon><infon key="name_1">surname:Al-Qurishi;given-names:M.</infon><infon key="name_2">surname:Aksoy;given-names:M.S.</infon><infon key="name_3">surname:Alrubaian;given-names:M.</infon><infon key="name_4">surname:Imran;given-names:M.</infon><infon key="pub-id_doi">10.1109/ACCESS.2020.3022773</infon><infon key="section_type">REF</infon><infon key="source">IEEE Access</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2020</infon><offset>51059</offset><text>A Robust Consistency Model of Crowd Workers in Text Labeling Tasks</text></passage><passage><infon key="name_0">surname:Williams;given-names:A.</infon><infon key="name_1">surname:Willis;given-names:C.G.</infon><infon key="name_2">surname:Davis;given-names:C.C.</infon><infon key="name_3">surname:Goh;given-names:J.</infon><infon key="name_4">surname:Ellison;given-names:A.M.</infon><infon key="name_5">surname:Law;given-names:E.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Fifth AAAI Conference on Human Computation and Crowdsourcing</infon><infon key="type">ref</infon><offset>51126</offset><text>Deja Vu: Characterizing worker quality using task consistency</text></passage><passage><infon key="name_0">surname:Dong;given-names:G.</infon><infon key="name_1">surname:Liu;given-names:H.</infon><infon key="section_type">REF</infon><infon key="source">Feature Engineering for Machine Learning and Data Analytics</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>51188</offset></passage><passage><infon key="fpage">551</infon><infon key="lpage">572</infon><infon key="name_0">surname:Benford;given-names:F.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the American Philosophical Society</infon><infon key="type">ref</infon><infon key="volume">Volume 78</infon><infon key="year">1938</infon><offset>51189</offset><text>The Law of Anomalous Numbers</text></passage><passage><infon key="name_0">surname:Mallat;given-names:S.</infon><infon key="section_type">REF</infon><infon key="source">A Wavelet Tour of Signal Processing</infon><infon key="type">ref</infon><infon key="year">2009</infon><offset>51218</offset></passage><passage><infon key="elocation-id">541</infon><infon key="name_0">surname:Delgado-Bonal;given-names:A.</infon><infon key="name_1">surname:Marshak;given-names:A.</infon><infon key="pub-id_doi">10.3390/e21060541</infon><infon key="section_type">REF</infon><infon key="source">Entropy</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2019</infon><offset>51219</offset><text>Approximate Entropy and Sample Entropy: A Comprehensive Tutorial</text></passage><passage><infon key="fpage">174102</infon><infon key="name_0">surname:Bandt;given-names:C.</infon><infon key="name_1">surname:Pompe;given-names:B.</infon><infon key="pub-id_doi">10.1103/PhysRevLett.88.174102</infon><infon key="pub-id_pmid">12005759</infon><infon key="section_type">REF</infon><infon key="source">Phys. Rev. Lett.</infon><infon key="type">ref</infon><infon key="volume">88</infon><infon key="year">2002</infon><offset>51284</offset><text>Permutation Entropy: A Natural Complexity Measure for Time Series</text></passage><passage><infon key="fpage">72</infon><infon key="lpage">77</infon><infon key="name_0">surname:Christ;given-names:M.</infon><infon key="name_1">surname:Braun;given-names:N.</infon><infon key="name_2">surname:Neuffer;given-names:J.</infon><infon key="name_3">surname:Kempa-Liehr;given-names:A.W.</infon><infon key="pub-id_doi">10.1016/j.neucom.2018.03.067</infon><infon key="section_type">REF</infon><infon key="source">Neurocomputing</infon><infon key="type">ref</infon><infon key="volume">307</infon><infon key="year">2018</infon><offset>51350</offset><text>Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests (tsfresh—A Python package)</text></passage><passage><infon key="fpage">3</infon><infon key="lpage">42</infon><infon key="name_0">surname:Geurts;given-names:P.</infon><infon key="name_1">surname:Ernst;given-names:D.</infon><infon key="name_2">surname:Wehenkel;given-names:L.</infon><infon key="pub-id_doi">10.1007/s10994-006-6226-1</infon><infon key="section_type">REF</infon><infon key="source">Mach. Learn.</infon><infon key="type">ref</infon><infon key="volume">63</infon><infon key="year">2006</infon><offset>51448</offset><text>Extremely randomized trees</text></passage><passage><infon key="fpage">973</infon><infon key="lpage">977</infon><infon key="name_0">surname:Eckmann;given-names:J.-P.</infon><infon key="name_1">surname:Kamphorst;given-names:S.O.</infon><infon key="name_2">surname:Ruelle;given-names:D.</infon><infon key="pub-id_doi">10.1209/0295-5075/4/9/004</infon><infon key="section_type">REF</infon><infon key="source">Europhys. Lett.</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">1987</infon><offset>51475</offset><text>Recurrence Plots of Dynamical Systems</text></passage><passage><infon key="name_0">surname:Nair;given-names:V.</infon><infon key="name_1">surname:Hinton;given-names:G.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the International Conference on Machine Learning</infon><infon key="type">ref</infon><offset>51513</offset><text>Rectified Linear Units Improve Restricted Boltzmann Machines Vinod</text></passage><passage><infon key="name_0">surname:Kingma;given-names:D.P.</infon><infon key="name_1">surname:Ba;given-names:J.</infon><infon key="pub-id_arxiv">1412.6980</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2014</infon><offset>51580</offset><text>Adam: A Method for Stochastic Optimization</text></passage><passage><infon key="fpage">464</infon><infon key="lpage">472</infon><infon key="name_0">surname:Smith;given-names:L.N.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2017 IEEE Winter Conference on Applications of Computer Vision (WACV)</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>51623</offset><text>Cyclical Learning Rates for Training Neural Networks</text></passage><passage><infon key="name_0">surname:Hatami;given-names:N.</infon><infon key="name_1">surname:Gavet;given-names:Y.</infon><infon key="name_2">surname:Debayle;given-names:J.</infon><infon key="pub-id_arxiv">1710.00886</infon><infon key="section_type">REF</infon><infon key="source">arXiv</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>51676</offset><text>Classification of time-series images using deep convolutional neural networks</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">122</infon><infon key="name_0">surname:Pavlov;given-names:Y.L.</infon><infon key="pub-id_doi">10.1201/9780429469275-8</infon><infon key="section_type">REF</infon><infon key="source">Random For.</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>51754</offset><text>Random forests</text></passage><passage><infon key="fpage">2231</infon><infon key="lpage">2240</infon><infon key="name_0">surname:Jeong;given-names:Y.S.</infon><infon key="name_1">surname:Jeong;given-names:M.K.</infon><infon key="name_2">surname:Omitaomu;given-names:O.A.</infon><infon key="pub-id_doi">10.1016/j.patcog.2010.09.022</infon><infon key="section_type">REF</infon><infon key="source">Pattern Recognit.</infon><infon key="type">ref</infon><infon key="volume">44</infon><infon key="year">2011</infon><offset>51769</offset><text>Weighted dynamic time warping for time series classification</text></passage><passage><infon key="fpage">69</infon><infon key="lpage">84</infon><infon key="name_0">surname:Müller;given-names:M.</infon><infon key="section_type">REF</infon><infon key="source">Information Retrieval for Music and Motion</infon><infon key="type">ref</infon><infon key="year">2007</infon><offset>51830</offset><text>Dynamic Time Warping</text></passage><passage><infon key="fpage">331</infon><infon key="lpage">378</infon><infon key="name_0">surname:Geler;given-names:Z.</infon><infon key="name_1">surname:Kurbalija;given-names:V.</infon><infon key="name_2">surname:Radovanović;given-names:M.</infon><infon key="name_3">surname:Ivanović;given-names:M.</infon><infon key="pub-id_doi">10.1007/s10115-015-0881-0</infon><infon key="section_type">REF</infon><infon key="source">Knowl. Inf. Syst.</infon><infon key="type">ref</infon><infon key="volume">48</infon><infon key="year">2016</infon><offset>51851</offset><text>Comparison of different weighting schemes for the kNN classifier on time-series data</text></passage><passage><infon key="fpage">31</infon><infon key="lpage">42</infon><infon key="name_0">surname:Cristianini;given-names:N.</infon><infon key="name_1">surname:Schölkopf;given-names:B.</infon><infon key="section_type">REF</infon><infon key="source">AI Mag.</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2002</infon><offset>51936</offset><text>Support Vector Machines and Kernel Methods The New Generation of Learning Machines</text></passage><passage><infon key="fpage">II-413</infon><infon key="lpage">II-416</infon><infon key="name_0">surname:Cuturi;given-names:M.</infon><infon key="name_1">surname:Vert;given-names:J.-P.</infon><infon key="name_2">surname:Birkenes;given-names:O.</infon><infon key="name_3">surname:Matsui;given-names:T.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2007 IEEE International Conference on Acoustics, Speech and Signal Processing—ICASSP’07</infon><infon key="type">ref</infon><infon key="volume">Volume 2</infon><infon key="year">2007</infon><offset>52019</offset><text>A Kernel for Time Series Based on Global Alignments</text></passage><passage><infon key="fpage">307</infon><infon key="lpage">319</infon><infon key="name_0">surname:Kim;given-names:K.J.</infon><infon key="pub-id_doi">10.1016/S0925-2312(03)00372-2</infon><infon key="section_type">REF</infon><infon key="source">Neurocomputing</infon><infon key="type">ref</infon><infon key="volume">55</infon><infon key="year">2003</infon><offset>52071</offset><text>Financial time series forecasting using support vector machines</text></passage><passage><infon key="fpage">512</infon><infon key="lpage">518</infon><infon key="name_0">surname:Kampouraki;given-names:A.</infon><infon key="name_1">surname:Manis;given-names:G.</infon><infon key="name_2">surname:Nikou;given-names:C.</infon><infon key="pub-id_doi">10.1109/TITB.2008.2003323</infon><infon key="pub-id_pmid">19273030</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Inf. Technol. Biomed.</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2009</infon><offset>52135</offset><text>Heartbeat time series classification with support vector machines</text></passage><passage><infon key="fpage">2825</infon><infon key="lpage">2830</infon><infon key="name_0">surname:Pedregosa;given-names:F.</infon><infon key="name_1">surname:Varoquaux;given-names:G.</infon><infon key="name_2">surname:Gramfort;given-names:A.</infon><infon key="name_3">surname:Michel;given-names:V.</infon><infon key="name_4">surname:Thirion;given-names:B.</infon><infon key="name_5">surname:Grisel;given-names:O.</infon><infon key="name_6">surname:Blondel;given-names:M.</infon><infon key="name_7">surname:Prettenhofer;given-names:P.</infon><infon key="name_8">surname:Weiss;given-names:R.</infon><infon key="name_9">surname:Dubourg;given-names:V.</infon><infon key="section_type">REF</infon><infon key="source">J. Mach. Learn. Res.</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2011</infon><offset>52201</offset><text>Scikit-learn: Machine learning in Python</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">6</infon><infon key="name_0">surname:Tavenard;given-names:R.</infon><infon key="name_1">surname:Vandewiele;given-names:G.</infon><infon key="name_2">surname:Divo;given-names:F.</infon><infon key="name_3">surname:Androz;given-names:G.</infon><infon key="name_4">surname:Holtz;given-names:C.</infon><infon key="name_5">surname:Payne;given-names:M.</infon><infon key="name_6">surname:Woods;given-names:E.</infon><infon key="pub-id_pmid">34305477</infon><infon key="section_type">REF</infon><infon key="source">J. Mach. Learn. Res.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2020</infon><offset>52242</offset><text>Tslearn, A Machine Learning Toolkit for Time Series Data</text></passage><passage><infon key="fpage">349</infon><infon key="lpage">365</infon><infon key="name_0">surname:Yentes;given-names:J.M.</infon><infon key="name_1">surname:Hunt;given-names:N.</infon><infon key="name_2">surname:Schmid;given-names:K.K.</infon><infon key="name_3">surname:Kaipust;given-names:J.P.</infon><infon key="name_4">surname:McGrath;given-names:D.</infon><infon key="name_5">surname:Stergiou;given-names:N.</infon><infon key="pub-id_doi">10.1007/s10439-012-0668-3</infon><infon key="pub-id_pmid">23064819</infon><infon key="section_type">REF</infon><infon key="source">Ann. Biomed. Eng.</infon><infon key="type">ref</infon><infon key="volume">41</infon><infon key="year">2013</infon><offset>52299</offset><text>The appropriate use of approximate entropy and sample entropy with short data sets</text></passage><passage><infon key="fpage">92</infon><infon key="lpage">99</infon><infon key="name_0">surname:Dogo;given-names:E.M.</infon><infon key="name_1">surname:Afolabi;given-names:O.J.</infon><infon key="name_2">surname:Nwulu;given-names:N.I.</infon><infon key="name_3">surname:Twala;given-names:B.</infon><infon key="name_4">surname:Aigbavboa;given-names:C.O.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the International Conference on Computational Techniques, Electronics and Mechanical Systems (CTEMS)</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>52382</offset><text>A Comparative Analysis of Gradient Descent-Based Optimization Algorithms on Convolutional Neural Networks</text></passage><passage><infon key="elocation-id">3595</infon><infon key="name_0">surname:Dos Santos;given-names:A.A.</infon><infon key="name_1">surname:Marcato Junior;given-names:J.</infon><infon key="name_2">surname:Araújo;given-names:M.S.</infon><infon key="name_3">surname:Di Martini;given-names:D.R.</infon><infon key="name_4">surname:Tetila;given-names:E.C.</infon><infon key="name_5">surname:Siqueira;given-names:H.L.</infon><infon key="name_6">surname:Aoki;given-names:C.</infon><infon key="name_7">surname:Eltner;given-names:A.</infon><infon key="name_8">surname:Matsubara;given-names:E.T.</infon><infon key="name_9">surname:Pistori;given-names:H.</infon><infon key="pub-id_doi">10.3390/s19163595</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2019</infon><offset>52488</offset><text>Assessment of CNN-Based Methods for Individual Tree Detection on Images Captured by RGB Cameras Attached to UAVs</text></passage><passage><infon key="elocation-id">2622</infon><infon key="name_0">surname:Yu;given-names:D.</infon><infon key="name_1">surname:Ji;given-names:S.</infon><infon key="pub-id_doi">10.3390/s19112622</infon><infon key="pub-id_pmid">31181854</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2019</infon><offset>52601</offset><text>Grid Based Spherical CNN for Object Detection from Panoramic Images</text></passage><passage><infon key="elocation-id">4353</infon><infon key="name_0">surname:Han;given-names:C.</infon><infon key="name_1">surname:Li;given-names:G.</infon><infon key="name_2">surname:Ding;given-names:Y.</infon><infon key="name_3">surname:Yan;given-names:F.</infon><infon key="name_4">surname:Bai;given-names:L.</infon><infon key="pub-id_doi">10.3390/s20164353</infon><infon key="pub-id_pmid">32764226</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2020</infon><offset>52669</offset><text>Chimney Detection Based on Faster R-CNN and Spatial Analysis Methods in High Resolution Remote Sensing Images</text></passage><passage><infon key="fpage">Id hal-02570804</infon><infon key="name_0">surname:Talbi;given-names:E.</infon><infon key="section_type">REF</infon><infon key="source">HAL</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>52779</offset><text>Optimization of deep neural networks: A survey and unified taxonomy</text></passage><passage><infon key="fpage">16</infon><infon key="name_0">surname:VanderPlas;given-names:J.T.</infon><infon key="pub-id_doi">10.3847/1538-4365/aab766</infon><infon key="section_type">REF</infon><infon key="source">Astrophys. J. Suppl. Ser.</infon><infon key="type">ref</infon><infon key="volume">236</infon><infon key="year">2018</infon><offset>52847</offset><text>Understanding the Lomb–Scargle Periodogram</text></passage><passage><infon key="fpage">660</infon><infon key="lpage">671</infon><infon key="name_0">surname:Bahadori;given-names:M.T.</infon><infon key="name_1">surname:Liu;given-names:Y.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2012 SIAM International Conference on Data Mining</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>52892</offset><text>Granger Causality Analysis in Irregular Time Series</text></passage><passage><infon key="fpage">561</infon><infon key="lpage">580</infon><infon key="name_0">surname:Salvador;given-names:S.</infon><infon key="name_1">surname:Chan;given-names:P.</infon><infon key="pub-id_doi">10.3233/IDA-2007-11508</infon><infon key="section_type">REF</infon><infon key="source">Intell. Data Anal.</infon><infon key="type">ref</infon><infon key="volume">11</infon><infon key="year">2007</infon><offset>52944</offset><text>FastDTW: Toward accurate dynamic time warping in linear time and space</text></passage><passage><infon key="elocation-id">633</infon><infon key="name_0">surname:Liu;given-names:X.</infon><infon key="name_1">surname:Mei;given-names:H.</infon><infon key="name_2">surname:Lu;given-names:H.</infon><infon key="name_3">surname:Kuang;given-names:H.</infon><infon key="name_4">surname:Ma;given-names:X.</infon><infon key="pub-id_doi">10.3390/s17030633</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2017</infon><offset>53015</offset><text>A Vehicle Steering Recognition System Based on Low-Cost Smartphone Sensors</text></passage><passage><infon key="file">sensors-21-05007-g001.jpg</infon><infon key="id">sensors-21-05007-f001</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>53090</offset><text>The proposed models.</text></passage><passage><infon key="file">sensors-21-05007-g002.jpg</infon><infon key="id">sensors-21-05007-f002</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>53111</offset><text>The image-CNN model architecture.</text></passage><passage><infon key="file">sensors-21-05007-g003.jpg</infon><infon key="id">sensors-21-05007-f003</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>53145</offset><text>Optimized learning rate vs. changing in loss.</text></passage><passage><infon key="file">sensors-21-05007-g004.jpg</infon><infon key="id">sensors-21-05007-f004</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>53191</offset><text>Optimized number of epochs.</text></passage><passage><infon key="file">sensors-21-05007-g005.jpg</infon><infon key="id">sensors-21-05007-f005</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>53219</offset><text>Training/validation accuracy and loss of the image-CNN model across the epochs.</text></passage><passage><infon key="file">sensors-21-05007-t001.xml</infon><infon key="id">sensors-21-05007-t001</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>53299</offset><text>The auxiliary features for image-CNN model.</text></passage><passage><infon key="file">sensors-21-05007-t001.xml</infon><infon key="id">sensors-21-05007-t001</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Feature Name&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Type&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Feature Description&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_mouse_movements&lt;/td&gt;&lt;td rowspan=&quot;7&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Action-based&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total number of mouse movements.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_scrolled_pixels _vertical&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total number of scrolled pixels.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_clicks&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total number of mouse clicks.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_keypresses&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total number of keyboard pressing.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_pastes&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total number of pastes.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_focus_changes&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total number of focusing changes. &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_pixels&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total number of pixels movements in x/y directions.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_task_time&lt;/td&gt;&lt;td rowspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; colspan=&quot;1&quot;&gt;Time-based&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total time of completing the HIT.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;total_on_foucs_time&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;The total time that was spent completing the HIT.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;recorded_time_disparity&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Difference between the total time and the time spent outside the HIT.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;avg_dwell_time&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Average time between two successive logged events.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>53343</offset><text>Feature Name	Type	Feature Description	 	total_mouse_movements	Action-based	The total number of mouse movements.	 	total_scrolled_pixels _vertical	The total number of scrolled pixels.	 	total_clicks	The total number of mouse clicks.	 	total_keypresses	The total number of keyboard pressing.	 	total_pastes	The total number of pastes.	 	total_focus_changes	The total number of focusing changes. 	 	total_pixels	The total number of pixels movements in x/y directions.	 	total_task_time	Time-based	The total time of completing the HIT.	 	total_on_foucs_time	The total time that was spent completing the HIT.	 	recorded_time_disparity	Difference between the total time and the time spent outside the HIT.	 	avg_dwell_time	Average time between two successive logged events.	 	</text></passage><passage><infon key="file">sensors-21-05007-t002.xml</infon><infon key="id">sensors-21-05007-t002</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>54114</offset><text>Accuracy and AUC-ROC for features vs. different importance thresholds.</text></passage><passage><infon key="file">sensors-21-05007-t002.xml</infon><infon key="id">sensors-21-05007-t002</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Importance&lt;break/&gt;Threshold&lt;break/&gt;(Log10)&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean/18&lt;break/&gt; &lt;break/&gt;−11.156&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean/9&lt;break/&gt; &lt;break/&gt;−10.463&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean/3&lt;break/&gt; &lt;break/&gt;−9.365&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean&lt;break/&gt; &lt;break/&gt;−8.266&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean &lt;inline-formula&gt;&lt;mml:math id=&quot;mm92&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt; 3&lt;break/&gt; &lt;break/&gt;−7.1678&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean × 9&lt;break/&gt; &lt;break/&gt;−6.061&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mean × 18&lt;break/&gt; &lt;break/&gt;−4.970&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;No. of features&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1629&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1158&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;984&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;770&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;377&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;41&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;Accuracy&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;82.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;83.3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;83.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;82.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;82.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;78.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;AUC-ROC&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;81.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;81.3&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80.9&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;82.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;81.1&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;79.1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>54185</offset><text>ImportanceThreshold(Log10)	Mean/18 −11.156	Mean/9 −10.463	Mean/3 −9.365	Mean −8.266	Mean  3 −7.1678	Mean × 9 −6.061	Mean × 18 −4.970	 	No. of features	1629	1158	984	770	377	78	41	 	Accuracy	82.9	83.3	83.1	82.1	82.8	80.6	78.2	 	AUC-ROC	81.1	81.3	80.9	82.0	81.1	80.8	79.1	 	</text></passage><passage><infon key="file">sensors-21-05007-t003.xml</infon><infon key="id">sensors-21-05007-t003</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>54481</offset><text>Hyper-parameter tuning.</text></passage><passage><infon key="file">sensors-21-05007-t003.xml</infon><infon key="id">sensors-21-05007-t003</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Hyper-Parameter&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Training Accuracy&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Validation Accuracy&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Training Loss&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Validation Loss&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Batch size&lt;/td&gt;&lt;td colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Learning rate: &lt;inline-formula&gt;&lt;mml:math id=&quot;mm93&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;, Epochs: 150, Input Dimensions 32 × 32, dropout rate for conv. layer and dense layer = 0.5 and 0.25, respectively.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;25&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.8050&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7633&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.4446&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6291&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;50&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7956&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.7712&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.4786&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.5475&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;75&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7827&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7539&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.4988&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5517&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Dropout rate (for the Conv. layer)&lt;/td&gt;&lt;td colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Batch size: 50, Learning rate: &lt;inline-formula&gt;&lt;mml:math id=&quot;mm94&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;, Epochs: 150, Input Dimensions 32 × 32, dropout rate dense layer: 0.25.&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.25&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7485&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.7649&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5225&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.5264&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.50&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7587&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7367&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5306&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5505&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.75&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7254&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7179&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5523&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5826&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Dropout rate (for the Dense layer)&lt;/td&gt;&lt;td colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;
&lt;italic&gt;Dropout rate: Conv. layer: 0.25, Batch size: 50, Learning rate:&lt;/italic&gt;
&lt;inline-formula&gt;&lt;mml:math id=&quot;mm95&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;
&lt;italic&gt;, Epochs: 150, Input Dimensions 32 × 32&lt;/italic&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.25&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.8054&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.7821&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.4551&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.5423&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.50&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7391&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7680&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5495&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5236&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.75&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6865&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6959&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6121&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6059&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Image Input dimensions&lt;/td&gt;&lt;td colspan=&quot;4&quot; align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot;&gt;Dropout rate: Conv. layer: 0.25, Batch size: 50, Learning rate:&lt;inline-formula&gt;&lt;mml:math id=&quot;mm96&quot;&gt;&lt;mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mtext&gt; &lt;/mml:mtext&gt;&lt;mml:msup&gt;&lt;mml:mrow&gt;&lt;mml:mn&gt;10&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;−&lt;/mml:mo&gt;&lt;mml:mn&gt;4&lt;/mml:mn&gt;&lt;/mml:mrow&gt;&lt;/mml:msup&gt;&lt;/mml:mrow&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;, Epochs: 150&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;32 × 32&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7705&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.7837&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.4987&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;0.5080&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;56 × 56&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.8195&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7382&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.4271&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5778&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;28 × 28&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7991&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7649&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.4695&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5408&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>54505</offset><text>Hyper-Parameter	Training Accuracy	Validation Accuracy	Training Loss	Validation Loss	 	Batch size	Learning rate: , Epochs: 150, Input Dimensions 32 × 32, dropout rate for conv. layer and dense layer = 0.5 and 0.25, respectively.	 	25	0.8050	0.7633	0.4446	0.6291	 	50	0.7956	0.7712	0.4786	0.5475	 	75	0.7827	0.7539	0.4988	0.5517	 	Dropout rate (for the Conv. layer)	Batch size: 50, Learning rate: , Epochs: 150, Input Dimensions 32 × 32, dropout rate dense layer: 0.25.	 	0.25	0.7485	0.7649	0.5225	0.5264	 	0.50	0.7587	0.7367	0.5306	0.5505	 	0.75	0.7254	0.7179	0.5523	0.5826	 	Dropout rate (for the Dense layer)	Dropout rate: Conv. layer: 0.25, Batch size: 50, Learning rate:, Epochs: 150, Input Dimensions 32 × 32	 	0.25	0.8054	0.7821	0.4551	0.5423	 	0.50	0.7391	0.7680	0.5495	0.5236	 	0.75	0.6865	0.6959	0.6121	0.6059	 	Image Input dimensions	Dropout rate: Conv. layer: 0.25, Batch size: 50, Learning rate:, Epochs: 150	 	32 × 32	0.7705	0.7837	0.4987	0.5080	 	56 × 56	0.8195	0.7382	0.4271	0.5778	 	28 × 28	0.7991	0.7649	0.4695	0.5408	 	</text></passage><passage><infon key="file">sensors-21-05007-t004.xml</infon><infon key="id">sensors-21-05007-t004</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>55548</offset><text>Performance comparison against baselines.</text></passage><passage><infon key="file">sensors-21-05007-t004.xml</infon><infon key="id">sensors-21-05007-t004</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline\Performance Metric&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accuracy&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;AUC-ROC&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;DT_AF &lt;xref rid=&quot;B32-sensors-21-05007&quot; ref-type=&quot;bibr&quot;&gt;32&lt;/xref&gt;&lt;xref rid=&quot;B34-sensors-21-05007&quot; ref-type=&quot;bibr&quot;&gt;34&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;65.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;52.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;RF_AF &lt;xref rid=&quot;B34-sensors-21-05007&quot; ref-type=&quot;bibr&quot;&gt;34&lt;/xref&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;66.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;53.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;DTW&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;65.0&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;50.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;TS-SVC&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;68.2&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;49.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Feature-based model&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;83.8&lt;/bold&gt;
&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;bold&gt;82.0&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Feature-based with reduction (avg. thresholds)&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;81.8&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;80.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Image-CNN based model&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;76.6&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;72.3&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>55590</offset><text>Baseline\Performance Metric	Accuracy	AUC-ROC	 	DT_AF 	65.2	52.1	 	RF_AF 	66.6	53.0	 	DTW	65.0	50.0	 	TS-SVC	68.2	49.5	 	Feature-based model	83.8	82.0	 	Feature-based with reduction (avg. thresholds)	81.8	80.9	 	Image-CNN based model	76.6	72.3	 	</text></passage></document></collection>
