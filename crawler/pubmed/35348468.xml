<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20220617</date><key>pmc.key</key><document><id>9006137</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.2196/35358</infon><infon key="article-id_pmc">9006137</infon><infon key="article-id_pmid">35348468</infon><infon key="article-id_publisher-id">v9i1e35358</infon><infon key="elocation-id">e35358</infon><infon key="issue">1</infon><infon key="kwd">social skills training virtual agent design virtual assistant virtual trainer chatbot acceptability realism virtual agent simulation social skill social interaction design training crowdsourcing</infon><infon key="license">This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Human Factors, is properly cited. The complete bibliographic information, a link to the original publication on https://humanfactors.jmir.org, as well as this copyright and license information must be included.</infon><infon key="name_0">surname:Kushniruk;given-names:Andre</infon><infon key="name_1">surname:Okada;given-names:Shogo</infon><infon key="name_2">surname:Chollet;given-names:Mathieu</infon><infon key="name_3">surname:Chaudhry;given-names:Beenish</infon><infon key="name_4">surname:Tanaka;given-names:Hiroki</infon><infon key="name_5">surname:Nakamura;given-names:Satoshi</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">9</infon><infon key="year">2022</infon><offset>0</offset><text>The Acceptability of Virtual Characters as Social Skills Trainers: Usability Study</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>83</offset><text>Background</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>94</offset><text>Social skills training by human trainers is a well-established method to provide appropriate social interaction skills and strengthen social self-efficacy. In our previous work, we attempted to automate social skills training by developing a virtual agent that taught social skills through interaction. Previous research has not investigated the visual design of virtual agents for social skills training. Thus, we investigated the effect of virtual agent visual design on automated social skills training.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>601</offset><text>Objective</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>611</offset><text>The 3 main purposes of this research were to investigate the effect of virtual agent appearance on automated social skills training, the relationship between acceptability and other measures (eg, likeability, realism, and familiarity), and the relationship between likeability and individual user characteristics (eg, gender, age, and autistic traits).</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>964</offset><text>Methods</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>972</offset><text>We prepared images and videos of a virtual agent, and 1218 crowdsourced workers rated the virtual agents through a questionnaire. In designing personalized virtual agents, we investigated the acceptability, likeability, and other impressions of the virtual agents and their relationship to individual characteristics.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>1290</offset><text>Results</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>1298</offset><text>We found that there were differences between the virtual agents in all measures (P&lt;.001). A female anime-type virtual agent was rated as the most likeable. We also confirmed that participants’ gender, age, and autistic traits were related to their ratings.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>1557</offset><text>Conclusions</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>1569</offset><text>We confirmed the effect of virtual agent design on automated social skills training. Our findings are important in designing the appearance of an agent for use in personalized automated social skills training.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1779</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1792</offset><text>Social skills training is a method widely applied to help people who lack social skills. It is used in medical hospitals, employment support facilities, workplaces, schools, and various other institutions. Social skills training is generally conducted by a human trainer to promote appropriate social interaction skills and strengthen social self-efficacy. The Bellack method (or step-by-step social skills training) is a well-structured and widely used evidence-based approach. It is a cognitive behavioral approach to social skills training inspired by the 5 core principles of social learning theory: modeling, shaping, reinforcement, overlearning, and generalization. The Bellack method defines the social skills training framework and its 4 basic skills: expressing positive feelings, listening to others, making requests, and expressing unpleasant feelings. These skills are beneficial for all people (not only those with autistic traits or schizophrenia). In particular, autism spectrum disorder (ASD) is a spectrum condition, meaning it has a broad range of characteristics, from mild to severe. Using computer agents in social skills training is motivated by the fact that even though some people with high-functioning autism experience difficulty during social communication, they also show good or even superior systemizing skills. Systemizing is the drive to analyze or build systems and understand and predict behavior in terms of underlying rules and regularities. The use of systematic computer-based training for people who need to improve their social skills has the following benefits: (1) it uses a computerized environment that is predictable, consistent, and free from social demands; (2) users can work at their own pace and level of understanding; (3) training can be repeated until the goal is achieved; and (4) interest and motivation can be maintained through computerized rewards. It may also be easier for those who suffer from social difficulties to use computer agents than to directly interact with humans. A past paper suggested that people with social difficulties such as ASD feel safer and more comfortable in virtual interactions than in interactions with actual people.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3999</offset><text>We and other research groups have been conducting studies to automate social skills training using virtual agents, and this work has led to the development of automatic social skills training that by design resembles human-led social skills training. The use of conversational agents in health care was reviewed by Tudor Car et al and Milne-Ives et al. Among types of conversational agents, our system includes video modeling of human behavior, real-time behavior recognition, and feedback. We previously confirmed the effectiveness of this training in children and adults with ASD and in the general population. The automated social skills training agent plays 2 roles: as a trainer and as a listener. We confirmed that the system was more effective in training social skills than the traditional methods of reading books or watching videos of role models, and that talking to a 3D virtual agent made users feel more comfortable and less tense than talking to a human. Automated social skills training targets various populations, from children to adult men and women, as well as those with ASD or schizophrenia. However, visual designs of virtual agents, and what kind of design is more favored or more accepted, has not yet been investigated. A previous study showed that the quality of the therapeutic alliance (ie, the level of rapport and trust) is a reliable predictor of positive clinical outcomes independent of the approach to psychotherapy (including social skills training and cognitive behavioral therapy) or the specific outcome measure. For automatic social skills training to be adopted and accepted by individuals, detailed investigation is necessary. In this study, we focus on comparing virtual agents with varying visual designs, rather than comparing humans and robots for assistive technology, because we consider that the design of virtual agents is easier to create and modify.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5901</offset><text>The visual design of the virtual agent in social skills training has been previously investigated, although not exhaustively. For example, Hoque et al paired male participants with a male coach and female participants with a female coach in order to minimize gender-based variability in behavior. By contrast, Tanaka et al did not consider the agent’s gender (they used only a female design). Previous studies have used various virtual agent designs for different tasks and compared their appearance and behavior, realism, intensity in dialogue scenarios, and the appropriateness of body and eye proportions. Past studies have also created a voice designed for the elderly and have examined the impact of gender and race on users’ self-efficacy. Troncone et al discussed seniors’ psychological perspectives in terms of the model of acceptance and associated factors. Our study applies these findings and rating measures to investigate the design of our virtual agents, aiming to create a more favorable and acceptable design for automated social skills training. To the best of our knowledge, previous work has not investigated the visual design of virtual agents for automated social skills training, the relationship between acceptability and other measures, and the relationship between likeability and individual user characteristics.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7246</offset><text>This study set Japanese adults as our target users. We prepared a variety of new virtual agent designs for social skills training and evaluated them with multiple items on a questionnaire: their acceptability as a trainer; their acceptability as a listener; their realism, familiarity, trustworthiness, and eeriness; the likeability of their face, eyes, hair, perceived age, and voice; and their overall impression. These criteria were chosen with reference to the studies of Esposito et al and Ring et al. We followed their statistical analysis framework and investigated the appearance of 3D characters in the context of automated social skills training. First, we evaluated virtual agent visual design, particularly realism. Previous work has showed that serious tasks, such as medical diagnosis, require realistic agents; on the other hand, anime-like agents are more suited to social chitchat-like dialogue systems. We hypothesized that anime-like characters would be preferable and more accepted for automated social skills training since such training requires friendly characteristics to maintain participant safety, and because agents play 2 roles: as trainers and as listeners. In addition, realism is affected by the “uncanny valley” phenomenon, with the most unrealistic character often being rated as the most acceptable. We hypothesized that we would find that the uncanny valley also applies to automated social skills training agents. Second, to examine new factors that correlate to acceptability, we quantified the relationships between acceptability and other measures. We hypothesized that these questionnaire items would be highly correlated with each other. Finally, we investigated the differences in preference for virtual agent design by considering individual users’ gender, age, and autistic traits in order to enable personalized automated social skills training. The three main research problems were (1) to investigate the visual appearance of virtual agents for automated social skills training; (2) to investigate the relationship between acceptability and other measures (eg, likeability, face, voice, realism, and familiarity); and (3) to investigate the relationship between acceptability and the individual characteristics of the user (ie, gender, age, and autistic traits).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9563</offset><text>This paper is an extension of conference proceedings in which we reported on the visual design of characters. This paper adds an analysis of realism and includes a greater number of participants. We created new agents and videos and evaluated their realism. We also investigated whether people with high or low autistic traits rated the likeability of virtual agents differently depending on the realism of the agent. We also analyzed the correlation matrix between all questionnaire items in order to confirm correlations between acceptability and other measures. Finally, this paper discusses and summarizes findings from a series of experiments.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>10212</offset><text>Methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>10220</offset><text>Visual Design of Virtual Agents</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10252</offset><text>We first prepared an illustration of a virtual agent, as shown in Figure 1. The virtual agents were designed by a company specializing in Japanese animation.</text></passage><passage><infon key="file">humanfactors_v9i1e35358_fig1.jpg</infon><infon key="id">figure1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>10410</offset><text>Images of the 9 virtual characters and representative measures collected from data set 1 and data set 2.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10515</offset><text>All characters faced the front with no emotional expression. Characters A and B (female) and C and D (male) were designed with a consistent age, with only the degree of their realism and gender changing. Character E was an inanimate object created for use with children. Character F was a nonhuman animal (a dog), also for use with children. For character G, we created a realistic 3D model similar in appearance to characters A and B and took a screen capture from the front. Character H was the default agent provided by the Greta platform (developed by Pelachaud et al), which is an embodied conversation agent that can be created with the Autodesk character generator (Autodesk Inc.). Character H was intended for use mainly with French- and English-speaking users. Character F was designed for Japanese female users. In the current study of automated social skills training, character I was selected as the virtual character. The representation of characters H and I was created by taking a screen capture from the front.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11542</offset><text>The sentence “Hello, let’s practice communication together” was embedded in the image with both a male and a female voice. The utterance was 5 seconds in length and spoken by Google Text-to-Speech. Characters E and F were created with higher-pitched voices than those used for normal female speech synthesis, to mimic children’s voices.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11887</offset><text>Since 3D models were available for characters H and I, we were also able to create videos for them in Greta (Figure 2). Movements and gestures were added, such as the character raising its hands or putting its hands on its chest, synchronized to the speech content. These same behaviors and synchronization for characters H and I were also generated in Japanese, with an utterance length of 8 seconds. The speech synthesis used the voice of the character “Yuki” in CereProc (CereProc Ltd.).</text></passage><passage><infon key="file">humanfactors_v9i1e35358_fig2.jpg</infon><infon key="id">figure2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>12382</offset><text>Screen captures of videos of two of the virtual characters (A) and representative measures collected from data set 3 (B, C).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12507</offset><text>We further analyzed the effect of realism by designing additional virtual agents, also with the aid of a design company specializing in Japanese animation. These agents were designed using the Maya tool (Autodesk Inc.). We prepared 6 levels of realism, following a previously reported method. The degrees of realism were as follows: (1) pencil toon, (2) flat toon, (3) shaded toon, (4) bare toon, (5) computer-generated toon, and (6) human (with subsurface scattering), as shown in Figure 3. The same behavior was generated for these 6 agents, with Japanese speech synthesis and lip-synching using the same words as described above. All of these images and movies are available upon request to the first author.</text></passage><passage><infon key="file">humanfactors_v9i1e35358_fig3.jpg</infon><infon key="id">figure3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>13219</offset><text>Screen captures of the 6 virtual agents (A); acceptability as a trainer in data set 4 (error bars represent SE) (B); and the evaluation of likeability by high and low SRS score groups (C).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>13408</offset><text>Participants</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13421</offset><text>For data collection, we recruited participants from a crowdsourcing service (Crowdworks). The recruitment notice asked for participants 18 years of age or older with Japanese nationality. In order to divide the task among the participants, data were collected in 4 separate data sets with different participants. Data set 1 had 305 participants (with a male to female ratio of 148 to 157), data set 2 had 301 participants (with a male to female ratio of 131 to 170), data set 3 had 302 participants (with a male to female ratio of 145 to 157), and data set 4 had 305 participants (with a male to female ratio of 145 to 160). All data sets can be found in multimedia appendix. Data set 1 was used to investigate image acceptability, likeability, familiarity, likeability of certain elements (ie, eyes, face, hair, voice, and perceived age), autistic traits, and alexithymia. Data set 2 was used to investigate realism, trustworthiness, and eeriness of the agents. Data set 3 was used to investigate the videos with characters H and I. Data set 4 was used to investigate the realism of the movies, as well as autistic traits. For the validation to have a sufficient sample size, we collected a larger sample size for each data set compared to previous works, which have recruited around 40 to 70 participants from regional communities or have used Amazon’s Mechanical Turk platform. In this study, we also performed a grouped analysis using 45 years as the threshold for high and low age groups (high age: n=84; low age: n=21).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>14949</offset><text>Autistic Traits</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14965</offset><text>In data set 1 and data set 4, we used the adult version of the Social Responsiveness Scale-2 (SRS) to assess autistic traits. This measures how many autistic traits an individual shows and can be used across the general population, not only with people who are suspected of having ASD. In data set 1, we measured the Toronto Alexithymia Scale-20 (TAS) to assess alexithymia. In both cases, we calculated the total score. We did not calculate subscales in this study. In data set 1, the 2 questionnaires had a Spearman correlation coefficient of 0.67 (P&lt;.001), which indicates a high correlation between autistic traits and alexithymia. We are currently planning a future analysis that will use SRS as a measure of autistic traits. In this study, we used a cutoff value of 81 points as the threshold for high and low SRS score (subjects with a high SRS score: n=113; low SRS score: n=192). We also measured SRS scores in data set 4 and also set a threshold for high and low SRS scores in that data set (high: n=129, low: n=177).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>15993</offset><text>Measures</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16002</offset><text>Questionnaire items and scales were prepared with reference to studies by Esposito et al and Ring et al. The questionnaire items measured the acceptability of the agent as a trainer and as a listener; its realism, familiarity, trustworthiness, and eeriness; the likeability of its face, eyes, hair, perceived age, and voice; and its overall impression. Each question was answered through a Google Form. In data set 1, each question item was answered after completing the SRS and TAS. In data set 3, in addition to the above, we added the likeability of the clothes the agent wore, because the video included the entire upper body of the virtual agent. We asked the participants to read a description of the concept of social skills training (in particular, the function of a virtual agent to train the user’s social communication skills and also listen to the user). We performed a preliminary test with a few adults to check whether the participants understood the social skills training, and we wrote instructions. Participants first looked at a set of all the images (Figure 1) to get an impression of all the virtual agents, and they then watched the individual virtual agents and answered each question. The questions were evaluated with a 5-point Likert scale (from 1, “I don’t think so at all,” to 5 “I think so very much”). Spearman ρ was calculated to determine the relationship between the questionnaire items.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17436</offset><text>R (R Foundation for Statistical Computing) was used for the analysis. Since normality could not be confirmed in the ratings of the questions by the Kolmogorov-Smirnov test, the Kruskal-Wallis test was used to examine the differences between the virtual agents. In the analysis for each group of gender, age, and SRS, we calculated the effect size (r). We report the top 3 combinations of r from all combinations of virtual agents and questionnaire items. Furthermore, we performed the Wilcoxon signed-rank test to compare pairs of factors.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>17976</offset><text>Ethical Considerations</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17999</offset><text>This was an anonymous study in which the participants enrolled themselves by registering through Crowdworks and agreeing to participate in the study. Since participation was anonymized, the study was exempt from registration with our institutional review board.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>18261</offset><text>Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>18269</offset><text>In reporting the results, we did not report all measures, in order to focus on significant findings. The following is a summary of the experimental results.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>18426</offset><text>First, the differences in ratings between the virtual characters. The Kruskal-Wallis test confirmed that there were significant differences between the virtual characters in all measures (P&lt;.001). Regarding realism, the distribution was as expected in the original design: character A was more realistic than character B and character G was the most realistic. The most preferred virtual character among the participants was character B, averaging 3.29 (SD 1.0) (Figure 1). Character B was also highly evaluated in other questionnaire items. We also found that the male characters, C and D, and the nonhuman characters, E and F, had lower likeability than character B, and that character H had less likeability and less familiarity.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>19159</offset><text>Next, the correlations between questionnaire items. Figure 4 shows the correlation matrix. There was a high correlation between face and preference (ρ=0.78, P&lt;.001). There was also a high correlation between acceptance as a trainer and acceptance as a listener (ρ=0.80, P&lt;.001). On the other hand, although a significant difference was confirmed regarding voice preference and other questionnaire items, the correlation coefficient was relatively low.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>19615</offset><text>Table 1 lists the top 3 combinations of virtual agents and questionnaire items that had the highest effect size (r) for gender, age, and SRS score. All cases with a statistically significant difference are listed in Multimedia Appendix 1. Male subjects evaluated character G’s face, overall likeability, and acceptability as a trainer more highly than did female subjects. The higher age group evaluated character I’s eyes and face more highly than did the lower age group. The high SRS score group evaluated the likeability of character G’s eyes and hair more highly than did the low SRS score group.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>20223</offset><text>Figure 2 shows a comparison of the videos of characters H and I, indicating that acceptability and familiarity were significantly greater for character I than H (all P&lt;.001).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>20398</offset><text>Figure 5 shows the overall rating for realism for the agents shown in Figure 3. The Kruskal-Wallis test confirmed that the virtual agents differed significantly in realism (P&lt;.001) and confirmed our design assumption that agents 1 through 6 would have increasingly greater realism. Figure 3 shows the acceptability as a trainer and likeability of the virtual agents. The Kruskal-Wallis test confirmed that the virtual agents differed significantly in all measures (P&lt;.001). We found a small difference between the high and low SRS score groups in their evaluation of likeability (Figure 3 lower right), but the Wilcoxon rank-sum test showed no significant difference (for character 1, P=.13 and for character 6, P=.25) and a small effect size.</text></passage><passage><infon key="file">humanfactors_v9i1e35358_fig4.jpg</infon><infon key="id">figure4</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>21142</offset><text>Correlation matrix of measures.</text></passage><passage><infon key="file">table1.xml</infon><infon key="id">table1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>21174</offset><text>Relationship between questionnaire items and gender, age, and SRS score.</text></passage><passage><infon key="file">table1.xml</infon><infon key="id">table1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot; width=&quot;1000&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot; border=&quot;1&quot;&gt;&lt;col width=&quot;30&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;250&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;240&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;240&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;240&quot; span=&quot;1&quot;/&gt;&lt;thead&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td colspan=&quot;2&quot; rowspan=&quot;1&quot;&gt;User characteristic&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Questionnaire item&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;italic&gt;r&lt;/italic&gt; (&lt;italic&gt;P&lt;/italic&gt; value)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Trend&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td colspan=&quot;5&quot; rowspan=&quot;1&quot;&gt;
&lt;bold&gt;Gender&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character G&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Face&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.29 (&amp;lt;.001)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Male &amp;gt; female&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character G&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Likeability&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.25 (&amp;lt;.001)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Male &amp;gt; female&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character G&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Trainer&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.25 (&amp;lt;.001)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Male &amp;gt; female&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td colspan=&quot;5&quot; rowspan=&quot;1&quot;&gt;
&lt;bold&gt;Age&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character I&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Eyes&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.21 (&amp;lt;.001)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;High &amp;gt; low&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character I&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Face&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.19 (&amp;lt;.001)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;High &amp;gt; low&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character A&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Listener&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.17 (.003)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;High &amp;lt; low&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td colspan=&quot;5&quot; rowspan=&quot;1&quot;&gt;
&lt;bold&gt;SRS score&lt;/bold&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character G&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Eyes&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.19 (.001)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;High &amp;gt; low&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character G&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Hair&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.18 (.002)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;High &amp;gt; low&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;break/&gt;
&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Character G&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Face&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.16 (.009)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;High &amp;gt; low&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>21247</offset><text>User characteristic	Questionnaire item	r (P value)	Trend	 	Gender	 		Character G	Face	0.29 (&lt;.001)	Male &gt; female	 		Character G	Likeability	0.25 (&lt;.001)	Male &gt; female	 		Character G	Trainer	0.25 (&lt;.001)	Male &gt; female	 	Age	 		Character I	Eyes	0.21 (&lt;.001)	High &gt; low	 		Character I	Face	0.19 (&lt;.001)	High &gt; low	 		Character A	Listener	0.17 (.003)	High &lt; low	 	SRS score	 		Character G	Eyes	0.19 (.001)	High &gt; low	 		Character G	Hair	0.18 (.002)	High &gt; low	 		Character G	Face	0.16 (.009)	High &gt; low	 	</text></passage><passage><infon key="file">humanfactors_v9i1e35358_fig5.jpg</infon><infon key="id">figure5</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>21749</offset><text>Realism measures collected from data set 4. Error bars represent SE.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>21818</offset><text>Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21829</offset><text>The objective of this study was to examine virtual agent visual design for automated social skills training, the relationship between acceptability and other measures, and the relationship between likeability and individual user characteristics. We also investigated the acceptability and likeability of the virtual agents, as well as various other measures. We were able to confirm that the virtual agents had different ratings. First, we found that the realism of the virtual agent design could be controlled through the selection of characters A, B, or G. We found that character B, originally designed as an anime-like teenage female character, was the most likable (Figure 1). Since Japanese people are rather accustomed to watching anime-like videos, familiarity with such characters is high. The anime art form, having originated in Japan in the early 1900s, is a uniquely stylized form of 2D and 3D illustration. Such a female anime-like character was also integrated and familiarized in our previous research on automated social skills training. On the other hand, other virtual characters, such as the inanimate object (character E) or the animal (character F), as well as characters G and H, were less accepted and were not preferred.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>23075</offset><text>We found significant correlations between questionnaire items (P&lt;.001) and a high correlation between face and preference. This face factor influenced the development of the automated social skills training. There was also a high correlation between acceptance as a trainer and acceptance as a listener (Figure 4). In this case, we could not confirm the difference between the role as trainer and that as listener, because no continuous interactive dialogue was available. When the roles of virtual characters are more carefully chosen in the future, we assume that an investigation of this issue will also be necessary. Since the same voice was used for each virtual character, the correlation coefficient was relatively low. Therefore, we should explore the effect of voice using a variety of speech synthesizers in the future.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>23905</offset><text>We also found very similar tendencies in video versions of the training agents. However, in terms of familiarity, we confirmed that the rating for the video version of character H was higher than its image version due to the addition of naturalistic movement. Regarding the videos shown in Figure 2, acceptability, and familiarity were significantly greater for character I than H. This shows that Japanese users preferred the anime-like character I over the original Greta character H.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>24392</offset><text>We also found that realism, as shown in Figure 5, was associated with acceptability and likeability (Figure 3), a finding that is similar to that reported by McDonnell et al. This may be related to the uncanny valley effect and represent an intermediary between the responses to characters 3 (shaded toon) and 4 (bare toon). Although the most highly evaluated agent was character 6, the human with subsurface scattering, this sort of agent may need high-quality 3D modeling for its appearance and movement to be natural enough for use in automated social skills training. Thus, the second-ranked character, character 3 (shaded toon), may be the most promising for a realistic virtual agent for automated social skills training.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>25120</offset><text>We found that the female virtual character, character G, was rated as more preferred by male participants. In addition, since we confirmed that character B was also significantly highly rated by male participants, it appears that the male participants rated female virtual characters as more preferable. Character B, originally designed as an anime-like teenage female character, was judged the most likable by all participants. We found that character I was preferred by older participants. Since character I was designed to appear relatively older (and was originally designed for participants in their 40s), it seems that the older group rated characters closer to their own age as more trustworthy. Therefore, when developing automated social skills training for older users, character I might be the most appropriate type of visual design. In this paper, one of our goals was to analyze the effect of autistic traits. We found that autistic traits were strongly associated with alexithymia (Spearman ρ=0.67). Thus, we focused only on SRS score to measure autistic traits. Our results showed that people with high autistic traits had a preference for realistic agents. We also confirmed that the group with high autistic traits gave a high rating to characters G and H in data set 1. This is a similar finding to previous work. However, we did not find a difference in the case of data set 4.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>26519</offset><text>Further investigation is needed to examine altered cognition in autism and its effects in order to conduct a comparison of virtual agents and real human agents. Although the target population of this study was adults 18 years or older, children with ASD may prefer nonhuman virtual agents, such as trains. We must consider the effects of virtual agents in younger users. In future work, we hope to examine the effect of cultural differences, younger age, and virtual agent facial expressions on acceptability. These features could be used as variables of interest. In addition, this study did not confirm whether crowdsourced workers have sufficient knowledge of social skills training. Consequently, we need to investigate the effects of integrating design into an interactive social skills training dialogue system.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>27337</offset><text>Conclusions</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>27349</offset><text>In this study, we prepared various new virtual agent visual designs for social skills training and evaluated the designs based on multiple questionnaire items that assessed likeability, acceptability, realism, familiarity, and trustworthiness, among other factors, in a study sample of 1218 crowdsourced evaluators. We tested differences in preferences for virtual agent visual designs based on the gender, age, and autistic traits of the participants, in order to create personalized virtual agents. We found that our participants preferred, perhaps through familiarity, anime-like characters, likely because Japanese people are rather accustomed to watching anime-like videos. Our conclusion for implementing an optimal virtual agent for use with Japanese users is generally to design a female anime-type agent (especially a toon-shaded type), which has been shown to be favored and acceptable. We also found that preferences for virtual agent visual design differed according to user gender, age, and autistic traits. For example, we confirmed that users with high autistic traits showed a high preference for virtual agents with a realistic appearance.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>28506</offset><text>Conflicts of Interest: None declared.</text></passage><passage><infon key="fpage">637</infon><infon key="lpage">638</infon><infon key="name_0">surname:Bellack;given-names:AS</infon><infon key="name_1">surname:Meuser;given-names:KT</infon><infon key="name_2">surname:Gingerich;given-names:S</infon><infon key="name_3">surname:Agresta;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">Social Skills Training for Schizophrenia: A Step-by-Step Guide</infon><infon key="type">ref</infon><infon key="year">1997</infon><offset>28544</offset></passage><passage><infon key="fpage">523</infon><infon key="issue">4</infon><infon key="lpage">6</infon><infon key="name_0">surname:Liberman;given-names:R P</infon><infon key="name_1">surname:Mueser;given-names:K T</infon><infon key="name_2">surname:Wallace;given-names:C J</infon><infon key="pub-id_doi">10.1176/ajp.143.4.523</infon><infon key="pub-id_medline">2869704</infon><infon key="pub-id_pmid">2869704</infon><infon key="section_type">REF</infon><infon key="source">Am J Psychiatry</infon><infon key="type">ref</infon><infon key="volume">143</infon><infon key="year">1986</infon><offset>28545</offset><text>Social skills training for schizophrenic individuals at risk for relapse</text></passage><passage><infon key="name_0">surname:Skinner;given-names:BF</infon><infon key="section_type">REF</infon><infon key="source">Science And Human Behavior</infon><infon key="type">ref</infon><infon key="year">1953</infon><offset>28618</offset></passage><passage><infon key="fpage">R786</infon><infon key="issue">19</infon><infon key="lpage">90</infon><infon key="name_0">surname:Frith;given-names:U</infon><infon key="name_1">surname:Happé;given-names:Francesca</infon><infon key="pub-id_doi">10.1016/j.cub.2005.09.033</infon><infon key="pub-id_medline">16213805</infon><infon key="pub-id_pii">S0960-9822(05)01102-4</infon><infon key="pub-id_pmid">16213805</infon><infon key="section_type">REF</infon><infon key="source">Curr Biol</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2005</infon><offset>28619</offset><text>Autism spectrum disorder</text></passage><passage><infon key="fpage">591</infon><infon key="issue">2</infon><infon key="lpage">617</infon><infon key="name_0">surname:Golan;given-names:Ofer</infon><infon key="name_1">surname:Baron-Cohen;given-names:Simon</infon><infon key="pub-id_doi">10.1017/S0954579406060305</infon><infon key="pub-id_medline">16600069</infon><infon key="pub-id_pii">S0954579406060305</infon><infon key="pub-id_pmid">16600069</infon><infon key="section_type">REF</infon><infon key="source">Dev Psychopathol</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2006</infon><offset>28644</offset><text>Systemizing empathy: teaching adults with Asperger syndrome or high-functioning autism to recognize complex emotions using interactive multimedia</text></passage><passage><infon key="fpage">e0182151</infon><infon key="issue">8</infon><infon key="name_0">surname:Tanaka;given-names:Hiroki</infon><infon key="name_1">surname:Negoro;given-names:Hideki</infon><infon key="name_2">surname:Iwasaka;given-names:Hidemi</infon><infon key="name_3">surname:Nakamura;given-names:Satoshi</infon><infon key="pub-id_doi">10.1371/journal.pone.0182151</infon><infon key="pub-id_medline">28796781</infon><infon key="pub-id_pii">PONE-D-17-04936</infon><infon key="pub-id_pmid">28796781</infon><infon key="section_type">REF</infon><infon key="source">PLoS One</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2017</infon><offset>28790</offset><text>Embodied conversational agents for multimodal automated social skills training in people with autism spectrum disorders</text></passage><passage><infon key="fpage">504</infon><infon key="lpage">505</infon><infon key="name_0">surname:Poyade;given-names:M</infon><infon key="name_1">surname:Morris;given-names:G</infon><infon key="name_2">surname:Taylor;given-names:I</infon><infon key="name_3">surname:Portela;given-names:V</infon><infon key="pub-id_doi">10.1145/3136755.3143025</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>28910</offset><text>Using mobile virtual reality to empower people with hidden disabilities to overcome their barriers</text></passage><passage><infon key="fpage">e0182151</infon><infon key="issue">8</infon><infon key="name_0">surname:Tanaka;given-names:H</infon><infon key="name_1">surname:Negoro;given-names:H</infon><infon key="name_2">surname:Iwasaka;given-names:H</infon><infon key="name_3">surname:Nakamura;given-names:S</infon><infon key="pub-id_doi">10.1371/journal.pone.0182151</infon><infon key="pub-id_medline">28796781</infon><infon key="pub-id_pii">PONE-D-17-04936</infon><infon key="pub-id_pmid">28796781</infon><infon key="section_type">REF</infon><infon key="source">PLoS One</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2017</infon><offset>29009</offset><text>Embodied conversational agents for multimodal automated social skills training in people with autism spectrum disorders</text></passage><passage><infon key="fpage">73</infon><infon key="issue">1</infon><infon key="lpage">82</infon><infon key="name_0">surname:Tanaka;given-names:H</infon><infon key="name_1">surname:Iwasaka;given-names:H</infon><infon key="name_2">surname:Negoro;given-names:H</infon><infon key="name_3">surname:Nakamura;given-names:S</infon><infon key="pub-id_doi">10.1007/s12193-019-00313-y</infon><infon key="section_type">REF</infon><infon key="source">J Multimodal User Interfaces</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2019</infon><offset>29129</offset><text>Analysis of conversational listening skills toward agent-based social skills training</text></passage><passage><infon key="fpage">65</infon><infon key="lpage">70</infon><infon key="name_0">surname:Tanaka;given-names:H</infon><infon key="name_1">surname:Iwasaka;given-names:H</infon><infon key="name_2">surname:Matsuda;given-names:Y</infon><infon key="name_3">surname:Okazaki;given-names:K</infon><infon key="name_4">surname:Nakamura;given-names:S</infon><infon key="pub-id_doi">10.1109/ojemb.2021.3075567</infon><infon key="pub-id_pmid">35402987</infon><infon key="section_type">REF</infon><infon key="source">IEEE Open J. Eng. Med. Biol</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2021</infon><offset>29215</offset><text>Analyzing Self-Efficacy and Summary Feedback in Automated Social Skills Training</text></passage><passage><infon key="fpage">E</infon><infon key="name_0">surname:Ali;given-names:MR</infon><infon key="name_1">surname:Rasazi;given-names:Z</infon><infon key="name_2">surname:Mamun;given-names:AA</infon><infon key="name_3">surname:Langevin;given-names:R</infon><infon key="name_4">surname:Rawassizadeh;given-names:R</infon><infon key="name_5">surname:Schubert;given-names:LK</infon><infon key="name_6">surname:Hoque;given-names:ME</infon><infon key="pub-id_doi">10.1145/3383652.3423900</infon><infon key="section_type">REF</infon><infon key="source">CoRR</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>29296</offset><text>A Virtual Conversational Agent for Teens with Autism: Experimental Results and Design Lessons</text></passage><passage><infon key="name_0">surname:Hoque;given-names:M</infon><infon key="name_1">surname:Courgeon;given-names:M</infon><infon key="name_2">surname:Martin;given-names:J-C</infon><infon key="name_3">surname:Mutlu;given-names:B</infon><infon key="name_4">surname:Picard;given-names:RW</infon><infon key="pub-id_doi">10.1145/2493432.2493502</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>29390</offset><text>MACH: my automated conversation coach, UbiComp, pp</text></passage><passage><infon key="fpage">e17158</infon><infon key="issue">8</infon><infon key="name_0">surname:Tudor Car;given-names:L</infon><infon key="name_1">surname:Dhinagaran;given-names:DA</infon><infon key="name_2">surname:Kyaw;given-names:BM</infon><infon key="name_3">surname:Kowatsch;given-names:T</infon><infon key="name_4">surname:Joty;given-names:S</infon><infon key="name_5">surname:Theng;given-names:Y</infon><infon key="name_6">surname:Atun;given-names:R</infon><infon key="pub-id_doi">10.2196/17158</infon><infon key="pub-id_medline">32763886</infon><infon key="pub-id_pii">v22i8e17158</infon><infon key="pub-id_pmid">32763886</infon><infon key="section_type">REF</infon><infon key="source">J Med Internet Res</infon><infon key="type">ref</infon><infon key="volume">22</infon><infon key="year">2020</infon><offset>29441</offset><text>Conversational Agents in Health Care: Scoping Review and Conceptual Analysis</text></passage><passage><infon key="fpage">e20346</infon><infon key="issue">10</infon><infon key="name_0">surname:Milne-Ives;given-names:M</infon><infon key="name_1">surname:de Cock;given-names:C</infon><infon key="name_2">surname:Lim;given-names:E</infon><infon key="name_3">surname:Shehadeh;given-names:MH</infon><infon key="name_4">surname:de Pennington;given-names:N</infon><infon key="name_5">surname:Mole;given-names:G</infon><infon key="name_6">surname:Normando;given-names:E</infon><infon key="name_7">surname:Meinert;given-names:E</infon><infon key="pub-id_doi">10.2196/20346</infon><infon key="pub-id_medline">33090118</infon><infon key="pub-id_pii">v22i10e20346</infon><infon key="pub-id_pmid">33090118</infon><infon key="section_type">REF</infon><infon key="source">J Med Internet Res</infon><infon key="type">ref</infon><infon key="volume">22</infon><infon key="year">2020</infon><offset>29518</offset><text>The Effectiveness of Artificial Intelligence Conversational Agents in Health Care: Systematic Review</text></passage><passage><infon key="fpage">1</infon><infon key="issue">2</infon><infon key="lpage">26</infon><infon key="name_0">surname:Tanaka;given-names:H</infon><infon key="name_1">surname:Sakriani;given-names:S</infon><infon key="name_2">surname:Neubig;given-names:G</infon><infon key="name_3">surname:Toda;given-names:T</infon><infon key="name_4">surname:Negoro;given-names:H</infon><infon key="name_5">surname:Iwasaka;given-names:H</infon><infon key="name_6">surname:Nakamura;given-names:S</infon><infon key="pub-id_doi">10.1145/2937757</infon><infon key="section_type">REF</infon><infon key="source">ACM Trans. Interact. Intell. Syst</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2016</infon><offset>29619</offset><text>Teaching Social Communication Skills Through Human-Agent Interaction</text></passage><passage><infon key="name_0">surname:Shidara;given-names:K</infon><infon key="name_1">surname:Tanaka;given-names:H</infon><infon key="name_2">surname:Adachi;given-names:H</infon><infon key="name_3">surname:Kanayama;given-names:D</infon><infon key="name_4">surname:Sakagami;given-names:Y</infon><infon key="name_5">surname:Kudo;given-names:T</infon><infon key="name_6">surname:Nakamura;given-names:S</infon><infon key="pub-id_doi">10.3389/fcomp.2022.762424</infon><infon key="section_type">REF</infon><infon key="source">Front. Comput. Sci</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2022</infon><offset>29688</offset><text>Automatic Thoughts and Facial Expressions in Cognitive Restructuring With Virtual Agents</text></passage><passage><infon key="fpage">270</infon><infon key="name_0">surname:Ardito;given-names:RB</infon><infon key="name_1">surname:Rabellino;given-names:D</infon><infon key="pub-id_doi">10.3389/fpsyg.2011.00270</infon><infon key="pub-id_medline">22028698</infon><infon key="pub-id_pmid">22028698</infon><infon key="section_type">REF</infon><infon key="source">Front Psychol</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2011</infon><offset>29777</offset><text>Therapeutic alliance and outcome of psychotherapy: historical excursus, measurements, and prospects for research</text></passage><passage><infon key="fpage">e0186581</infon><infon key="issue">10</infon><infon key="name_0">surname:Kumazaki;given-names:H</infon><infon key="name_1">surname:Warren;given-names:Z</infon><infon key="name_10">surname:Mimura;given-names:M</infon><infon key="name_11">surname:Minabe;given-names:Y</infon><infon key="name_12">surname:Kikuchi;given-names:M</infon><infon key="name_2">surname:Muramatsu;given-names:T</infon><infon key="name_3">surname:Yoshikawa;given-names:Y</infon><infon key="name_4">surname:Matsumoto;given-names:Y</infon><infon key="name_5">surname:Miyao;given-names:M</infon><infon key="name_6">surname:Nakano;given-names:M</infon><infon key="name_7">surname:Mizushima;given-names:S</infon><infon key="name_8">surname:Wakita;given-names:Y</infon><infon key="name_9">surname:Ishiguro;given-names:H</infon><infon key="pub-id_doi">10.1371/journal.pone.0186581</infon><infon key="pub-id_medline">29028837</infon><infon key="pub-id_pii">PONE-D-17-30493</infon><infon key="pub-id_pmid">29028837</infon><infon key="section_type">REF</infon><infon key="source">PLoS One</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2017</infon><offset>29890</offset><text>A pilot study for robot appearance preferences among high-functioning individuals with autism spectrum disorder: Implications for therapeutic use</text></passage><passage><infon key="fpage">277</infon><infon key="lpage">282</infon><infon key="name_0">surname:Robins;given-names:B</infon><infon key="name_1">surname:Dautenhahn;given-names:K</infon><infon key="name_2">surname:Te Boekhorst;given-names:R</infon><infon key="name_3">surname:Billard;given-names:A</infon><infon key="pub-id_doi">10.1109/roman.2004.1374773</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2004</infon><offset>30036</offset><text>Robots as assistive technology - does appearance matter?</text></passage><passage><infon key="fpage">429</infon><infon key="name_0">surname:Esposito;given-names:A</infon><infon key="name_1">surname:Amorese;given-names:T</infon><infon key="name_2">surname:Cucinello;given-names:M</infon><infon key="name_3">surname:Esposito;given-names:AM</infon><infon key="name_4">surname:Troncone;given-names:A</infon><infon key="name_5">surname:Ines Torres;given-names:M</infon><infon key="name_6">surname:Schlogl;given-names:S</infon><infon key="name_7">surname:Cordasco;given-names:G</infon><infon key="pub-id_doi">10.48550/arXiv.2105.00506</infon><infon key="section_type">REF</infon><infon key="source">Italian Forum of Ambient Assisted Living</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>30093</offset><text>Seniors' Acceptance of Virtual Humanoid Agents</text></passage><passage><infon key="fpage">243</infon><infon key="lpage">246</infon><infon key="name_0">surname:Esposito;given-names:A</infon><infon key="name_1">surname:Amorese;given-names:T</infon><infon key="name_2">surname:Cuciniello;given-names:M</infon><infon key="name_3">surname:Pica;given-names:I</infon><infon key="name_4">surname:Riviello;given-names:MT</infon><infon key="name_5">surname:Troncone;given-names:A</infon><infon key="name_6">surname:Cordasco;given-names:G</infon><infon key="name_7">surname:Esposito;given-names:AM</infon><infon key="pub-id_doi">10.1109/isce.2019.8900983</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>30140</offset><text>Elders Prefer Female Robots with a High Degree of Human Likeness</text></passage><passage><infon key="fpage">929</infon><infon key="lpage">934</infon><infon key="name_0">surname:Terada;given-names:K</infon><infon key="name_1">surname:Jing;given-names:L</infon><infon key="name_2">surname:Yamada;given-names:S</infon><infon key="pub-id_doi">10.1145/2702613.2732798</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>30205</offset><text>Effects of Agent Appearance on Customer Buying Motivations on Online Shopping Sites</text></passage><passage><infon key="fpage">1</infon><infon key="issue">4</infon><infon key="lpage">11</infon><infon key="name_0">surname:McDonnell;given-names:R</infon><infon key="name_1">surname:Breidt;given-names:M</infon><infon key="name_2">surname:Bülthoff;given-names:HH</infon><infon key="pub-id_doi">10.1145/2185520.2185587</infon><infon key="section_type">REF</infon><infon key="source">ACM Trans. Graph</infon><infon key="type">ref</infon><infon key="volume">31</infon><infon key="year">2012</infon><offset>30289</offset><text>Render me real?: investigating the effect of render style on the perception of animated virtual humans</text></passage><passage><infon key="fpage">374</infon><infon key="lpage">384</infon><infon key="name_0">surname:Ring;given-names:L</infon><infon key="name_1">surname:Utami;given-names:D</infon><infon key="name_2">surname:Bickmore;given-names:T</infon><infon key="pub-id_doi">10.1007/978-3-319-09767-1_49</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2014</infon><offset>30392</offset><text>The Right Agent for the Job? The Effects of Agent Visual Appearance on Task Domain</text></passage><passage><infon key="fpage">31</infon><infon key="name_0">surname:Esposito;given-names:A</infon><infon key="name_1">surname:Amorese;given-names:T</infon><infon key="name_2">surname:Cuciniello;given-names:M</infon><infon key="name_3">surname:Riviello;given-names:MT</infon><infon key="name_4">surname:Esposito;given-names:AM</infon><infon key="name_5">surname:Troncone;given-names:A</infon><infon key="name_6">surname:Cordasco;given-names:G</infon><infon key="pub-id_doi">10.21437/interspeech.2019-1734</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>30475</offset><text>The Dependability of Voice on Elders' Acceptance of Humanoid Agents</text></passage><passage><infon key="fpage">592</infon><infon key="name_0">surname:Baylor;given-names:AL</infon><infon key="name_1">surname:Yanghee;given-names:K</infon><infon key="pub-id_doi">10.1007/978-3-540-30139-4_56</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2004</infon><offset>30543</offset><text>Pedagogical Agent Design: The Impact of Agent Realism, Gender, Ethnicity, and Instructional Role</text></passage><passage><infon key="fpage">163</infon><infon key="issue">2</infon><infon key="lpage">189</infon><infon key="name_0">surname:Troncone;given-names:A</infon><infon key="name_1">surname:Amorese;given-names:T</infon><infon key="name_2">surname:Cuciniello;given-names:M</infon><infon key="name_3">surname:Saturno;given-names:R</infon><infon key="name_4">surname:Pugliese;given-names:L</infon><infon key="name_5">surname:Cordasco;given-names:G</infon><infon key="name_6">surname:Vogel;given-names:C</infon><infon key="name_7">surname:Esposito;given-names:A</infon><infon key="pub-id_doi">10.12700/aph.17.2.2020.2.10</infon><infon key="section_type">REF</infon><infon key="source">ACTA POLYTECH HUNG</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2020</infon><offset>30640</offset><text>Advanced Assistive Technologies for Elderly People: A Psychological Perspective on Seniors’ Needs and Preferences (part A)</text></passage><passage><infon key="fpage">4959</infon><infon key="lpage">4962</infon><infon key="name_0">surname:Tanaka;given-names:H</infon><infon key="name_1">surname:Nakamura;given-names:S</infon><infon key="pub-id_doi">10.1109/embc46164.2021.9630741</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>30765</offset><text>Virtual Agent Design for Social Skills Training Considering Autistic Traits</text></passage><passage><infon key="fpage">3</infon><infon key="lpage">25</infon><infon key="name_0">surname:Poggi;given-names:C</infon><infon key="name_1">surname:Pelachaud;given-names:C</infon><infon key="name_2">surname:De Rosis;given-names:F</infon><infon key="name_3">surname:Carofiglio;given-names:V</infon><infon key="name_4">surname:De Carolis;given-names:B</infon><infon key="section_type">REF</infon><infon key="source">Multimodal Intelligent Information Presentation</infon><infon key="type">ref</infon><infon key="year">2005</infon><offset>30841</offset><text>Greta. A Believable Embodied Conversational Agent</text></passage><passage><infon key="comment">
https://charactergenerator.autodesk.com/
</infon><infon key="section_type">REF</infon><infon key="source">Autodesk Character Generator</infon><infon key="type">ref</infon><offset>30891</offset></passage><passage><infon key="name_0">surname:Constantino;given-names:JN</infon><infon key="section_type">REF</infon><infon key="source">Social Responsiveness Scale - Second Edition (SRS-2)</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>30892</offset><text>Social Responsiveness Scale - Second Edition (SRS-2), WPS</text></passage><passage><infon key="fpage">23</infon><infon key="issue">1</infon><infon key="lpage">32</infon><infon key="name_0">surname:Bagby;given-names:R</infon><infon key="name_1">surname:Parker;given-names:JD</infon><infon key="name_2">surname:Taylor;given-names:GJ</infon><infon key="pub-id_doi">10.1016/0022-3999(94)90005-1</infon><infon key="pub-id_pmid">8126686</infon><infon key="section_type">REF</infon><infon key="source">Journal of Psychosomatic Research</infon><infon key="type">ref</infon><infon key="volume">38</infon><infon key="year">1994</infon><offset>30950</offset><text>The twenty-item Toronto Alexithymia scale—I. Item selection and cross-validation of the factor structure</text></passage><passage><infon key="fpage">2402</infon><infon key="issue">7</infon><infon key="lpage">2415</infon><infon key="name_0">surname:Bezemer;given-names:ML</infon><infon key="name_1">surname:Blijd-Hoogewys;given-names:EMA</infon><infon key="name_2">surname:Meek-Heekelaar;given-names:M</infon><infon key="pub-id_doi">10.1007/s10803-020-04699-7</infon><infon key="pub-id_medline">33001348</infon><infon key="pub-id_pii">10.1007/s10803-020-04699-7</infon><infon key="pub-id_pmid">33001348</infon><infon key="section_type">REF</infon><infon key="source">J Autism Dev Disord</infon><infon key="type">ref</infon><infon key="volume">51</infon><infon key="year">2021</infon><offset>31057</offset><text>The Predictive Value of the AQ and the SRS-A in the Diagnosis of ASD in Adults in Clinical Practice</text></passage><passage><infon key="comment">
http://animeartmuseum.org/whatisanimeart/
</infon><infon key="section_type">REF</infon><infon key="source">Anime Art Museum</infon><infon key="type">ref</infon><offset>31157</offset></passage><passage><infon key="name_0">surname:Koschate;given-names:M</infon><infon key="name_1">surname:Potter;given-names:R</infon><infon key="name_2">surname:Bremner;given-names:P</infon><infon key="name_3">surname:Levine;given-names:M</infon><infon key="pub-id_doi">10.1109/hri.2016.7451773</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>31158</offset><text>Overcoming the uncanny valley: Displays of emotions reduce the uncanniness of humanlike robots</text></passage><passage><infon key="fpage">33</infon><infon key="name_0">surname:Mori;given-names:M</infon><infon key="pub-id_doi">10.5749/j.ctvtv937f.7</infon><infon key="section_type">REF</infon><infon key="source">Energy 7</infon><infon key="type">ref</infon><infon key="year">1970</infon><offset>31253</offset><text>The uncanny valley</text></passage></document></collection>
