<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20201213</date><key>pmc.key</key><document><id>6927342</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.7717/peerj.8339</infon><infon key="article-id_pmc">6927342</infon><infon key="article-id_pmid">31875164</infon><infon key="article-id_publisher-id">8339</infon><infon key="elocation-id">e8339</infon><infon key="kwd">Online experiment Perception Vision Contrast threshold</infon><infon key="license">This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</infon><infon key="name_0">surname:Sasaki;given-names:Kyoshiro</infon><infon key="name_1">surname:Yamada;given-names:Yuki</infon><infon key="name_2">surname:Rocha;given-names:Joao</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">7</infon><infon key="year">2019</infon><offset>0</offset><text>Crowdsourcing visual perception experiments: a case of contrast threshold</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>74</offset><text>Crowdsourcing has commonly been used for psychological research but not for studies on sensory perception. A reason is that in online experiments, one cannot ensure that the rigorous settings required for the experimental environment are replicated. The present study examined the suitability of online experiments on basic visual perception, particularly the contrast threshold. We conducted similar visual experiments in the laboratory and online, employing three experimental conditions. The first was a laboratory experiment, where a small sample of participants (n = 24; laboratory condition) completed a task with 10 iterations. The other two conditions were online experiments: participants were either presented with a task without repetition of trials (n = 285; online non-repetition condition) or one with 10 iterations (n = 166; online repetition condition). The results showed significant equivalence in the contrast thresholds between the laboratory and online repetition conditions, although a substantial amount of data needed to be excluded from the analyses in the latter condition. The contrast threshold was significantly higher in the online non-repetition condition compared with the laboratory and online repetition conditions. To make crowdsourcing more suitable for investigating the contrast threshold, ways to reduce data wastage need to be formulated.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1453</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1466</offset><text>Over the last decade, experiments in psychological research have gone beyond the laboratory. The increasing diversity of research methods and technological advances has increased opportunities for researchers to use resources outside the laboratory. For example, researchers are using outsourcing services to recruit experimental participants and, often, even commissioning research firms to conduct their surveys and experiments. In addition, based on outstanding technological advances in the digital environment and mobile information devices, “crowdsourcing,” which is the practice of asking many unspecified people to various kinds of tasks via the internet, has become a powerful tool for psychological research (for a review, see).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2209</offset><text>Crowdsourcing can be used for data collection and in asking large numbers of people to participate in surveys or experiments via the internet. Service providers (e.g., Amazon and Yahoo!) manage an experimenter’s task and act as a payment agency. The use of crowdsourcing has a number of advantages. The first is its very low cost; for example, participants receive less than one USD for responding to a simple questionnaire or engaging in an easy cognitive task. Second, large (more than 1,000 people) and diverse (in age, sex, and culture) samples can easily be employed. The ease in collecting large amounts of diverse data is beneficial not only from the perspective of random sampling but also for planning experiments and estimating the effect size prior to conducting the experiment. Third, it enables researchers to use their time efficiently. With experiments running all hours of the day and night, data from 1,000 people can be obtained within a day or two, depending on how many active users are registered with the service.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3247</offset><text>Various kinds of online experiments and tasks have been conducted with crowdsourcing. For example, many experimental studies have reported findings based on self-report questionnaires and crowdsourced tasks: visual search, reaction time, keystroke, Stroop, attentional blink, flanker, Simon, lexical decision, category learning, memory, priming, and decision-making tasks. A previous study using auditory stimuli likewise employed crowdsourcing. A recent study recruited infants aged 5–8 months via crowdsourcing and measured their looking time with webcams. These studies have suggested that the effect size of the performance in such tasks is comparable to that in laboratory experiments; hence, crowdsourcing can be used for diverse online experiments with publishable reliability.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4034</offset><text>However, conventional studies on sensory perception are completed in the laboratory. Moreover, only authors or their laboratory members, who should be well experienced with psychophysical measurements, often participate in experiments on sensory perception. Only a small number of studies have attempted to run sensory perceptual experiments via crowdsourcing. Previous studies have investigated color and randomness on the web but used one-time color-matching, color word selection, forced choices (same or different), or magnitude estimation tasks. A few studies have measured the point of subjective equality, sensitivity, or thresholds using psychophysical methods in studies on color perception, volume perception, size perception scene perception, and stimulus visibility. One reason that experiments on sensory perception are rarely conducted online is the necessity for rigorous control over the experimental environment. Online experiments depend significantly on the participant’s own computing environment, and experimenters cannot control the display settings, visual distance (or visual field), or lighting conditions. Thus far, online experiments seem unsuitable for experimental studies that focus on the visual functions of spatial and temporal resolutions. For example, in examining the issue of the temporal aspect of stimulus presentation, researchers have found that stimuli are systematically presented for 20 ms longer than the programed durations. However, the above concerns might be negligible, and crowdsourcing is possibly suitable for perception studies. In this case, a large sample could be recruited to bring sufficient statistical power. Further, large and diverse samples are beneficial for the examination of individual differences in perception studies.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>5825</offset><text>Aim of the present study</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5850</offset><text>This study focused on measuring low-level visual perception via online experiments. We examined the contrast threshold in vision via online crowdsourcing and laboratory experiments. Contrast threshold is a non-temporal visual capacity that is highly susceptible to the influence of the display condition during measurement. Its measurement needs strict linearization of the output of the display with gamma correction; however, most displays of home PCs are not linearized. Moreover, the viewing distance should vary across the participants in the online condition; the spatial frequency depends on this distance. We believed that a comparison between web and lab measurements of visual contrast thresholds would provide tangible evidence of what online experiments can and cannot test regarding non-temporal aspects of stimulus presentation. If the non-linearity of monitor displays, differences in the viewing distance, and other possible factors comprise a negligible random effect, then the contrast threshold online and in the laboratory would be similar. Another important issue is boredom in the participants. In online experiments, boredom in participants substantially decreases data quality; many repetitions are likely to induce boredom. Thus, the present study used two types of iteration for online experiments: the repetition and non-repetition conditions. In the former, participants were presented with each trial 10 times per stimulus condition, whereas in the latter condition, each trial was presented only once. If we could control for measurement errors or individual differences by increasing the sample size, then a single trial for a stimulus condition would suffice to lead to an appropriate conclusion, even in online experiments, without data deterioration. For this reason, the sample size of the participants in the non-repetitive condition was about 10 times that of the repetitive condition.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>7773</offset><text>Methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>7781</offset><text>Participants</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">footnote</infon><offset>7794</offset><text>Discrepancies between the number of recruitments and that of the actual participants were often found when we used Yahoo! Crowdsourcing. We could not determine the exact reason. One possibility was that the four-digit number was shared online (e.g., SNS) and some crowdworkers may have seen it. In this case, they could be illegally admitted as completing the task by Yahoo! Crowdsourcing even if they did not actually complete the task. Moreover, Yahoo! Crowdsourcing allowed crowdworkers to access the recruiting page only once. Yahoo! Crowdsourcing manages the number of those accessing the recruiting page via Yahoo ID. Crowdworkers, who had multiple Yahoo IDs, could access the recruiting page several times. Therefore, after a participant had completed our experiment, received the four-digit number, and taken the reward, they could access the recruiting page with their other IDs again and input the four-digit number without performing the experiment. These ways of hacking might have caused the discrepancy. Setting and generating unique four-digit number for each participant could prevent this discrepancy; this is impossible at the present system. We plan to discuss means for preventing these issues with Yahoo! Crowdsourcing.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9035</offset><text>We used G * Power to determine the sample sizes needed for the repetition condition (α = 0.05, 1−β = 0.80). In the laboratory condition, we used a moderate effect size (f = 0.25) in the calculation of the required sample size. The required and maximum sample size was 24. In the online repetition condition, we used a small effect size (f = 0.10) in the calculation of the required sample size, because of the potential for noise in the data from online experiments. The required sample size was revealed to be 138. Considering potential satisficers, who do not devote an appropriate amount of attentional resources to a task and hence cursorily perform it, 200 people was set as the maximum sample size; participants were recruited through a crowdsourcing service (Yahoo! Crowdsourcing: ). The required sample size in the online non-repetition condition was at least 10 times that in the laboratory condition (240 people) according to the differences in the number of repetitions. Similarly, in the online repetition condition, we recruited 300 people as the maximum sample size to account for the potential influence of satisficers. The participants in the laboratory conditions undertook several experiments, including the present experiment, for 3 h, and subsequently received 4,000 JPY (the present experiment itself took less than 30 min, although we did not accurately record the duration). The order of these experiments was randomized across the participants. The participants in the online repetition and non-repetition conditions received 50 and 20 T-points (Japanese point service, in which one T-point is worth one JPY)1 , respectively. The participants were not made aware of the purpose of the study. The experiment was conducted according to the principles laid down in the Helsinki Declaration. The protocol was approved by the ethics committees of Waseda University (Approval Number: 2015-033) and Kyushu University (Approval Number: 2016-017). We obtained written informed consent from all of the participants in the laboratory condition. Meanwhile, it was difficult to obtain written informed consent in the online conditions. Thus, according to the protocol (Approval Number: 2016-017), we explained the details of the online experiments in instructions sections, and then asked the participants to take part in the experiments only when they agreed to the instructions. We recruited only PC users to participate in the online experiment.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>11502</offset><text>Apparatus</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11512</offset><text>In the laboratory condition, stimuli were presented on a 23.5-inch LCD display (FG2421; EIZO, Japan). The resolution of the display was 1,920 × 1,080 pixels, and the refresh rate was 100 Hz. We performed gamma correction for the luminance emitted from the monitor. The presentation of stimuli and the collection of data were computer-controlled (Mac mini, Apple, Cupertino, CA, USA). We used MATLAB with the Psychtoolbox extension to generate the stimuli. The observer’s visual field was fixed using a chin-and-head rest at a viewing distance of 57 cm from the display. The size information at the visual angle described for the laboratory condition was based on this viewing distance. In the online conditions, the experiment was conducted on a web browser with a JavaScript application (jsPsych). jsPsych is a useful toolbox for psychological research, employed in several previous studies.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>12408</offset><text>Stimuli and procedure</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12430</offset><text>Stimuli consisted of a fixation circle (diameter of 0.24°) and Gabor patches, the diameter of which was 42 pixels (2° in the laboratory conditions). The SD of a gaussian function was six pixels (0.29°). There were four spatial frequencies of the carrier: 0.02, 0.05, 0.09 and 0.38 cycles per pixel (cpp; 0.5, 1, 2 and 8 cycles per degree (cpd) in the laboratory conditions). We set seven contrast levels (the Michelson contrast), varying across the spatial frequencies. The contrasts in the 0.02 cpp (0.5 cpd) trials were 3%, 8%, 13%, 18%, 23%, 28% and 33%. The contrasts in the 0.05 and 0.09 cpp (1 and 2 cpd) trials were 1%, 6%, 11%, 16%, 21%, 26% and 31%. The contrasts in the 0.38 cpp (8 cpd) trials were 5%, 10%, 15%, 20%, 25%, 30% and 35%. The Gabor patches were tilted 45° clockwise or counterclockwise. We took screenshots of the stonline non-repetition conditionimuli on the monitor at the laboratory and then used them for the online conditions.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13390</offset><text>In the laboratory condition, the experiment was conducted in a darkened room. Fig. 1 shows the timeline of a trial in each of the conditions. The participants initiated each trial by pressing the space key. The fixation circle was presented for 500 ms. After the fixation circle disappeared, the Gabor patch was presented for 50 ms. Then, a blank screen was presented for 300 ms, followed by the prompt: “In which direction was the stimulus tilted?” The participants were asked whether the stimulus was tilted clockwise or counterclockwise. They responded without time limits or feedback. Each of the spatial frequency conditions was conducted in a separate session; thus, the experiment consisted of four sessions. The session order was randomized across the participants. In each session, trials were conducted for seven contrasts in two orientations. In the repetition condition, each combination of contrast and orientation was presented 10 times per session. Thus, participants in the repetition condition completed 560 trials, whereas those in the non-repetition condition completed only 56. The order of the trials was also randomized across the participants. Before the first session, we conducted a practice session, in which the participants completed four trials. The spatial frequency of the practice session was identical to that of the first session, and the contrast was 100%. Both of the orientations appeared twice. As in the experiment conditions, the trial order of each session was randomized across the participants.</text></passage><passage><infon key="file">peerj-07-8339-g001.jpg</infon><infon key="id">fig-1</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>14932</offset><text>Timeline of a trial in all the conditions.</text></passage><passage><infon key="file">peerj-07-8339-g001.jpg</infon><infon key="id">fig-1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>14975</offset><text>For enhanced visibility, we presented the stimulus in 100% contrast level in this figure.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15065</offset><text>In the online conditions, the participants accessed the page of Crowdsourcing for the link to the web address of the experiment. They navigated to the experiment page via the web address and then input their age and sex. Moreover, after completing the experiment, a four-digit number (8,382 and 3,599 in the online repetition and non-repetition conditions, respectively) was presented at the final experiment page; the participants typed this number on an empty form on the Yahoo! Crowdsourcing page. The four-digit number was registered for Yahoo! Crowdsourcing in advance. Only when the input and registered numbers corresponded would Yahoo! Crowdsourcing acknowledge that the participants had completed the experiment and give the reward. If the input and registered numbers did not correspond, Yahoo! Crowdsourcing made the participants drop out and did not give the reward. The procedures were identical to that of the laboratory conditions, except for the added insertion of attention check questions (ACQs). This additional step was included because online participants are often distracted or are satisficers. ACQs can reduce low-quality responses. These tend to be easy calculations based on the four basic arithmetic operations (e.g., 20 + 15 = ?). In the present study, ACQs appeared halfway through the total number of trials in each session and participants selected the correct answer from five options. We conducted the online repetition and online non-repetition conditions from 25 to 28 January 2019 and 29 January to 7 February 2019, respectively.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>16631</offset><text>Data analysis</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16645</offset><text>We excluded participants who gave incorrect answers to one or more of the ACQs. In the laboratory and online repetition conditions, we calculated the contrast threshold of each spatial frequency for each participant, for which the proportion of “correct” responses was 0.82, using a probit analysis (i.e., fitting a cumulative Gaussian function to the proportion of “correct” responses as a function of the contrast level). We used the “glm” function in R (3.4.4). The probit analysis provided the means and standard deviations (SDs) of the distributions. Then, we calculated the contrast thresholds using the means, SDs, and the “qnorm” function in R. We excluded participant data when β calculated by the probit analysis was a negative value. This negative value indicated a reduction in correct responses as the contrast level increased. In such cases, we could not calculate the thresholds. We also excluded the data from participants whose contrast thresholds were less than zero or greater than 100% because the contrast threshold should be within this range. In the online non-repetition condition, we used the pooled data from all the participants and then calculated the contrast threshold for each spatial frequency by the same procedure of the repetition condition.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17939</offset><text>First, to confirm whether the contrast threshold depended on the spatial frequency, we conducted a one-way analysis of variance (ANOVA) on the contrast thresholds, with spatial frequency as a within-participant factor, for the laboratory and online repetition conditions. We set the alpha level at 0.05 and calculated ηp2. When the main effects were significant, we conducted multiple comparison tests using Holm’s method. We conducted the t-test six times. Therefore, we increased α from 0.008 to 0.05 based on Holm’s correction.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18476</offset><text>As our purpose was to examine whether the contrast thresholds were different or equivalent between experimental environments in each spatial frequency, we conducted two-tailed Welch’s t-tests for the contrast thresholds for each spatial frequency. After the t-tests, we conducted equivalence tests for the pairs in which the contrast thresholds were not significantly different. For the equivalence tests, we used the TOSTER package in R and set Cohen’s d to 0.5. We compared the contrast threshold of the laboratory condition and the online repetition and non-repetition conditions; thus, we had to conduct t-tests and equivalence test three times at most. Therefore, we set α from 0.017 to 0.05 based on Holm’s correction.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>19208</offset><text>Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>19216</offset><text>The results of the proportion of the correct responses and the thresholds in the laboratory and online experiments are shown in Figs. 2 and 3, respectively. We collected data from 24 people in the laboratory condition. In the online repetition condition, of the 200 people recruited, only 80 participated1. As this number did not reach the required sample size, we recruited another 200 people and 86 people participated. Hence, we collected data from 166 people in total. For the online non-repetition condition, of the 300 people recruited, only 156 participated. Therefore, we recruited another 250 people and 129 people participated. Hence, we collected data from 285 people in total. We excluded the data from two (one owing to a negative β and the other, for having a contrast threshold greater than 100%), 84 (53 owing to a negative β; 13, a contrast threshold less than 0; 8, a contrast threshold greater than 100%; and 10, wrong answers to ACQ), and 19 (all owing to wrong answers to ACQ) participants in the laboratory, online repetition, and online non-repetition conditions, respectively, based on the rules detailed in the Data analysis section. Thus, we submitted the data from 22 (16 males and six females, mean age ± SEM = 21.39 ± 0.39), 82 (54 males, 26 females, and two non-respondents, mean age ± SEM = 43.56 ± 1.04), and 266 (176 males and 90 females, mean age ± SEM = 42.92 ± 0.61) participants in the laboratory, online repetition, and online non-repetition conditions, respectively, for the statistical analyses.</text></passage><passage><infon key="file">peerj-07-8339-g002.jpg</infon><infon key="id">fig-2</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>20764</offset><text>Results of the correct responses in the laboratory and online experiments.</text></passage><passage><infon key="file">peerj-07-8339-g003.jpg</infon><infon key="id">fig-3</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>20839</offset><text>Results of the thresholds in the laboratory and online experiments.</text></passage><passage><infon key="file">peerj-07-8339-g003.jpg</infon><infon key="id">fig-3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>20907</offset><text>Error bars denote standard deviations.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>20946</offset><text>Effects of spatial frequency within the laboratory and online repetition conditions</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">footnote</infon><offset>21030</offset><text>We added these post-hoc analyses according to the reviewer’s comment.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>21102</offset><text>The results of the ANOVA on the contrast thresholds in the laboratory condition revealed that the main effect was significant, F(3, 63) = 7.63, p &lt; 0.001, ηp2 = 0.27. The multiple comparison tests showed that the threshold was significantly higher in the 0.5 cpd trials compared with the 1 and 2 cpd trials, ts(21) &gt; 6.25, ps &lt; 0.001, Cohen’s dzs &gt; 1.33. Moreover, the threshold was significantly higher in the 8 cpd trials compared with the 2 cpd trials, t(21) = 2.88, p = 0.009, Cohen’s dz = 0.61. The results of the ANOVA on the contrast thresholds in the online repetition condition revealed that the main effect was significant, F(3, 243) = 26.23, p &lt; 0.001, ηp2 = 0.24. The multiple comparison tests showed that the threshold was significantly higher in the 8 cpd trials compared with the 1 and 2 cpd trials, ts(81) &gt; 6.77, ps &lt; 0.001, Cohen’s dzs &gt; 0.74. The threshold was also significantly higher in the 0.5 cpd trials compared with the 1 and 2 cpd trials, ts(81) &gt; 4.98, ps &lt; 0.001, Cohen’s dzs &gt; 0.64. Moreover, we calculated a McFadden’s pseudo R2 for each of spatial frequency in the laboratory and online repetition conditions and performed the two-way ANOVA on McFadden’s pseudo R2 with spatial frequency as a within-participant factor and experimental circumstances as a between-participant factor2. As a result, the main effect of spatial frequency was significant (F(3, 306) = 27.88, p &lt; 0.001, ηp2 = 0.21). Importantly, the main effect of experimental circumstances and interaction were not significant (experimental circumstances: F(1, 102) = 0.83, p = 0.37, ηp2 = 0.008; interaction: F(3, 306) = 0.52, p = 0.67, ηp2 = 0.005).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>22766</offset><text>Differences and equivalences between laboratory and repeated and non-repeated online conditions</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>22862</offset><text>Table 1 shows the summary of the results. For the 0.5 cpd trials, the threshold was significantly higher in the online non-repetition condition compared with the online repetition, t(332.97) = 6.14, p &lt; 0.001, Cohen’s d = 0.51, and laboratory conditions, t(159.41) = 5.95, p &lt; 0.001, Cohen’s d = 0.45. Meanwhile, the online repetition and laboratory conditions showed no significant difference, t(68.92) = 0.31, p = 0.76, Cohen’s d = 0.05. The equivalence test showed significant equivalence between the online repetition and laboratory conditions, t(68.92) = 2.26, p = 0.013.</text></passage><passage><infon key="file">table-1.xml</infon><infon key="id">table-1</infon><infon key="section_type">TABLE</infon><infon key="type">table_title_caption</infon><offset>23445</offset><text>Summary of the results in differences and equivalences between laboratory, repeated, and non-repeated online conditions.</text></passage><passage><infon key="file">table-1.xml</infon><infon key="id">table-1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot; content-type=&quot;text&quot;&gt;&lt;colgroup span=&quot;1&quot;&gt;&lt;col span=&quot;1&quot;/&gt;&lt;col span=&quot;1&quot;/&gt;&lt;col span=&quot;1&quot;/&gt;&lt;col span=&quot;1&quot;/&gt;&lt;col span=&quot;1&quot;/&gt;&lt;/colgroup&gt;&lt;thead&gt;&lt;tr&gt;&lt;th rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;cpd&lt;/th&gt;&lt;th rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;th rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Laboratory&lt;/th&gt;&lt;th rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online repetition&lt;/th&gt;&lt;th rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online non-repetition&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; colspan=&quot;1&quot;&gt;0.5&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Laboratory&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online repetition&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Eq.&lt;/bold&gt;&lt;break/&gt;TOST (90% CI [−3.1 to 4.5])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online non-repetition&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Dif.&lt;/bold&gt;&lt;break/&gt;NHST (95% CI [−22.6 to −11.3])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Dif.&lt;/bold&gt;&lt;break/&gt;NHST (95% CI [−23.3 to −12.0])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Laboratory&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online repetition&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Eq.&lt;/bold&gt;&lt;break/&gt;TOST (90% CI [−0.8 to 1.6])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online non-repetition&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Dif.&lt;/bold&gt;&lt;break/&gt;NHST (95% CI [−16.4 to −9.5])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Dif.&lt;/bold&gt;&lt;break/&gt;NHST (95% CI [−16.9 to −9.9])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; colspan=&quot;1&quot;&gt;2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Laboratory&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online repetition&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Eq.&lt;/bold&gt;&lt;break/&gt;TOST (90% CI [−1.8 to 1.2])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online non-repetition&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Dif.&lt;/bold&gt;&lt;break/&gt;NHST (95% CI [−16.5 to −9.3])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Dif.&lt;/bold&gt;&lt;break/&gt;NHST (95% CI [−16.1 to −9.1])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;3&quot; colspan=&quot;1&quot;&gt;8&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Laboratory&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online repetition&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Marg. Sig. Eq.&lt;/bold&gt;&lt;break/&gt;TOST (90% CI [−9.8 to 4.9])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Online non-repetition&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Dif.&lt;/bold&gt;&lt;break/&gt;NHST (95% CI [−35.5 to −15.4])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Sig. Dif.&lt;/bold&gt;&lt;break/&gt;NHST (95% CI [−30.3 to −15.7])&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>23566</offset><text>cpd		Laboratory	Online repetition	Online non-repetition	 	0.5	Laboratory				 	Online repetition	Sig. Eq.TOST (90% CI [−3.1 to 4.5])			 	Online non-repetition	Sig. Dif.NHST (95% CI [−22.6 to −11.3])	Sig. Dif.NHST (95% CI [−23.3 to −12.0])		 	1	Laboratory				 	Online repetition	Sig. Eq.TOST (90% CI [−0.8 to 1.6])			 	Online non-repetition	Sig. Dif.NHST (95% CI [−16.4 to −9.5])	Sig. Dif.NHST (95% CI [−16.9 to −9.9])		 	2	Laboratory				 	Online repetition	Sig. Eq.TOST (90% CI [−1.8 to 1.2])			 	Online non-repetition	Sig. Dif.NHST (95% CI [−16.5 to −9.3])	Sig. Dif.NHST (95% CI [−16.1 to −9.1])		 	8	Laboratory				 	Online repetition	Marg. Sig. Eq.TOST (90% CI [−9.8 to 4.9])			 	Online non-repetition	Sig. Dif.NHST (95% CI [−35.5 to −15.4])	Sig. Dif.NHST (95% CI [−30.3 to −15.7])		 	</text></passage><passage><infon key="file">table-1.xml</infon><infon key="id">table-1</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>24393</offset><text>Note:</text></passage><passage><infon key="file">table-1.xml</infon><infon key="id">table-1</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>24399</offset><text>NHST 95% CI = Null Hypothesis Significant Test 95% confidence interval, for cases of a significant difference between pairs; TOST 90% CI = Two One-Sided Test 90% confidence interval, for cases of a (marginally) significant equivalence between pairs.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>24649</offset><text>For the 1 cpd trials, the threshold was significantly higher in the online non-repetition condition compared with the online repetition, t(314.58) = 7.54, p &lt; 0.001, Cohen’s d = 0.55, and laboratory conditions, t(285.95) = 7.43, p &lt; 0.001, Cohen’s d = 0.71. No significant difference was observed between the online repetition and laboratory conditions, t(82.43) = 0.56, p = 0.580, Cohen’s d = 0.09. The equivalence test showed significant equivalence between the online repetition and laboratory conditions, t(82.43) = 2.13, p = 0.018.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25192</offset><text>For the 2 cpd trials, the threshold was significantly higher in the online non-repetition condition than in the online repetition, t(319.24) = 7.06, p &lt; 0.001, Cohen’s d = 0.52, and laboratory conditions, t(268.92) = 7.11, p &lt; 0.001, Cohen’s d = 0.72; no significant difference was found between the online repetition and laboratory conditions, t(57.31) = 0.33, p = 0.742, Cohen’s d = 0.06. The equivalence test showed significant equivalence between the online repetition and laboratory conditions, t(57.31) = 2.12, p = 0.019.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25726</offset><text>For the 8 cpd trials, the threshold was significantly higher in the online non-repetition condition compared with the online repetition, t(344.97) = 6.23, p &lt; 0.001, Cohen’s d = 0.50, and laboratory conditions, t(56.41) = 5.06, p &lt; 0.001, Cohen’s d = 0.51. However, no significant difference was found between the online repetition and laboratory conditions, t(31.40) = 0.56, p = 0.577, Cohen’s d = 0.14. The equivalence test showed that the equivalence between the online repetition and laboratory conditions was marginally significant, t(31.40) = 1.48, p = 0.075.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>26298</offset><text>Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>26309</offset><text>In particular, detection to low contrast stimuli on a non-gamma-corrected monitor are often easier than that on a gamma-corrected monitor: There might be differences in performances for the lowest contrast stimuli between laboratory and online repetition conditions. Thus, according to the reviewer’s suggestion, we performed a two-way ANOVA on proportions of the correct responses in the lowest contrast stimuli with spatial frequency (0.5, 1, 2 and 8 cpd) as a within-participant factor and experimental circumstances (laboratory and online repetition) as a between-participant factor. As a result, while the main effect of spatial frequency was significant (F(3, 306) = 3.34, p = 0.02, ηp2 = 0.03), the main effect of experimental circumstances and interaction were not significant (experimental circumstances: F(1, 102) = 0.02, p = 0.89, ηp2 &lt; 0.001; interaction: F(3, 306) = 0.27, p = 0.84, ηp2 = 0.003). Thus, at least, the differences in performances for the lowest contrast stimuli were not found in the present study.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>27342</offset><text>This study examined whether the contrast threshold was properly measured in an online experiment with two conditions: a condition with repetition of trials and another without repetition. The results showed equivalences in the contrast thresholds of the online repetition and laboratory conditions. The contrast threshold in the online non-repetition condition was higher than that in the online repetition and laboratory conditions. Thus, online experiments seem to be able to measure the contrast threshold as adequately as laboratory experiments, provided enough repetition3 . Notably, it is difficult to measure contrast thresholds without repetitions. However, as discussed below, there was a high rate of exclusions. In this case, it might be difficult to obtain large and diverse data; thus, one of the advantages of crowdsourcing is possibly lost. Taken together, rash decisions to use crowdsourcing for perception studies is likely to be risky at this time.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>28309</offset><text>The present study excluded 51% of the data in the online repetition condition. These exclusions mainly stemmed from the fact that the correct responses decreased as the contrast level increased or the thresholds were under zero. That is, in the online repetition condition, the contrast threshold could be barely calculated precisely. One possibility is that the experimental environment of 49% of the participants in the online repetition condition might be similar to that of the laboratory condition. We were able to calculate the thresholds of these participants and found significant equivalences between the laboratory and online repetition conditions. Meanwhile, the contrast thresholds were much higher in the online non-repetition condition. Although it is difficult to interpret this result, one can argue that the repetitive performance of the experimental task in the online repetition condition caused perceptual learning. It has been well known that contrast discrimination increases with repeated practice or training. However, there are only 10 repetitions for each stimulus in the online repetitive condition, and this little practice does not seem to cause sufficient perceptual learning. Alternatively, the difference in the results with and without repetition may provide clues for problems specific to online experiments. A large amount of the data was excluded in the online repetition condition. Based on this, we can expect the data obtained via online experiments to be noisy. Such noisy data might be included in and mediate the results of the online non-repetition condition. Given the large amount of data exclusion in the online repetition condition and the results of the online non-repetition condition, we could not conclude that online experiments are adequate for measuring the contrast threshold. Indeed, the contrast threshold would be difficult to measure via crowdsourcing unless the lighting conditions of each online participant can be measured and calibrated via camera.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>30321</offset><text>There may be solutions for improving the situation of online measurements of the contrast threshold. One would be to control the experimental environment of each participant in the online experiments to match that of a laboratory experiment. A previous study proposed beneficial tips for controlling the size of stimuli, distance from the monitor, sound volume, and brightness. also provided a possible way to adjust color, which seems to be difficult to control across online participants. They referenced the hints from a psychophysical study that demonstrated that humans have the ability comparable to a photometer when asked to match two patches in terms of brightness. The potential solution of was to ask participants to video record their computer screen and a colorful object (reference object) close to the screen using the camera on a mobile device, and then manually calibrate the screen color to the reference object. At this time, these methods require much effort from the participants and experimenters, and prone to technological difficulties; thus, they might not be ultimately effective. The ways to control experimental environments easily should lead to a reduction in low-quality data, and to a decrease in the exclusion of data, while also maintaining the ease of online experiments via crowdsourcing.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>31646</offset><text>Another solution is related to participant negligence. In the online experiment, participants might have a difficulty maintaining their motivation while performing tasks; for instance, they may have been unprepared to participate in a psychological experiment and not met the experimenters. Participants with inconsistent motivation often do not devote enough effort to the tasks, and, hence, cursory responses increase (satisficing,). ACQs, which we set during the online condition sessions, are beneficial for protecting the quality of the data from satisficing. It is easy for participants to answer ACQs correctly when they perform the tasks carefully. Generally, it is important to exclude the data from those who wrongly answer ACQs because of inattention and/or cursory responses, to improve the quality of data. However, in the present study, the data exclusion owing to incorrect ACQ responses accounted for 6% of the total data in each of the online conditions. Thus, the ACQ might not have worked as intended in the present study. The type of ACQ was extremely different from that of the main task (i.e., judging the orientation of the Gabor patch). Given this, the ACQ could be improved so that participants are not easily caught out, or another method could be used. An instructional manipulation check (IMC) is also helpful for detecting satisficers. An IMC checks whether the participants carefully read the instructions for the tasks. Specifically, they can incorporate the instruction not to answer questions into some methods commonly used in psychological research (e.g., Likert scales); thus, if the participants do not carefully read the instructions, they mistakenly answer the questions. The data from such participants should be excluded because they improperly dealt with the tasks. Additionally, in a recent study, alerting satisficers to their inattentiveness by a repeated IMC was helpful in improving their information processing. In general, ACQs and IMCs are valid tools for the detection and exclusion of data from satisficers. However, it is difficult to prevent satisficers from participating in experiments. To avoid losing data owing to satisficers, blacklisting them might be more effective in the long term.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>33892</offset><text>Other ways could be employed to maintain the quality of psychophysical online data. One is developing a platform designed for scientific research. Crowdsourcing services, such as Yahoo! Crowdsourcing and Amazon Mechanical Turk, have some advantages for conducting psychological research. However, they were not developed as research tools and have some inconveniences as well. Recently, a platform for scientific research was designed (TurkPrime, recently rebranded as CloudResearch:) and integrated with Amazon Mechanical Turk. Prolific is also a remarkable platform for conducting surveys and experiments online. These helpful systems for improving the quality of online data have also been proposed: Excluding participants based on previous participation, communicating with participants, and monitoring dropout and engagement rates. Elevating these platforms should be helpful for improving the quality of data in online experiments.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>34830</offset><text>Contrast sensitivity seemed to be lower in the present study than in the previous ones. This discrepancy might be attributed to the intensity level of the stimulus. Several studies have pointed out that the typical hardware used in psychological studies (256 intensity levels, eight bits) is insufficient for measuring contrast thresholds. One of the solutions is to use a graphics card able to display more than 256 different luminance intensities, but this does not seem to be realistic in online experiments. A previous study proposed the solution of adding visual noise to the stimulus, thereby not requiring special hardware. This solution might fit the context of online experiments. We aim to address these issues in future studies.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>35570</offset><text>Although crowdsourcing does not seem to be suitable for measurements of perception studies at this time, the improvement of environments in online experiments will bring advantages. For example, crowdsourcing enables researchers to obtain large amounts of data from various people, which is advantageous for examining individual differences in perceptual and cognitive processing. In classic laboratory experiments, most participants are university or graduate students, and large amounts of data tend to be difficult to collect. The demographics, personal traits, and cognitive characteristics of the participants do not vary enough to examine the relation between individual differences in perceptual and cognitive processing. Thus, this relation and underlying mechanism have not been understood well, warranting further investigations. Crowdsourcing, however, allows researchers to recruit participants from around the world, and hence, mass data from participants with various personality traits can be collected. Indeed, we and others have already shown the relation between individual differences in personality traits (e.g., social anxiety, behavioral activation/inhibition systems, and mood) and emotional reactions using crowdsourcing. Moreover, we previously conducted a perceptual study indicating the age and sex differences in the perception of pattern randomness. If the environment in online experiments is improved and crowdsourcing becomes suitable for investigating visual perception, then online experiments will be helpful for addressing issues regarding individual differences in visual perception.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>37191</offset><text>Conclusions</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>37203</offset><text>The present study examined the suitability of online experiments on the contrast threshold. As a result, online experiments seem to be able to measure the contrast threshold as adequately as laboratory experiments, provided enough repetitions. However, there was a high rate of exclusions, which is likely to spoil one of the advantages of crowdsourcing research. Thus, rash decisions to use crowdsourcing for perception studies might be risky at this time. The improvement of technology environments in online experiments via crowdsourcing will bring advantages; individual differences in perceptual processing will be measurable.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>37835</offset><text>Additional Information and Declarations</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title_1</infon><offset>37875</offset><text>Competing Interests</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">footnote</infon><offset>37895</offset><text>The authors declare that they have no competing interests.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title_1</infon><offset>37954</offset><text>Author Contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">footnote</infon><offset>37975</offset><text>Kyoshiro Sasaki analyzed the data, conceived and designed the experiments, performed the experiments, prepared figures and/or tables, authored or reviewed drafts of the paper, and approved the final draft.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">footnote</infon><offset>38181</offset><text>Yuki Yamada conceived and designed the experiments, authored or reviewed drafts of the paper, and approved the final draft.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title_1</infon><offset>38305</offset><text>Human Ethics</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">footnote</infon><offset>38318</offset><text>The following information was supplied relating to ethical approvals (i.e., approving body and any reference numbers):</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">footnote</infon><offset>38437</offset><text>The protocol was approved by the ethics committees of Waseda University (approval number: 2015-033) and Kyushu University (approval number: 2016-017).</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title_1</infon><offset>38588</offset><text>Data Availability</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">footnote</infon><offset>38606</offset><text>The following information was supplied regarding data availability:</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">footnote</infon><offset>38674</offset><text>The dataset is available at Figshare: Sasaki, Kyoshiro; Yamada, Yuki (2019): Online experiment of contrast thresholds. figshare. .</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>38805</offset><text>References</text></passage><passage><infon key="fpage">735</infon><infon key="issue">3</infon><infon key="lpage">743</infon><infon key="name_0">surname:Allard;given-names:R</infon><infon key="name_1">surname:Faubert;given-names:J</infon><infon key="pub-id_doi">10.3758/BRM.40.3.735</infon><infon key="pub-id_pmid">18697669</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">40</infon><infon key="year">2008</infon><offset>38816</offset><text>The noisy-bit method for digital displays: converting a 256 luminance resolution into a continuous resolution</text></passage><passage><infon key="fpage">527</infon><infon key="issue">2</infon><infon key="lpage">535</infon><infon key="name_0">surname:Aust;given-names:F</infon><infon key="name_1">surname:Diedenhofen;given-names:B</infon><infon key="name_2">surname:Ullrich;given-names:S</infon><infon key="name_3">surname:Musch;given-names:J</infon><infon key="pub-id_doi">10.3758/s13428-012-0265-2</infon><infon key="pub-id_pmid">23055170</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">45</infon><infon key="year">2013</infon><offset>38926</offset><text>Seriousness checks are useful to improve data validity in online research</text></passage><passage><infon key="fpage">437</infon><infon key="issue">3</infon><infon key="lpage">452</infon><infon key="name_0">surname:Bang;given-names:JW</infon><infon key="name_1">surname:Shekhar;given-names:M</infon><infon key="name_2">surname:Rahnev;given-names:D</infon><infon key="pub-id_doi">10.1037/xge0000511</infon><infon key="pub-id_pmid">30382720</infon><infon key="section_type">REF</infon><infon key="source">Journal of Experimental Psychology: General</infon><infon key="type">ref</infon><infon key="volume">148</infon><infon key="year">2019</infon><offset>39000</offset><text>Sensory noise increases metacognitive efficiency</text></passage><passage><infon key="fpage">918</infon><infon key="issue">4</infon><infon key="lpage">929</infon><infon key="name_0">surname:Barnhoorn;given-names:JS</infon><infon key="name_1">surname:Haasnoot;given-names:E</infon><infon key="name_2">surname:Bocanegra;given-names:BR</infon><infon key="name_3">surname:Van Steenbergen;given-names:H</infon><infon key="pub-id_doi">10.3758/s13428-014-0530-7</infon><infon key="pub-id_pmid">25407763</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">47</infon><infon key="year">2015</infon><offset>39049</offset><text>QRTEngine: an easy solution for running online reaction time experiments using qualtrics</text></passage><passage><infon key="fpage">351</infon><infon key="issue">3</infon><infon key="lpage">368</infon><infon key="name_0">surname:Berinsky;given-names:AJ</infon><infon key="name_1">surname:Huber;given-names:GA</infon><infon key="name_2">surname:Lenz;given-names:GS</infon><infon key="pub-id_doi">10.1093/pan/mpr057</infon><infon key="section_type">REF</infon><infon key="source">Political Analysis</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2012</infon><offset>39138</offset><text>Evaluating online labor markets for experimental research: Amazon.com’s Mechanical Turk</text></passage><passage><infon key="fpage">20</infon><infon key="lpage">28</infon><infon key="name_0">surname:Berinsky;given-names:AJ</infon><infon key="name_1">surname:Margolis;given-names:MF</infon><infon key="name_2">surname:Sances;given-names:MW</infon><infon key="pub-id_doi">10.1016/j.jesp.2015.09.010</infon><infon key="section_type">REF</infon><infon key="source">Journal of Experimental Social Psychology</infon><infon key="type">ref</infon><infon key="volume">66</infon><infon key="year">2016</infon><offset>39228</offset><text>Can we turn shirkers into workers?</text></passage><passage><infon key="fpage">384</infon><infon key="issue">3</infon><infon key="lpage">392</infon><infon key="name_0">surname:Brady;given-names:TF</infon><infon key="name_1">surname:Alvarez;given-names:GA</infon><infon key="pub-id_doi">10.1177/0956797610397956</infon><infon key="pub-id_pmid">21296808</infon><infon key="section_type">REF</infon><infon key="source">Psychological Science</infon><infon key="type">ref</infon><infon key="volume">22</infon><infon key="year">2011</infon><offset>39263</offset><text>Hierarchical encoding in visual working memory: ensemble statistics bias memory for individual items</text></passage><passage><infon key="fpage">1160</infon><infon key="issue">6</infon><infon key="lpage">1176</infon><infon key="name_0">surname:Brady;given-names:TF</infon><infon key="name_1">surname:Shafer-Skelton;given-names:A</infon><infon key="name_2">surname:Alvarez;given-names:GA</infon><infon key="pub-id_doi">10.1037/xhp0000399</infon><infon key="pub-id_pmid">28263635</infon><infon key="section_type">REF</infon><infon key="source">Journal of Experimental Psychology: Human Perception and Performance</infon><infon key="type">ref</infon><infon key="volume">43</infon><infon key="year">2017</infon><offset>39364</offset><text>Global ensemble texture representations are critical to rapid scene perception</text></passage><passage><infon key="fpage">433</infon><infon key="issue">4</infon><infon key="lpage">436</infon><infon key="name_0">surname:Brainard;given-names:DH</infon><infon key="pub-id_doi">10.1163/156856897X00357</infon><infon key="pub-id_pmid">9176952</infon><infon key="section_type">REF</infon><infon key="source">Spatial Vision</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">1997</infon><offset>39443</offset><text>The psychophysics toolbox</text></passage><passage><infon key="elocation-id">e100662</infon><infon key="issue">7</infon><infon key="name_0">surname:Brown;given-names:HR</infon><infon key="name_1">surname:Zeidman;given-names:P</infon><infon key="name_2">surname:Smittenaar;given-names:P</infon><infon key="name_3">surname:Adams;given-names:RA</infon><infon key="name_4">surname:McNab;given-names:F</infon><infon key="name_5">surname:Rutledge;given-names:RB</infon><infon key="name_6">surname:Dolan;given-names:RJ</infon><infon key="pub-id_doi">10.1371/journal.pone.0100662</infon><infon key="pub-id_pmid">25025865</infon><infon key="section_type">REF</infon><infon key="source">PLOS ONE</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2014</infon><offset>39469</offset><text>Crowdsourcing for cognitive science—the utility of smartphones</text></passage><passage><infon key="fpage">949</infon><infon key="issue">8</infon><infon key="lpage">967</infon><infon key="name_0">surname:Cameron;given-names:EL</infon><infon key="name_1">surname:Tai;given-names:JC</infon><infon key="name_2">surname:Carrasco;given-names:M</infon><infon key="pub-id_doi">10.1016/S0042-6989(02)00039-1</infon><infon key="pub-id_pmid">11934448</infon><infon key="section_type">REF</infon><infon key="source">Vision Research</infon><infon key="type">ref</infon><infon key="volume">42</infon><infon key="year">2002</infon><offset>39534</offset><text>Covert attention affects the psychometric function of contrast sensitivity</text></passage><passage><infon key="fpage">112</infon><infon key="issue">1</infon><infon key="lpage">130</infon><infon key="name_0">surname:Chandler;given-names:J</infon><infon key="name_1">surname:Mueller;given-names:P</infon><infon key="name_2">surname:Paolacci;given-names:G</infon><infon key="pub-id_doi">10.3758/s13428-013-0365-7</infon><infon key="pub-id_pmid">23835650</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">46</infon><infon key="year">2014</infon><offset>39609</offset><text>Nonnaïveté among Amazon Mechanical Turk workers: consequences and solutions for behavioral researchers</text></passage><passage><infon key="elocation-id">e1942</infon><infon key="issue">9</infon><infon key="name_0">surname:Chaya;given-names:K</infon><infon key="name_1">surname:Xue;given-names:Y</infon><infon key="name_2">surname:Uto;given-names:Y</infon><infon key="name_3">surname:Yao;given-names:Q</infon><infon key="name_4">surname:Yamada;given-names:Y</infon><infon key="pub-id_doi">10.7717/peerj.1942</infon><infon key="pub-id_pmid">27168967</infon><infon key="section_type">REF</infon><infon key="source">PeerJ</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2016</infon><offset>39714</offset><text>Fear of eyes: triadic relation among social anxiety, trypophobia, and discomfort for eye cluster</text></passage><passage><infon key="elocation-id">e0188246</infon><infon key="issue">11</infon><infon key="name_0">surname:Chrabaszcz;given-names:JS</infon><infon key="name_1">surname:Tidwell;given-names:JW</infon><infon key="name_2">surname:Dougherty;given-names:MR</infon><infon key="pub-id_doi">10.1371/journal.pone.0188246</infon><infon key="pub-id_pmid">29145511</infon><infon key="section_type">REF</infon><infon key="source">PLOS ONE</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2017</infon><offset>39811</offset><text>Crowdsourcing prior information to improve study design and data analysis</text></passage><passage><infon key="elocation-id">e867</infon><infon key="issue">1</infon><infon key="name_0">surname:Crangle;given-names:CE</infon><infon key="name_1">surname:Kart;given-names:JB</infon><infon key="pub-id_doi">10.7717/peerj.867</infon><infon key="pub-id_pmid">25870768</infon><infon key="section_type">REF</infon><infon key="source">PeerJ</infon><infon key="type">ref</infon><infon key="volume">3</infon><infon key="year">2015</infon><offset>39885</offset><text>A questions-based investigation of consumer mental-health information</text></passage><passage><infon key="elocation-id">e57410</infon><infon key="issue">3</infon><infon key="name_0">surname:Crump;given-names:MJC</infon><infon key="name_1">surname:McDonnell;given-names:JV</infon><infon key="name_2">surname:Gureckis;given-names:TM</infon><infon key="pub-id_doi">10.1371/journal.pone.0057410</infon><infon key="pub-id_pmid">23516406</infon><infon key="section_type">REF</infon><infon key="source">PLOS ONE</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2013</infon><offset>39955</offset><text>Evaluating Amazon’s Mechanical Turk as a tool for experimental behavioral research</text></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">12</infon><infon key="name_0">surname:de Leeuw;given-names:JR</infon><infon key="pub-id_doi">10.3758/s13428-014-0458-y</infon><infon key="pub-id_pmid">24683129</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">47</infon><infon key="year">2015</infon><offset>40040</offset><text>jsPsych: a JavaScript library for creating behavioral experiments in a web browser</text></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">12</infon><infon key="name_0">surname:de Leeuw;given-names:JR</infon><infon key="name_1">surname:Motz;given-names:BA</infon><infon key="pub-id_doi">10.3758/s13428-015-0567-2</infon><infon key="pub-id_pmid">25761390</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">48</infon><infon key="year">2016</infon><offset>40123</offset><text>Psychophysics in a web browser? Comparing response times collected with JavaScript and psychophysics toolbox in a visual search task</text></passage><passage><infon key="fpage">160059</infon><infon key="issue">8</infon><infon key="name_0">surname:Garcia;given-names:D</infon><infon key="name_1">surname:Kappas;given-names:A</infon><infon key="name_2">surname:Küster;given-names:D</infon><infon key="name_3">surname:Schweitzer;given-names:F</infon><infon key="pub-id_doi">10.1098/rsos.160059</infon><infon key="pub-id_pmid">27853586</infon><infon key="section_type">REF</infon><infon key="source">Royal Society Open Science</infon><infon key="type">ref</infon><infon key="volume">3</infon><infon key="year">2016</infon><offset>40256</offset><text>The dynamics of emotions in online interaction</text></passage><passage><infon key="fpage">121</infon><infon key="issue">1</infon><infon key="lpage">130</infon><infon key="name_0">surname:Gottlieb;given-names:S</infon><infon key="name_1">surname:Lombrozo;given-names:T</infon><infon key="pub-id_doi">10.1177/0956797617722609</infon><infon key="pub-id_pmid">29095658</infon><infon key="section_type">REF</infon><infon key="source">Psychological Science</infon><infon key="type">ref</infon><infon key="volume">29</infon><infon key="year">2018</infon><offset>40303</offset><text>Can science explain the human mind? Intuitive judgments about the limits of science</text></passage><passage><infon key="fpage">65</infon><infon key="lpage">70</infon><infon key="name_0">surname:Holm;given-names:S</infon><infon key="pub-id_doi">10.2307/4615733</infon><infon key="section_type">REF</infon><infon key="source">Scandinavian Journal of Statistics</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">1979</infon><offset>40387</offset><text>A simple sequentially rejective multiple test procedure</text></passage><passage><infon key="fpage">88</infon><infon key="issue">1</infon><infon key="lpage">106</infon><infon key="name_0">surname:Hurling;given-names:R</infon><infon key="name_1">surname:Murray;given-names:P</infon><infon key="name_10">surname:So;given-names:TT</infon><infon key="name_2">surname:Tomlin;given-names:C</infon><infon key="name_3">surname:Warner;given-names:A</infon><infon key="name_4">surname:Wilkinson;given-names:J</infon><infon key="name_5">surname:York;given-names:G</infon><infon key="name_6">surname:Linley;given-names:PA</infon><infon key="name_7">surname:Dovey;given-names:H</infon><infon key="name_8">surname:Hogan;given-names:RA</infon><infon key="name_9">surname:Maltby;given-names:J</infon><infon key="pub-id_doi">10.5539/ijps.v9n1p88</infon><infon key="section_type">REF</infon><infon key="source">International Journal of Psychological Studies</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2017</infon><offset>40443</offset><text>Short tips delivered in the moment can boost positive emotion</text></passage><passage><infon key="fpage">R545</infon><infon key="issue">13</infon><infon key="lpage">R546</infon><infon key="name_0">surname:Lafer-Sousa;given-names:R</infon><infon key="name_1">surname:Hermann;given-names:KL</infon><infon key="name_2">surname:Conway;given-names:BR</infon><infon key="pub-id_doi">10.1016/j.cub.2015.04.053</infon><infon key="pub-id_pmid">25981795</infon><infon key="section_type">REF</infon><infon key="source">Current Biology</infon><infon key="type">ref</infon><infon key="volume">25</infon><infon key="year">2015</infon><offset>40505</offset><text>Striking individual differences in color perception uncovered by ‘the dress’ photograph</text></passage><passage><infon key="fpage">259</infon><infon key="issue">2</infon><infon key="lpage">269</infon><infon key="name_0">surname:Lakens;given-names:D</infon><infon key="name_1">surname:Scheel;given-names:AM</infon><infon key="name_2">surname:Isager;given-names:PM</infon><infon key="pub-id_doi">10.1177/2515245918770963</infon><infon key="section_type">REF</infon><infon key="source">Advances in Methods and Practices in Psychological Science</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2018</infon><offset>40597</offset><text>Equivalence testing for psychological research: a tutorial</text></passage><passage><infon key="fpage">978</infon><infon key="issue">5</infon><infon key="lpage">984</infon><infon key="name_0">surname:Lee;given-names:TH</infon><infon key="name_1">surname:Baek;given-names:J</infon><infon key="name_2">surname:Lu;given-names:ZL</infon><infon key="name_3">surname:Mather;given-names:M</infon><infon key="pub-id_doi">10.1037/a0037047</infon><infon key="pub-id_pmid">24932842</infon><infon key="section_type">REF</infon><infon key="source">Emotion</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2014</infon><offset>40656</offset><text>How arousal modulates the visual contrast sensitivity function</text></passage><passage><infon key="fpage">433</infon><infon key="issue">2</infon><infon key="lpage">442</infon><infon key="name_0">surname:Litman;given-names:L</infon><infon key="name_1">surname:Robinson;given-names:J</infon><infon key="name_2">surname:Abberbock;given-names:T</infon><infon key="pub-id_doi">10.3758/s13428-016-0727-z</infon><infon key="pub-id_pmid">27071389</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">49</infon><infon key="year">2017</infon><offset>40719</offset><text>TurkPrime. com: a versatile crowdsourcing data acquisition platform for the behavioral sciences</text></passage><passage><infon key="name_0">surname:Lu;given-names:Z</infon><infon key="name_1">surname:Dosher;given-names:B</infon><infon key="section_type">REF</infon><infon key="source">Visual psychophysics: from laboratory to theory</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>40815</offset></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">12</infon><infon key="name_0">surname:Majima;given-names:Y</infon><infon key="pub-id_doi">10.1177/2158244017698731</infon><infon key="section_type">REF</infon><infon key="source">SAGE Open</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2017</infon><offset>40816</offset><text>The feasibility of a Japanese crowdsourcing service for experimental research in psychology</text></passage><passage><infon key="fpage">61</infon><infon key="lpage">83</infon><infon key="name_0">surname:Maniaci;given-names:MR</infon><infon key="name_1">surname:Rogge;given-names:RD</infon><infon key="pub-id_doi">10.1016/j.jrp.2013.09.008</infon><infon key="section_type">REF</infon><infon key="source">Journal of Research in Personality</infon><infon key="type">ref</infon><infon key="volume">48</infon><infon key="year">2014</infon><offset>40908</offset><text>Caring about carelessness: participant inattention and its effects on research</text></passage><passage><infon key="fpage">1563</infon><infon key="name_0">surname:Miura;given-names:A</infon><infon key="name_1">surname:Kobayashi;given-names:T</infon><infon key="pub-id_doi">10.3389/fpsyg.2016.01563</infon><infon key="pub-id_pmid">27803680</infon><infon key="section_type">REF</infon><infon key="source">Frontiers in Psychology</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2016</infon><offset>40987</offset><text>Survey satisficing inflates stereotypical responses in online experiment: the case of immigration study</text></passage><passage><infon key="fpage">101</infon><infon key="issue">1</infon><infon key="lpage">115</infon><infon key="name_0">surname:Nosek;given-names:BA</infon><infon key="name_1">surname:Banaji;given-names:M</infon><infon key="name_2">surname:Greenwald;given-names:AG</infon><infon key="pub-id_doi">10.1037/1089-2699.6.1.101</infon><infon key="section_type">REF</infon><infon key="source">Group Dynamics: Theory</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2002</infon><offset>41091</offset><text>Harvesting implicit group attitudes and beliefs from a demonstration web site</text></passage><passage><infon key="fpage">867</infon><infon key="issue">4</infon><infon key="lpage">872</infon><infon key="name_0">surname:Oppenheimer;given-names:DM</infon><infon key="name_1">surname:Meyvis;given-names:T</infon><infon key="name_2">surname:Davidenko;given-names:N</infon><infon key="pub-id_doi">10.1016/j.jesp.2009.03.009</infon><infon key="section_type">REF</infon><infon key="source">Journal of Experimental Social Psychology</infon><infon key="type">ref</infon><infon key="volume">45</infon><infon key="year">2009</infon><offset>41169</offset><text>Instructional manipulation checks: detecting satisficing to increase statistical power</text></passage><passage><infon key="fpage">22</infon><infon key="lpage">27</infon><infon key="name_0">surname:Palan;given-names:S</infon><infon key="name_1">surname:Schitter;given-names:C</infon><infon key="pub-id_doi">10.1016/j.jbef.2017.12.004</infon><infon key="section_type">REF</infon><infon key="source">Journal of Behavioral and Experimental Finance</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2018</infon><offset>41256</offset><text>Prolific.ac—a subject pool for online experiments</text></passage><passage><infon key="elocation-id">e0144536</infon><infon key="issue">12</infon><infon key="name_0">surname:Pechey;given-names:R</infon><infon key="name_1">surname:Attwood;given-names:AS</infon><infon key="name_2">surname:Couturier;given-names:DL</infon><infon key="name_3">surname:Munafò;given-names:MR</infon><infon key="name_4">surname:Scott-Samuel;given-names:NE</infon><infon key="name_5">surname:Woods;given-names:A</infon><infon key="name_6">surname:Marteau;given-names:TM</infon><infon key="pub-id_doi">10.1371/journal.pone.0144536</infon><infon key="pub-id_pmid">26698577</infon><infon key="section_type">REF</infon><infon key="source">PLOS ONE</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2015</infon><offset>41308</offset><text>Does glass size and shape influence judgements of the volume of wine?</text></passage><passage><infon key="fpage">437</infon><infon key="issue">4</infon><infon key="lpage">442</infon><infon key="name_0">surname:Pelli;given-names:DG</infon><infon key="pub-id_doi">10.1163/156856897X00366</infon><infon key="pub-id_pmid">9176953</infon><infon key="section_type">REF</infon><infon key="source">Spatial Vision</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">1997</infon><offset>41378</offset><text>The VideoToolbox software for visual psychophysics: transforming numbers into movies</text></passage><passage><infon key="fpage">1163</infon><infon key="issue">3</infon><infon key="lpage">1176</infon><infon key="name_0">surname:Pinet;given-names:S</infon><infon key="name_1">surname:Zielinski;given-names:C</infon><infon key="name_2">surname:Mathot;given-names:S</infon><infon key="name_3">surname:Dufau;given-names:S</infon><infon key="name_4">surname:Alario;given-names:FX</infon><infon key="name_5">surname:Longcamp;given-names:M</infon><infon key="pub-id_doi">10.3758/s13428-016-0776-3</infon><infon key="pub-id_pmid">27412730</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">49</infon><infon key="year">2017</infon><offset>41463</offset><text>Measuring sequences of keystrokes with jsPsych: reliability of response times and inter-keystroke intervals</text></passage><passage><infon key="fpage">309</infon><infon key="issue">2</infon><infon key="lpage">327</infon><infon key="name_0">surname:Reimers;given-names:S</infon><infon key="name_1">surname:Stewart;given-names:N</infon><infon key="pub-id_doi">10.3758/s13428-014-0471-1</infon><infon key="pub-id_pmid">24903687</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">47</infon><infon key="year">2015</infon><offset>41571</offset><text>Presentation and response timing accuracy in Adobe Flash and HTML5/JavaScript web experiments</text></passage><passage><infon key="fpage">1792</infon><infon key="name_0">surname:Sasaki;given-names:K</infon><infon key="name_1">surname:Ihaya;given-names:K</infon><infon key="name_2">surname:Yamada;given-names:Y</infon><infon key="pub-id_doi">10.3389/fpsyg.2017.01792</infon><infon key="pub-id_pmid">29123490</infon><infon key="section_type">REF</infon><infon key="source">Frontiers in Psychology</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2017</infon><offset>41665</offset><text>Avoidance of novelty contributes to the uncanny valley</text></passage><passage><infon key="elocation-id">e67769</infon><infon key="issue">6</infon><infon key="name_0">surname:Schubert;given-names:TW</infon><infon key="name_1">surname:Murteira;given-names:C</infon><infon key="name_2">surname:Collins;given-names:EC</infon><infon key="name_3">surname:Lopes;given-names:D</infon><infon key="pub-id_doi">10.1371/journal.pone.0067769</infon><infon key="pub-id_pmid">23805326</infon><infon key="section_type">REF</infon><infon key="source">PLOS ONE</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2013</infon><offset>41720</offset><text>ScriptingRT: a software library for collecting response latencies in online studies of cognition</text></passage><passage><infon key="fpage">95</infon><infon key="issue">1</infon><infon key="lpage">111</infon><infon key="name_0">surname:Simcox;given-names:T</infon><infon key="name_1">surname:Fiez;given-names:JA</infon><infon key="pub-id_doi">10.3758/s13428-013-0345-y</infon><infon key="pub-id_pmid">23670340</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">46</infon><infon key="year">2014</infon><offset>41817</offset><text>Collecting response times using Amazon Mechanical Turk and Adobe Flash</text></passage><passage><infon key="fpage">1249</infon><infon key="issue">10</infon><infon key="lpage">1258</infon><infon key="name_0">surname:Sowden;given-names:PT</infon><infon key="name_1">surname:Rose;given-names:D</infon><infon key="name_2">surname:Davies;given-names:IRL</infon><infon key="pub-id_doi">10.1016/S0042-6989(02)00019-6</infon><infon key="pub-id_pmid">12044757</infon><infon key="section_type">REF</infon><infon key="source">Vision Research</infon><infon key="type">ref</infon><infon key="volume">42</infon><infon key="year">2002</infon><offset>41888</offset><text>Perceptual learning of luminance contrast detection: specific for spatial frequency and retinal location but not orientation</text></passage><passage><infon key="fpage">736</infon><infon key="issue">10</infon><infon key="lpage">748</infon><infon key="name_0">surname:Stewart;given-names:N</infon><infon key="name_1">surname:Chandler;given-names:J</infon><infon key="name_2">surname:Paolacci;given-names:G</infon><infon key="pub-id_doi">10.1016/j.tics.2017.06.007</infon><infon key="pub-id_pmid">28803699</infon><infon key="section_type">REF</infon><infon key="source">Trends in Cognitive Sciences</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2017</infon><offset>42013</offset><text>Crowdsourcing samples in cognitive science</text></passage><passage><infon key="fpage">228</infon><infon key="lpage">233</infon><infon key="name_0">surname:Szafir;given-names:DA</infon><infon key="name_1">surname:Stone;given-names:M</infon><infon key="name_2">surname:Gleicher;given-names:M</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2014</infon><offset>42056</offset><text>Adapting color difference for design</text></passage><passage><infon key="fpage">15</infon><infon key="lpage">24</infon><infon key="name_0">surname:To;given-names:L</infon><infon key="name_1">surname:Woods;given-names:RL</infon><infon key="name_2">surname:Goldstein;given-names:RB</infon><infon key="name_3">surname:Peli;given-names:E</infon><infon key="pub-id_doi">10.1016/j.visres.2013.04.011</infon><infon key="pub-id_pmid">23643843</infon><infon key="section_type">REF</infon><infon key="source">Vision Research</infon><infon key="type">ref</infon><infon key="volume">90</infon><infon key="year">2013</infon><offset>42093</offset><text>Psychophysical contrast calibration</text></passage><passage><infon key="fpage">168</infon><infon key="lpage">178</infon><infon key="name_0">surname:Tran;given-names:M</infon><infon key="name_1">surname:Cabral;given-names:L</infon><infon key="name_2">surname:Patel;given-names:R</infon><infon key="name_3">surname:Cusack;given-names:R</infon><infon key="pub-id_doi">10.1016/j.jecp.2016.12.003</infon><infon key="pub-id_pmid">28088051</infon><infon key="section_type">REF</infon><infon key="source">Journal of Experimental Child Psychology</infon><infon key="type">ref</infon><infon key="volume">156</infon><infon key="year">2017</infon><offset>42129</offset><text>Online recruitment and testing of infants with Mechanical Turk</text></passage><passage><infon key="fpage">2777</infon><infon key="issue">9</infon><infon key="lpage">2790</infon><infon key="name_0">surname:Ware;given-names:C</infon><infon key="name_1">surname:Turton;given-names:TL</infon><infon key="name_2">surname:Bujack;given-names:R</infon><infon key="name_3">surname:Samsel;given-names:F</infon><infon key="name_4">surname:Shrivastava;given-names:P</infon><infon key="name_5">surname:Rogers;given-names:DH</infon><infon key="pub-id_doi">10.1109/TVCG.2018.2855742</infon><infon key="pub-id_pmid">30028708</infon><infon key="section_type">REF</infon><infon key="source">IEEE Transactions on Visualization and Computer Graphics</infon><infon key="type">ref</infon><infon key="volume">25</infon><infon key="year">2018</infon><offset>42192</offset><text>Measuring and modeling the feature detection threshold functions of colormaps</text></passage><passage><infon key="fpage">2064</infon><infon key="issue">7</infon><infon key="lpage">2072</infon><infon key="name_0">surname:Woods;given-names:KJ</infon><infon key="name_1">surname:Siegel;given-names:MH</infon><infon key="name_2">surname:Traer;given-names:J</infon><infon key="name_3">surname:McDermott;given-names:JH</infon><infon key="pub-id_doi">10.3758/s13414-017-1361-2</infon><infon key="section_type">REF</infon><infon key="source">Attention, Perception, &amp; Psychophysics</infon><infon key="type">ref</infon><infon key="volume">79</infon><infon key="year">2017</infon><offset>42270</offset><text>Headphone screening to facilitate web-based auditory experiments</text></passage><passage><infon key="elocation-id">e1058</infon><infon key="name_0">surname:Woods;given-names:AT</infon><infon key="name_1">surname:Velasco;given-names:C</infon><infon key="name_2">surname:Levitan;given-names:CA</infon><infon key="name_3">surname:Wan;given-names:X</infon><infon key="name_4">surname:Spence;given-names:C</infon><infon key="pub-id_doi">10.7717/peerj.1058</infon><infon key="pub-id_pmid">26244107</infon><infon key="section_type">REF</infon><infon key="source">PeerJ</infon><infon key="type">ref</infon><infon key="volume">3</infon><infon key="year">2015</infon><offset>42335</offset><text>Conducting perception research over the internet: a tutorial review</text></passage><passage><infon key="elocation-id">e00041</infon><infon key="issue">2</infon><infon key="name_0">surname:Yamada;given-names:Y</infon><infon key="pub-id_doi">10.14340/spp.2015.01A0002</infon><infon key="section_type">REF</infon><infon key="source">Science Postprint</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2015</infon><offset>42403</offset><text>Gender and age differences in visual perception of pattern randomness</text></passage><passage><infon key="fpage">4</infon><infon key="issue">3</infon><infon key="lpage">14</infon><infon key="name_0">surname:Yu;given-names:C</infon><infon key="name_1">surname:Klein;given-names:SA</infon><infon key="name_2">surname:Levi;given-names:DM</infon><infon key="pub-id_doi">10.1167/4.3.4</infon><infon key="section_type">REF</infon><infon key="source">Journal of Vision</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2004</infon><offset>42473</offset><text>Perceptual learning in contrast discrimination and the (minimal) role of context</text></passage><passage><infon key="fpage">1968</infon><infon key="issue">5</infon><infon key="lpage">1972</infon><infon key="name_0">surname:Zwaan;given-names:RA</infon><infon key="name_1">surname:Pecher;given-names:D</infon><infon key="name_2">surname:Paolacci;given-names:G</infon><infon key="name_3">surname:Bouwmeester;given-names:S</infon><infon key="name_4">surname:Verkoeijen;given-names:P</infon><infon key="name_5">surname:Dijkstra;given-names:K</infon><infon key="name_6">surname:Zeelenberg;given-names:R</infon><infon key="pub-id_doi">10.3758/s13423-017-1348-y</infon><infon key="pub-id_pmid">28744765</infon><infon key="section_type">REF</infon><infon key="source">Psychonomic Bulletin &amp; Review</infon><infon key="type">ref</infon><infon key="volume">25</infon><infon key="year">2018</infon><offset>42554</offset><text>Participant nonnaiveté and the reproducibility of cognitive psychology</text></passage></document></collection>
