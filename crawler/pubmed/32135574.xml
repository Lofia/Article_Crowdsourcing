<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20211004</date><key>pmc.key</key><document><id>7483427</id><infon key="license">author_manuscript</infon><passage><infon key="article-id_doi">10.1111/add.15032</infon><infon key="article-id_manuscript">NIHMS1576078</infon><infon key="article-id_pmc">7483427</infon><infon key="article-id_pmid">32135574</infon><infon key="fpage">1960</infon><infon key="issue">10</infon><infon key="kwd">Amazon Mechanical Turk addiction crowdsourcing survey research online</infon><infon key="license">
          This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
        </infon><infon key="lpage">1968</infon><infon key="name_0">surname:Mellis;given-names:Alexandra M.</infon><infon key="name_1">surname:Bickel;given-names:Warren K.</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">115</infon><infon key="year">2021</infon><offset>0</offset><text>Mechanical Turk Data Collection in Addiction Research: Utility, Concerns and Best Practices</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>92</offset><text>Aims:</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>98</offset><text>Amazon Mechanical Turk (MTurk) provides a crowdsourcing platform for the engagement of potential research participants with data collection instruments. This review (1) provides an introduction to the mechanics and validity of MTurk research; (2) gives examples of MTurk research; and (3) discusses current limitations and best practices in MTurk research.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>455</offset><text>Methods:</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>464</offset><text>We review four use cases of MTurk for research relevant to addictions: 1) the development of novel measures, 2) testing interventions, 3) the collection of longitudinal use data to determine the feasibility of longer-term studies of substance use, and 4) the completion of large batteries of assessments to characterize the relationships between measured constructs. We review concerns with the platform, ways of mitigating these, and important information to include when presenting findings.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>958</offset><text>Results:</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>967</offset><text>MTurk has proven to be a useful source of data for behavioral science more broadly, with specific applications to addiction science. However, it is still not appropriate for all use cases, such as population-level inference. To live up to the potential of highly transparent, reproducible science from MTurk, researchers should clearly report inclusion/exclusion criteria, data quality checks and reasons for excluding collected data, how and when data was collected, and both targeted and actual participant compensation.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>1490</offset><text>Conclusions:</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>1503</offset><text>Although online survey research is not a substitute for random sampling or clinical recruitment, the MTurk community of both participants and researchers has developed multiple tools to promote data quality, fairness, and rigor. Overall, MTurk has provided a useful source of convenience samples despite its limitations and has demonstrated utility in the engagement of relevant groups for addiction science.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1912</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1925</offset><text>Since its launch in 2005, Amazon Mechanical Turk (MTurk) has provided for a source for both data and debate in the behavioral sciences. Boasting a user base of hundreds of thousands of individuals, MTurk has fueled a spate of survey-based research in the social sciences. Critically, however, concerns with the nature of crowdsourcing websites, the quality of data collection, and the particulars of the MTurk labor market remain. Much ink has been spilled reviewing the use of MTurk in academic research, including in-depth review with specific applications to addiction science. Here, we seek to provide a brief overview of research on MTurk, outline four use cases in which MTurk has usefully addressed research questions, and make best practice recommendations for readers as well as addressing pitfalls in research conducted on Mturk.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>2765</offset><text>The Mechanics of the Mechanical Turk</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2802</offset><text>Amazon Mechanical Turk serves as a clearinghouse for entities who need tasks completed and individual workers offering their labor, in a system known as crowdsourcing. Requesters, such as researchers, can post data collection instruments as Human Intelligence Tasks, or HITs. These HITs typically take the form of a link from the MTurk website to a survey or other data collection service, such as Qualtrics. A labor pool of available Workers, or potential research participants, can then complete these HITs for compensation. These payments are typically delivered as both a base payment and a bonus, starting at $0.01 for task completion. Requesters can select from available workers through both native and Requester-generated restrictions on access to data collection instruments, called qualifications. Requesters may, for example, select a qualification that only Workers with a past approval rating above a certain percent (indicating that over all of the Worker’s previous HITs, that percent were accepted and therefore received base compensation) may complete their HIT.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3884</offset><text>Despite being initially developed to support computing projects (for example, by identifying and removing duplicate product listings on online retail marketplaces), MTurk was quickly identified for its potential contribution to research (see Figure 1). Thousands of manuscripts have been published since the website’s launch. A seminal series of reviews drew attention to MTurk for its ability to provide data of comparable reliability to data collected in-person. Indeed, despite the existence of multiple alternatives to MTurk (including comparable crowdsourcing websites such as CrowdFlower, and research-focused participant pools such as Prolific Academic; for a more complete review of online crowdsourcing alternatives to MTurk, see), MTurk remains the most highly used platform in the behavioral and social sciences. However, given the ease of running behavioral research projects on MTurk and similar platforms, concerns are growing about the possibility of low-quality studies proliferating. These concerns about the validity of data collected from MTurk are typically shared more generally with survey-based research performed in convenience samples and may be mitigated with careful research design. Furthermore, new research implemented on the platform (see “Four Use Cases for MTurk”) have supported the use of MTurk for use in research that would otherwise not be feasible for in-person data collection, demonstrating the rewards of these careful designs.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>5360</offset><text>Comparability between MTurk and Other Convenience Samples</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5418</offset><text>Multiple studies have sought to replicate a battery of psychological assessments in both lab-based and online samples, including samples of unpaid volunteers and in comparisons between computer-based tasks completed on MTurk and purely behavioral tasks. One study systematically compared performance across 10 tasks (including Stroop, flanker, and multiple learning tasks) among MTurk workers to published results from in-person studies. Overall, task performance was comparable in the online sample as in previously published results, especially after the introduction of instruction comprehension checks. Another study compared performance on two decision-making tasks, the Asian disease problem and the physician problem, and found similar biases in decision-making among individuals recruited from MTurk, alternative crowdsourcing platforms (including CrowdFlower and ProlificAcademic), and a midwestern university. Direct comparisons have also been made between data collected on MTurk and data collected via online panels. We highlight here one exemplar study that replicated previously-observed effects, relevant to addiction, in an MTurk sample.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6572</offset><text>Delay discounting, or the phenomenon of devaluing reinforcers as a function of delay to their receipt, has been well documented in both nonhuman and human research. Specific findings related to discounting rates and addiction, including observation of steeper delay discounting among individuals with substance use disorders compared to those without, have also been replicated and demonstrated in meta-analyses. Johnson and colleagues attempted to replicate six phenomena previously observed in delay discounting research. Five of the six phenomena, including observation of hyperbolic discounting rates, negative correlation between discounting rate and age and education, and steeper discounting of consumable reinforcers (cigarettes) than of money. After controlling for education, this study did not observe statistically significant differences in discount rate between substance users (here, smokers) and controls. However, this was attributed to methodological choices in the survey design (included a longest possible delay to reward receipt of 24 hours), rather than differences in the MTurk population.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7686</offset><text>Overall, a review of 35 manuscripts comparing performance between MTurk and other samples identified that responses are comparable across populations. Some additional research has specifically explored differences in survey completion strategy between MTurk and other samples, revealing possibly higher rates of survey satisficing among online, for-pay survey completers, and sensitivity of MTurk participants to slight changes in instructions. However, by and large, a replication-based approach has indicated that results observed on MTurk can generalize to other laboratory populations.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>8276</offset><text>Concerns and Limitations in Mechanical Turk Research</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>8329</offset><text>We note that although MTurk has its place for recruitment of convenience samples, including in addiction research, several cautions must be mentioned. Specifically, recent concerns have been articulated about rates of low-quality data and nonsensical, distracted, or fraudulent responding, which may be increasing since 2018. Similarly, online studies may allow recruitment of individuals who do not meet study eligibility criteria (e.g., participants outside of the US for studies intended to be US-based). Indeed, rates of Virtual Private Server (VPS) use may have recently increased on MTurk These systems allow users to “spoof” IP addresses to, for example, appear to respond as if located in the United States, and can be addressed using standard survey software such as Qualtrics. Another, potentially graver concern is that although the MTurk platform itself describes a potential pool of 500,000 participants, the effective sample may be much smaller. One long-term study of the demographics of the MTurk workforce used capture-recapture methods to monitor changes in MTurk population characteristics and size between 2015 and 2018. Critically, although substantial numbers of workers are observed repeating multiple studies, this analysis estimated that tens of thousands of new workers arrive on the platform each year, and the average worker half-life is around 400 days. However, at any given time the estimated population available is under 2,500 workers. Alternative analyses have placed this number at around 7,300. If the overall population of available workers is small, experimental history must be considered in recruitment and analysis. As MTurk is increasingly used to study the effects of interventions, the possibility of non-naivete must also be considered in the blinding of participants to active and control groups, or must be accounted for analytically (as in, which explicitly interrogated participant’s expectation of being assigned to either an active or a control group). Note, however, that the effective pool of available workers may be increased through multiple methodological choices, such as posting HITs in larger batches (making a larger number of tasks available at once and disallowing repeated submissions), excluding past participants through assigned Qualifications, and allowing Workers who have completed fewer HITs total to participate.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>10720</offset><text>Finally, any researcher must remember that MTurk is fundamentally a source for convenience sampling, and does not offer a representative sample of either whole populations or of particular clinical groups. The MTurk population has been previously shown to be younger and less likely to be fully employed than national averages and to have different financial attitudes than those from other community samples. Within the US, MTurk workers are also more likely to be politically liberal. Due to the nature of the platform, workers are also typically computer-savvy, an effect which is exacerbated among the most prolific Workers by the need for browser extensions and supportive scripts to help workers reduce downtime between HITs and maximize earnings. However, MTurk has potential (as does other online, social-media-based recruitment) to offer a nonprobability-based method for oversampling participants with particular conditions relevant to addiction, such as heavy drinkers or individuals reporting chronic pain--similar to flyer-based community recruitment of individuals with a history of substance use. These sampling methods must be carefully considered to recruit ideal participants (e.g., recruiting participants based on drinking rate, rather than AUDIT score, for an intervention targeting drinking rate itself). Individuals may also be recruited to complete extensive screening batteries to allow for the assignment of researcher-defined Qualifications. Although online recruitment precludes biological verification of responses, these assessments may be appropriate for any inclusion criterion typically assessed using self-report screeners. Critically, no matter how carefully convenience sampling methods are employed, these methods should not be used to make population-level inferences.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>12527</offset><text>Four Use Cases for Mturk</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>12552</offset><text>Validating an Instrument.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>12578</offset><text>Emphasizing the ability of online research to reach large sample sizes at low cost, MTurk has proven valuable in the development of multiple instruments in psychometric research. In one study, 647 participants were screened from MTurk to identify 300 self-identifying chronic pain patients to develop a measure of the likelihood of taking a novel analgesic based on varying levels of pain relief and the probability of addiction. The external validity of this measure was demonstrated, identifying that individuals at the highest risk for opioid misuse using a standard clinical measure were also the most likely to take a novel analgesic with high potential for addiction.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>13252</offset><text>Testing an Intervention.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>13277</offset><text>One additional use for MTurk is in the development and validation of interventions, rather than instruments. Narrative interventions for addiction may be particularly well-suited to development via crowdsourcing. One narrative intervention, episodic future thinking, requires participants to engage in self-relevant, positive prospection to ameliorate steep delay discounting rates. Episodic future thinking has been shown to reduce discounting and valuation of alcohol. Additionally, compared to a control condition, episodic future thinking reduced delay discounting and self-administration of cigarettes; see Figure 2, top panel. In an extension of this work, Stein and colleagues examined the effects of episodic future thinking in an MTurk sample of 117 cigarette smokers, all of whom passed internal consistency measures serving as data quality checks. Participants were randomly assigned to either an episodic future thinking or control condition and completed assessments of delay discounting as well as a hypothetical cigarette purchase task and craving assessment. Participants in the episodic future thinking group demonstrated reduced discounting and greater intensity of demand for cigarettes; see Figure 2, bottom panel. This study demonstrates the use of crowdsourcing particularly to test whether a theoretically-informed intervention alters hypothesized process measures.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>14666</offset><text>Not all studies developing interventions for addiction have found success through MTurk. One study examined the feasibility of using MTurk to recruit for an online intervention on drinking behaviors. In approximately 3 hours, 1,252 participants had screened for the initial HIT. Three months after screening, 423 eligible participants who had consented to additional randomization were prompted to engage with either an online brief intervention or a control condition, and 360 participants completed a follow-up survey. Fewer than 40% of participants in the intervention group engaged with a brief intervention. Critically, engagement with this brief drinking intervention was not compensated, unlike engagement with episodic future thinking above. MTurk workers may be particularly sensitive to time constraints, and unlikely to engage with interventions unless directly compensated for their time engaged in research. Researchers must consider this when developing MTurk studies (see Review of Best Practices).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>15680</offset><text>Collecting Longitudinal Data.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>15710</offset><text>Another study demonstrated the feasibility of MTurk for the collection of longitudinal data concerning alcohol use. A sample of 278 adult drinkers was recruited to participate in 18 weekly assessments of alcohol and soda use. Compensation was offered both as payment for survey completion and as a probabilistic reward through a lottery for additional bonuses. Overall, the average response rate over the 18-week period was 73%, and 43% of participants completed all 18 weekly assessments. Participants reported these weekly assessments as overall enjoyable, convenient, fairly compensated, and easy to complete. The validity of this data was supported both by replication of previously-published relationships with drinking reports and demographic variables observed in conventional lab samples; and in reporting of higher drinking on weekends. Taken together, these results support the use of MTurk to recruit populations for repeated engagement with compensated assessment batteries.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>16697</offset><text>Completing Intensive Batteries.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>16729</offset><text>Finally, a large-scale examination of the reliability of self-control measures has provided a “stress test” for the engagement of participants through MTurk. In an ambitious research project examining underlying features defining the construct of self-control, participants have been recruited from MTurk to engage in lengthy batteries of self-control measures. Participants were given a week to complete a 10-hour battery of 63 assessments, including both task-based and survey-based measures of self-control, in addition to demographic variables assessing health behaviors. In the first presentation of this battery, 84% of participants completed all measures and were compensated $65-$75. Subsequently, 242 participants were invited to re-complete this battery after 2–4 months, and 150 participants completed these assessments. Test-retest reliability of self-control measures in this follow-up study was high, suggesting both stability in the construct of self-control and in the validity of data collected through MTurk.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>17762</offset><text>Summary of Appropriate Use Cases.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>17796</offset><text>developing measures (as in use case 1), testing specific hypotheses of theories (use case 2),</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>17890</offset><text>testing generalizability of effects to online or self-administered platforms (use case 2), recruiting participants for self-report assessments (use case 3),</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>18047</offset><text>and recruiting large samples for whom in-person data collection may not be feasible for all research groups (use case 4).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>18169</offset><text>Overall, MTurk (and other crowdsourcing clearinghouses) provide useful tools for researchers, which must be used thoughtfully. The four use cases described above demonstrate examples when MTurk provided additional insight to the addiction science community, but are not exhaustively representative of the types of research suited to the platform. Nor, however, do they indicate that all similar work would be appropriate. MTurk is especially well-suited to: </text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>18628</offset><text>In general, these are circumstances where in-person data collection in non-clinical samples would be appropriate, but not necessarily feasible. However, MTurk is not well-suited to the generation of population-level estimates (e.g., of the frequency of co-use of particular substances), collection of data where falsified reports may appear incentivized (e.g., recruitment of participants for contingency management interventions, without alternative verification of self-reported use), and paradigms in which the data collection environment may challenge the conclusions that may be drawn from research (e.g., where varying levels of distraction may hamper interpretation).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>19303</offset><text>Review of Best Practices</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>19328</offset><text>A key consideration in best practices for research must be the ethical treatment of research participants. Although MTurk has grown in popularity largely as a source of “inexpensive, high-quality data”, participants are still volunteering for research and sharing information with minimal personal benefit. Participants must be fairly compensated, and recent manuscripts have demonstrated model behaviors in reporting both planned and actual hourly compensation rates. Fair pay is a central ethical concern for this research, as is the ability of participants to withdraw without prejudice. Median pay across MTurk is approximately $2/hr after accounting for the time required for Workers to identify HITs. Compensation should be thoughtfully reviewed during study design and IRB approvals, reported in manuscripts, and is increasingly being made transparent to workers, by workers. Researchers can engage with the MTurk worker community through multiple community websites and tools, including TurkOpticon/Dynamo, TurkerNation, TurkerView, and TurkerHub. Just as researchers may develop qualifying (or disqualifying) criteria for particular workers based on other Requester’s feedback (e.g., “&lt;95% of HITs approved historically”), workers have developed systems to rate requesters. Workers have reported fairness in approval/rejection of work, prompt compensation, minimum payments, and responsiveness of requesters as primary concerns. At times, researcher expectations of experimental control are at odds with worker expectation of compensation (e.g., when the ideal inclusion criteria would best be assessed through a 20-question screener, but participants expect to be compensated for screeners longer than a few questions). Given the overall low burden of collecting data from MTurk, researchers should strive to consider the norms and preferences of the microtask, crowdsourcing economy when designing experimental and compensation schemes. These expectations, and challenges faced especially when working with institutional Requesters, have been articulated by Worker communities themselves (Brian McInnis Cornell University, Ith...)</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21480</offset><text>Additionally, multiple best practices have been developed to promote data quality in MTurk studies from a research perspective. Posting research instruments as single, large batches of HITs may increase the effective population size available, reducing the probability of “repeat participants” in research where naivete is an important consideration. By posting larger batches and disallowing repeated submissions to the same batch, researchers can more easily ensure that each participant may only respond once, leading “deeper” sampling of the Worker population. These include both the use of checks to ensure that participants understand task instructions clearly, and use of an inclusion criterion based on Worker’s “reputation,” or total percentage of approved HITs, in addition to other attention check questions and task-specific data quality assessments (e.g.,). Expecting a clear presentation of inclusion/exclusion criteria, and the number of collected datasets excluded for each reason will increase rigor. Inclusion criteria must also be plainly described to ensure accurate reporting of behavior patterns (e.g., “self-reported heavy drinking in the past week”) compared to diagnoses (e.g., “alcohol use disorder”), which typically cannot be verified in crowdsourced samples. Additionally, manuscripts reporting MTurk studies have begun to present specific dates and times of data collection, to ensure that researchers clearly articulate cases where additional participants were added post hoc (e.g., to increase sample size and observe a smaller-than-expected effect). These expectations may help improve replicability and reduce the risk of false-positive reports.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>23182</offset><text>The potential for highly transparent, highly reproducible science.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>23249</offset><text>As new tools are developed for use within the MTurk environment, additional methods may emerge for researchers to help each other manage the “crowd” component of crowdsourcing research. Previous efforts have combined data collected from MTurk across multiple labs to determine the possible effects of experimental history. Analysis of open-source data has also been critical to identifying common patterns used among participants employing VPSs to circumvent location restrictions, and helped to address scientific questions of both theoretical and methodological import Taken together, the entirely-online MTurk environment means that both individual researchers and broader scientific efforts benefit from steps taken towards transparency both in data and in analyses. The MTurk Application Programming Interface (API) permits scripted experiment presentation, review of responses, and participant contact/compensation. These command-line tools allow for scripting of procedures such as posting of HITs, assessing and granting Qualifications, approving or rejecting responses, and granting bonuses, in multiple languages. This could theoretically allow for fully open source research, in which the complete code for both experimental procedures and analysis are made available for replication (as in). We note, however, that the MTurk landscape is constantly changing--as of this review, the package for MTurk study scripting in the R language has been deprecated and replaced by a new version which relies on Amazon’s Python tools, pyMturkR. As new methods and norms in crowdsourcing platforms emerge (e.g., the rating of requesters based on pay, rejection rates, and responsiveness, as on Turker Nation) and competitors innovate with additional tools to support research (e.g., by screening for naivete to experimental manipulations across tasks, as Prolific Academic proposes to do), scientists will both enjoy additional tools for research and additional responsibilities to use them wisely.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>25253</offset><text>Conclusion</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>25264</offset><text>Crowdsourcing platforms like MTurk provide a useful tool for convenience sampling in behavioral research. The platform permits deployment of both task-based and survey-based data collection instruments and has been shown to successfully engage special subpopulations of participants relevant for addiction research (e.g., regular drinkers and those who self-report chronic pain). The limitations of this platform tend to be shared with other convenience samples--namely, non-random opt-in responding--but special attention must be paid to the limits inherent to online and remote assessment. MTurk is best understood as a system for targeted sampling of these special populations, rather than as a source for clinical populations (requiring verification through personal health information) or representative sources of population estimates.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">footnote</infon><offset>26106</offset><text>Declaration of interests: none</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>26137</offset><text>References</text></passage><passage><infon key="fpage">172</infon><infon key="lpage">9</infon><infon key="name_0">surname:Rand;given-names:DG</infon><infon key="pub-id_pmid">21402081</infon><infon key="section_type">REF</infon><infon key="source">J Theor Biol</infon><infon key="type">ref</infon><infon key="volume">299</infon><infon key="year">2012</infon><offset>26148</offset><text>The promise of Mechanical Turk: how online labor markets can help theorists run behavioral experiments</text></passage><passage><infon key="fpage">3</infon><infon key="issue">1</infon><infon key="lpage">5</infon><infon key="name_0">surname:Buhrmester;given-names:M</infon><infon key="name_1">surname:Kwang;given-names:T</infon><infon key="name_2">surname:Gosling;given-names:SD</infon><infon key="pub-id_pmid">26162106</infon><infon key="section_type">REF</infon><infon key="source">Perspect Psychol Sci</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2011</infon><offset>26251</offset><text>Amazon’s Mechanical Turk: A New Source of Inexpensive, Yet High-Quality, Data?</text></passage><passage><infon key="comment">Available from</infon><infon key="fpage">1</infon><infon key="lpage">23</infon><infon key="name_0">surname:Mason;given-names:W</infon><infon key="name_1">surname:Suri;given-names:S</infon><infon key="pub-id_doi">10.3758/s13428-011-0124-6</infon><infon key="pub-id_pmid">21717266</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>26332</offset><text>Conducting behavioral research on Amazon’s Mechanical Turk [Internet]. Vol. 44</text></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">18</infon><infon key="name_0">surname:Strickland;given-names:JC</infon><infon key="name_1">surname:Stoops;given-names:WW</infon><infon key="pub-id_pmid">30489114</infon><infon key="section_type">REF</infon><infon key="source">Exp Clin Psychopharmacol</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2019</infon><offset>26413</offset><text>The use of crowdsourcing in addiction science research: Amazon Mechanical Turk</text></passage><passage><infon key="fpage">22</infon><infon key="lpage">7</infon><infon key="name_0">surname:Palan;given-names:S</infon><infon key="name_1">surname:Schitter;given-names:C</infon><infon key="section_type">REF</infon><infon key="source">Journal of Behavioral and Experimental Finance</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2018</infon><offset>26492</offset><text>Prolific.ac—A subject pool for online experiments</text></passage><passage><infon key="fpage">153</infon><infon key="lpage">63</infon><infon key="name_0">surname:Peer;given-names:E</infon><infon key="name_1">surname:Brandimarte;given-names:L</infon><infon key="name_2">surname:Samat;given-names:S</infon><infon key="name_3">surname:Acquisti;given-names:A</infon><infon key="section_type">REF</infon><infon key="source">J Exp Soc Psychol</infon><infon key="type">ref</infon><infon key="volume">70</infon><infon key="year">2017</infon><offset>26544</offset><text>Beyond the Turk: Alternative platforms for crowdsourcing behavioral research</text></passage><passage><infon key="fpage">847</infon><infon key="issue">5</infon><infon key="lpage">57</infon><infon key="name_0">surname:Germine;given-names:L</infon><infon key="name_1">surname:Nakayama;given-names:K</infon><infon key="name_2">surname:Duchaine;given-names:BC</infon><infon key="name_3">surname:Chabris;given-names:CF</infon><infon key="name_4">surname:Chatterjee;given-names:G</infon><infon key="name_5">surname:Wilmer;given-names:JB</infon><infon key="pub-id_pmid">22829343</infon><infon key="section_type">REF</infon><infon key="source">Psychon Bull Rev</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2012</infon><offset>26621</offset><text>Is the Web as good as the lab? Comparable performance from Web and lab in cognitive/perceptual experiments</text></passage><passage><infon key="fpage">2156</infon><infon key="issue">6</infon><infon key="lpage">60</infon><infon key="name_0">surname:Casler;given-names:K</infon><infon key="name_1">surname:Bickel;given-names:L</infon><infon key="name_2">surname:Hackett;given-names:E</infon><infon key="section_type">REF</infon><infon key="source">Comput Human Behav</infon><infon key="type">ref</infon><infon key="volume">29</infon><infon key="year">2013</infon><offset>26728</offset><text>Separate but equal? A comparison of participants and data gathered via Amazon’s MTurk, social media, and face-to-face behavioral testing</text></passage><passage><infon key="fpage">e57410</infon><infon key="issue">3</infon><infon key="name_0">surname:Crump;given-names:MJC</infon><infon key="name_1">surname:McDonnell;given-names:JV</infon><infon key="name_2">surname:Gureckis;given-names:TM</infon><infon key="pub-id_pmid">23516406</infon><infon key="section_type">REF</infon><infon key="source">PLoS One</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2013</infon><offset>26867</offset><text>Evaluating Amazon’s Mechanical Turk as a tool for experimental behavioral research</text></passage><passage><infon key="comment">cited https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1626226</infon><infon key="name_0">surname:Paolacci;given-names:G</infon><infon key="name_1">surname:Chandler;given-names:J</infon><infon key="name_2">surname:Ipeirotis;given-names:PG</infon><infon key="section_type">REF</infon><infon key="source">Running Experiments on Amazon Mechanical Turk</infon><infon key="type">ref</infon><infon key="year">2010</infon><offset>26952</offset></passage><passage><infon key="name_0">surname:Chandler;given-names:J</infon><infon key="name_1">surname:Rosenzweig;given-names:C</infon><infon key="name_2">surname:Moss;given-names:AJ</infon><infon key="name_3">surname:Robinson;given-names:J</infon><infon key="name_4">surname:Litman;given-names:L</infon><infon key="pub-id_doi">10.3758/s13428-019-01273-7</infon><infon key="section_type">REF</infon><infon key="source">Behav Res Methods [Internet]</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>26953</offset><text>Online panels in social science research: Expanding sampling methods beyond Mechanical Turk</text></passage><passage><infon key="fpage">305</infon><infon key="issue">3</infon><infon key="lpage">21</infon><infon key="name_0">surname:MacKillop;given-names:J</infon><infon key="name_1">surname:Amlung;given-names:MT</infon><infon key="name_2">surname:Few;given-names:LR</infon><infon key="name_3">surname:Ray;given-names:LA</infon><infon key="name_4">surname:Sweet;given-names:LH</infon><infon key="name_5">surname:Munafò;given-names:MR</infon><infon key="pub-id_pmid">21373791</infon><infon key="section_type">REF</infon><infon key="source">Psychopharmacology </infon><infon key="type">ref</infon><infon key="volume">216</infon><infon key="year">2011</infon><offset>27045</offset><text>Delayed reward discounting and addictive behavior: a meta-analysis</text></passage><passage><infon key="name_0">surname:Amlung;given-names:M</infon><infon key="name_1">surname:Vedelago;given-names:L</infon><infon key="name_2">surname:Acker;given-names:J</infon><infon key="name_3">surname:Balodis;given-names:I</infon><infon key="name_4">surname:MacKillop;given-names:J</infon><infon key="pub-id_doi">10.1111/add.13535</infon><infon key="section_type">REF</infon><infon key="source">Addiction [Internet]</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>27112</offset><text>Steep Delay Discounting and Addictive Behavior: A Meta-Analysis of Continuous Associations</text></passage><passage><infon key="fpage">87</infon><infon key="issue">1</infon><infon key="lpage">107</infon><infon key="name_0">surname:Johnson;given-names:PS</infon><infon key="name_1">surname:Herrmann;given-names:ES</infon><infon key="name_2">surname:Johnson;given-names:MW</infon><infon key="pub-id_pmid">25388973</infon><infon key="section_type">REF</infon><infon key="source">J Exp Anal Behav</infon><infon key="type">ref</infon><infon key="volume">103</infon><infon key="year">2015</infon><offset>27203</offset><text>Opportunity costs of reward delays and the discounting of hypothetical money and cigarettes</text></passage><passage><infon key="fpage">533</infon><infon key="issue">4</infon><infon key="lpage">8</infon><infon key="name_0">surname:Mortensen;given-names:K</infon><infon key="name_1">surname:Hughes;given-names:TL</infon><infon key="pub-id_pmid">29302882</infon><infon key="section_type">REF</infon><infon key="source">J Gen Intern Med</infon><infon key="type">ref</infon><infon key="volume">33</infon><infon key="year">2018</infon><offset>27295</offset><text>Comparing Amazon’s Mechanical Turk Platform to Conventional Data Collection Methods in the Health and Medical Research Literature</text></passage><passage><infon key="fpage">912</infon><infon key="issue">6</infon><infon key="lpage">32</infon><infon key="name_0">surname:Hamby;given-names:T</infon><infon key="name_1">surname:Taylor;given-names:W</infon><infon key="pub-id_pmid">29795893</infon><infon key="section_type">REF</infon><infon key="source">Educ Psychol Meas</infon><infon key="type">ref</infon><infon key="volume">76</infon><infon key="year">2016</infon><offset>27427</offset><text>Survey Satisficing Inflates Reliability and Validity Measures: An Experimental Comparison of College and Amazon Mechanical Turk Samples</text></passage><passage><infon key="fpage">400</infon><infon key="issue">1</infon><infon key="lpage">7</infon><infon key="name_0">surname:Hauser;given-names:DJ</infon><infon key="name_1">surname:Schwarz;given-names:N</infon><infon key="pub-id_pmid">25761395</infon><infon key="section_type">REF</infon><infon key="source">Behav Res Methods</infon><infon key="type">ref</infon><infon key="volume">48</infon><infon key="year">2016</infon><offset>27563</offset><text>Attentive Turkers: MTurk participants perform better on online attention checks than do subject pool participants</text></passage><passage><infon key="comment">2053168018822174.</infon><infon key="issue">1</infon><infon key="name_0">surname:Coppock;given-names:A</infon><infon key="name_1">surname:McClellan;given-names:OA</infon><infon key="section_type">REF</infon><infon key="source">Research &amp; Politics</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2019</infon><offset>27677</offset><text>Validating the demographic, political, psychological, and experimental results obtained from a new source of online survey respondents</text></passage><passage><infon key="comment">1948550619875149.</infon><infon key="name_0">surname:Chmielewski;given-names:M</infon><infon key="name_1">surname:Kucker;given-names:SC</infon><infon key="section_type">REF</infon><infon key="source">Soc Psychol Personal Sci</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>27812</offset><text>An MTurk Crisis? Shifts in Data Quality and the Impact on Study Results</text></passage><passage><infon key="comment">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3272468</infon><infon key="name_0">surname:Kennedy;given-names:R</infon><infon key="name_1">surname:Clifford;given-names:S</infon><infon key="name_2">surname:Burleigh;given-names:T</infon><infon key="name_3">surname:Waggoner;given-names:P</infon><infon key="section_type">REF</infon><infon key="source">Available at [Internet]</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>27884</offset><text>The shape of and solutions to the MTurk quality crisis</text></passage><passage><infon key="comment">cited https://papers.ssrn.com/abstract=3327274</infon><infon key="name_0">surname:Winter;given-names:N</infon><infon key="name_1">surname:Burleigh;given-names:T</infon><infon key="name_2">surname:Kennedy;given-names:R</infon><infon key="name_3">surname:Clifford;given-names:S</infon><infon key="section_type">REF</infon><infon key="source">A Simplified Protocol to Screen Out VPS and International Respondents Using Qualtrics [Internet]</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>27939</offset></passage><passage><infon key="comment">(WSDM ‘18).</infon><infon key="fpage">135</infon><infon key="lpage">43</infon><infon key="name_0">surname:Difallah;given-names:D</infon><infon key="name_1">surname:Filatova;given-names:E</infon><infon key="name_2">surname:Ipeirotis;given-names:P</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>27940</offset></passage><passage><infon key="fpage">479</infon><infon key="issue">5</infon><infon key="lpage">91</infon><infon key="name_0">surname:Stewart;given-names:N</infon><infon key="name_1">surname:Ungemach;given-names:C</infon><infon key="name_2">surname:Harris;given-names:AJL</infon><infon key="name_3">surname:Bartels;given-names:DM</infon><infon key="name_4">surname:Newell;given-names:BR</infon><infon key="name_5">surname:Paolacci;given-names:G</infon><infon key="section_type">REF</infon><infon key="source">Judgm Decis Mak</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2015</infon><offset>27941</offset><text>The average laboratory samples a population of 7,300 Amazon Mechanical Turk workers</text></passage><passage><infon key="name_0">surname:Stein;given-names:JS</infon><infon key="name_1">surname:Tegge;given-names:AN</infon><infon key="name_2">surname:Turner;given-names:JK</infon><infon key="name_3">surname:Bickel;given-names:WK</infon><infon key="pub-id_doi">10.1007/s10865-017-9908-1</infon><infon key="section_type">REF</infon><infon key="source">J Behav Med [Internet]</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>28025</offset><text>Episodic future thinking reduces delay discounting and cigarette demand: an investigation of the good-subject effect</text></passage><passage><infon key="fpage">213</infon><infon key="issue">3</infon><infon key="lpage">24</infon><infon key="name_0">surname:Goodman;given-names:JK</infon><infon key="name_1">surname:Cryder;given-names:CE</infon><infon key="name_2">surname:Cheema;given-names:A</infon><infon key="section_type">REF</infon><infon key="source">J Behav Decis Mak</infon><infon key="type">ref</infon><infon key="volume">26</infon><infon key="year">2013</infon><offset>28142</offset><text>Data Collection in a Flat World: The Strengths and Weaknesses of Mechanical Turk Samples</text></passage><passage><infon key="fpage">2053168015604648</infon><infon key="issue">3</infon><infon key="name_0">surname:Huff;given-names:C</infon><infon key="name_1">surname:Tingley;given-names:D</infon><infon key="section_type">REF</infon><infon key="source">Research &amp; Politics</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2015</infon><offset>28231</offset><text>“Who are these people?” Evaluating the demographic characteristics and political preferences of MTurk survey respondents</text></passage><passage><infon key="fpage">e48</infon><infon key="issue">2</infon><infon key="name_0">surname:Borodovsky;given-names:JT</infon><infon key="name_1">surname:Marsch;given-names:LA</infon><infon key="name_2">surname:Budney;given-names:AJ</infon><infon key="pub-id_pmid">29720366</infon><infon key="section_type">REF</infon><infon key="source">JMIR Public Health Surveill</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2018</infon><offset>28356</offset><text>Studying Cannabis Use Behaviors With Facebook and Web Surveys: Methods and Insights</text></passage><passage><infon key="fpage">12</infon><infon key="lpage">6</infon><infon key="name_0">surname:Cunningham;given-names:JA</infon><infon key="name_1">surname:Godinho;given-names:A</infon><infon key="name_2">surname:Kushnir;given-names:V</infon><infon key="pub-id_pmid">30135748</infon><infon key="section_type">REF</infon><infon key="source">Internet Interv</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2017</infon><offset>28440</offset><text>Can Amazon’s Mechanical Turk be used to recruit participants for internet intervention trials? A pilot study involving a randomized controlled trial of a brief online intervention for hazardous alcohol use</text></passage><passage><infon key="fpage">67</infon><infon key="issue">1</infon><infon key="lpage">79</infon><infon key="name_0">surname:Tompkins;given-names:DA</infon><infon key="name_1">surname:Huhn;given-names:AS</infon><infon key="name_2">surname:Johnson;given-names:PS</infon><infon key="name_3">surname:Smith;given-names:MT</infon><infon key="name_4">surname:Strain;given-names:EC</infon><infon key="name_5">surname:Edwards;given-names:RR</infon><infon key="pub-id_pmid">28645137</infon><infon key="section_type">REF</infon><infon key="source">Addiction</infon><infon key="type">ref</infon><infon key="volume">113</infon><infon key="year">2018</infon><offset>28648</offset><text>To take or not to take: the association between perceived addiction risk, expected analgesic response and likelihood of trying novel pain relievers in self-identified chronic pain patients</text></passage><passage><infon key="comment">Nebraska Symposium on Motivation</infon><infon key="fpage">227</infon><infon key="lpage">67</infon><infon key="name_0">surname:Bickel;given-names:WK</infon><infon key="name_1">surname:Stein;given-names:JS</infon><infon key="name_2">surname:Moody;given-names:LN</infon><infon key="name_3">surname:Snider;given-names:SE</infon><infon key="name_4">surname:Mellis;given-names:AM</infon><infon key="name_5">surname:Quisenberry;given-names:AJ</infon><infon key="name_6">surname:Stevens;given-names:JR</infon><infon key="section_type">REF</infon><infon key="source">Impulsivity</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>28837</offset></passage><passage><infon key="fpage">1558</infon><infon key="issue">7</infon><infon key="lpage">66</infon><infon key="name_0">surname:Snider;given-names:SE</infon><infon key="name_1">surname:LaConte;given-names:SM</infon><infon key="name_2">surname:Bickel;given-names:WK</infon><infon key="pub-id_pmid">27246691</infon><infon key="section_type">REF</infon><infon key="source">Alcohol Clin Exp Res</infon><infon key="type">ref</infon><infon key="volume">40</infon><infon key="year">2016</infon><offset>28838</offset><text>Episodic Future Thinking: Expansion of the Temporal Window in Individuals with Alcohol Dependence</text></passage><passage><infon key="fpage">3771</infon><infon key="issue">21–22</infon><infon key="lpage">8</infon><infon key="name_0">surname:Stein;given-names:JS</infon><infon key="name_1">surname:Wilson;given-names:AG</infon><infon key="name_2">surname:Koffarnus;given-names:MN</infon><infon key="name_3">surname:Daniel;given-names:TO</infon><infon key="name_4">surname:Epstein;given-names:LH</infon><infon key="name_5">surname:Bickel;given-names:WK</infon><infon key="pub-id_pmid">27553824</infon><infon key="section_type">REF</infon><infon key="source">Psychopharmacology </infon><infon key="type">ref</infon><infon key="volume">233</infon><infon key="year">2016</infon><offset>28936</offset><text>Unstuck in time: episodic future thinking reduces delay discounting and cigarette smoking</text></passage><passage><infon key="fpage">136</infon><infon key="issue">1</infon><infon key="lpage">53</infon><infon key="name_0">surname:Strickland;given-names:JC</infon><infon key="name_1">surname:Stoops;given-names:WW</infon><infon key="pub-id_pmid">29873806</infon><infon key="section_type">REF</infon><infon key="source">J Exp Anal Behav</infon><infon key="type">ref</infon><infon key="volume">110</infon><infon key="year">2018</infon><offset>29026</offset><text>Feasibility, acceptability, and validity of crowdsourcing for collecting longitudinal alcohol use data</text></passage><passage><infon key="fpage">46</infon><infon key="lpage">57</infon><infon key="name_0">surname:Eisenberg;given-names:IW</infon><infon key="name_1">surname:Bissett;given-names:PG</infon><infon key="name_2">surname:Canning;given-names:JR</infon><infon key="name_3">surname:Dallery;given-names:J</infon><infon key="name_4">surname:Enkavi;given-names:AZ</infon><infon key="name_5">surname:Whitfield-Gabrieli;given-names:S</infon><infon key="pub-id_pmid">29066077</infon><infon key="section_type">REF</infon><infon key="source">Behav Res Ther</infon><infon key="type">ref</infon><infon key="volume">101</infon><infon key="year">2018</infon><offset>29129</offset><text>Applying novel technologies and methods to inform the ontology of self-regulation</text></passage><passage><infon key="fpage">5472</infon><infon key="issue">12</infon><infon key="lpage">7</infon><infon key="name_0">surname:Enkavi;given-names:AZ</infon><infon key="name_1">surname:Eisenberg;given-names:IW</infon><infon key="name_2">surname:Bissett;given-names:PG</infon><infon key="name_3">surname:Mazza;given-names:GL</infon><infon key="name_4">surname:MacKinnon;given-names:DP</infon><infon key="name_5">surname:Marsch;given-names:LA</infon><infon key="pub-id_pmid">30842284</infon><infon key="section_type">REF</infon><infon key="source">Proc Natl Acad Sci U S A</infon><infon key="type">ref</infon><infon key="volume">116</infon><infon key="year">2019</infon><offset>29211</offset><text>Large-scale analysis of test-retest reliabilities of self-regulation measures</text></passage><passage><infon key="fpage">1333</infon><infon key="issue">4</infon><infon key="lpage">42</infon><infon key="name_0">surname:Gleibs;given-names:IH</infon><infon key="pub-id_pmid">27515317</infon><infon key="section_type">REF</infon><infon key="source">Behav Res Methods</infon><infon key="type">ref</infon><infon key="volume">49</infon><infon key="year">2017</infon><offset>29289</offset><text>Are all “research fields” equal? Rethinking practice for the use of data from crowdsourcing market places</text></passage><passage><infon key="comment">1–449:14. (CHI ‘18).</infon><infon key="fpage">449</infon><infon key="name_0">surname:Hara;given-names:K</infon><infon key="name_1">surname:Adams;given-names:A</infon><infon key="name_2">surname:Milland;given-names:K</infon><infon key="name_3">surname:Savage;given-names:S</infon><infon key="name_4">surname:Callison-Burch;given-names:C</infon><infon key="name_5">surname:Bigham;given-names:JP</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>29399</offset></passage><passage><infon key="comment">(CHI ‘13).</infon><infon key="fpage">611</infon><infon key="lpage">20</infon><infon key="name_0">surname:Irani;given-names:LC</infon><infon key="name_1">surname:Silberman;given-names:MS</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>29400</offset></passage><passage><infon key="fpage">1023</infon><infon key="issue">4</infon><infon key="lpage">31</infon><infon key="name_0">surname:Peer;given-names:E</infon><infon key="name_1">surname:Vosgerau;given-names:J</infon><infon key="name_2">surname:Acquisti;given-names:A</infon><infon key="pub-id_pmid">24356996</infon><infon key="section_type">REF</infon><infon key="source">Behav Res Methods</infon><infon key="type">ref</infon><infon key="volume">46</infon><infon key="year">2014</infon><offset>29401</offset><text>Reputation as a sufficient condition for data quality on Amazon Mechanical Turk</text></passage><passage><infon key="fpage">739</infon><infon key="issue">3</infon><infon key="lpage">53</infon><infon key="name_0">surname:Berinsky;given-names:AJ</infon><infon key="name_1">surname:Margolis;given-names:MF</infon><infon key="name_2">surname:Sances;given-names:MW</infon><infon key="section_type">REF</infon><infon key="source">Am J Pol Sci</infon><infon key="type">ref</infon><infon key="volume">58</infon><infon key="year">2014</infon><offset>29481</offset><text>Separating the Shirkers from the Workers? Making Sure Respondents Pay Attention on Self-Administered Surveys</text></passage><passage><infon key="fpage">264</infon><infon key="issue">3</infon><infon key="lpage">74</infon><infon key="name_0">surname:Johnson;given-names:MW</infon><infon key="name_1">surname:Bickel;given-names:WK</infon><infon key="pub-id_pmid">18540786</infon><infon key="section_type">REF</infon><infon key="source">Exp Clin Psychopharmacol</infon><infon key="type">ref</infon><infon key="volume">16</infon><infon key="year">2008</infon><offset>29590</offset><text>An algorithm for identifying nonsystematic delay-discounting data</text></passage><passage><infon key="fpage">377</infon><infon key="issue">5</infon><infon key="lpage">86</infon><infon key="name_0">surname:Stein;given-names:JS</infon><infon key="name_1">surname:Koffarnus;given-names:MN</infon><infon key="name_2">surname:Snider;given-names:SE</infon><infon key="name_3">surname:Quisenberry;given-names:AJ</infon><infon key="name_4">surname:Bickel;given-names:WK</infon><infon key="pub-id_pmid">26147181</infon><infon key="section_type">REF</infon><infon key="source">Exp Clin Psychopharmacol</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2015</infon><offset>29656</offset><text>Identification and management of nonsystematic purchase task data: Toward best practice</text></passage><passage><infon key="fpage">112</infon><infon key="issue">1</infon><infon key="lpage">30</infon><infon key="name_0">surname:Chandler;given-names:J</infon><infon key="name_1">surname:Mueller;given-names:P</infon><infon key="name_2">surname:Paolacci;given-names:G</infon><infon key="pub-id_pmid">23835650</infon><infon key="section_type">REF</infon><infon key="source">Behav Res Methods</infon><infon key="type">ref</infon><infon key="volume">46</infon><infon key="year">2014</infon><offset>29744</offset><text>Nonnaïveté among Amazon Mechanical Turk workers: consequences and solutions for behavioral researchers</text></passage><passage><infon key="name_0">surname:Robinson;given-names:J</infon><infon key="name_1">surname:Rosenzweig;given-names:C</infon><infon key="name_2">surname:Moss;given-names:AJ</infon><infon key="name_3">surname:Litman;given-names:L</infon><infon key="section_type">REF</infon><infon key="source">Tapped Out or Barely Tapped? Recommendations for How to Harness the Vast and Largely Unused Potential of the Mechanical Turk Participant Pool [Internet]</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>29849</offset></passage><passage><infon key="fpage">2228</infon><infon key="issue">5</infon><infon key="lpage">37</infon><infon key="name_0">surname:Dupuis;given-names:M</infon><infon key="name_1">surname:Meier;given-names:E</infon><infon key="name_2">surname:Cuneo;given-names:F</infon><infon key="pub-id_pmid">30091086</infon><infon key="section_type">REF</infon><infon key="source">Behav Res Methods</infon><infon key="type">ref</infon><infon key="volume">51</infon><infon key="year">2019</infon><offset>29850</offset><text>Detecting computer-generated random responding in questionnaire-based data: A comparison of seven indices</text></passage><passage><infon key="fpage">1285</infon><infon key="issue">37</infon><infon key="name_0">surname:Waggoner;given-names:P</infon><infon key="name_1">surname:Kennedy;given-names:R</infon><infon key="name_2">surname:Clifford;given-names:S</infon><infon key="section_type">REF</infon><infon key="source">JOSS</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2019</infon><offset>29956</offset><text>Detecting Fraud in Online Surveys by Tracing, Scoring, and Visualizing IP Addresses</text></passage><passage><infon key="issue">5.1</infon><infon key="name_0">surname:Leeper;given-names:TJ</infon><infon key="section_type">REF</infon><infon key="source">R package version 0</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2015</infon><offset>30040</offset><text>MTurkR: Access to Amazon Mechanical Turk Requester API via R</text></passage><passage><infon key="comment">https://cran.r-project.org/web/packages/pyMTurkR/pyMTurkR.pdf</infon><infon key="name_0">surname:Burleigh;given-names:T</infon><infon key="section_type">REF</infon><infon key="source">pyMTurkR [Internet]</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>30101</offset></passage><passage><infon key="comment">https://dl.acm.org/doi/10.1145/2858036.2858539</infon><infon key="name_0">surname:McInnis;given-names:B</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>30102</offset><text>Taking a HIT: Designing around Rejection, Mistrust, Risk, and Workers’ Experiences in Amazon Mechanical Turk</text></passage><passage><infon key="file">nihms-1576078-f0001.jpg</infon><infon key="id">F1</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>30213</offset><text>The Growing MTurk Literature.</text></passage><passage><infon key="file">nihms-1576078-f0001.jpg</infon><infon key="id">F1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>30243</offset><text>Figure 1 depicts the number of Google Scholar hits (y) over time (x) for the term “Amazon Mechanical Turk”, as of December 31, 2019.</text></passage><passage><infon key="file">nihms-1576078-f0002.jpg</infon><infon key="id">F2</infon><infon key="section_type">FIG</infon><infon key="type">fig_title_caption</infon><offset>30380</offset><text>Intervention validation through MTurk.</text></passage><passage><infon key="file">nihms-1576078-f0002.jpg</infon><infon key="id">F2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>30419</offset><text>The top panel depicts delay discounting rates (A) and the number of cigarette puffs consumed (B) after engagement with either episodic future thinking (EFT) or a control condition (ERT), collected from an in-person study. The bottom panel depicts a summary measure of delay discounting rates (A) and cigarette purchase task data (B) after engagement with either episodic future thinking (EFT) or a control condition (ERT), collected via MTurk. Reprinted with permission.</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>30890</offset><text>Approaches to mitigate common concerns with Mturk</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;box&quot; rules=&quot;all&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Concern&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Approach&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Non-naivete&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; • Post HITs in large batches, to increase the effective worker pool available.&lt;break/&gt; • Assign qualifications to Workers who have completed previous, similar HITs. Share these Worker IDs among collaborating research groups&lt;xref rid=&quot;R43&quot; ref-type=&quot;bibr&quot;&gt;43&lt;/xref&gt;, with participant consent.&lt;break/&gt; • Allow Workers with a lower number of completed HITs to complete assessments&lt;xref rid=&quot;R44&quot; ref-type=&quot;bibr&quot;&gt;44&lt;/xref&gt;. Note, however, that “reputations” are not granted until a Worker has completed &amp;gt;100 HITs.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Worker inattention&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; • Include attention check questions or “catch” trials. These can include instruction comprehension checks in addition to more traditional attention checks.&lt;break/&gt; • Full-screen tasks to minimize multi-tab browsing, as through commercial services (e.g., Inquisit Web) or custom-built web stimulus presentation tools.&lt;break/&gt; • Validated criteria for excluding responses or flagging data for inattention/inability to understand tasks (e.g., Johnson &amp;amp; Bickel criteria for excluding delay discounting task data). Ideally, these should be pre-registered, even informally, to reduce researcher degrees of freedom. Report full sample collected and reasons for data exclusion.&lt;break/&gt; • Screen based on Worker “reputation”&lt;xref rid=&quot;R39&quot; ref-type=&quot;bibr&quot;&gt;39&lt;/xref&gt;. Note, however, that this common practice may reduce worker naivete&lt;xref rid=&quot;R44&quot; ref-type=&quot;bibr&quot;&gt;44&lt;/xref&gt;.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Fraudulent responses&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; • Check for common VPS (virtual private server) signatures, such as the use of commonly “spoofed” IP addresses, post-hoc in collected data.&lt;break/&gt; • Check for response consistency and random responding&lt;xref rid=&quot;R45&quot; ref-type=&quot;bibr&quot;&gt;45&lt;/xref&gt; &lt;break/&gt; • Prevent multiple responses from matching IP addresses, or any responses from commonly fraudulent addresses &lt;xref rid=&quot;R46&quot; ref-type=&quot;bibr&quot;&gt;46&lt;/xref&gt;&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Worker treatment&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt; • Compensate appropriately for the actual duration of tasks. Report both planned and actual hourly compensation.&lt;break/&gt; • Compensate for lengthy screenings, considering that Workers estimate payment by the minute.&lt;break/&gt; • Exclude past participants through custom Qualifications, not by Blocking workers.&lt;break/&gt; • Provide an option for participants to withdraw consent while still being compensated, e.g. through custom survey codes.&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>30940</offset><text>Concern	Approach	 	Non-naivete	 • Post HITs in large batches, to increase the effective worker pool available. • Assign qualifications to Workers who have completed previous, similar HITs. Share these Worker IDs among collaborating research groups, with participant consent. • Allow Workers with a lower number of completed HITs to complete assessments. Note, however, that “reputations” are not granted until a Worker has completed &gt;100 HITs.	 	Worker inattention	 • Include attention check questions or “catch” trials. These can include instruction comprehension checks in addition to more traditional attention checks. • Full-screen tasks to minimize multi-tab browsing, as through commercial services (e.g., Inquisit Web) or custom-built web stimulus presentation tools. • Validated criteria for excluding responses or flagging data for inattention/inability to understand tasks (e.g., Johnson &amp; Bickel criteria for excluding delay discounting task data). Ideally, these should be pre-registered, even informally, to reduce researcher degrees of freedom. Report full sample collected and reasons for data exclusion. • Screen based on Worker “reputation”. Note, however, that this common practice may reduce worker naivete.	 	Fraudulent responses	 • Check for common VPS (virtual private server) signatures, such as the use of commonly “spoofed” IP addresses, post-hoc in collected data. • Check for response consistency and random responding • Prevent multiple responses from matching IP addresses, or any responses from commonly fraudulent addresses 	 	Worker treatment	 • Compensate appropriately for the actual duration of tasks. Report both planned and actual hourly compensation. • Compensate for lengthy screenings, considering that Workers estimate payment by the minute. • Exclude past participants through custom Qualifications, not by Blocking workers. • Provide an option for participants to withdraw consent while still being compensated, e.g. through custom survey codes.	 	</text></passage></document></collection>
