<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20201215</date><key>pmc.key</key><document><id>7564950</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.3390/jpm10030086</infon><infon key="article-id_pmc">7564950</infon><infon key="article-id_pmid">32823538</infon><infon key="article-id_publisher-id">jpm-10-00086</infon><infon key="elocation-id">86</infon><infon key="issue">3</infon><infon key="kwd">crowdsourcing machine learning diagnostics telemedicine autism pediatrics</infon><infon key="license">Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).</infon><infon key="name_0">surname:Washington;given-names:Peter</infon><infon key="name_1">surname:Leblanc;given-names:Emilie</infon><infon key="name_10">surname:Voss;given-names:Catalin</infon><infon key="name_11">surname:Haber;given-names:Nick</infon><infon key="name_12">surname:Wall;given-names:Dennis P.</infon><infon key="name_2">surname:Dunlap;given-names:Kaitlyn</infon><infon key="name_3">surname:Penev;given-names:Yordan</infon><infon key="name_4">surname:Kline;given-names:Aaron</infon><infon key="name_5">surname:Paskov;given-names:Kelley</infon><infon key="name_6">surname:Sun;given-names:Min Woo</infon><infon key="name_7">surname:Chrisman;given-names:Brianna</infon><infon key="name_8">surname:Stockham;given-names:Nathaniel</infon><infon key="name_9">surname:Varma;given-names:Maya</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">10</infon><infon key="year">2020</infon><offset>0</offset><text>Precision Telemedicine through Crowdsourced Machine Learning: Testing Variability of Crowd Workers for Video-Based Autism Feature Recognition</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>142</offset><text>Mobilized telemedicine is becoming a key, and even necessary, facet of both precision health and precision medicine. In this study, we evaluate the capability and potential of a crowd of virtual workers—defined as vetted members of popular crowdsourcing platforms—to aid in the task of diagnosing autism. We evaluate workers when crowdsourcing the task of providing categorical ordinal behavioral ratings to unstructured public YouTube videos of children with autism and neurotypical controls. To evaluate emerging patterns that are consistent across independent crowds, we target workers from distinct geographic loci on two crowdsourcing platforms: an international group of workers on Amazon Mechanical Turk (MTurk) (N = 15) and Microworkers from Bangladesh (N = 56), Kenya (N = 23), and the Philippines (N = 25). We feed worker responses as input to a validated diagnostic machine learning classifier trained on clinician-filled electronic health records. We find that regardless of crowd platform or targeted country, workers vary in the average confidence of the correct diagnosis predicted by the classifier. The best worker responses produce a mean probability of the correct class above 80% and over one standard deviation above 50%, accuracy and variability on par with experts according to prior studies. There is a weak correlation between mean time spent on task and mean performance (r = 0.358, p = 0.005). These results demonstrate that while the crowd can produce accurate diagnoses, there are intrinsic differences in crowdworker ability to rate behavioral features. We propose a novel strategy for recruitment of crowdsourced workers to ensure high quality diagnostic evaluations of autism, and potentially many other pediatric behavioral health conditions. Our approach represents a viable step in the direction of crowd-based approaches for more scalable and affordable precision medicine.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>2056</offset><text>1. Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2072</offset><text>Autism spectrum disorder (ASD or autism) is a developmental delay with a continuously rising prevalence in the United States. Access to care can be limited, particularly in rural and in lower socioeconomic areas, as families must wait for over a year to receive a formal diagnosis and therefore treatment. Epidemiological estimates indicate that over 80% of U.S. counties do not have autism diagnostic resources. Scalable and accessible tools would begin to address these inefficiencies in the healthcare system. Since autism consists of a largely behavioral phenotype, video data are a particularly powerful and rich means of capturing the range of social symptoms a child may exhibit in a fast and virtually cost-free manner. Accurate diagnoses and behavioral classifications have been inferred from categorical ordinal labels extracted by untrained humans from the short video clips, which are recorded by digital mobile and wearable interventions during use by the child or administering parent. Such a process can be scaled through crowdsourcing platforms, which allow distributed workers from around the globe to perform short on-demand tasks.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3222</offset><text>Crowdsourcing offers a powerful mobilized telemedicine solution to providing a rapid and personalized diagnosis for and behavioral characterization of children at risk for developmental delays. Crowdsourcing is increasingly being used for sensitive work such as mental health tracking, body weight inference, prescription drug use and reactions, and investigating crime. While at least partially automated diagnostics is an important goal for precision healthcare, the quantification and categorization of several social activities are beyond the scope of current machine learning methods, resulting in a major barrier in the field of precision medicine for behavioral conditions. While answers from a crowd worker on a variety of behavioral dimensions can provide a precision diagnosis for one individual, each label can be used as training data for a general-purpose machine learning model that can make precision medicine more automated and scalable. Achieving this goal, however, relies on high quality data from the crowd, necessitating careful characterization of worker performance and subsequent filtering of crowd workers.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4354</offset><text>Here, we evaluate the performance of individual workers within four independent pools of crowdsourced workers from Amazon Mechanical Turk (MTurk), a popular paid crowdsourcing platform, and Microworkers, another paid crowdsourcing platform with a significantly larger international pool of workers compared to MTurk. The workers watch unstructured videos of children with autism and neurotypical controls and fill out a series of multiple-choice questions about the child’s behavior. The series of multiple-choice answers serve as a vector of categorical ordinal features used as input to a previously validated logistic regression classifier distinguishing neurotypical children from autistic children. We assess the differences in classifier probabilities and final predictions across workers, finding that there are significant differences in worker performance despite identical video difficulty levels. These results suggest that crowd workers must be filtered before incorporation into clinical diagnostic practices. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>5380</offset><text>2. Materials and Methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>5405</offset><text>Our methods consist of (1) first identifying a clinically representative video set, (2) choosing an appropriate classifier for evaluating worker responses, and (3) crowdsourcing a video rating task to a wide pool of global workers.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>5637</offset><text>2.1. Clinically Representative Video Set</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>5678</offset><text>Clinically representative videos were downloaded from YouTube. We selected publicly available videos of both children with and without autism. Diagnosis was based on video title and description reported by the uploader. We only selected videos that matched all of the following criteria: (1) the child’s hands and face are clearly visible, (2) there are opportunities for social engagement, and (3) there is at least one opportunity for using an object such as a toy or utensil. No further selection criteria were used.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>6200</offset><text>All three rating groups on Microworkers received the same set of 24 videos with a mean duration of 47.75 s (SD = 30.71 s). Six videos contain a female child with autism, six videos contain a neurotypical female child, six videos contain a male child with autism, and six videos contain a neurotypical male child. The mean age of children in the video was 3.65 years (SD = 1.82 years). </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>6586</offset><text>We asked 4 licensed clinical experts (2 Child and Adolescent Psychiatrists, 1 Clinical Psychologist, and 1 Speech Language Pathologist) to watch each video of the 12 children with an autism diagnosis and to rate the severity of the child’s autism symptoms according to the first question of the Clinical Global Impression (CGI) scale measuring the “severity of illness” between 1 (“normal, not at all ill”) to 7 (“among the most extremely ill patients”). We then recorded the mean rating rounded to the nearest whole number. There was one video with a mean rating of 2 (“borderline mentally ill”), four with a mean of 4 (“moderately ill”), five with a mean of 5 (“markedly ill”), and two with a mean of 6 (“severely ill”), validating that we posted a clinically representative set of videos on Microworkers.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>7424</offset><text>We additionally conducted a post-hoc analysis of previously crowdsourced yet unpublished pilot test results from MTurk with the exact same rating tasks except using a separate set of 43 videos to rate with a mean duration of 43.85 s (SD = 26.06 s). Ten videos from this set contain a female child with autism, eleven videos contain a neurotypical female child, twelve videos contain a male child with autism, and ten videos contain a neurotypical male child. The mean age of children in the video set was 3.61 years (SD = 1.61 years). The 4 clinical experts rated the 22 children with autism in this set using the CGI. There were three videos with a mean rating of 2 (“borderline mentally ill”), five with a mean of 3 (“mildly ill”), three with a mean of 4 (“moderately ill”), six with a mean of 5 (“markedly ill”), and five with a mean of 6 (“severely ill”), validating that we posted a clinically representative set of videos on MTurk.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>8382</offset><text>2.2. Video Observation Classifier</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8416</offset><text>To evaluate the performance of crowd workers against a clinician gold standard, a previously validated binary logistic regression classifier was trained on electronic health record data consisting of clinician filled Autism Diagnostic Observation Schedule (ADOS) scoresheets for 1319 children with autism and 70 non-autism controls. We chose logistic regression over alternative classical machine learning techniques like support vector machines and alternating decision trees because of the previously published head-to-head comparison of these techniques by Tariq et al., which found that logistic regression resulted in both the highest accuracy and highest unweighted average recall. We used the default scikit-learn parameters for logistic regression, except we evaluated both L1 and L2 regularization with an inverse regularization strength of 0.05, forcing strong regularization. We reported the metrics with the greatest accuracy of L1 or L2 regularization. Because our goal was to evaluate worker performance and not to maximize the performance of a classifier, we did not perform any further hyperparameter tuning.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9541</offset><text>Because logistic regression classifiers emit a probability for a binary outcome, we treat the probability as a confidence score of the crowdsourced workers’ responses. Here, we exclusively analyze the probability of the correct class (referred to as PCC from here on out), which is p when the true class is autism and 1-p when the true class is neurotypical. When assessing classifier predictions, we use a threshold of 0.5. Throughout this paper, we refer to a worker’s average PCC for videos the worker rated as a measure of the worker’s video tagging capability. Similarly, we refer to a video’s PCC as the difficulty level of the video.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>10190</offset><text>2.3. Video Rating Tasks</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10214</offset><text>We aimed to crowdsource workers from three culturally distinct countries where autism is prevalent yet access to resources is lacking. These are samples of areas where accessible, affordable, and scalable precision medicine solutions, such as instantiations of the technique described here, can enable access to care to underserved populations globally. In particular, we selected Bangladesh, Kenya, and the Philippines, countries that collectively represent diverse areas containing problematic issues with autism prevalence and limited access to services. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10773</offset><text>In order to generalize our findings across these distinct groups of workers, we posted four sets of video rating tasks under the following hypotheses:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10924</offset><text> There are workers on MTurk whose mean classifier PCC will exceed 75%. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10996</offset><text> There are “super recognizer” workers on MTurk whose mean classifier PCC will exceed 75% and whose mean will be over one standard deviation above 50%. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11152</offset><text> There are workers from Bangladesh on Microworkers whose mean classifier PCC will exceed 75%. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11247</offset><text> There are “super recognizer” workers from Bangladesh on Microworkers whose mean classifier PCC will exceed 75% and whose mean will be over one standard deviation above 50%. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11426</offset><text> There are workers from Kenya on Microworkers whose mean classifier PCC will exceed 75%. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11516</offset><text> There are “super recognizer” workers from Kenya on Microworkers whose mean classifier PCC will exceed 75% and whose mean will be over one standard deviation above 50%. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11690</offset><text> There are workers from the Philippines on Microworkers whose mean classifier PCC will exceed 75%. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11790</offset><text> There are “super recognizer” workers from the Philippines on Microworkers whose mean classifier PCC will exceed 75% and whose mean will be over one standard deviation above 50%. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11974</offset><text>We evaluate the above hypotheses only for workers who rated at least ten videos and for videos that received at least ten sets of ratings from workers. Hypotheses H1a, H2a, H3a, and H4a verify that there exist workers whose mean classifier PCC is consistently higher than the classification decision boundary by a sizable margin (25%) that is consistent with the documented 75% agreement rate between qualified multidisciplinary team diagnosis using the Autism Diagnostic Observation Schedule (ADOS) and Gilliam Autism Rating Scale (GARS) scales. Hypotheses H1b, H2b, H3b, and H4b are more stringent, requiring the worker to exhibit low enough variance in their answers such that one standard deviation below their mean PCC is still above the classifier decision boundary and therefore still yields the correct diagnostic prediction. This level of robustness to variability is reasonable given the measures of inter-rater reliability of ADOS scoresheets, with Cohen’s kappa coefficients for individual ADOS items ranging between 0.24 and 0.94.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13020</offset><text>The first set of tasks was posted on MTurk. The second, third, and fourth sets were posted to distinct groups of workers on Microworkers. The Microworkers crowdsourcing tasks were targeted to workers in Bangladesh, Kenya, and the Philippines in order to sample a sufficiently diverse global population of crowdworkers while comparing independent subsets of the crowd. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13389</offset><text>All four independent studies consisted of a series of 13 multiple choice questions which were fed as inputs into the video observation classifier (Figure 1). Although the videos did not necessarily contain evidence of all 13 behavioral features used as inputs, workers were asked to infer how the child would behave if placed in the situation in question. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13746</offset><text>On MTurk, workers were only allowed to proceed with rating further videos if they passed a series of quality control metrics recording performance against the ADOS gold standard classifier (see section Materials and Methods: Video Observation Classifier) and the time spent working on the task. On Microworkers, worker filtering did not occur besides requiring a bare minimum of time rating each video (a minimum of 2 min per video was required to accept a worker’s response). </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>14226</offset><text>3. Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>14237</offset><text>We analyze (1) the distribution of worker performance in different countries and crowd platforms, (2) the number of higher performing workers and “super recognizers” in each study group, and (3) the correlation between mean time spent on the task and mean worker performance for each study group.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>14538</offset><text>3.1. Distribution of Worker Performance</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>14578</offset><text>For all four worker groups, there was major variation in the average probability score of the classifier per video (Figure 2) and per worker (Figure 3). The mean probability of the true class for the 43 videos with at least ten worker ratings on MTurk was 63.80% (SD = 13.78%), with a minimum of 16.90% and a maximum of 84.05%. On Microworkers, the mean PCC for videos with at least ten ratings were 63.15% (N = 24; SD = 10.42%; range = 33.73–79.03%) for Bangladesh, 67.75% (N = 24; SD = 14.68%; range = 32.71–88.91%) for Kenya, and 72.05% (N =2 4; SD = 13.05%; range = 47.84–90.80%) for the Philippines. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>15190</offset><text>The mean classifier PCC for the 15 workers with 10 or more videos rated on MTurk was 66.67% (SD = 5.98%), with a minimum of 48.16% and a maximum of 70.82%. On Microworkers, the mean worker classifier PCC for those who provided ten or more ratings were 62.53% (N = 56; SD = 10.43%; range = 42.21–79.53%) for Bangladesh, 66.67% (N = 23; SD = 9.75%; range = 46.62–81.03%) for Kenya, and 72.71% (N = 25; SD = 10.25%; range = 51.38–89.08%) for the Philippines. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>15653</offset><text>Crucially, while there were individual differences in the subset of videos rated across workers, there was no significant difference in the difficulties of these videos across workers (Figure 4) for workers who rated at least ten videos and videos with at least ten ratings from workers. This confirms that the variability in worker performance in not attributable to the video difficulties. In all four groups, a Pearson correlation test between the mean video PCC and mean worker PCC yielded insignificant results (r = 0.088, p = 0.07 for MTurk; r = 0.017, p = 0.62 for Bangladesh Microworkers; r = −0.018, p = 0.70 for Kenya Microworkers; and r = −0.030, p = 0.52 for Philippines Microworkers).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>16355</offset><text>3.2. Super Recognizers</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>16378</offset><text>Figure 3 and Figure 4 reveal that hypotheses H1a, H2a, H3a, and H4a are confirmed: there were workers in all four study groups whose mean classifier PCC exceeded 75%. On MTurk, there was one worker whose mean was greater than one standard deviation above 50%, confirming hypothesis H1b. There were three Microworkers in the Bangladesh cohort, two Microworkers in the Kenya cohort and ten Microworkers in the Philippines cohort whose mean was greater than one standard deviation above 50%, confirming hypotheses H2b, H3b and H4b.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>16907</offset><text>3.3. Effect of Time Spent Rating</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>16940</offset><text>Because of pervasive practices among MTurk workers of artificially inflating the time spent on the task out of fear of spending insufficient time on the task, we only analyzed timing information of Microworkers data. Several recorded times for MTurk tasks exceeded several hours, suggesting MTurk worker behavior of bloating task times.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>17277</offset><text>There was no statistically significant Pearson correlation between mean time spent on the task and mean worker performance for the Kenya and Philippines Microworkers groups individually (r = 0.191, p = 0.38 for Kenya Microworkers; and r = 0.193, p = 0.35 for Philippines Microworkers). For Bangladesh Microworkers, there was a statistically significant correlation (r = 0.326, p = 0.01). When aggregating all Microworkers results, the correlation is slightly strengthened (r = 0.358, p = 0.005).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>17773</offset><text>4. Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>17787</offset><text>We discuss (1) the overall implications of the worker variability in all study groups and the presence of “super recognizers,” (2) the formalization of a crowd filtration process which can be leveraged for the identification of high performing crowd workers for a variety of precision medicine tasks, and (3) limitations of the present study and areas of potential future work.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>18169</offset><text>4.1. General Implications</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>18195</offset><text>All four independent worker groups produced at least one worker who rated at least ten videos and whose mean classifier PCC exceeded 75%. There was one MTurk worker, three Microworkers in Bangladesh, two Microworkers in the Kenya cohort, and ten Microworkers in the Philippines cohort whose mean was greater than one standard deviation above 50%. It is unclear whether language barriers, differences in Microworker demographics across countries, or other factors are responsible for this inconsistency across countries.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>18715</offset><text>We observe a high variation in worker performance in all four study groups. This variation in performance is distinct from other common crowdsourcing tasks such as image labeling, where worker responses are generally accepted to be high quality and therefore only simple quality control metrics (rather than filtering processes) are usually in place. These results suggest that there are innate differences between crowd workers’ abilities to successfully and accurately label behavioral features from short unstructured videos of children. This variation in intrinsic ability to rate diagnostically rich features suggests that a filtering process must occur to curate a subset of the crowd who are skilled at inferring behavior patterns from videos. We term this skilled distributed workforce “super recognizers” as they appear consistently adept at recognizing and tagging core autism symptoms from unstructured video without prior training. </text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>19666</offset><text>Further, we find that the time spent rating is weakly correlated with average performance, indicating that workers can be filtered for spending too little time on the tasks in aggregate. Although this trend was not observed in the Kenya and Philippines cohorts individually, this may likely be attributed to the smaller sample sizes of these groups. Including these data in the aggregate time correlation analysis bolstered the statistical significance of the correlation.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>20139</offset><text>Gold standard classifiers trained on clinician-filled electronic health records are pertinent to scaling digital behavioral diagnostics. The source of training data is crucial, as behavioral instruments are not always consistent with categorizing diagnostic outcomes for the same individual. The classifier used here was trained on ADOS records, but the children in the videos were not necessarily diagnosed via the ADOS, as there are several diagnostic instruments for autism capturing overlapping yet distinct behaviors.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>20662</offset><text>It is clear that different workers possess varying capabilities in behavioral video tagging, a nontrivial task. To realize economic crowdsourcing, several subsets of the crowd should be evaluated, with adept subgroups further pursued. Curating such a skilled crowd workforce in a developing country may lead to part time employment of “super recognizers” in telemedical practices in that country. This would eventually enable automated precision medicine through training machine learning classifiers using the labeled video data libraries accumulated through distributed behavioral video tagging.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>21264</offset><text>4.2. Formalization of a Crowd Filtration Process</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21313</offset><text>Train one or more machine learning classifiers using data accumulated by domain expert clinicians. These data may be actively acquired or mined from existing data sources. It is crucial that the gold standard data are representative of the target pediatric population.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21582</offset><text>Define a target performance metric for worker evaluation and a target number of workers to recruit.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21682</offset><text>Collect labels from a massive and distributed set of crowd workers (Figure 5).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21761</offset><text>Filter the crowd workers progressively and repeatedly until the target number of workers have reached or surpassed the target performance metric.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21907</offset><text>The final set of globally recruited “super recognizers” can be leveraged in precision health and precision medicine clinical workflows toward rating a worldwide pediatric population (Figure 5).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>22105</offset><text>These results suggest that clinical workflows incorporating crowdsourced workers for pediatric diagnostics of complex behavioral conditions like autism should first filter down the crowd to a subset of workers who repeatedly and consistently perform well. Here, we propose a novel workflow for recruitment of crowdsourced workers to ensure high quality diagnostic evaluations of pediatric behavioral health conditions:</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>22524</offset><text>4.3. Limitations and Future Work</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>22557</offset><text>There are several limitations of the present study and fruitful avenues for future work. More structured videos, such as those collected in home smartphone autism interventions, may yield more consistent video difficulty levels due to the standardization of collected videos. Mobile therapeutics in conjunction with crowdsourcing may be leveraged toward longitudinal outcome tracking of symptoms. Testing more subsets of the crowd, partitioned not only by location but by a wide array of demographic factors, will reveal economical subsets of the crowd for remote behavioral video tagging. To understand the reasons for differences in performance across subsets, videos of children that reflect the demographics of the population being targeted should be deployed and compared against a control set of videos. We welcome and call for replication crowdsourcing studies with separate video sets and crowd recruitment strategies. We also hope similar approaches to those tried here will be replicated for other behavioral conditions such as ADHD, speech delay, and OCD.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>23624</offset><text>5. Conclusions</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>23639</offset><text>Crowdsourcing is a powerful yet understudied emerging tool for telemedical precision medicine and health. We have demonstrated that crowdsourced workers vary in their performance on behavioral tagging of clinically representative videos of autism and matched neurotypical controls, and we provide formalization of a crowd filtration process for curation of the most capable members of the crowd for repeated use in crowdsourcing-based clinical workflows. This process consists of training a classifier from records filled by domain experts, identifying quantitative metrics for evaluating workers, crowdsourcing a clinical task, filtering workers using the clinician-trained classifier, and repeating until the ideal workforce size has been reached.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>24389</offset><text>As data from human crowd-powered telemedical precision medicine pipelines are recorded and stored in growing databases, computer vision classifiers of core autism symptoms such as hand stimming, eye contact, and emotion evocation can be trained using these labeled datasets. Curation of a workforce of “super recognizers” will allow clinicians to trust the diagnostic labels and allow engineers to use high quality features when training novel classifiers for precision medicine. This will enable an eventual increase in the automation, and therefore throughput, of precision medicine techniques for pediatric developmental delays such as autism. </text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title</infon><offset>25041</offset><text>Author Contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>25062</offset><text>Conceptualization, P.W., E.L. and D.P.W.; data curation, P.W., K.D., A.K., K.P., and D.W.; formal analysis, P.W., E.L., and D.P.W.; funding acquisition, P.W., K.D., Y.P., A.K., and D.P.W.; investigation, N.H. and D.P.W.; methodology, P.W., E.L., K.D., Y.P., A.K., K.P., M.W.S., B.C., N.S., M.V., C.V., N.H., and D.P.W.; project administration, K.D., A.K., and D.P.W.; resources, K.D., Y.P., and D.P.W.; software, P.W. and D.P.W.; supervision, D.P.W.; validation, E.L., K.D., Y.P., A.K., K.P., M.W.S., B.C., N.S., M.V., C.V., N.H., and D.P.W.; visualization, P.W.; writing—original draft, P.W. and D.W.; writing—review and editing, E.L., K.D., Y.P., A.K., K.P., M.W.S., B.C., N.S., M.V., C.V., N.H. and D.P.W. All authors have read and agree to the published version of the manuscript.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>25851</offset><text>Funding</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>25859</offset><text>These studies were supported by awards to DPW by the National Institutes of Health (1R21HD091500-01 and 1R01EB025025-01). Additionally, we acknowledge the support of grants to DPW from The Hartwell Foundation, the David and Lucile Packard Foundation Special Projects Grant, Beckman Center for Molecular and Genetic Medicine, Coulter Endowment Translational Research Grant, Berry Fellowship, Spectrum Pilot Program, Stanford’s Precision Health and Integrated Diagnostics Center (PHIND), Wu Tsai Neurosciences Institute Neuroscience: Translate Program, Spark Program in Translational Research, Stanford’s Institute of Human Centered Artificial Intelligence, the Weston Havens Foundation, as well as philanthropic support from Peter Sullivan. PW would like to acknowledge support from the Stanford Interdisciplinary Graduate Fellowship (SIGF). </text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title</infon><offset>26705</offset><text>Conflicts of Interest</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>26727</offset><text>D.P.W. is the founder of Cognoa.com. This company is developing digital health solutions for pediatric care. C.V., N.H., and A.K. work as part-time consultant to Cognoa.com. All other authors declare no conflict of interests.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>26953</offset><text>References</text></passage><passage><infon key="fpage">717</infon><infon key="lpage">720</infon><infon key="name_0">surname:Fombonne;given-names:E.</infon><infon key="pub-id_doi">10.1111/jcpp.12941</infon><infon key="pub-id_pmid">29924395</infon><infon key="section_type">REF</infon><infon key="source">J. Child Psychol. Psychiatry</infon><infon key="type">ref</infon><infon key="volume">59</infon><infon key="year">2018</infon><offset>26964</offset><text>The rising prevalence of autism</text></passage><passage><infon key="fpage">418</infon><infon key="lpage">425</infon><infon key="name_0">surname:Matson;given-names:J.L.</infon><infon key="name_1">surname:Kozlowski;given-names:A.M.</infon><infon key="pub-id_doi">10.1016/j.rasd.2010.06.004</infon><infon key="section_type">REF</infon><infon key="source">Res. Autism Spectr. Disord.</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2011</infon><offset>26996</offset><text>The increasing prevalence of autism spectrum disorders</text></passage><passage><infon key="fpage">851</infon><infon key="lpage">859</infon><infon key="name_0">surname:Gordon-Lipkin;given-names:E.</infon><infon key="name_1">surname:Jessica;given-names:F.</infon><infon key="name_2">surname:Georgina;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Pediatric Clin.</infon><infon key="type">ref</infon><infon key="volume">63</infon><infon key="year">2016</infon><offset>27051</offset><text>Whittling down the wait time: Exploring models to minimize the delay from initial concern to diagnosis and treatment of autism spectrum disorder</text></passage><passage><infon key="fpage">e13094</infon><infon key="name_0">surname:Ning;given-names:M.</infon><infon key="name_1">surname:Daniels;given-names:J.</infon><infon key="name_2">surname:Schwartz;given-names:J.</infon><infon key="name_3">surname:Dunlap;given-names:K.</infon><infon key="name_4">surname:Washington;given-names:P.</infon><infon key="name_5">surname:Kalantarian;given-names:H.</infon><infon key="name_6">surname:Du;given-names:M.</infon><infon key="name_7">surname:Wall;given-names:D.P.</infon><infon key="name_8">surname:Cao;given-names:Y.</infon><infon key="name_9">surname:Antoniou;given-names:P.</infon><infon key="pub-id_doi">10.2196/13094</infon><infon key="pub-id_pmid">31293243</infon><infon key="section_type">REF</infon><infon key="source">J. Med. Internet Res.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2019</infon><offset>27196</offset><text>Identification and Quantification of Gaps in Access to Autism Resources in the United States: An Infodemiological Study</text></passage><passage><infon key="fpage">e13822</infon><infon key="name_0">surname:Tariq;given-names:Q.</infon><infon key="name_1">surname:Fleming;given-names:S.L.</infon><infon key="name_2">surname:Schwartz;given-names:J.</infon><infon key="name_3">surname:Dunlap;given-names:K.</infon><infon key="name_4">surname:Corbin;given-names:C.</infon><infon key="name_5">surname:Washington;given-names:P.</infon><infon key="name_6">surname:Kalantarian;given-names:H.</infon><infon key="name_7">surname:Khan;given-names:N.Z.</infon><infon key="name_8">surname:Darmstadt;given-names:G.L.</infon><infon key="name_9">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.2196/13822</infon><infon key="pub-id_pmid">31017583</infon><infon key="section_type">REF</infon><infon key="source">J. Med. Internet Res.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2019</infon><offset>27316</offset><text>Detecting Developmental Delay and Autism Through Machine Learning Models Using Home Videos of Bangladeshi Children: Development and Validation Study</text></passage><passage><infon key="fpage">e13668</infon><infon key="name_0">surname:Washington;given-names:P.</infon><infon key="name_1">surname:Kalantarian;given-names:H.</infon><infon key="name_2">surname:Tariq;given-names:Q.</infon><infon key="name_3">surname:Schwartz;given-names:J.</infon><infon key="name_4">surname:Dunlap;given-names:K.</infon><infon key="name_5">surname:Chrisman;given-names:B.</infon><infon key="name_6">surname:Varma;given-names:M.</infon><infon key="name_7">surname:Ning;given-names:M.</infon><infon key="name_8">surname:Kline;given-names:A.</infon><infon key="name_9">surname:Stockham;given-names:N.</infon><infon key="pub-id_doi">10.2196/13668</infon><infon key="pub-id_pmid">31124463</infon><infon key="section_type">REF</infon><infon key="source">J. Med. Internet Res.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2019</infon><offset>27465</offset><text>Validity of Online Screening for Autism: Crowdsourcing Study Comparing Paid and Unpaid Diagnostic Tasks</text></passage><passage><infon key="name_0">surname:Washington;given-names:P.</infon><infon key="name_1">surname:Park;given-names:N.</infon><infon key="name_2">surname:Srivastava;given-names:P.</infon><infon key="name_3">surname:Voss;given-names:C.</infon><infon key="name_4">surname:Kline;given-names:A.</infon><infon key="name_5">surname:Varma;given-names:M.</infon><infon key="name_6">surname:Tariq;given-names:Q.</infon><infon key="name_7">surname:Kalantarian;given-names:H.</infon><infon key="name_8">surname:Schwartz;given-names:J.</infon><infon key="name_9">surname:Patnaik;given-names:R.</infon><infon key="pub-id_doi">10.1016/j.bpsc.2019.11.015</infon><infon key="section_type">REF</infon><infon key="source">Biol. Psychiatry Cogn. Neurosci. Neuroimaging</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>27569</offset><text>Data-Driven Diagnostics and the Potential of Mobile Artificial Intelligence for Digital Therapeutic Phenotyping in Computational Psychiatry</text></passage><passage><infon key="fpage">e514</infon><infon key="name_0">surname:Kosmicki;given-names:J.A.</infon><infon key="name_1">surname:Sochat;given-names:V.V.</infon><infon key="name_2">surname:Duda;given-names:M.</infon><infon key="name_3">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1038/tp.2015.7</infon><infon key="pub-id_pmid">25710120</infon><infon key="section_type">REF</infon><infon key="source">Transl. Psychiatry</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2015</infon><offset>27709</offset><text>Searching for a minimal set of behaviors for autism detection through feature selection-based machine learning</text></passage><passage><infon key="fpage">e100</infon><infon key="name_0">surname:Wall;given-names:D.P.</infon><infon key="name_1">surname:Kosmicki;given-names:J.</infon><infon key="name_2">surname:DeLuca;given-names:T.F.</infon><infon key="name_3">surname:Harstad;given-names:E.</infon><infon key="name_4">surname:Fusaro;given-names:V.A.</infon><infon key="pub-id_doi">10.1038/tp.2012.10</infon><infon key="pub-id_pmid">22832900</infon><infon key="section_type">REF</infon><infon key="source">Transl. Psychiatry</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2012</infon><offset>27820</offset><text>Use of machine learning to shorten observation-based screening and diagnosis of autism</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">8</infon><infon key="name_0">surname:Abbas;given-names:H.</infon><infon key="name_1">surname:Garberson;given-names:F.</infon><infon key="name_2">surname:Liu-Mayo;given-names:S.</infon><infon key="name_3">surname:Glover;given-names:E.</infon><infon key="name_4">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1038/s41598-020-61213-w</infon><infon key="pub-id_pmid">31913322</infon><infon key="section_type">REF</infon><infon key="source">Sci. Rep.</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2020</infon><offset>27907</offset><text>Multi-modular Ai Approach to Streamline Autism Diagnosis in Young children</text></passage><passage><infon key="fpage">446</infon><infon key="lpage">454</infon><infon key="name_0">surname:Voss;given-names:C.</infon><infon key="name_1">surname:Schwartz;given-names:J.</infon><infon key="name_2">surname:Daniels;given-names:J.</infon><infon key="name_3">surname:Kline;given-names:A.</infon><infon key="name_4">surname:Haber;given-names:N.</infon><infon key="name_5">surname:Washington;given-names:P.</infon><infon key="name_6">surname:Tariq;given-names:Q.</infon><infon key="name_7">surname:Robinson;given-names:T.N.</infon><infon key="name_8">surname:Desai;given-names:M.</infon><infon key="name_9">surname:Phillips;given-names:J.M.</infon><infon key="pub-id_doi">10.1001/jamapediatrics.2019.0285</infon><infon key="pub-id_pmid">30907929</infon><infon key="section_type">REF</infon><infon key="source">JAMA Pediatr.</infon><infon key="type">ref</infon><infon key="volume">173</infon><infon key="year">2019</infon><offset>27982</offset><text>Effect of Wearable Digital Intervention for Improving Socialization in Children with Autism Spectrum Disorder: A Randomized Clinical Trial</text></passage><passage><infon key="fpage">35</infon><infon key="lpage">38</infon><infon key="name_0">surname:Kline;given-names:A.</infon><infon key="name_1">surname:Voss;given-names:C.</infon><infon key="name_2">surname:Washington;given-names:P.</infon><infon key="name_3">surname:Haber;given-names:N.</infon><infon key="name_4">surname:Schwartz;given-names:H.</infon><infon key="name_5">surname:Tariq;given-names:Q.</infon><infon key="name_6">surname:Winograd;given-names:T.</infon><infon key="name_7">surname:Feinstein;given-names:C.</infon><infon key="name_8">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1145/3372300.3372308</infon><infon key="section_type">REF</infon><infon key="source">GetMobile Mob. Comput. Commun.</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2019</infon><offset>28121</offset><text>Superpower Glass</text></passage><passage><infon key="fpage">112</infon><infon key="name_0">surname:Washington;given-names:P.</infon><infon key="name_1">surname:Catalin;given-names:V.</infon><infon key="name_2">surname:Aaron;given-names:K.</infon><infon key="name_3">surname:Nick;given-names:H.</infon><infon key="name_4">surname:Jena;given-names:D.</infon><infon key="name_5">surname:Azar;given-names:F.</infon><infon key="name_6">surname:Titas;given-names:D.</infon><infon key="name_7">surname:Carl;given-names:F.</infon><infon key="name_8">surname:Terry;given-names:W.</infon><infon key="name_9">surname:Dennis;given-names:W.</infon><infon key="pub-id_doi">10.1145/3130977</infon><infon key="section_type">REF</infon><infon key="source">Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2017</infon><offset>28138</offset><text>Superpowerglass: A wearable aid for the at-home therapy of children with autism</text></passage><passage><infon key="fpage">32</infon><infon key="name_0">surname:Daniels;given-names:J.</infon><infon key="name_1">surname:Schwartz;given-names:J.N.</infon><infon key="name_2">surname:Voss;given-names:C.</infon><infon key="name_3">surname:Haber;given-names:N.</infon><infon key="name_4">surname:Fazel;given-names:A.</infon><infon key="name_5">surname:Kline;given-names:A.</infon><infon key="name_6">surname:Washington;given-names:P.</infon><infon key="name_7">surname:Feinstein;given-names:C.</infon><infon key="name_8">surname:Winograd;given-names:T.</infon><infon key="name_9">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1038/s41746-018-0035-3</infon><infon key="pub-id_pmid">31304314</infon><infon key="section_type">REF</infon><infon key="source">NPJ Digit. Med.</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2018</infon><offset>28218</offset><text>Exploratory study examining the at-home feasibility of a wearable tool for social-affective learning in children with autism</text></passage><passage><infon key="fpage">77</infon><infon key="lpage">86</infon><infon key="name_0">surname:Kalantarian;given-names:H.</infon><infon key="name_1">surname:Jedoui;given-names:K.</infon><infon key="name_2">surname:Washington;given-names:P.</infon><infon key="name_3">surname:Tariq;given-names:Q.</infon><infon key="name_4">surname:Dunlap;given-names:K.</infon><infon key="name_5">surname:Schwartz;given-names:J.</infon><infon key="name_6">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1016/j.artmed.2019.06.004</infon><infon key="pub-id_pmid">31521254</infon><infon key="section_type">REF</infon><infon key="source">Artif. Intell. Med.</infon><infon key="type">ref</infon><infon key="volume">98</infon><infon key="year">2019</infon><offset>28343</offset><text>Labeling images with facial emotion and the potential for pediatric healthcare</text></passage><passage><infon key="fpage">350</infon><infon key="lpage">352</infon><infon key="name_0">surname:Kalantarian;given-names:H.</infon><infon key="name_1">surname:Washington;given-names:P.</infon><infon key="name_2">surname:Schwartz;given-names:J.</infon><infon key="name_3">surname:Daniels;given-names:J.</infon><infon key="name_4">surname:Haber;given-names:N.</infon><infon key="name_5">surname:Wall;given-names:D.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2018 IEEE International Conference on Healthcare Informatics (ICHI)</infon><infon key="type">ref</infon><offset>28422</offset><text>A Gamified Mobile System for Crowdsourcing Video for Autism Research</text></passage><passage><infon key="fpage">43</infon><infon key="lpage">66</infon><infon key="name_0">surname:Kalantarian;given-names:H.</infon><infon key="name_1">surname:Washington;given-names:P.</infon><infon key="name_2">surname:Schwartz;given-names:J.</infon><infon key="name_3">surname:Daniels;given-names:J.</infon><infon key="name_4">surname:Haber;given-names:N.</infon><infon key="name_5">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1007/s41666-018-0034-9</infon><infon key="section_type">REF</infon><infon key="source">J. Healthc. Informatics Res.</infon><infon key="type">ref</infon><infon key="volume">3</infon><infon key="year">2018</infon><offset>28491</offset><text>Guess What?</text></passage><passage><infon key="fpage">1</infon><infon key="name_0">surname:Kalantarian;given-names:H.</infon><infon key="name_1">surname:Jedoui;given-names:K.</infon><infon key="name_2">surname:Washington;given-names:P.</infon><infon key="name_3">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1109/TG.2018.2877325</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. Games</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>28503</offset><text>A Mobile Game for Automatic Emotion-Labeling of Images</text></passage><passage><infon key="fpage">e13174</infon><infon key="name_0">surname:Kalantarian;given-names:H.</infon><infon key="name_1">surname:Jedoui;given-names:K.</infon><infon key="name_2">surname:Dunlap;given-names:K.</infon><infon key="name_3">surname:Schwartz;given-names:J.</infon><infon key="name_4">surname:Washington;given-names:P.</infon><infon key="name_5">surname:Husic;given-names:A.</infon><infon key="name_6">surname:Tariq;given-names:Q.</infon><infon key="name_7">surname:Ning;given-names:M.</infon><infon key="pub-id_doi">10.2196/13174</infon><infon key="pub-id_pmid">32234701</infon><infon key="section_type">REF</infon><infon key="source">JMIR Ment. Health</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2020</infon><offset>28558</offset><text>The Performance of Emotion Classifiers for Children with Parent-Reported Autism: Quantitative Feasibility Study</text></passage><passage><infon key="fpage">eaao6760</infon><infon key="name_0">surname:Rudovic;given-names:O.</infon><infon key="name_1">surname:Lee;given-names:J.</infon><infon key="name_2">surname:Dai;given-names:M.</infon><infon key="name_3">surname:Schuller;given-names:B.W.</infon><infon key="name_4">surname:Picard;given-names:R.W.</infon><infon key="pub-id_doi">10.1126/scirobotics.aao6760</infon><infon key="section_type">REF</infon><infon key="source">Sci. Robot.</infon><infon key="type">ref</infon><infon key="volume">3</infon><infon key="year">2018</infon><offset>28670</offset><text>Personalized machine learning for robot perception of affect and engagement in autism therapy</text></passage><passage><infon key="fpage">20</infon><infon key="name_0">surname:Egger;given-names:H.L.</infon><infon key="name_1">surname:Dawson;given-names:G.</infon><infon key="name_2">surname:Hashemi;given-names:J.</infon><infon key="name_3">surname:Carpenter;given-names:K.L.</infon><infon key="name_4">surname:Espinosa;given-names:S.</infon><infon key="name_5">surname:Campbell;given-names:K.</infon><infon key="name_6">surname:Brotkin;given-names:S.</infon><infon key="name_7">surname:Schaich-Borg;given-names:J.</infon><infon key="name_8">surname:Qiu;given-names:Q.</infon><infon key="name_9">surname:Tepper;given-names:M.</infon><infon key="pub-id_doi">10.1038/s41746-018-0024-6</infon><infon key="pub-id_pmid">31304303</infon><infon key="section_type">REF</infon><infon key="source">NPJ Digit. Med.</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2018</infon><offset>28764</offset><text>Automatic emotion and attention analysis of young children at home: A ResearchKit autism feasibility study</text></passage><passage><infon key="fpage">13863</infon><infon key="name_0">surname:Kolakowska;given-names:A.</infon><infon key="name_1">surname:Landowska;given-names:A.</infon><infon key="name_2">surname:Anzulewicz;given-names:A.</infon><infon key="name_3">surname:Sobota;given-names:K.</infon><infon key="pub-id_doi">10.1038/s41598-017-14209-y</infon><infon key="pub-id_pmid">29066747</infon><infon key="section_type">REF</infon><infon key="source">Sci. Rep.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2017</infon><offset>28871</offset><text>Automatic recognition of therapy progress among children with autism</text></passage><passage><infon key="fpage">374</infon><infon key="lpage">379</infon><infon key="name_0">surname:Chang;given-names:C.-H.</infon><infon key="name_1">surname:Saravia;given-names:E.</infon><infon key="name_2">surname:Chen;given-names:Y.-S.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>28940</offset><text>Subconscious Crowdsourcing: A feasible data collection mechanism for mental disorder detection on social media</text></passage><passage><infon key="fpage">123</infon><infon key="lpage">144</infon><infon key="name_0">surname:Van Der Krieke;given-names:L.</infon><infon key="name_1">surname:Jeronimus;given-names:B.</infon><infon key="name_2">surname:Blaauw;given-names:F.J.</infon><infon key="name_3">surname:Wanders;given-names:R.B.</infon><infon key="name_4">surname:Emerencia;given-names:A.C.</infon><infon key="name_5">surname:Schenk;given-names:H.M.</infon><infon key="name_6">surname:De Vos;given-names:S.</infon><infon key="name_7">surname:Snippe;given-names:E.</infon><infon key="name_8">surname:Wichers;given-names:M.</infon><infon key="name_9">surname:Wigman;given-names:J.T.</infon><infon key="pub-id_doi">10.1002/mpr.1495</infon><infon key="pub-id_pmid">26395198</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Methods Psychiatr. Res.</infon><infon key="type">ref</infon><infon key="volume">25</infon><infon key="year">2015</infon><offset>29051</offset><text>HowNutsAreTheDutch (HoeGekIsNL): A crowdsourcing study of mental symptoms and strengths</text></passage><passage><infon key="fpage">105</infon><infon key="lpage">109</infon><infon key="name_0">surname:Weber;given-names:I.</infon><infon key="name_1">surname:Mejova;given-names:Y.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 6th International Conference on Digital Health Conference</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>29139</offset><text>Crowdsourcing health labels: Inferring body weight from profile pictures</text></passage><passage><infon key="fpage">280</infon><infon key="lpage">287</infon><infon key="name_0">surname:Alvaro;given-names:N.</infon><infon key="name_1">surname:Conway;given-names:M.</infon><infon key="name_2">surname:Doan;given-names:S.</infon><infon key="name_3">surname:Lofi;given-names:C.</infon><infon key="name_4">surname:Overington;given-names:J.</infon><infon key="name_5">surname:Collier;given-names:N.</infon><infon key="pub-id_doi">10.1016/j.jbi.2015.11.004</infon><infon key="section_type">REF</infon><infon key="source">J. Biomed. Informatics</infon><infon key="type">ref</infon><infon key="volume">58</infon><infon key="year">2015</infon><offset>29212</offset><text>Crowdsourcing Twitter annotations to identify first-hand experiences of prescription drug use</text></passage><passage><infon key="fpage">e80</infon><infon key="name_0">surname:Gottlieb;given-names:A.</infon><infon key="name_1">surname:Hoehndorf;given-names:R.</infon><infon key="name_2">surname:Dumontier;given-names:M.</infon><infon key="name_3">surname:Altman;given-names:R.B.</infon><infon key="name_4">surname:Johnson;given-names:K.</infon><infon key="pub-id_doi">10.2196/jmir.3962</infon><infon key="pub-id_pmid">25800813</infon><infon key="section_type">REF</infon><infon key="source">J. Med. Internet Res.</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2015</infon><offset>29306</offset><text>Ranking Adverse Drug Reactions with Crowdsourcing</text></passage><passage><infon key="fpage">335</infon><infon key="lpage">340</infon><infon key="name_0">surname:Ariffin;given-names:I.</infon><infon key="name_1">surname:Solemon;given-names:B.</infon><infon key="name_2">surname:Abu Bakar;given-names:W.M.L.W.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 6th International Conference on Information Technology and Multimedia</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>29356</offset><text>An evaluative study on mobile crowdsourcing applications for crime watch</text></passage><passage><infon key="fpage">891</infon><infon key="lpage">896</infon><infon key="name_0">surname:Evans;given-names:M.B.</infon><infon key="name_1">surname:O’Hara;given-names:K.</infon><infon key="name_2">surname:Tiropanis;given-names:T.</infon><infon key="name_3">surname:Webber;given-names:C.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 22nd International Conference on World Wide Web</infon><infon key="type">ref</infon><offset>29429</offset><text>Crime applications and social machines: Crowdsourcing sensitive data</text></passage><passage><infon key="fpage">30</infon><infon key="lpage">51</infon><infon key="name_0">surname:Williams;given-names:C.</infon><infon key="pub-id_doi">10.13169/statecrime.2.1.0030</infon><infon key="section_type">REF</infon><infon key="source">State Crime J.</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2013</infon><offset>29498</offset><text>Crowdsourcing Research: A Methodology for Investigating State Crime</text></passage><passage><infon key="fpage">318</infon><infon key="lpage">328</infon><infon key="name_0">surname:Choy;given-names:G.</infon><infon key="name_1">surname:Khalilzadeh;given-names:O.</infon><infon key="name_2">surname:Michalski;given-names:M.</infon><infon key="name_3">surname:Synho;given-names:D.</infon><infon key="name_4">surname:Samir;given-names:A.E.</infon><infon key="name_5">surname:Pianykh;given-names:O.S.</infon><infon key="name_6">surname:Geis;given-names:J.R.</infon><infon key="name_7">surname:Pandharipande;given-names:P.V.</infon><infon key="name_8">surname:Brink;given-names:J.A.</infon><infon key="name_9">surname:Dreyer;given-names:K.J.</infon><infon key="pub-id_doi">10.1148/radiol.2018171820</infon><infon key="pub-id_pmid">29944078</infon><infon key="section_type">REF</infon><infon key="source">Radiology</infon><infon key="type">ref</infon><infon key="volume">288</infon><infon key="year">2018</infon><offset>29566</offset><text>Current Applications and Future Impact of Machine Learning in Radiology</text></passage><passage><infon key="fpage">962</infon><infon key="lpage">969</infon><infon key="name_0">surname:Gargeya;given-names:R.</infon><infon key="name_1">surname:Leng;given-names:T.</infon><infon key="pub-id_doi">10.1016/j.ophtha.2017.02.008</infon><infon key="pub-id_pmid">28359545</infon><infon key="section_type">REF</infon><infon key="source">Ophthalmology</infon><infon key="type">ref</infon><infon key="volume">124</infon><infon key="year">2017</infon><offset>29638</offset><text>Automated Identification of Diabetic Retinopathy Using Deep Learning</text></passage><passage><infon key="fpage">95</infon><infon key="name_0">surname:Iwabuchi;given-names:S.J.</infon><infon key="name_1">surname:Liddle;given-names:P.F.</infon><infon key="name_2">surname:Palaniyappan;given-names:L.</infon><infon key="pub-id_doi">10.3389/fpsyt.2013.00095</infon><infon key="pub-id_pmid">23450458</infon><infon key="section_type">REF</infon><infon key="source">Front. Psychol.</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2013</infon><offset>29707</offset><text>Clinical Utility of Machine-Learning Approaches in Schizophrenia: Improving Diagnostic Confidence for Translational Neuroimaging</text></passage><passage><infon key="fpage">719</infon><infon key="lpage">731</infon><infon key="name_0">surname:Yu;given-names:K.-H.</infon><infon key="name_1">surname:Beam;given-names:A.</infon><infon key="name_2">surname:Kohane;given-names:I.S.</infon><infon key="pub-id_doi">10.1038/s41551-018-0305-z</infon><infon key="pub-id_pmid">31015651</infon><infon key="section_type">REF</infon><infon key="source">Nat. Biomed. Eng.</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2018</infon><offset>29836</offset><text>Artificial intelligence in healthcare</text></passage><passage><infon key="fpage">27</infon><infon key="lpage">35</infon><infon key="name_0">surname:Hsueh;given-names:P.-Y.</infon><infon key="name_1">surname:Melville;given-names:P.</infon><infon key="name_2">surname:Sindhwani;given-names:V.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing</infon><infon key="type">ref</infon><offset>29874</offset><text>Data quality from crowdsourcing: A study of annotation selection criteria</text></passage><passage><infon key="fpage">25</infon><infon key="lpage">32</infon><infon key="name_0">surname:Welinder;given-names:P.</infon><infon key="name_1">surname:Perona;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops</infon><infon key="type">ref</infon><infon key="year">2010</infon><offset>29948</offset><text>Online crowdsourcing: Rating annotators and obtaining cost-effective labels</text></passage><passage><infon key="fpage">453</infon><infon key="lpage">456</infon><infon key="name_0">surname:Kittur;given-names:A.</infon><infon key="name_1">surname:Chi;given-names:E.H.</infon><infon key="name_2">surname:Bongwon;given-names:S.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</infon><infon key="type">ref</infon><offset>30024</offset><text>Crowdsourcing user studies with Mechanical Turk</text></passage><passage><infon key="fpage">411</infon><infon key="lpage">419</infon><infon key="name_0">surname:Paolacci;given-names:G.</infon><infon key="name_1">surname:Jesse;given-names:C.</infon><infon key="name_2">surname:Panagiotis;given-names:G.I.</infon><infon key="section_type">REF</infon><infon key="source">Judgm. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2010</infon><offset>30072</offset><text>Running experiments on amazon mechanical turk</text></passage><passage><infon key="fpage">35</infon><infon key="lpage">36</infon><infon key="name_0">surname:Gardlo;given-names:B.</infon><infon key="name_1">surname:Ries;given-names:M.</infon><infon key="name_2">surname:Hossfeld;given-names:T.</infon><infon key="name_3">surname:Schatz;given-names:R.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2012 Fourth International Workshop on Quality of Multimedia Experience</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>30118</offset><text>Microworkers vs. facebook: The impact of crowdsourcing platform choice on experimental results</text></passage><passage><infon key="fpage">1</infon><infon key="name_0">surname:Nguyen;given-names:N.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2014 International ACM Workshop on Crowdsourcing for Multimedia</infon><infon key="type">ref</infon><offset>30213</offset><text>Microworkers Crowdsourcing Approach, Challenges and Solutions</text></passage><passage><infon key="fpage">322</infon><infon key="lpage">329</infon><infon key="name_0">surname:Hirth;given-names:M.</infon><infon key="name_1">surname:Hossfeld;given-names:T.</infon><infon key="name_2">surname:Tran-Gia;given-names:P.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 2011 Fifth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing, Korean Bible University</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>30275</offset><text>Anatomy of a crowdsourcing platform-using the example of microworkers. com</text></passage><passage><infon key="fpage">65</infon><infon key="name_0">surname:Levy;given-names:S.</infon><infon key="name_1">surname:Duda;given-names:M.</infon><infon key="name_2">surname:Haber;given-names:N.</infon><infon key="name_3">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1186/s13229-017-0180-6</infon><infon key="pub-id_pmid">29270283</infon><infon key="section_type">REF</infon><infon key="source">Mol. Autism</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2017</infon><offset>30350</offset><text>Sparsifying machine learning models identify stable subsets of predictive features for behavioral detection of autism</text></passage><passage><infon key="elocation-id">e1002705</infon><infon key="name_0">surname:Tariq;given-names:Q.</infon><infon key="name_1">surname:Daniels;given-names:J.</infon><infon key="name_2">surname:Schwartz;given-names:J.</infon><infon key="name_3">surname:Washington;given-names:P.</infon><infon key="name_4">surname:Kalantarian;given-names:H.</infon><infon key="name_5">surname:Wall;given-names:D.P.</infon><infon key="pub-id_doi">10.1371/journal.pmed.1002705</infon><infon key="pub-id_pmid">30481180</infon><infon key="section_type">REF</infon><infon key="source">PLoS Med.</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2018</infon><offset>30468</offset><text>Mobile detection of autism through machine learning on home video: A development and prospective validation study</text></passage><passage><infon key="name_0">surname:Guy;given-names:W.</infon><infon key="section_type">REF</infon><infon key="source">ECDEU Assessment Manual for Psychopharmacology</infon><infon key="type">ref</infon><infon key="year">1976</infon><offset>30582</offset></passage><passage><infon key="fpage">185</infon><infon key="lpage">212</infon><infon key="name_0">surname:Lord;given-names:C.</infon><infon key="name_1">surname:Rutter;given-names:M.</infon><infon key="name_2">surname:Goode;given-names:S.</infon><infon key="name_3">surname:Heemsbergen;given-names:J.</infon><infon key="name_4">surname:Jordan;given-names:H.</infon><infon key="name_5">surname:Mawhood;given-names:L.</infon><infon key="name_6">surname:Schopler;given-names:E.</infon><infon key="pub-id_doi">10.1007/BF02211841</infon><infon key="pub-id_pmid">2745388</infon><infon key="section_type">REF</infon><infon key="source">J. Autism Dev. Disord.</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">1989</infon><offset>30583</offset><text>Austism diagnostic observation schedule: A standardized observation of communicative and social behavior</text></passage><passage><infon key="fpage">801</infon><infon key="lpage">803</infon><infon key="name_0">surname:Ahmed;given-names:N.</infon><infon key="name_1">surname:Raheem;given-names:E.</infon><infon key="name_2">surname:Rahman;given-names:N.</infon><infon key="name_3">surname:Khan;given-names:M.Z.R.</infon><infon key="name_4">surname:Al Mosabbir;given-names:A.</infon><infon key="name_5">surname:Hossain;given-names:M.S.</infon><infon key="pub-id_doi">10.1177/1362361318773981</infon><infon key="pub-id_pmid">29788765</infon><infon key="section_type">REF</infon><infon key="source">Autism</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2018</infon><offset>30688</offset><text>Managing autism spectrum disorder in developing countries by utilizing existing resources: A perspective from Bangladesh</text></passage><passage><infon key="name_0">surname:Ehsan;given-names:U.</infon><infon key="name_1">surname:Sakib;given-names:N.</infon><infon key="name_2">surname:Haque;given-names:M.</infon><infon key="name_3">surname:Soron;given-names:T.</infon><infon key="name_4">surname:Saxena;given-names:D.</infon><infon key="name_5">surname:Ahamed;given-names:S.</infon><infon key="name_6">surname:Schwichtenberg;given-names:A.</infon><infon key="name_7">surname:Rabbani;given-names:G.</infon><infon key="name_8">surname:Akter;given-names:S.</infon><infon key="name_9">surname:Alam;given-names:F.</infon><infon key="pub-id_doi">10.4108/eai.13-7-2018.155082</infon><infon key="section_type">REF</infon><infon key="source">EAI Endorsed Trans. Pervasive Health Technol.</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2018</infon><offset>30809</offset><text>Confronting Autism in Urban Bangladesh: Unpacking Infrastructural and Cultural Challenges</text></passage><passage><infon key="fpage">3517</infon><infon key="name_0">surname:Gona;given-names:J.K.</infon><infon key="name_1">surname:Newton;given-names:C.R.</infon><infon key="name_2">surname:Rimba;given-names:K.K.</infon><infon key="name_3">surname:Mapenzi;given-names:R.</infon><infon key="name_4">surname:Kihara;given-names:M.</infon><infon key="name_5">surname:Van De Vijver;given-names:F.J.R.</infon><infon key="name_6">surname:Abubakar;given-names:A.</infon><infon key="pub-id_pmid">27098766</infon><infon key="section_type">REF</infon><infon key="source">Rural. Remote Health</infon><infon key="type">ref</infon><infon key="volume">16</infon><infon key="year">2016</infon><offset>30899</offset><text>Challenges and coping strategies of parents of children with autism on the Kenyan coast</text></passage><passage><infon key="name_0">surname:Ryan;given-names:C.M.M.</infon><infon key="name_1">surname:Diana;given-names:M.</infon><infon key="name_2">surname:Jumadiao;given-names:J.J.S.U.</infon><infon key="name_3">surname:Angel;given-names:J.J.Q.</infon><infon key="name_4">surname:Leonard;given-names:J.P.R.</infon><infon key="name_5">surname:Yoshiki;given-names:B.K.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the International Conference on Industrial Engineering and Operations Management</infon><infon key="type">ref</infon><offset>30987</offset><text>Awetism: A User Ergonomic Learning Management System Intended for Autism Diagnosed Students in the Philippines</text></passage><passage><infon key="fpage">533</infon><infon key="lpage">549</infon><infon key="name_0">surname:Mazefsky;given-names:C.A.</infon><infon key="name_1">surname:Oswald;given-names:D.</infon><infon key="pub-id_doi">10.1177/1362361306068505</infon><infon key="pub-id_pmid">17088271</infon><infon key="section_type">REF</infon><infon key="source">Autism</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2006</infon><offset>31098</offset><text>The discriminative ability and diagnostic utility of the ADOS-G, ADI-R, and GARS for children in a clinical setting</text></passage><passage><infon key="name_0">surname:James;given-names:E.G.</infon><infon key="section_type">REF</infon><infon key="source">Gilliam Autism Rating Scale: Examiner’s Manual</infon><infon key="type">ref</infon><infon key="year">1995</infon><offset>31214</offset></passage><passage><infon key="fpage">769</infon><infon key="lpage">780</infon><infon key="name_0">surname:Zander;given-names:E.</infon><infon key="name_1">surname:Willfors;given-names:C.</infon><infon key="name_2">surname:Berggren;given-names:S.</infon><infon key="name_3">surname:Choque-Olsson;given-names:N.</infon><infon key="name_4">surname:Coco;given-names:C.</infon><infon key="name_5">surname:Elmund;given-names:A.</infon><infon key="name_6">surname:Moretti;given-names:Å.H.</infon><infon key="name_7">surname:Holm;given-names:A.</infon><infon key="name_8">surname:Jifält;given-names:I.</infon><infon key="name_9">surname:Kosieradzki;given-names:R.</infon><infon key="pub-id_doi">10.1007/s00787-015-0793-2</infon><infon key="pub-id_pmid">26584575</infon><infon key="section_type">REF</infon><infon key="source">Eur. Child Adolesc. Psychiatry</infon><infon key="type">ref</infon><infon key="volume">25</infon><infon key="year">2015</infon><offset>31215</offset><text>The objectivity of the Autism Diagnostic Observation Schedule (ADOS) in naturalistic clinical settings</text></passage><passage><infon key="fpage">531</infon><infon key="lpage">546</infon><infon key="name_0">surname:Brawley;given-names:A.M.</infon><infon key="name_1">surname:Pury;given-names:C.L.S.</infon><infon key="pub-id_doi">10.1016/j.chb.2015.08.031</infon><infon key="section_type">REF</infon><infon key="source">Comput. Hum. Behav.</infon><infon key="type">ref</infon><infon key="volume">54</infon><infon key="year">2016</infon><offset>31318</offset><text>Work experiences on MTurk: Job satisfaction, turnover, and information sharing</text></passage><passage><infon key="elocation-id">e0157732</infon><infon key="name_0">surname:Necka;given-names:E.A.</infon><infon key="name_1">surname:Cacioppo;given-names:S.</infon><infon key="name_2">surname:Norman;given-names:G.J.</infon><infon key="name_3">surname:Cacioppo;given-names:J.T.</infon><infon key="pub-id_doi">10.1371/journal.pone.0157732</infon><infon key="pub-id_pmid">27351378</infon><infon key="section_type">REF</infon><infon key="source">PLoS ONE</infon><infon key="type">ref</infon><infon key="volume">11</infon><infon key="year">2016</infon><offset>31397</offset><text>Measuring the Prevalence of Problematic Respondent Behaviors among MTurk, Campus, and Community Participants</text></passage><passage><infon key="fpage">707</infon><infon key="lpage">718</infon><infon key="name_0">surname:Washington;given-names:P.</infon><infon key="name_1">surname:Paskov;given-names:K.M.</infon><infon key="name_2">surname:Kalantarian;given-names:H.</infon><infon key="name_3">surname:Stockham;given-names:N.</infon><infon key="name_4">surname:Voss;given-names:C.</infon><infon key="name_5">surname:Kline;given-names:A.</infon><infon key="name_6">surname:Patnaik;given-names:R.</infon><infon key="name_7">surname:Chrisman;given-names:B.</infon><infon key="name_8">surname:Varma;given-names:M.</infon><infon key="name_9">surname:Tariq;given-names:Q.</infon><infon key="pub-id_pmid">31797640</infon><infon key="section_type">REF</infon><infon key="source">Pac. Symp. Biocomput.</infon><infon key="type">ref</infon><infon key="volume">25</infon><infon key="year">2020</infon><offset>31506</offset><text>Feature Selection and Dimension Reduction of Social Autism Data</text></passage><passage><infon key="fpage">659</infon><infon key="lpage">685</infon><infon key="name_0">surname:Lord;given-names:C.</infon><infon key="name_1">surname:Rutter;given-names:M.</infon><infon key="name_2">surname:Le Couteur;given-names:A.</infon><infon key="pub-id_doi">10.1007/BF02172145</infon><infon key="pub-id_pmid">7814313</infon><infon key="section_type">REF</infon><infon key="source">J. Autism Dev. Disord.</infon><infon key="type">ref</infon><infon key="volume">24</infon><infon key="year">1994</infon><offset>31570</offset><text>Autism Diagnostic Interview-Revised: A revised version of a diagnostic interview for caregivers of individuals with possible pervasive developmental disorders</text></passage><passage><infon key="name_0">surname:Rutter;given-names:M.</infon><infon key="name_1">surname:Bailey;given-names:A.</infon><infon key="name_2">surname:Lord;given-names:C.</infon><infon key="name_3">surname:Cianchetti;given-names:C.</infon><infon key="name_4">surname:Fancelli;given-names:G.S.</infon><infon key="section_type">REF</infon><infon key="source">Social Communication Questionnaire</infon><infon key="type">ref</infon><infon key="year">2003</infon><offset>31729</offset></passage><passage><infon key="name_0">surname:Sparrow;given-names:S.S.</infon><infon key="name_1">surname:Cicchetti;given-names:D.</infon><infon key="name_2">surname:Balla;given-names:D.A.</infon><infon key="section_type">REF</infon><infon key="source">Vineland Adaptive Behavior Scales</infon><infon key="type">ref</infon><infon key="year">2005</infon><offset>31730</offset></passage><passage><infon key="fpage">947</infon><infon key="lpage">964</infon><infon key="name_0">surname:Carrow-Woolfolk;given-names:E.</infon><infon key="section_type">REF</infon><infon key="source">Oral and Written Language Scales</infon><infon key="type">ref</infon><infon key="volume">Volume 93</infon><infon key="year">1995</infon><offset>31731</offset></passage><passage><infon key="name_0">surname:Phelps-Terasaki;given-names:D.</infon><infon key="name_1">surname:Phelsp-Gunn;given-names:T.</infon><infon key="section_type">REF</infon><infon key="source">Test of Pragmatic Language (TOPL-2)</infon><infon key="type">ref</infon><infon key="year">2007</infon><offset>31732</offset></passage><passage><infon key="name_0">surname:Wechsler;given-names:D.</infon><infon key="section_type">REF</infon><infon key="source">WISC-V: Technical and Interpretive Manual</infon><infon key="type">ref</infon><infon key="year">2014</infon><offset>31733</offset></passage><passage><infon key="file">jpm-10-00086-g001.jpg</infon><infon key="id">jpm-10-00086-f001</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>31734</offset><text>The process for calculating a probability score of autism from the categorical answers provided by crowdsourced workers. (A) Workers answer a series of multiple-choice questions per video that correspond to (B) categorical ordinal variables used in the input feature matrix to the (C) logistic regression classifier trained on electronic medical record data. This classifier emits a probability score for autism, which is the probability of the correct class when the true class is autism and 1 minus this probability when the true class is neurotypical (the latter case is depicted). (D) A vector of these probabilities is used to calculate mean worker and mean video probabilities of the correct class.</text></passage><passage><infon key="file">jpm-10-00086-g002.jpg</infon><infon key="id">jpm-10-00086-f002</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>32439</offset><text>Distribution of average classifier probability of the correct class per video with at least ten ratings from (A) MTurk workers, (B) Bangladesh Microworkers, (C) Kenya Microworkers, and (D) Philippines Microworkers. There is wide variability in the difficulty level of rated videos.</text></passage><passage><infon key="file">jpm-10-00086-g003.jpg</infon><infon key="id">jpm-10-00086-f003</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>32721</offset><text>Distribution of average probability of the correct class per (A) MTurk worker, (B) Bangladesh Microworker, (C) Kenya Microworker, and (D) Philippines Microworker who provided at least ten ratings. There is wide variability in the ability of workers to provide accurate categorical labels.</text></passage><passage><infon key="file">jpm-10-00086-g004.jpg</infon><infon key="id">jpm-10-00086-f004</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>33010</offset><text>Mean classifier confidence per video vs. per worker for (A) MTurk workers, (B) Bangladesh Microworkers, (C) Kenya Microworkers, and (D) Philippines Microworkers for videos with at least 10 ratings and workers who provided at least ten ratings. Each vertical line of points contains the difficulty levels of videos rated for one worker, visually demonstrating that workers received similar distributions of video difficulties to rate despite displaying large variation in average diagnostic confidence.</text></passage><passage><infon key="file">jpm-10-00086-g005.jpg</infon><infon key="id">jpm-10-00086-f005</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>33512</offset><text>Crowd filtration pipeline. Crowdsourced workers are first evaluated globally. The highest performers from each location are further evaluated for one or more rounds until a final skilled workforce is curated. These “super recognizers” may then be repeatedly employed in global clinical workflows.</text></passage></document></collection>
