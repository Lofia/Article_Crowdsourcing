<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20220623</date><key>pmc.key</key><document><id>7292742</id><infon key="license">author_manuscript</infon><passage><infon key="article-id_doi">10.1080/10410236.2019.1700882</infon><infon key="article-id_manuscript">NIHMS1546415</infon><infon key="article-id_pmc">7292742</infon><infon key="article-id_pmid">31830827</infon><infon key="fpage">497</infon><infon key="issue">4</infon><infon key="kwd">e-cigarettes content analysis media text valence crowdsourcing</infon><infon key="license">
          This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
        </infon><infon key="lpage">507</infon><infon key="name_0">surname:Lee;given-names:Stella Juhyun</infon><infon key="name_1">surname:Liu;given-names:Jiaying</infon><infon key="name_2">surname:Gibson;given-names:Laura A.</infon><infon key="name_3">surname:Hornik;given-names:Robert C.</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">36</infon><infon key="year">2022</infon><offset>0</offset><text>Rating the valence of media content about electronic cigarettes using crowdsourcing: Testing rater instructions and estimating the optimal number of raters</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>156</offset><text>Electronic cigarettes (e-cigarettes) are a controversial public health topic due to their increasing popularity among youth and the uncertainty about their risks and benefits. Researchers have started to assess the valence of media content about e-cigarette use, mostly using expert coding. The current study aims to offer a methodological framework and guideline when using crowdsourcing to rate the valence of e-cigarette media content. Specifically, we present 1) an experiment to determine rating instructions that would result in reliable valence ratings and 2) an analysis to identify the optimal number of raters needed to replicate these ratings. Specifically, we compared ratings produced by crowdsourced raters instructed to rate from several different perspectives (e.g., objective vs. subjective) and determined the instructions that led to reliable ratings. We then used bootstrapping methods and a set of criteria to identify the minimum number of raters needed to replicate these ratings. Results suggested that when rating e-cigarette valence, instructing raters to rate from their own subjective perspective produced reliable results, and nine raters were deemed the optimal number of raters. We expect these findings to inform future content analyses of e-cigarette valence. The study procedures can be applied to crowdsourced content analyses of other health-related media content to determine appropriate rating instructions and the number of raters.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1627</offset><text>Electronic cigarettes (e-cigarettes) are at the center of a public health debate. Current e-cigarette use among high school students increased from 1.5% in 2011 to 20.8% in 2018; among middle school students it increased from 0.6% in 2011 to 4.9% in 2018. The Surgeon General issued a report warning against youth e-cigarette use that voiced concerns about addiction and other health effects. On the other hand, since e-cigarettes are less toxic than traditional cigarettes, some propose that using e-cigarettes could reduce harm for adult smokers (; Warner, 2018). Amidst conflicting views, communication about e-cigarettes through news articles and unregulated e-cigarette advertising have the potential to shape public perceptions about e-cigarette use. This backdrop calls for close monitoring of the public communication environment about e-cigarettes.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2485</offset><text>In response, many studies have conducted analyses of e-cigarette content in newspapers and social media sources (e.g.,). However, most studies have used expert coding, where a pre-defined coding scheme is used to determine, for example, the sentiment or valence towards e-cigarettes. We propose that using crowdsourcing–utilizing a crowd of workers–(; Sheehan, 2017) to rate the valence of e-cigarette related media content can be particularly useful when aiming to predict public intentions from media content analysis, and given the complex nature of e-cigarette valence. In doing so, the objective of the current article is to outline and provide a methodological framework and guidelines to address two methodological issues–specifically, 1) which perspective to use for rating instructions; and 2) the most efficient number of workers needed to rate the valence of e-cigarette media texts.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3386</offset><text>Below, we first introduce the context of measuring the valence of e-cigarette texts and elaborate on why crowdsourced rating may be conducive to this context. Second, we present an experiment that manipulated the instructions to crowdworkers to change their perspectives when rating the valence of e-cigarette texts. We report the instruction that achieved the highest reliability. Third, we further analyze the experimental results to determine the minimum number of crowdsourced workers needed to replicate these results. Together we expect these findings to provide practical guidelines for future studies using crowdsourced methods for content analysis of e-cigarette valence, as well as other health communication topics.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>4113</offset><text>Assessing valence perceptions of e-cigarette media content with crowdsourcing</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4191</offset><text>The present study stems from a larger project that aimed to characterize the perceived valence of media content about e-cigarettes to examine how this valence content may affect population intentions to use e-cigarettes. Whether media coverage is mostly supportive of using e-cigarettes and the e-cigarette industry (i.e., pro-ecig valence) or mostly against using e-cigarettes and the e-cigarette industry (i.e., anti-ecig valence) may impact the public’s attitudes and intentions towards using e-cigarettes (Yang, Liu, Lochbuehler, &amp; Hornik, 2017). E-cigarette use has become an increasingly salient public health issue. For example, youth use of e-cigarettes has increased at an alarming rate, but some propose that e-cigarettes can be used as a harm-reduction tool for adult smokers (Warner, 2018). As such, media content about e-cigarettes is expected to be complex and varied in valence.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5087</offset><text>Our decision to use crowdsourced raters (from Amazon Mechanical Turk [MTurk]) to assess the valence of e-cigarette media texts instead of traditional expert coding was shaped by both our aim to predict public intentions to use e-cigarettes from the valence of a large corpus of media coverage and our expectation of valence complexity. First, it made sense to use lay crowdsourced raters instead of expert coders since raters would more accurately represent a typical reader’s understanding of e-cigarette media texts. Compared to expert coders who may view e-cigarette media texts differently due to their knowledge and expertise on e-cigarettes, crowdsourced workers may relatively better characterize valence from the public’s point of view. Research shows that samples from MTurk reasonably represent the U.S. public in that their results are no different from Internet panels or nationally representative samples. Also, given our large corpus of media texts, we chose to task crowdsourced raters who are easier to recruit in large numbers and typically do not require extensive training. Second, valence of e-cigarette coverage is likely to be complex and may be better assessed with crowdsourced rating. Research has consistently shown that crowds produce evaluations of content similar to that of a smaller number of experts even when content is complex and latent.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6464</offset><text>This logic can also be applied to our study context of rating e-cigarette valence. The valence of e-cigarette texts is not easy to comprehensively describe through a codebook for expert coders because of multiple valence dimensions. For example, an article describing an event where e-cigarettes are banned may illustrate an anti-ecig valence while an author’s upset reaction to the ban may indicate pro-ecig sentiment. Instead, relying on the interpretation of the texts from a larger number of raters may yield a valence estimate more representative of typical readers’ perceptions, which may predict population opinion more accurately.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>7107</offset><text>Maximizing the reliability of crowdsourced ratings: Perspective</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>7171</offset><text>The goal of measurement is validity, in this case assessing how well a measure of valence captures perceived valence that can accurately predict population intentions. While the test of validity is beyond the scope of this study, reliability, in turn, is measurable and a prerequisite for validity. We compare which crowdsourced rating procedures (meant to validly measure population-perceived valence) yield maximum reliability. The standards for this comparison must reflect the assumptions of how content is characterized. Traditionally, the goal to describe content objectively has led experts to code the valence of media content by treating it as manifest content. Manifest content is content that is “believed to have an objective pattern that all coders should uncover by sorting through symbols and recognizing the connections among them” (, p. 259). Previous tobacco-related content analyses relied on expert coding using detailed coding schemes that a priori defined valence in specific instances and contexts. For example, a codebook might specify that descriptions of tobacco regulations and secondhand smoke issues should be coded as anti-tobacco valence. The level of agreement across expert coders indicated whether the standard set by the codebook could be reliably reproduced.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>8470</offset><text>On the other hand, when the goal is to capture a typical reader’s impression of valence to predict population intentions, crowdsourced ratings that treat valence as latent content may be more appropriate. Latent content is content in which researchers “put precedence with the coders’ judgments and believe that the elements in the content are symbols that require viewers to access their pre-existing mental schema in order to judge the meaning in the content” (, p. 259). The agreement across crowdsourced raters indicates that they are reliably converging on a shared norm or mental schema. In order to maximize the reliability of crowdsourced ratings, the task for researchers is to devise definitions and instructions that will get raters to access schemas that lead to high agreement.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>9269</offset><text>With this standard in mind, it is reasonable to assume that the perspective raters take may influence their level of agreement. In the context of rating the sentiment toward political actors, only one study has examined the impact of perspectives on rating outcomes by asking raters for either “explicit evaluations”, “evaluation”, or to “take the perspective of the target of opinion”. However, to the best of our knowledge, there are no studies that examine the impact of perspectives in the domain of rating the valence of e-cigarette related media texts. In addition, there is limited research on how the level of agreement across raters is affected by differing rating perspectives.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>9969</offset><text>Nonetheless, instructions for crowdsourced text analyses do vary, and, intended or not, seem to call for different perspectives. For instance, when asking crowdsourced workers to rate the ideological slant of news articles, Budak and colleagues (2016) asked: “Is the article generally positive, neutral, or negative toward members of the Democratic party?” The wording “is the article” implicitly suggests there is an objective, “true” slant that exists, independent of subjective interpretation. These instructions imply the perspective of manifest content. In contrast, when Benoit and colleagues had crowdsourced workers rate the ideological slant of policies, they asked: “If you believe the sentence expresses a centrist position on economic or social policy…click the ‘neither…nor…’ position on the scale.” Here the stem “if you believe” directs raters to use their own perspective and subjective judgment. These instructions reflect the perspective of latent content. Thus, while instructions for crowdsourced ratings vary in the perspectives requested, the question of which of these instructions can maximize rater agreement in the context of assessing valence perceptions of e-cigarette media content remains unaddressed.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>11231</offset><text>The current study aims to fill this gap by experimentally varying perspectives in rating instructions and comparing the agreement levels produced by each instruction. Specifically, the study compared instructions implying an objective perspective such as those used by (Objective-text), and instructions requesting subjective judgments of the rater’s own opinion such as those used by (Subjective-own opinion). In addition, we considered two other subjective instructions that asked for ratings from the perspective of “most people” (Subjective-most people) and “someone who only knows a little about e-cigarettes” (Subjective-naïve people). We expected that taking the perspective of others might reduce individual biases and lead to more homogenous ratings.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>12002</offset><text>RQ1: Among the four perspectives: Objective-text, Subjective-own opinion, Subjective-most people, Subjective-naïve people, which one(s) will yield the highest level of agreement across raters when rating the valence of e-cigarette media content?</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>12249</offset><text>Maximizing the efficiency of crowdsourced ratings: Optimal number of raters</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>12325</offset><text>Another important concern when using crowdsourced rating is maximizing efficiency. Sampling theory predicts that a large number of raters will converge on a more accurate estimate of valence compared to a small number of raters. However, a large number of raters requires more resources, and may therefore be less efficient. Therefore, we examined the optimal number of raters needed to reach accuracy. We define the optimal number as the minimum number of raters needed to closely reproduce the pattern of rating results produced by a larger set of raters (from the condition that was most successful in our instructions experiment). Prior research in educational and medical settings has used criteria such as the deviation of ratings produced by fewer raters from estimates produced by a large number of raters (e.g., smallest standard errors). examined the issue of optimal rater sample size to achieve accurate evaluation ratings of anti-tobacco messages. They used multiple criteria including Pearson correlation, deviation of ratings produced by fewer raters from the original data (i.e., mean difference), proportions of misspecification errors, and classification of messages into top vs. bottom rated groups.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>13544</offset><text>Following this line of inquiry, the current study used two criteria used by, Pearson correlations and mean differences between the original sample and subsamples of fewer raters. These were used to gauge the extent to which subsamples of fewer raters can reproduce the percentage of raters who made the correct choice in the original sample. In addition, we propose two new metrics, percentage of “Any Mistakes” and “Big Mistakes” to maximally reduce rating errors. These metrics help mitigate against misspecification (particularly extreme deviation) of valence labels. We used these criteria to identify the minimum number of raters required.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>14197</offset><text>Bootstrapping methods were used to draw subsamples of fewer raters and to empirically estimate the four metrics. Bootstrapping is a nonparametric simulation-based approach that is most useful when strong assumptions of normal sampling distributions cannot be made or are unknown, or when sample sizes are relatively small. The key underlying logic for performing bootstrapping in our study context is to treat the rater sample as the population, and to iteratively conduct random resampling (with replacement) from the sample to mimic the original sampling process. The new subsamples generated by the resampling processes form empirical sampling distributions that allow for calculations of confidence intervals and hypothesis testing. Bootstrapping is particularly appropriate for comparing mean consistency across different rater sizes because rating data is by nature skewed (in fact, the higher the consistency, the more skewed the distribution), and our sample sizes (both for texts and raters) are relatively small. Applying bootstrapping procedures, we aimed to identify an efficient rater size by comparing the Pearson correlations and mean differences between the original sample and the new subsamples and by calculating the percentage of “Any Mistakes” and “Big Mistakes” in subsamples.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>15504</offset><text>RQ2: What is the minimum number of raters necessary to provide valence ratings that sufficiently reproduce the results from a larger set of raters and avoids misspecification errors when rating e-cigarette media content?</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>15725</offset><text>Method</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>15732</offset><text>Study design</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15745</offset><text>Raters (N=526) were recruited from Amazon Mechanical Turk’s platform to participate in a preliminary qualification task in June 2016. Raters who were located in the US; had a Human Intelligence Task (HIT) approval rate greater than 95%; and had completed more than 100 HITs were invited. Raters had a mean age of 35 (SD=12); almost half had a college degree or more; and 78% were White, 8% Black, and 6% Hispanic. The qualification task familiarized raters with the condition-specific definitions of e-cigarette valence (see Table 1), provided them with example texts, and asked them to rate texts judged by the investigators to have a clear valencei using the rating instructions to which they were randomly assigned (one of four). This step trained raters on the task and allowed us to exclude low-quality raters who were inattentive or unable to follow instructions carefully. Only those who passed the qualification were given the opportunity to participate in the main experiment that took place within a week of the qualification task.ii</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16791</offset><text>In the main experiment, 20 raters in each condition from the pool of qualified raters entered the same conditions to which they were originally assigned (n=20 per condition; N=80) on a first come basis. The main experiment asked raters to rate the valence of 34 texts randomly selected from a pool of media articles (media articles published between May 2014–December 2015; Associated Press [n=6], newspapers [n=6], websites [n=12], and broadcast TV news [n=10]). We required each article to have at least three e-cigarette relevant terms to ensure that some portion of the article was centrally about e-cigarettes, and not just a passing mention of them.iii The sample size of 34 texts was determined by following the formula for judging consistency of ratings, which is a function of the smallest estimated proportion of a certain valence label in the population of texts (.33; assuming equal proportions across the three valence categories: anti-ecig, pro-ecig, and not applicable), the smallest acceptable Krippendorff’s alpha (.667), and the desired level of significance (.05).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>17879</offset><text>Main experiment procedure</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17905</offset><text>The main experiment was hosted on the Qualtrics survey platform. Raters were first reminded of the definition for e-cigarettes and condition-specific definitions of the valence categories: anti-ecig, pro-ecig, and not applicable. They then rated 34 e-cigarette texts, one text at a time.iv To reduce rating fatigue, e-cigarette-relevant words in the text were highlighted.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>18278</offset><text>Conditions.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18290</offset><text>The four conditions of the qualification task and main experiment manipulated the perspective from which raters were asked to make a judgment (i.e., Objective-text, Subjective-own opinion, Subjective-most people, Subjective-naïve people). Condition-specific definitions and question wordings are listed in Table 1.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>18606</offset><text>Measures.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18616</offset><text>The majority of texts in the corpus were about e-cigarettes, but due to the automated nature of text retrieval, a few were not. Therefore, before rating the valence of each given text, raters were first asked whether some part of the text was relevant to e-cigarettes. Those who answered yes were then asked whether the e-cigarette relevant content was either pro-ecig, anti-ecig, or not applicable. It is important to note that the latter question about valence was framed differently depending on the condition to which raters were assigned. For example, for raters in Condition 1 (Objective-text), the question was framed as: “For the content that is ecig-relevant, is it mostly anti-ecig, pro-ecig or not applicable?” The phrase, “is it” was used to consistently instruct the rater to rate from the objective perspective of the text. In contrast, the question for Condition 2 (Subjective-own opinion) reads: “For the content that is ecig-relevant, would you understand it to be mostly anti-ecig, pro-ecig or not applicable?” The phrase, “would you understand it to be” was used to instruct raters to judge from their own perspective or opinion.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>19781</offset><text>Analysis: Instructions for reliable ratings</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19825</offset><text>First, to assess the level of rating consistency across raters by condition, 95% and 83% confidence intervals for Krippendorff’s alpha were calculated for each condition using bootstrapping. Krippendorff’s alpha was chosen as the primary metric as it provides the degree of agreement across multiple raters within a condition while adjusting for chance agreement. Eighty three percent confidence intervals were computed because they allow direct comparison between estimates; if the 83% CIs of two alpha estimates do not overlap, we infer that the alphas are not equal at the p&lt;.05 level, two-tailed. Our second measure of consistency re-coded raters’ valence labels according to how consistent they were with the within-condition rating consensus for each text.v For example, if the consensus for a text in Condition 1 was anti-ecig, then anti-ecig ratings were assigned a score of 3 (most consistent), NA ratings a score of 2, and pro-ecig ratings a score of 1 (least consistent).vi We conducted a multilevel regression analysis with these 3-level consistency scores as the dependent variable and condition as a categorical independent variable, controlling for random variations of rater and text differences. We used Bonferroni-corrected post-hoc pair-wise comparisons to examine differences in consistency scores across all pairs of conditions.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>21181</offset><text>Analysis: Optimal number of raters</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21216</offset><text>The rating results produced by the 20 raters in the condition that achieved the highest agreement were deemed as reliable and were used to determine the minimum number of raters needed to replicate ratings by the full sample of raters. Specifically, four steps were involved.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>21492</offset><text>Step 1: Determine “majority score” of texts.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21541</offset><text>First, the “majority” valence label was determined for each of the 34 texts based on the consensus across the 20 raters. We used the label of the mode category as the “majority” label for the text unless the mode percentage was below 50%. In that case, we labeled the text NA instead since in such cases the percentages of raters who chose pro-ecig and anti-ecig labels were relatively equal, thus satisfying the definition of NA (see Table 1). For each text, the percentage of raters who chose the “majority” label category was named the “majority score”, reflecting the extent to which raters were able to converge on the “majority” label.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>22203</offset><text>Step 2: Draw bootstrap samples.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22235</offset><text>After calculating the “majority scores” for all 34 texts, our next step was to estimate rating outcomes produced by fewer raters. Following prior practices, bootstrapping was used to draw multiple random subsamples with replacement from the pool of 20 raters, with rater sample sizes ranging from one to 20 with an increment of one; 500 bootstrap samples were drawn for each sample size.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>22627</offset><text>Step 3: Calculate “sample score” for each bootstrap sample.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22691</offset><text>Next, for each bootstrap sample, we calculated the percentage of raters who chose the “majority” label for each of the 34 texts, which we called the “sample score”. This step produced 500 “sample scores” for each text at each sample size (i.e., for a given text, each of the 500 bootstrap samples drawn for five raters yielded one “sample score” for this text). These sample scores were used in the next stage for comparisons with the original data (i.e., “majority score”) using various criteria.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>23209</offset><text>Step 4: Compare ratings with multiple criteria.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23257</offset><text>First, two criteria were used to compare the rating estimates from smaller samples (“sample scores”) with the ratings from the original data (“majority scores”). The first criterion was 1) Pearson Correlation Coefficients. Correlations between all “sample scores” derived from the bootstrap samples and the corresponding “majority scores” for the 34 texts at each sample size were calculated. Then the average correlation across 500 bootstrap samples with the same rater sample size was calculated (Figure 1, Panel A). This procedure yielded 20 average correlation coefficients (i.e., one for each sample size aggregating the results of the 500 bootstrap samples) each indicating the conformity of smaller sample size ratings with the full sample ratings. Higher correlation coefficients indicate that the bootstrap samples reproduce the original data better.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24133</offset><text>The second criterion was the 2) Aggregated Mean Absolute Differences between the “sample scores” and the “majority scores” at each sample size. Similar to the first criterion, for each of the bootstrap samples, the absolute difference between the “sample score” and the “majority score” was calculated for each text, and then summed across 34 texts to get an overall estimation of how much that particular bootstrap sample deviated from the original data. We then averaged the difference scores over 500 bootstrap samples within each sample size to estimate how much deviation from the original data the raters at each sample size would produce (Figure 1, Panel B). The smaller the absolute differences, the better the bootstrap samples reproduced the original rating results. These two criteria provide quantifiable metrics to identify a reasonable threshold in sample sizes–i.e., a point where adding an additional rater would not result in either much higher correlations or much smaller difference scores.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25161</offset><text>In addition to these two criteria, we also considered the best number of raters to avoid rating errors, particularly ones that deviate too far from the “majority” label. Therefore, two additional criteria, 3) Percentage of “Any Mistakes” and 4) Percentage of “Big Mistakes” were proposed. “Any mistakes” refer to instances where the percentage of raters in a bootstrap sample who chose the “majority” label was less than 50% (e.g., 40% chose pro-ecig, when the “majority” label is pro-ecig); “big mistakes” refer to instances where 50% or more of the raters in a bootstrap sample chose the opposite valence category relative to the “majority” label (e.g., 60% chose anti-ecig, when the “majority” label is pro-ecig). The fourth criterion was applied only to texts that had either pro-ecig or anti-ecig “majority” labels (n = 26). At each sample size, we calculated the average percentage of “any mistakes” and “big mistakes” across the total number of texts (34 or 26) and across the 500 bootstrap samples (Figure 1, Panels C and D). The smaller the average percentage of mistakes, the better the bootstrap samples reproduced the original rating results.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>26364</offset><text>Considering that we have four criteria that each represent different aspects of rating, implications of all criteria need to be considered simultaneously to determine the optimal rater size. Therefore, we considered a rater size that 1) does not violate conclusions based on any of the criteria, 2) is determined by the largest minimum number required by each of the criteria; and 3) represents the smallest rater size possible from a cost-benefit perspective.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>26825</offset><text>Results: Instructions for reliable ratings</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26868</offset><text>Table 2 presents Krippendorff’s alpha estimates and their 95% and 83% confidence intervals by condition. Condition 2 (Subjective-own opinion) yielded the highest estimate (.77) indicating consensus across the 20 raters was highest when rating the texts based on their own understanding. However, it is important to note that the confidence intervals overlapped across conditions. Table 3 presents the results from a multilevel regression model predicting the 3-level consistency scores from the four conditions. Table 4 provides post-hoc comparisons across each pair of conditions. The results suggest that rating from raters’ own perspective (Condition 2) and rating from the perspective of most people (Condition 3) led to more consistent ratings compared to rating from the perspective of the objective text (Condition 1). Taken together, results indicate that ratings based on one’s own understanding may achieve the most homogenous ratings of e-cigarette valence in media texts.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>27858</offset><text>Results: Optimal number of raters</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27892</offset><text>The four criteria were examined together to determine the optimal number of raters needed. Figure 2 plots the correlation coefficients between the “majority scores” and aggregated “sample scores” for each rater sample size, and the growth rates which reflect the percent increase in correlation coefficients when comparing rater size n to rater size n - 1  As demonstrated in Figure 2, while the magnitude of correlations gradually increased with each additional rater, after about seven raters, the growth rate started to reach a saturation point. Particularly, adding a tenth rater to the sample of nine only minimally increased (1.22%) the strength of correlations, indicating that increasing the sample size beyond nine raters would not increase efficiency.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>28662</offset><text>The mean absolute differences between the “sample scores” and “majority scores” were examined next. We plotted the average absolute differences at each sample size as well as the decrease rates  with each additional rater in Figure 3. The absolute difference values demonstrated a gradually decreasing trend as the sample size increased. Each additional rater substantially reduced the absolute differences between sample scores and “majority scores”, until reaching a saturation point of around nine raters. Although there were fluctuations in absolute differences with 10-20 raters, on average changes after this point were small.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29307</offset><text>The last two criteria were related to the likelihood of wrong decisions on sample labels compared to the “majority” labels. As shown in Figure 4, estimates of “any mistakes” decreased in general as the number of raters increased. However, even numbers of raters, relative to odd numbers of raters, tended to produce higher percentages of “any mistakes”. The chances of having more than one mode (i.e., most frequently selected valence category) are usually higher with an even number of raters, thus making it more difficult to have a single dominant category (≥50% according to our definition). In contrast, odd numbers of raters are less likely to have tied ratings. Therefore, to achieve consensus, odd numbers of raters are preferable given our method of determining the “majority” text labels.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30124</offset><text>As shown in Figure 5, the estimated average percentages of “big mistakes” were relatively low across all sample sizes, ranging from 0% to 4%. The biggest jump was observed with five raters, indicating that with at least five raters, the percentage of extreme misspecification occurring (i.e., choosing an opposite valence label) could be effectively lowered to 1% or less.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30501</offset><text>Finally, the results from all four criteria were considered together to determine the optimal number of raters for this task. Criterion #1 indicated that the correlation with the “majority score” reached a saturation point at around seven raters; criterion #2 found the saturation point to be around nine raters; criterion #3 suggested that an odd number of raters should be considered; and criterion #4 recommended that at least five raters are needed to minimize the likelihood of “big mistakes”. Therefore, based on the three principles laid out earlier, we determined that nine is the minimum number that 1) does not violate any of the four criteria, 2) is the largest minimum number among the requirements of each criterion, and 3) represents the smallest rater sample size possible (i.e., any odd number that is larger than nine can produce estimates close enough to the “majority score” but is not as cost-effective).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>31438</offset><text>Conclusions and Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>31465</offset><text>Summary of Results</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>31484</offset><text>The present study found that rating from raters’ own perspectives (Condition 2: Subjective-own opinion) resulted in both the highest estimate of Krippendorff’s alpha (.77) and the most consistent 3-level consistency score compared to rating from an objective perspective (Condition 1: Objective-text). Taken together, in the context of rating the valence towards e-cigarettes with the objective to predict public response from ratings, we recommend instructing raters to rate from their own perspective to elicit higher agreement across raters. The minimum number of raters needed to replicate the proportion of raters who agreed on the “majority” valence label of e-cigarette texts from the full rater sample (from Condition 2) and to avoid making mistakes on judgments of text valence was nine. The procedures and methods used to determine appropriate instructions and number of raters can be applied to future studies in different contexts and domains of health communication.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>32472</offset><text>Implications</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>32485</offset><text>Most surprisingly, instructing raters to rate the valence of e-cigarette media texts from their own perspective yielded the most homogenous ratings particularly in comparison to an instruction frequently used in previous research where raters were asked to rate with an objective perspective. While the study results cannot explain why this was so, one can speculate about potential mechanisms. Rating from raters’ own understanding may have relieved them of the burden of carrying out a somewhat ambiguous task when rating complex, latent content. For example, asking raters “Is the text pro-, anti- or NA?” (Condition 1 Objective-text) could have increased raters’ cognitive burden by implying that there is an objectively right or wrong answer. Rating from another group’s perspective (i.e., Condition 4 Subjective-Naïve people and Condition 3 Subjective-Most people) could have been difficult for raters because they needed to think from other people’s perspectives. These cognitive burdens may have led to less agreement in those conditions, as well as potentially biased ratings depending on raters’ assumptions about naïve people and most people’s attitudes towards e-cigarettes. Of note, appropriate instructions may differ depending on the nature of the content analysis task and the health topic of interest. For example, an objective perspective may yield more homogenous ratings when rating more manifest content such as well-defined themes (e.g., mentions about youth substance use). Or health topics with social connotations (e.g., stigmatized media representations of obesity) may benefit from instructing participants to rate with most people in mind. These of course are empirical questions that can be addressed with methods utilized in the current study.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>34277</offset><text>Regarding the issue of determining the minimum number of crowdsourced raters needed, it is important to note that there is no single metric for making this choice. Decisions about how many raters are needed will be heavily dependent on the ambiguity of the health communication context, the rule for deciding upon the “majority” label of texts, and the criteria considered. As illustrated in this study, a single criterion does not suffice to make the most informed decision. We chose the optimal number of raters by taking into consideration two dimensions: close reproduction of the original data and minimum likelihood of rating errors. It is worth noting that our two new criteria, “any mistakes” and “big mistakes”, led us to choose an odd number of raters, no smaller than five, in order to maximally avoid misspecification of valence labels, particularly the opposite ones. Minimizing errors was especially important in this study because these ratings will be used for media effects analyses where accurately assessing the direction of valence is crucial for predicting population-level effects. Thus, we recommend that future studies carefully evaluate or perhaps modify the metrics used here based on their rating goals and specific health behavior contexts, to ensure that they serve their rating purpose.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>35606</offset><text>The study has some limitations. When examining the effect of different instructions on levels of rater agreement, confidence intervals for the four Krippendorff’s alphas overlapped and the highest estimate was .77. Considering that it is often more difficult to achieve high reliability for non-expert ratings of a complex latent construct, .77 may be adequate, but not as high as desired. One reason for lower reliability could be that rating the valence of texts about e-cigarettes, may have been difficult for raters since e-cigarettes are relatively new products. Thus, the context of the health topic should be considered when interpreting reliability data.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>36271</offset><text>While the bootstrapping methods employed in the current study provide a helpful methodological framework for future efforts to determine empirically an optimal rater sample size, it is important to point out two caveats. First, the performance of bootstrapped samples is always bounded by the performance of the full sample with which researchers start. Namely, determining an optimal rater size can be achieved in a relatively rather than absolutely. Therefore, it is important that ratings of the full sample are of the highest quality possible. Second, while the use of multiple criteria can help make informed decisions by accounting for various dimensions of accuracy, it is at the researchers’ discretion to decide which dimensions to include, and to construct rules and specify cutoff points for each criterion. Researcher judgment also weighs heavily in how to inspect and interpret resampling results when formal statistical tests are not viable. Therefore, it is important to fully acknowledge that subjective decisions may exist in this process, and reasonable justifications for each step are necessary.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>37389</offset><text>Finally, the current study used a sample of Mturk raters. While there is research suggesting that similar study conclusions can be drawn from Mturk populations compared to larger probability samples or in-lab participants, if crowdworkers are generally homogenous on characteristics that might affect their judgment (e.g., education), there is a risk that the estimates will not represent how the texts will be read by the population as a whole. Thus, future studies may benefit from striving to acquire a more diverse crowdworker sample to avoid bias.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>37942</offset><text>Despite these limitations, this study is important because it discusses standards of reliability and efficiency when using crowdsourced ratings in the context of assessing valence perceptions of e-cigarette media texts and presents methods and procedures for evaluating these standards. We expect the results will inform more reliable and efficient future research using crowdsourced ratings in health communication.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>38359</offset><text>The qualification task included 6 texts (e-cig irrelevant [n=1], pro-ecig [n=2], anti-ecig [n=2], or not applicable [n=1]). We qualified raters based on whether they correctly answered valence or relevance for the 5 texts that were clear in valence/relevance (i.e., e-cig irrelevant, pro-ecig and anti-ecig texts).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>38674</offset><text>The proportion of qualified participants was 49% on average and did not differ by condition (χ2 (3) = 2.93, p = .40).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>38794</offset><text>To identify e-cigarette related texts, we compiled a list of e-cigarette keyword rules, which were developed through expert consensus and an iterative process of adding and dropping keywords with a training set of broadly tobacco-related texts based on precision and recall. Final precision for e-cigarette texts was &gt;.97 for all sources and recall was 1.0. The final set of keywords including e(−)cig, e(−)cigarette, electronic cigarette, e(−)hookah, hookah pen, vape, vaping, blu, njoy, ego, etc., were used to retrieve e-cigarette related articles and determine whether an article was mostly about e-cigarettes. The three mentions cutoff demonstrated precision of .85 and recall of .80 in distinguishing between more than passing and passing mention texts across different types of media.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>39592</offset><text>We acknowledge that raters can rate smaller units of text such as sentences or paragraphs. The present study however focuses on the entire text as the unit of analysis because 1) it allows raters to rate in a more naturalistic setting (i.e., readers are expected to understand entire texts as a whole vs. interpreting disconnected chunks of text individually); and 2) because it allows assessment of the general impression of the text which dovetails with the overall project goal to predict the public’s intentions from analyzed content.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>40133</offset><text>Determining the within-condition consensus for each text followed the rule used to determine the “majority valence” label of texts described next in the analysis of number of raters needed.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>40327</offset><text>When the consensus for a certain text within a certain condition was NA, for those who rated the text as either pro-ecig or anti-ecig, the proportion of raters choosing either pro-ecig or anti-ecig was used to judge the consistency score for these raters. For example, if the proportion of those choosing pro-ecig was larger than anti-ecig, those who rated the text as pro-ecig received a score of 2 while those who rated it as anti-ecig were assigned a score of 1.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>40793</offset><text>References</text></passage><passage><infon key="fpage">226</infon><infon key="lpage">229</infon><infon key="name_0">surname:Allem;given-names:J-P</infon><infon key="name_1">surname:Escobedo;given-names:P</infon><infon key="name_2">surname:Chu;given-names:K-H</infon><infon key="name_3">surname:Soto;given-names:DW</infon><infon key="name_4">surname:Cruz;given-names:TB</infon><infon key="name_5">surname:Unger;given-names:JB</infon><infon key="pub-id_doi">10.1136/tobaccocontrol-2015-052757</infon><infon key="pub-id_pmid">26956467</infon><infon key="section_type">REF</infon><infon key="source">Tobacco Control</infon><infon key="type">ref</infon><infon key="volume">26</infon><infon key="year">2017</infon><offset>40804</offset><text>Campaigns and counter campaigns: Reactions on Twitter to e-cigarette education</text></passage><passage><infon key="fpage">278</infon><infon key="lpage">295</infon><infon key="name_0">surname:Benoit;given-names:K</infon><infon key="name_1">surname:Conway;given-names:D</infon><infon key="name_2">surname:Lauderdale;given-names:BE</infon><infon key="name_3">surname:Laver;given-names:M</infon><infon key="name_4">surname:Mikhaylov;given-names:S</infon><infon key="section_type">REF</infon><infon key="source">American Political Science Review</infon><infon key="type">ref</infon><infon key="volume">110</infon><infon key="year">2016</infon><offset>40883</offset><text>Crowd-sourced text analysis: Reproducible and agile production of political data</text></passage><passage><infon key="fpage">351</infon><infon key="lpage">368</infon><infon key="name_0">surname:Berinsky;given-names:AJ</infon><infon key="name_1">surname:Huber;given-names:GA</infon><infon key="name_2">surname:Lenz;given-names:GS</infon><infon key="pub-id_doi">10.1093/pan/mpr057</infon><infon key="section_type">REF</infon><infon key="source">Political Analysis</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2012</infon><offset>40964</offset><text>Evaluating online labor markets for experimental research: Amazon.com’s Mechanical Turk</text></passage><passage><infon key="fpage">269</infon><infon key="lpage">287</infon><infon key="name_0">surname:Bloch;given-names:DA</infon><infon key="name_1">surname:Kraemer;given-names:HC</infon><infon key="pub-id_doi">10.2307/2532052</infon><infon key="pub-id_pmid">2655731</infon><infon key="section_type">REF</infon><infon key="source">Biometrics</infon><infon key="type">ref</infon><infon key="volume">45</infon><infon key="year">1989</infon><offset>41054</offset><text>2 x 2 Kappa Coefficients: Measures of Agreement or Association</text></passage><passage><infon key="fpage">250</infon><infon key="lpage">271</infon><infon key="name_0">surname:Budak;given-names:C</infon><infon key="name_1">surname:Goel;given-names:S</infon><infon key="name_2">surname:Rao;given-names:JM</infon><infon key="pub-id_doi">10.1093/poq/nfw007</infon><infon key="section_type">REF</infon><infon key="source">Public Opinion Quarterly</infon><infon key="type">ref</infon><infon key="volume">80</infon><infon key="year">2016</infon><offset>41117</offset><text>Fair and balanced?: Quantifying media bias through crowdsourced content analysis</text></passage><passage><infon key="fpage">3</infon><infon key="lpage">5</infon><infon key="name_0">surname:Buhrmester;given-names:M</infon><infon key="name_1">surname:Kwang;given-names:T</infon><infon key="name_2">surname:Gosling;given-names:SD</infon><infon key="pub-id_doi">10.1177/1745691610393980</infon><infon key="pub-id_pmid">26162106</infon><infon key="section_type">REF</infon><infon key="source">Perspectives on Psychological Science</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2011</infon><offset>41198</offset><text>Amazon’s Mechanical Turk: A new source of inexpensive, yet high-quality, data?</text></passage><passage><infon key="fpage">2156</infon><infon key="lpage">2160</infon><infon key="name_0">surname:Casler;given-names:K</infon><infon key="name_1">surname:Bickel;given-names:L</infon><infon key="name_2">surname:Hackett;given-names:E</infon><infon key="pub-id_doi">10.1016/j.chb.2013.05.009</infon><infon key="section_type">REF</infon><infon key="source">Computers in Human Behavior</infon><infon key="type">ref</infon><infon key="volume">29</infon><infon key="year">2013</infon><offset>41279</offset><text>Separate but equal? A comparison of participants and data gathered via Amazon’s MTurk, social media, and face-to-face behavioral testing</text></passage><passage><infon key="fpage">112</infon><infon key="lpage">130</infon><infon key="name_0">surname:Chandler;given-names:J</infon><infon key="name_1">surname:Mueller;given-names:P</infon><infon key="name_2">surname:Paolacci;given-names:G</infon><infon key="pub-id_doi">10.3758/s13428-013-0365-7</infon><infon key="pub-id_pmid">23835650</infon><infon key="section_type">REF</infon><infon key="source">Behavior Research Methods</infon><infon key="type">ref</infon><infon key="volume">46</infon><infon key="year">2014</infon><offset>41418</offset><text>Nonnaïveté among Amazon Mechanical Turk workers: Consequences and solutions for behavioral researchers</text></passage><passage><infon key="fpage">e208</infon><infon key="name_0">surname:Cole-Lewis;given-names:H</infon><infon key="name_1">surname:Varghese;given-names:A</infon><infon key="name_2">surname:Sanders;given-names:A</infon><infon key="name_3">surname:Schwarz;given-names:M</infon><infon key="name_4">surname:Pugatch;given-names:J</infon><infon key="name_5">surname:Augustson;given-names:E</infon><infon key="pub-id_doi">10.2196/jmir.4392</infon><infon key="pub-id_pmid">26307512</infon><infon key="section_type">REF</infon><infon key="source">Journal of Medical Internet Research</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2015</infon><offset>41523</offset><text>Assessing electronic cigarette-related tweets for sentiment and content using supervised machine learning</text></passage><passage><infon key="fpage">1276</infon><infon key="lpage">1277</infon><infon key="name_0">surname:Cullen;given-names:KA</infon><infon key="pub-id_doi">10.15585/mmwr.mm6745a5</infon><infon key="pub-id_pmid">30439875</infon><infon key="section_type">REF</infon><infon key="source">MMWR. Morbidity and Mortality Weekly Report</infon><infon key="type">ref</infon><infon key="volume">67</infon><infon key="year">2018</infon><offset>41629</offset><text>Notes from the field: Use of electronic cigarettes and any tobacco product among middle and high school students — United States, 2011–2018</text></passage><passage><infon key="fpage">ii75</infon><infon key="lpage">ii81</infon><infon key="name_0">surname:Durrant;given-names:R</infon><infon key="name_1">surname:Wakefield;given-names:M</infon><infon key="name_2">surname:McLeod;given-names:K</infon><infon key="name_3">surname:Clegg-Smith;given-names:K</infon><infon key="name_4">surname:Chapman;given-names:S</infon><infon key="pub-id_pmid">12878777</infon><infon key="section_type">REF</infon><infon key="source">Tobacco Control</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2003</infon><offset>41773</offset><text>Tobacco in the news: An analysis of newspaper coverage of tobacco issues in australia, 2001</text></passage><passage><infon key="fpage">iii17</infon><infon key="issue">suppl 3</infon><infon key="lpage">iii25</infon><infon key="name_0">surname:Emery;given-names:SL</infon><infon key="name_1">surname:Vera;given-names:L</infon><infon key="name_2">surname:Huang;given-names:J</infon><infon key="name_3">surname:Szczypka;given-names:G</infon><infon key="pub-id_doi">10.1136/tobaccocontrol-2014-051648</infon><infon key="pub-id_pmid">24935893</infon><infon key="section_type">REF</infon><infon key="source">Tobacco Control</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2014</infon><offset>41865</offset><text>Wanna know about vaping? Patterns of message exposure, seeking and sharing information about e-cigarettes across media platforms</text></passage><passage><infon key="fpage">686</infon><infon key="lpage">693</infon><infon key="name_0">surname:Farrelly;given-names:MC</infon><infon key="name_1">surname:Duke;given-names:JC</infon><infon key="name_2">surname:Crankshaw;given-names:EC</infon><infon key="name_3">surname:Eggers;given-names:ME</infon><infon key="name_4">surname:Lee;given-names:YO</infon><infon key="name_5">surname:Nonnemaker;given-names:JM</infon><infon key="name_6">surname:Porter;given-names:L</infon><infon key="pub-id_doi">10.1016/j.amepre.2015.05.010</infon><infon key="pub-id_pmid">26163170</infon><infon key="section_type">REF</infon><infon key="source">American Journal of Preventive Medicine</infon><infon key="type">ref</infon><infon key="volume">49</infon><infon key="year">2015</infon><offset>41994</offset><text>A randomized trial of the effect of e-cigarette TV advertisements on intentions to use e-cigarettes</text></passage><passage><infon key="fpage">2623</infon><infon key="lpage">2646</infon><infon key="name_0">surname:Haselmayer;given-names:M</infon><infon key="name_1">surname:Jenny;given-names:M</infon><infon key="pub-id_doi">10.1007/s11135-016-0412-4</infon><infon key="section_type">REF</infon><infon key="source">Quality &amp; Quantity</infon><infon key="type">ref</infon><infon key="volume">56</infon><infon key="year">2016</infon><offset>42094</offset><text>Sentiment analysis of political communication: Combining a dictionary approach with crowdcoding</text></passage><passage><infon key="fpage">77</infon><infon key="lpage">89</infon><infon key="name_0">surname:Hayes;given-names:AF</infon><infon key="name_1">surname:Krippendorff;given-names:K</infon><infon key="section_type">REF</infon><infon key="source">Communication Methods and Measures</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2007</infon><offset>42190</offset><text>Answering the call for a standard reliability measure for coding data</text></passage><passage><infon key="fpage">229</infon><infon key="lpage">247</infon><infon key="name_0">surname:Hopkins;given-names:DJ</infon><infon key="name_1">surname:King;given-names:G</infon><infon key="section_type">REF</infon><infon key="source">American Journal of Political Science</infon><infon key="type">ref</infon><infon key="volume">54</infon><infon key="year">2010</infon><offset>42260</offset><text>A method of automated nonparametric content analysis for social science</text></passage><passage><infon key="fpage">236</infon><infon key="lpage">247</infon><infon key="name_0">surname:Horn;given-names:A</infon><infon key="pub-id_doi">10.1111/1475-6765.12278</infon><infon key="section_type">REF</infon><infon key="source">European Journal of Political Research</infon><infon key="type">ref</infon><infon key="volume">58</infon><infon key="year">2019</infon><offset>42332</offset><text>Can the online crowd match real expert judgments? How task complexity and coder location affect the validity of crowd-coded data</text></passage><passage><infon key="fpage">1</infon><infon key="issue">6</infon><infon key="lpage">4</infon><infon key="name_0">surname:Howe;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">Wired Magazine</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2006</infon><offset>42461</offset><text>The rise of crowdsourcing</text></passage><passage><infon key="fpage">885</infon><infon key="lpage">897</infon><infon key="name_0">surname:Hurtz;given-names:GM</infon><infon key="name_1">surname:Hertz;given-names:NR</infon><infon key="pub-id_doi">10.1177/00131649921970233</infon><infon key="section_type">REF</infon><infon key="source">Educational and Psychological Measurement</infon><infon key="type">ref</infon><infon key="volume">59</infon><infon key="year">1999</infon><offset>42487</offset><text>How Many Raters Should be Used for Establishing Cutoff Scores with the Angoff Method? A Generalizability Theory Study</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">10</infon><infon key="name_0">surname:Kim;given-names:M</infon><infon key="name_1">surname:Cappella;given-names:JN</infon><infon key="pub-id_doi">10.1080/10810730.2019.1668090</infon><infon key="section_type">REF</infon><infon key="source">Journal of Health Communication</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>42605</offset><text>An efficient message evaluation protocol: Two empirical analyses on positional effects and optimal sample size</text></passage><passage><infon key="fpage">93</infon><infon key="lpage">99</infon><infon key="name_0">surname:Kraemer;given-names:JD</infon><infon key="name_1">surname:Strasser;given-names:AA</infon><infon key="name_2">surname:Lindblom;given-names:EN</infon><infon key="name_3">surname:Niaura;given-names:RS</infon><infon key="name_4">surname:Mays;given-names:D</infon><infon key="pub-id_doi">10.1016/j.ypmed.2017.07.006</infon><infon key="pub-id_pmid">28694063</infon><infon key="section_type">REF</infon><infon key="source">Preventive Medicine</infon><infon key="type">ref</infon><infon key="volume">102</infon><infon key="year">2017</infon><offset>42716</offset><text>Crowdsourced data collection for public health: A comparison with nationally representative, population tobacco use data</text></passage><passage><infon key="name_0">surname:Krippendorff;given-names:KH</infon><infon key="section_type">REF</infon><infon key="source">Content Analysis: An Introduction to Its Methodology</infon><infon key="type">ref</infon><infon key="year">2012</infon><offset>42837</offset></passage><passage><infon key="fpage">791</infon><infon key="lpage">811</infon><infon key="name_0">surname:Lacy;given-names:S</infon><infon key="name_1">surname:Watson;given-names:BR</infon><infon key="name_2">surname:Riffe;given-names:D</infon><infon key="name_3">surname:Lovejoy;given-names:J</infon><infon key="pub-id_doi">10.1177/1077699015607338</infon><infon key="section_type">REF</infon><infon key="source">Journalism &amp; Mass Communication Quarterly</infon><infon key="type">ref</infon><infon key="volume">92</infon><infon key="year">2015</infon><offset>42838</offset><text>Issues and best practices in content analysis</text></passage><passage><infon key="fpage">18</infon><infon key="lpage">25</infon><infon key="name_0">surname:Levy;given-names:DT</infon><infon key="name_1">surname:Borland;given-names:R</infon><infon key="name_2">surname:Lindblom;given-names:EN</infon><infon key="name_3">surname:Goniewicz;given-names:ML</infon><infon key="name_4">surname:Meza;given-names:R</infon><infon key="name_5">surname:Holford;given-names:TR</infon><infon key="name_6">surname:Abrams;given-names:DB</infon><infon key="pub-id_doi">10.1136/tobaccocontrol-2017-053759</infon><infon key="pub-id_pmid">28970328</infon><infon key="section_type">REF</infon><infon key="source">Tobacco Control</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2018</infon><offset>42884</offset><text>Potential deaths averted in USA by replacing cigarettes with e-cigarettes</text></passage><passage><infon key="fpage">191</infon><infon key="lpage">209</infon><infon key="name_0">surname:Lind;given-names:F</infon><infon key="name_1">surname:Gruber;given-names:M</infon><infon key="name_2">surname:Boomgaarden;given-names:HG</infon><infon key="pub-id_doi">10.1080/19312458.2017.1317338</infon><infon key="pub-id_pmid">29118893</infon><infon key="section_type">REF</infon><infon key="source">Communication Methods and Measures</infon><infon key="type">ref</infon><infon key="volume">11</infon><infon key="year">2017</infon><offset>42958</offset><text>Content analysis by the crowd: Assessing the usability of crowdsourcing for coding latent constructs</text></passage><passage><infon key="fpage">65</infon><infon key="lpage">67</infon><infon key="name_0">surname:Mooney;given-names:CZ</infon><infon key="name_1">surname:Lavrakas;given-names:PJ</infon><infon key="section_type">REF</infon><infon key="source">Encyclopedia of Survey Research Methods</infon><infon key="type">ref</infon><infon key="year">2008</infon><offset>43059</offset></passage><passage><infon key="pub-id_doi">10.17226/24952</infon><infon key="section_type">REF</infon><infon key="source">Public Health Consequences of E-Cigarettes</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>43060</offset></passage><passage><infon key="fpage">106</infon><infon key="lpage">108</infon><infon key="name_0">surname:Neiheisel;given-names:JR</infon><infon key="name_1">surname:Allen;given-names:M</infon><infon key="section_type">REF</infon><infon key="source">The SAGE Encyclopedia of Communication Research Methods</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>43061</offset></passage><passage><infon key="fpage">119</infon><infon key="lpage">125</infon><infon key="name_0">surname:Noda;given-names:AM</infon><infon key="name_1">surname:Kraemer;given-names:HC</infon><infon key="name_2">surname:Yesavage;given-names:JA</infon><infon key="name_3">surname:Periyakoil;given-names:VS</infon><infon key="pub-id_doi">10.1002/mpr.107</infon><infon key="section_type">REF</infon><infon key="source">International Journal of Methods in Psychiatric Research</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2001</infon><offset>43062</offset><text>How many raters are needed for a reliable diagnosis?</text></passage><passage><infon key="fpage">545</infon><infon key="lpage">560</infon><infon key="name_0">surname:Paek;given-names:H-J</infon><infon key="name_1">surname:Kim;given-names:S</infon><infon key="name_2">surname:Hove;given-names:T</infon><infon key="name_3">surname:Huh;given-names:JY</infon><infon key="pub-id_doi">10.1080/10810730.2013.821560</infon><infon key="pub-id_pmid">24117370</infon><infon key="section_type">REF</infon><infon key="source">Journal of Health Communication</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2014</infon><offset>43115</offset><text>Reduced harm or another gateway to smoking? Source, message, and information characteristics of e-cigarette videos on youtube</text></passage><passage><infon key="fpage">184</infon><infon key="lpage">188</infon><infon key="name_0">surname:Paolacci;given-names:G</infon><infon key="name_1">surname:Chandler;given-names:J</infon><infon key="pub-id_doi">10.1177/0963721414531598</infon><infon key="section_type">REF</infon><infon key="source">Current Directions in Psychological Science</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2014</infon><offset>43241</offset><text>Inside the turk: Understanding Mechanical Turk as a participant pool</text></passage><passage><infon key="comment">http://www.ncbi.nlm.nih.gov/pmc/articles/PMC524673/</infon><infon key="name_0">surname:Payton;given-names:ME</infon><infon key="name_1">surname:Greenstone;given-names:MH</infon><infon key="name_2">surname:Schenker;given-names:N</infon><infon key="section_type">REF</infon><infon key="source">Journal of Insect Science</infon><infon key="type">ref</infon><infon key="volume">3</infon><infon key="year">2003</infon><offset>43310</offset><text>Overlapping confidence intervals or standard error intervals: What do they mean in terms of statistical significance?</text></passage><passage><infon key="fpage">iii31</infon><infon key="issue">suppl 3</infon><infon key="lpage">iii36</infon><infon key="name_0">surname:Pepper;given-names:JK</infon><infon key="name_1">surname:Emery;given-names:SL</infon><infon key="name_2">surname:Ribisl;given-names:KM</infon><infon key="name_3">surname:Southwell;given-names:BG</infon><infon key="name_4">surname:Brewer;given-names:NT</infon><infon key="pub-id_doi">10.1136/tobaccocontrol-2014-051718</infon><infon key="pub-id_pmid">24935896</infon><infon key="section_type">REF</infon><infon key="source">Tobacco Control</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2014</infon><offset>43428</offset><text>Effects of advertisements on smokers’ interest in trying e-cigarettes: The roles of product comparison and visual cues</text></passage><passage><infon key="fpage">258</infon><infon key="lpage">284</infon><infon key="name_0">surname:Potter;given-names:WJ</infon><infon key="name_1">surname:Levine‐Donnerstein;given-names:D</infon><infon key="pub-id_doi">10.1080/00909889909365539</infon><infon key="section_type">REF</infon><infon key="source">Journal of Applied Communication Research</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">1999</infon><offset>43549</offset><text>Rethinking validity and reliability in content analysis</text></passage><passage><infon key="fpage">140</infon><infon key="lpage">156</infon><infon key="name_0">surname:Sheehan;given-names:KB</infon><infon key="pub-id_doi">10.1080/03637751.2017.1342043</infon><infon key="section_type">REF</infon><infon key="source">Communication Monographs</infon><infon key="type">ref</infon><infon key="volume">85</infon><infon key="year">2018</infon><offset>43605</offset><text>Crowdsourcing research: Data collection with Amazon’s Mechanical Turk</text></passage><passage><infon key="fpage">e20154155</infon><infon key="name_0">surname:Singh;given-names:T</infon><infon key="name_1">surname:Agaku;given-names:IT</infon><infon key="name_2">surname:Arrazola;given-names:RA</infon><infon key="name_3">surname:Marynak;given-names:KL</infon><infon key="name_4">surname:Neff;given-names:LJ</infon><infon key="name_5">surname:Rolle;given-names:IT</infon><infon key="name_6">surname:King;given-names:BA</infon><infon key="pub-id_doi">10.1542/peds.2015-4155</infon><infon key="pub-id_pmid">27244815</infon><infon key="section_type">REF</infon><infon key="source">Pediatrics</infon><infon key="type">ref</infon><infon key="volume">137</infon><infon key="year">2016</infon><offset>43677</offset><text>Exposure to advertisements and electronic cigarette use among US middle and high school students</text></passage><passage><infon key="section_type">REF</infon><infon key="source">E-cigarette Use Among Youth and Young Adults: A Report of the Surgeon General-Executive Summary</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>43774</offset></passage><passage><infon key="fpage">313</infon><infon key="lpage">325</infon><infon key="name_0">surname:Wakefield;given-names:MA</infon><infon key="name_1">surname:Brennan;given-names:E</infon><infon key="name_2">surname:Durkin;given-names:SJ</infon><infon key="name_3">surname:McLeod;given-names:K</infon><infon key="name_4">surname:Smith;given-names:KC</infon><infon key="pub-id_doi">10.1080/09581596.2010.502930</infon><infon key="section_type">REF</infon><infon key="source">Critical Public Health</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2011</infon><offset>43775</offset><text>Still a burning issue: Trends in the volume, content and population reach of newspaper coverage about tobacco issues</text></passage><passage><infon key="fpage">1299</infon><infon key="lpage">1309</infon><infon key="name_0">surname:Warner;given-names:KE</infon><infon key="pub-id_doi">10.1093/ntr/nty084</infon><infon key="pub-id_pmid">29718475</infon><infon key="section_type">REF</infon><infon key="source">Nicotine &amp; Tobacco Research</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2019</infon><offset>43892</offset><text>How to think – not feel – about tobacco harm reduction</text></passage><passage><infon key="fpage">298</infon><infon key="lpage">305</infon><infon key="name_0">surname:Yang;given-names:Q</infon><infon key="name_1">surname:Liu;given-names:J</infon><infon key="name_2">surname:Lochbuehler;given-names:K</infon><infon key="name_3">surname:Hornik;given-names:R</infon><infon key="pub-id_doi">10.1080/10410236.2017.1407229</infon><infon key="pub-id_pmid">29236549</infon><infon key="section_type">REF</infon><infon key="source">Health Communication</infon><infon key="type">ref</infon><infon key="volume">34</infon><infon key="year">2019</infon><offset>43951</offset><text>Does seeking e-cigarette information lead to vaping? Evidence from a national longitudinal survey of youth and young adults</text></passage><passage><infon key="fpage">94</infon><infon key="lpage">102</infon><infon key="name_0">surname:Yates;given-names:K</infon><infon key="name_1">surname:Friedman;given-names:K</infon><infon key="name_2">surname:Slater;given-names:MD</infon><infon key="name_3">surname:Berman;given-names:M</infon><infon key="name_4">surname:Paskett;given-names:E</infon><infon key="name_5">surname:Ferketich;given-names:AK</infon><infon key="pub-id_doi">10.18001/TRS.1.1.9</infon><infon key="pub-id_pmid">26229974</infon><infon key="section_type">REF</infon><infon key="source">Tobacco Regulatory Science</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2015</infon><offset>44075</offset><text>A content analysis of electronic cigarette portrayal in newspapers</text></passage><passage><infon key="file">nihms-1546415-f0001.jpg</infon><infon key="id">F1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>44142</offset><text>Four metrics for comparing results from bootstrap samples with the original “majority scores” (maj. score): (A) Pearson correlation with “sample scores”; (B) Absolute difference of “sample score” from “majority scores”; (C) Proportion of “Any mistakes”; (D) Proportion of “Big mistakes”.</text></passage><passage><infon key="file">nihms-1546415-f0002.jpg</infon><infon key="id">F2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>44454</offset><text>Pearson correlations between “majority score” and “sample score” at each rater sample size and growth rates at each increment of sample size. Each estimate is calculated from 500 bootstrap samples.</text></passage><passage><infon key="file">nihms-1546415-f0003.jpg</infon><infon key="id">F3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>44660</offset><text>Absolute differences between “majority score” and “sample score” at each rater sample size and decrease rates at each increment of sample size. Each estimate is calculated from 500 bootstrap samples.</text></passage><passage><infon key="file">nihms-1546415-f0004.jpg</infon><infon key="id">F4</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>44868</offset><text>Average percentage of making “any mistakes” at each rater sample size. Each estimate is calculated from 500 bootstrap samples.</text></passage><passage><infon key="file">nihms-1546415-f0005.jpg</infon><infon key="id">F5</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>44999</offset><text>Average percentage of making “big mistakes” at each rater sample size. Each estimate is calculated from 500 bootstrap samples.</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>45130</offset><text>Definitions of Valence Labels (Pro-ecig, Anti-ecig, and Not applicable) and Rating Questions for Four Conditions</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;all&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition&lt;/th&gt;
            &lt;th align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Definitions of Valence Labels&lt;/th&gt;
            &lt;th align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Rating Question&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; colspan=&quot;1&quot;&gt;Condition 1: Objective-Text&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Pro-ecig: &lt;bold&gt;&lt;italic&gt;The text is&lt;/italic&gt;&lt;/bold&gt; mostly supportive of e-cigarette use OR supportive of the e-cigarette industry – as a whole, it encourages using e-cigarettes.&lt;/td&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;top&quot; colspan=&quot;1&quot;&gt;
              &lt;italic&gt;For the content that is ecig-relevant, &lt;bold&gt;is it mostly&lt;/bold&gt; anti-ecig, pro-ecig or not applicable?&lt;/italic&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Anti-ecig: &lt;bold&gt;&lt;italic&gt;The text is&lt;/italic&gt;&lt;/bold&gt; mostly against e-cigarette use OR against the e-cigarette industry – as a whole, it discourages using e-cigarettes.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not applicable: &lt;bold&gt;&lt;italic&gt;The text&lt;/italic&gt;&lt;/bold&gt; does not have enough information to judge if it is mostly pro-ecig or mostly anti-ecig.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; colspan=&quot;1&quot;&gt;Condition 2: Subjective-Own opinion&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Pro-ecig: &lt;bold&gt;&lt;italic&gt;You understand the text to be&lt;/italic&gt;&lt;/bold&gt; mostly supportive of e-cigarette use OR supportive of the e-cigarette industry – as a whole, it encourages using e-cigarettes.&lt;/td&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;top&quot; colspan=&quot;1&quot;&gt;
              &lt;italic&gt;For the content that is ecig-relevant, &lt;bold&gt;would you understand it to be&lt;/bold&gt; mostly anti-ecig, pro-ecig or not applicable?&lt;/italic&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Anti-ecig: &lt;bold&gt;&lt;italic&gt;You understand the text to be&lt;/italic&gt;&lt;/bold&gt; mostly against e-cigarette use OR against the e-cigarette industry – as a whole, it discourages using e-cigarettes.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not applicable: &lt;bold&gt;&lt;italic&gt;You understand the text&lt;/italic&gt; to&lt;/bold&gt; not have enough information to judge if it is mostly pro-ecig or mostly anti-ecig.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; colspan=&quot;1&quot;&gt;Condition 3: Subjective-Most people&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Pro-ecig: &lt;bold&gt;&lt;italic&gt;Most people would understand the text to be&lt;/italic&gt;&lt;/bold&gt; mostly supportive of e-cigarette use OR supportive of the e-cigarette industry – they would see it as encouraging the use of e-cigarettes.&lt;/td&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;top&quot; colspan=&quot;1&quot;&gt;
              &lt;italic&gt;For the content that is ecig-relevant, &lt;bold&gt;would most people understand it to be&lt;/bold&gt; mostly anti-ecig, pro-ecig or not applicable?&lt;/italic&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Anti-ecig: &lt;bold&gt;&lt;italic&gt;Most people would understand the text to be&lt;/italic&gt;&lt;/bold&gt; mostly against e-cigarette use OR against the e-cigarette industry – they would see it as discouraging the use of e-cigarettes.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not applicable: &lt;bold&gt;&lt;italic&gt;Most people would understand the text to&lt;/italic&gt;&lt;/bold&gt; not have enough information to judge if it is mostly pro-ecig or mostly anti-ecig.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; colspan=&quot;1&quot;&gt;Condition 4: Subjective-Naïve people&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Pro-ecig: &lt;bold&gt;&lt;italic&gt;Someone who only knows a little about e-cigarettes would understand the text to be&lt;/italic&gt;&lt;/bold&gt; mostly against e-cigarette use OR against the e-cigarette industry – they would see it as discouraging the use of e-cigarettes.&lt;/td&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;center&quot; valign=&quot;top&quot; colspan=&quot;1&quot;&gt;
              &lt;italic&gt;For the content that is ecig-relevant, &lt;bold&gt;would someone who only knows a little about e-cigarettes understand it to be&lt;/bold&gt; mostly anti-ecig, pro-ecig or not applicable?&lt;/italic&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Anti-ecig: &lt;bold&gt;&lt;italic&gt;Someone who only knows a little about e-cigarettes would understand the text to be&lt;/italic&gt;&lt;/bold&gt; mostly supportive of e-cigarette use OR supportive of the e-cigarette industry – they would see it as encouraging the use of e-cigarettes.&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Not applicable: &lt;bold&gt;&lt;italic&gt;Someone who only knows a little about e-cigarettes would understand the text to&lt;/italic&gt;&lt;/bold&gt; not have enough information to judge if it is mostly pro-ecig or mostly anti-ecig.&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>45243</offset><text>Condition	Definitions of Valence Labels	Rating Question	 	Condition 1: Objective-Text	Pro-ecig: The text is mostly supportive of e-cigarette use OR supportive of the e-cigarette industry – as a whole, it encourages using e-cigarettes.	For the content that is ecig-relevant, is it mostly anti-ecig, pro-ecig or not applicable?	 	Anti-ecig: The text is mostly against e-cigarette use OR against the e-cigarette industry – as a whole, it discourages using e-cigarettes.	 	Not applicable: The text does not have enough information to judge if it is mostly pro-ecig or mostly anti-ecig.	 	Condition 2: Subjective-Own opinion	Pro-ecig: You understand the text to be mostly supportive of e-cigarette use OR supportive of the e-cigarette industry – as a whole, it encourages using e-cigarettes.	For the content that is ecig-relevant, would you understand it to be mostly anti-ecig, pro-ecig or not applicable?	 	Anti-ecig: You understand the text to be mostly against e-cigarette use OR against the e-cigarette industry – as a whole, it discourages using e-cigarettes.	 	Not applicable: You understand the text to not have enough information to judge if it is mostly pro-ecig or mostly anti-ecig.	 	Condition 3: Subjective-Most people	Pro-ecig: Most people would understand the text to be mostly supportive of e-cigarette use OR supportive of the e-cigarette industry – they would see it as encouraging the use of e-cigarettes.	For the content that is ecig-relevant, would most people understand it to be mostly anti-ecig, pro-ecig or not applicable?	 	Anti-ecig: Most people would understand the text to be mostly against e-cigarette use OR against the e-cigarette industry – they would see it as discouraging the use of e-cigarettes.	 	Not applicable: Most people would understand the text to not have enough information to judge if it is mostly pro-ecig or mostly anti-ecig.	 	Condition 4: Subjective-Naïve people	Pro-ecig: Someone who only knows a little about e-cigarettes would understand the text to be mostly against e-cigarette use OR against the e-cigarette industry – they would see it as discouraging the use of e-cigarettes.	For the content that is ecig-relevant, would someone who only knows a little about e-cigarettes understand it to be mostly anti-ecig, pro-ecig or not applicable?	 	Anti-ecig: Someone who only knows a little about e-cigarettes would understand the text to be mostly supportive of e-cigarette use OR supportive of the e-cigarette industry – they would see it as encouraging the use of e-cigarettes.	 	Not applicable: Someone who only knows a little about e-cigarettes would understand the text to not have enough information to judge if it is mostly pro-ecig or mostly anti-ecig.	 	</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>47971</offset><text>Note. The “Not applicable” label could include judgments that texts do not have any valence (i.e., neutral), but also those that had mixed valence (having both pro- and anti-ecig content) since there is not enough information to judge whether texts were mostly pro- or anti-ecig.</text></passage><passage><infon key="file">T2.xml</infon><infon key="id">T2</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>48255</offset><text>Krippendorff’s Alphas (95% and 83% Confidence Intervals) by Condition</text></passage><passage><infon key="file">T2.xml</infon><infon key="id">T2</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition&lt;/th&gt;
            &lt;th align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Krippendorff’s Alpha&lt;/th&gt;
            &lt;th align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[95% CI]&lt;/th&gt;
            &lt;th align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[83% CI]&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 1: Objective-Text&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.56&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0.34, 0.77]&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0.41, 0.70]&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 2: Subjective-Own opinion&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.77&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0.60, 0.93]&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0.66, 0.90]&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 3: Subjective-Most people&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.67&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0.47, 0.84]&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0.54, 0.80]&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 4: Subjective-Naïve people&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.52&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0.22, 0.78]&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0.31, 0.70]&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>48327</offset><text>Condition	Krippendorff’s Alpha	[95% CI]	[83% CI]	 	Condition 1: Objective-Text	0.56	[0.34, 0.77]	[0.41, 0.70]	 	Condition 2: Subjective-Own opinion	0.77	[0.60, 0.93]	[0.66, 0.90]	 	Condition 3: Subjective-Most people	0.67	[0.47, 0.84]	[0.54, 0.80]	 	Condition 4: Subjective-Naïve people	0.52	[0.22, 0.78]	[0.31, 0.70]	 	</text></passage><passage><infon key="file">T2.xml</infon><infon key="id">T2</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>48651</offset><text>Note. N = 20 raters of 34 texts per condition.</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>48698</offset><text>Multilevel Regression Model Predicting Consistency Scores from Study Conditions</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Fixed effects variables&lt;/th&gt;
            &lt;th align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;B (SE)&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 1: Objective-Text&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Reference&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 2: Subjective-Own opinion&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.11&lt;xref rid=&quot;TFN4&quot; ref-type=&quot;table-fn&quot;&gt;**&lt;/xref&gt; (.04)&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 3: Subjective-Most people&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.11&lt;xref rid=&quot;TFN4&quot; ref-type=&quot;table-fn&quot;&gt;**&lt;/xref&gt; (.04)&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 4: Subjective-Naïve people&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.06 (.04)&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Intercept&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2.58 (.06)&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot;&gt;
              &lt;hr/&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Random effects variables&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td colspan=&quot;2&quot; align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot;&gt;
              &lt;hr/&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Texts&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.30&lt;xref rid=&quot;TFN5&quot; ref-type=&quot;table-fn&quot;&gt;*&lt;/xref&gt; (.04)&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Raters&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.11&lt;xref rid=&quot;TFN5&quot; ref-type=&quot;table-fn&quot;&gt;*&lt;/xref&gt; (.02)&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>48778</offset><text>Fixed effects variables	B (SE)	 	Condition 1: Objective-Text	Reference	 	Condition 2: Subjective-Own opinion	.11** (.04)	 	Condition 3: Subjective-Most people	.11** (.04)	 	Condition 4: Subjective-Naïve people	.06 (.04)	 	Intercept	2.58 (.06)	 		 	Random effects variables		 		 	Texts	.30* (.04)	 	Raters	.11* (.02)	 	</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>49098</offset><text>Note. N = 80 raters of 34 texts.</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>49131</offset><text>p &lt; .01;</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>49140</offset><text>p &lt; .05</text></passage><passage><infon key="file">T4.xml</infon><infon key="id">T4</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>49148</offset><text>Bonferroni Pair-wise Comparisons of Consistency Scores across Conditions</text></passage><passage><infon key="file">T4.xml</infon><infon key="id">T4</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Pairs&lt;/th&gt;
            &lt;th align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Contrast [95% CI]&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 2 vs. Condition 1&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.11 [.02, .20]&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 3 vs. Condition 1&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.11 [.02, .21]&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 4 vs. Condition 1&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.06 [−.04, .15]&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 3 vs. Condition 2&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;.00 [−.09, .10]&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 4 vs. Condition 2&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;−.05 [−.15, .04]&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Condition 4 vs. Condition 3&lt;/td&gt;
            &lt;td align=&quot;center&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;−.06 [−.15, .04]&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>49221</offset><text>Pairs	Contrast [95% CI]	 	Condition 2 vs. Condition 1	.11 [.02, .20]	 	Condition 3 vs. Condition 1	.11 [.02, .21]	 	Condition 4 vs. Condition 1	.06 [−.04, .15]	 	Condition 3 vs. Condition 2	.00 [−.09, .10]	 	Condition 4 vs. Condition 2	−.05 [−.15, .04]	 	Condition 4 vs. Condition 3	−.06 [−.15, .04]	 	</text></passage><passage><infon key="file">T4.xml</infon><infon key="id">T4</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>49536</offset><text>Note. N = 20 raters of 34 texts per condition. Condition 1 = Objective-Text; Condition 2 = Subjective-Own opinion; Condition 3 = Subjective-Most people; Condition 4 = Subjective-Naïve people.</text></passage></document></collection>
