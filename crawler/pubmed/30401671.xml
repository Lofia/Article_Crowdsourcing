<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20201221</date><key>pmc.key</key><document><id>6246963</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.2196/ijmr.9359</infon><infon key="article-id_pmc">6246963</infon><infon key="article-id_pmid">30401671</infon><infon key="article-id_publisher-id">v7i2e17</infon><infon key="elocation-id">e17</infon><infon key="issue">2</infon><infon key="kwd">calorie estimation image annotation crowdsourcing obesity public health</infon><infon key="license">This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Interactive Journal of Medical Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.i-jmr.org/, as well as this copyright and license information must be included.</infon><infon key="name_0">surname:Eysenbach;given-names:Gunther</infon><infon key="name_1">surname:Partridge;given-names:Stephanie</infon><infon key="name_2">surname:Rosenkranz;given-names:Richard</infon><infon key="name_3">surname:Zhou;given-names:Jun</infon><infon key="name_4">surname:Bell;given-names:Dane</infon><infon key="name_5">surname:Nusrat;given-names:Sabrina</infon><infon key="name_6">surname:Hingle;given-names:Melanie</infon><infon key="name_7">surname:Surdeanu;given-names:Mihai</infon><infon key="name_8">surname:Kobourov;given-names:Stephen</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">7</infon><infon key="year">2018</infon><offset>0</offset><text>Calorie Estimation From Pictures of Food: Crowdsourcing Study</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>62</offset><text>Background</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>73</offset><text>Software designed to accurately estimate food calories from still images could help users and health professionals identify dietary patterns and food choices associated with health and health risks more effectively. However, calorie estimation from images is difficult, and no publicly available software can do so accurately while minimizing the burden associated with data collection and analysis.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>473</offset><text>Objective</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>483</offset><text>The aim of this study was to determine the accuracy of crowdsourced annotations of calorie content in food images and to identify and quantify sources of bias and noise as a function of respondent characteristics and food qualities (eg, energy density).</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>737</offset><text>Methods</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>745</offset><text>We invited adult social media users to provide calorie estimates for 20 food images (for which ground truth calorie data were known) using a custom-built webpage that administers an online quiz. The images were selected to provide a range of food types and energy density. Participants optionally provided age range, gender, and their height and weight. In addition, 5 nutrition experts provided annotations for the same data to form a basis of comparison. We examined estimated accuracy on the basis of expertise, demographic data, and food qualities using linear mixed-effects models with participant and image index as random variables. We also analyzed the advantage of aggregating nonexpert estimates.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>1452</offset><text>Results</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>1460</offset><text>A total of 2028 respondents agreed to participate in the study (males: 770/2028, 37.97%, mean body mass index: 27.5 kg/m2). Average accuracy was 5 out of 20 correct guesses, where “correct” was defined as a number within 20% of the ground truth. Even a small crowd of 10 individuals achieved an accuracy of 7, exceeding the average individual and expert annotator’s accuracy of 5. Women were more accurate than men (P&lt;.001), and younger people were more accurate than older people (P&lt;.001). The calorie content of energy-dense foods was overestimated (P=.02). Participants performed worse when images contained reference objects, such as credit cards, for scale (P=.01).</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>2137</offset><text>Conclusions</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>2149</offset><text>Our findings provide new information about how calories are estimated from food images, which can inform the design of related software and analyses.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>2299</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>2312</offset><text>Background</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2323</offset><text>Estimating calories in pictures of food is an important task, providing data to inform nutrition research and practice and helping individuals achieve optimal, balanced dietary intakes. Yet this task turns out to be difficult for both experts and nonexperts. We are using this study as an opportunity to enhance our understanding of whether and how calorie estimation works “in the wild,” that is, in real-world scenarios. There are many applications of this understanding, ranging from improving the methodological rigor (and reducing the associated burden) of dietary assessment, a pervasive and unanswered question in nutrition science, to influencing the design of interventions focused on dietary behavior change.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3046</offset><text>The fact that individuals do not estimate calories well has motivated the design of software apps to help individuals better estimate different aspects of dietary intake (eg, calories, energy density, nutrient density, and portions) using machine learning (ML) and by harnessing the “wisdom of the crowd.” The latter phenomenon was first documented in a 1907 Nature paper and has been successfully used in many domains, ranging from gene network inference to computational problems. Apps in this space remain quite difficult to use, requiring burdensome manual logging of what one eats, or, when ML is used to classify pictures of foods, explicit weight values to be entered manually. To a large extent, the identification of calorie content from images of food either through crowd sourcing or ML remains an open research question. This work is a necessary step toward the automated identification of calorie content from images of food.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>3989</offset><text>Objectives</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4000</offset><text>The aim of this study was to determine the accuracy of crowdsourced annotations of calorie content in food images and to identify and quantify sources of bias and noise as a function of respondent characteristics and food qualities (eg, energy density).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>4254</offset><text>Methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>4262</offset><text>Procedure</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>4272</offset><text>The proposed task is essentially a combination of 2 tests individuals must engage in when estimating calories. The first test relates to the relative energy density of the food pictured, whereas the second test discerns the portion size. Thus, we contend that the ecological validity of our approach is high, despite the task’s complexity. The study protocol described herein was reviewed by an institutional review board at the University of Arizona and met the criteria for exemption under 45 CFR 46.101(b).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>4784</offset><text>We designed a simple online quiz administered by a custom-built webpage to measure the accuracy of calorie estimation in pictures of food, verify the existence of collective wisdom, and analyze data and find patterns and trends that can be useful in the design of calorie-tracking apps.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>5071</offset><text>We posted the quiz to SampleSize, a subreddit (ie, a forum on reddit) dedicated to posting surveys and survey results. This choice was made on the basis of having a large, active user base that reflects the demographics likely to make large-scale food annotations for reasons of personal interest in self-quantification.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>5392</offset><text>The quiz began with a short introduction: “We would like to see whether you have a good understanding about calories. We will show you several pictures of food and your task, should you choose to accept it, is to guess how many calories are in the food. We will not share any identifying information about you. All of the data is anonymous.”</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>5738</offset><text>The quiz included 20 questions. Each question consisted of a picture of some food item (see Figure 1) and the prompt, “How many calories are in the food pictured here? (Type a number in the box between 50 and 800).” Implausible dietary data, from (un)intentional under-reporting or over-reporting, are a pervasive problem in nutrition research and can introduce bias or lead to erroneous interpretations of diet-weight or diet-disease relationships. A common way of handling this issue is to exclude extreme values after the fact based on the distribution of the data (eg, removing data more than 2 SDs from the mean) or by subjective assessment. In contrast, we provided the upper and lower limits on the guesses, based on the ground truth data, to ease an already difficult task and thereby reduce the amount of data that would later be necessary to remove. The numbers also helped clarify that we were referring to kilocalories and helped reduce outliers. Neither the correct calorie amounts nor other participants’ answers were visible to a participant during the estimation portion of the experiment, although it is possible that some might have read the reddit comments before participation, which revealed some calorie values. We decided to not add additional information to the pictures (eg, does the sandwich contain mayonnaise?) to keep the task closer to a realistic image annotation task.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>7145</offset><text>Following the food-related questions, the participants were asked to provide their age group, gender, and body mass index (BMI). An option to calculate BMI via height and weight information was also available. We deliberately chose not to ask for additional demographic questions (eg, location, income, and education) to protect participant privacy. We reported the accuracy of the individual participant who just completed the quiz, as well as the average accuracy of all prior participants, using a breakdown showing the performance of each question.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>7698</offset><text>Quiz Materials</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>7713</offset><text>We used 2 categories of food for the pictures: single-ingredient (eg, broccoli, cheese) and mixed-ingredients (eg, sandwich, pizza). There were 20 pictures of food items in total (Figure 1): 12 single-ingredient and 8 mixed. The food shown in the pictures ranged from 100 to 720 kcal. Importantly, we chose these food items according to the United States Department of Agriculture’s (USDA) MyPlate model that captures the building blocks for a healthy diet, and which includes 5 types of food (vegetables, fruits, protein, dairy, and grain), as well as mixed foods containing these ingredients. Our selection aimed to follow this model, to include realistic foods that appear in daily consumption, and to be concise so participants engage with the quiz.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8469</offset><text>The food portions selected are summarized in Table 1. The images were ordered so that each food type was maximally separated from other instances of its type, and the order was the same for each participant. We collected nutrition information about some food items from official restaurant websites. Although the calorie content of the foods pictured was not directly measured, US federal statute requires the published calorie values of restaurant food items to be within 20% of actual calorie value.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8971</offset><text>We chose not to inform the participants of the sources of the images, to reduce the potential that they would search the Web for “ground truth” data, for example, by going to the actual Burger King’s website. Likewise, the participants were not explicitly told that some images were from fast food restaurants.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>9288</offset><text>Patterns and Analysis</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9310</offset><text>A total of 3 measures were relevant to our analysis:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9363</offset><text>Error, e, is estimated kilocalories (ĉ) minus ground truth kilocalories (c), e = ĉ − c, and percent error, η, is error as a percentage of the ground truth kilocalories, η = e / c, both of which are positive in overestimation and negative in underestimation. Because of the variation in the ground truth kilocalories of the foods, the latter is a more reliable indicator of the scale of response bias.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9770</offset><text>Absolute error, |e|, measures accuracy irrespective of the direction of estimation bias (|e| = |ĉ − c|).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9878</offset><text>Discrete accuracy, D, is the number of estimates that were within 20% of the true calorie value (out of 20 estimates); discrete accuracy was the measure reported to quiz participants:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10062</offset><text>Before this analysis, we removed participants who reported a BMI less than 15 or more than 50 kg/m2 (which are unlikely to be correct), and participants who did not report their gender. In addition, we eliminated responses of less than 50 kcal or greater than 800 kcal and retained all the remaining ones.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10368</offset><text>We analyzed the results of the survey using linear mixed-effects modeling in R, allowing regression with random intercepts for both participants and foods simultaneously. The R2 values are the proportion of the variance in the data that is described by the models’ predicted values. For all analyses, a P value less than alpha=.05 was considered indicative of a statistically significant relation.</text></passage><passage><infon key="file">ijmr_v7i2e17_fig1.jpg</infon><infon key="id">figure1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>10768</offset><text>Untrained participants estimated the food calories in these 20 images.</text></passage><passage><infon key="file">table1.xml</infon><infon key="id">table1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>10839</offset><text>Foods were chosen for the quiz to attain maximum coverage of food types encountered in daily life by likely participants. Scaling refers to the presence of reference objects, such as credit cards, which could indicate food volume.</text></passage><passage><infon key="file">table1.xml</infon><infon key="id">table1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot; width=&quot;1000&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot; border=&quot;1&quot;&gt;&lt;col width=&quot;270&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;130&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;130&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;130&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;130&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;210&quot; span=&quot;1&quot;/&gt;&lt;thead&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Food&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Type&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Energy (kcal)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mass (g)&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Scaling?&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Source&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Cheddar cheese&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Dairy&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;200&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;51&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;wiseGEEK &lt;xref rid=&quot;ref12&quot; ref-type=&quot;bibr&quot;&gt;12&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Gouda cheese&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Dairy&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;300&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;84&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yes&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;HealthAssist &lt;xref rid=&quot;ref13&quot; ref-type=&quot;bibr&quot;&gt;13&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Avocado&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Fruit&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;200&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;125&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;wiseGEEK &lt;xref rid=&quot;ref12&quot; ref-type=&quot;bibr&quot;&gt;12&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Kiwi&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Fruit&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;200&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;328&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;wiseGEEK &lt;xref rid=&quot;ref12&quot; ref-type=&quot;bibr&quot;&gt;12&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Brown rice&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Grain&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;420&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;297.7&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Panda Express &lt;xref rid=&quot;ref14&quot; ref-type=&quot;bibr&quot;&gt;14&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Cereal&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Grain&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;200&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;55&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;wiseGEEK &lt;xref rid=&quot;ref12&quot; ref-type=&quot;bibr&quot;&gt;12&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Ham&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Meat&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;300&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;185.1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yes&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;HealthAssist &lt;xref rid=&quot;ref13&quot; ref-type=&quot;bibr&quot;&gt;13&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Salami&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Meat&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;300&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;72.9&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yes&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;HealthAssist &lt;xref rid=&quot;ref13&quot; ref-type=&quot;bibr&quot;&gt;13&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Red onion&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vegetable&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;200&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;475&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;wiseGEEK &lt;xref rid=&quot;ref12&quot; ref-type=&quot;bibr&quot;&gt;12&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Potato&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vegetable&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;141.7&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Food Network &lt;xref rid=&quot;ref15&quot; ref-type=&quot;bibr&quot;&gt;15&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Broccoli&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vegetable&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;200&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;588&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;wiseGEEK &lt;xref rid=&quot;ref12&quot; ref-type=&quot;bibr&quot;&gt;12&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Cauliflower&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vegetable&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;300&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1200&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yes&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;HealthAssist &lt;xref rid=&quot;ref13&quot; ref-type=&quot;bibr&quot;&gt;13&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Cheeseburger&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mixed&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;270&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;104&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Burger King &lt;xref rid=&quot;ref16&quot; ref-type=&quot;bibr&quot;&gt;16&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Hot dog&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mixed&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;310&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;123&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Burger King &lt;xref rid=&quot;ref16&quot; ref-type=&quot;bibr&quot;&gt;16&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Green tea cake&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mixed&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;136&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;40&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Wit Co, Ltd &lt;xref rid=&quot;ref17&quot; ref-type=&quot;bibr&quot;&gt;17&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Long cheeseburger&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mixed&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;590&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;213&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Burger King &lt;xref rid=&quot;ref16&quot; ref-type=&quot;bibr&quot;&gt;16&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Pepperoni and sausage pizza&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mixed&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;240&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;97&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Papa John’s Pizza &lt;xref rid=&quot;ref18&quot; ref-type=&quot;bibr&quot;&gt;18&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Swiss roll&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mixed&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;251&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;96&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Slism &lt;xref rid=&quot;ref19&quot; ref-type=&quot;bibr&quot;&gt;19&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Tuna sandwich&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mixed&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;720&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;420&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yes&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Jimmy John’s &lt;xref rid=&quot;ref20&quot; ref-type=&quot;bibr&quot;&gt;20&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Turkey sandwich&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mixed&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;510&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;254&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yes&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Jimmy John’s &lt;xref rid=&quot;ref20&quot; ref-type=&quot;bibr&quot;&gt;20&lt;/xref&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>11070</offset><text>Food	Type	Energy (kcal)	Mass (g)	Scaling?	Source	 	Cheddar cheese	Dairy	200	51	No	wiseGEEK 	 	Gouda cheese	Dairy	300	84	Yes	HealthAssist 	 	Avocado	Fruit	200	125	No	wiseGEEK 	 	Kiwi	Fruit	200	328	No	wiseGEEK 	 	Brown rice	Grain	420	297.7	No	Panda Express 	 	Cereal	Grain	200	55	No	wiseGEEK 	 	Ham	Meat	300	185.1	Yes	HealthAssist 	 	Salami	Meat	300	72.9	Yes	HealthAssist 	 	Red onion	Vegetable	200	475	No	wiseGEEK 	 	Potato	Vegetable	100	141.7	No	Food Network 	 	Broccoli	Vegetable	200	588	No	wiseGEEK 	 	Cauliflower	Vegetable	300	1200	Yes	HealthAssist 	 	Cheeseburger	Mixed	270	104	No	Burger King 	 	Hot dog	Mixed	310	123	No	Burger King 	 	Green tea cake	Mixed	136	40	No	Wit Co, Ltd 	 	Long cheeseburger	Mixed	590	213	No	Burger King 	 	Pepperoni and sausage pizza	Mixed	240	97	No	Papa John’s Pizza 	 	Swiss roll	Mixed	251	96	No	Slism 	 	Tuna sandwich	Mixed	720	420	Yes	Jimmy John’s 	 	Turkey sandwich	Mixed	510	254	Yes	Jimmy John’s 	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>12012</offset><text>Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>12020</offset><text>In total, 2125 individuals participated in our reddit quiz. After removing 97 participants with missing or invalid demographic data, 2028 individuals were included in the analysis.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>12201</offset><text>Participant Demographics</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>12226</offset><text>The demographics of the participants are summarized in Figures 2-5. Although we collected no location data, an earlier study, again recruiting from the SampleSize subreddit, found that 67.4% (421/625) of participants reported a location within the United States, a rate that is similar to the 64% reported in another voluntary survey with participants from across reddit. We also have a higher percentage of female participants than the US average, and a larger fraction of people with BMI around 25 kg/m2. It is possible that the participants in our quiz were more interested in this topic than the average person. However, in their self-selection, they are more demographically similar than the average person to likely crowdsourcing annotators for potential future app development.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>13011</offset><text>Participant Feedback</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>13032</offset><text>The participants volunteered their BMI and other demographic information, and 18 participants left 31 comments on the reddit thread. Table 2 summarizes the types of feedback comments we received, as well as some examples.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>13254</offset><text>The feedback from the participants demonstrates engagement, interest, and curiosity. This implies that such tasks could be legitimately gamified (applying game mechanics and game design techniques to engage and motivate people to achieve their goals). It also shows that unlike Mechanical Turk participants, the participants in our study were engaged and motivated by intrinsic interest.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>13642</offset><text>Note that our work addresses some of the requests shown in Table 2. For example, we found no increased accuracy from the presence of reference objects for scale in the pictures.</text></passage><passage><infon key="file">ijmr_v7i2e17_fig2.jpg</infon><infon key="id">figure2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>13820</offset><text>The reported gender of respondents to our quiz is compared with data from National Health and Nutrition Examination survey (NHANES).</text></passage><passage><infon key="file">ijmr_v7i2e17_fig3.jpg</infon><infon key="id">figure3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>13953</offset><text>The age of respondents to our quiz is compared with data from National Health and Nutrition Examination survey (NHANES).</text></passage><passage><infon key="file">ijmr_v7i2e17_fig4.jpg</infon><infon key="id">figure4</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>14074</offset><text>The body mass index (kg/m²) of respondents to our quiz is compared with data from National Health and Nutrition Examination survey (NHANES).</text></passage><passage><infon key="file">ijmr_v7i2e17_fig5.jpg</infon><infon key="id">figure5</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>14216</offset><text>The body mass index (kg/m²) category of respondents to our quiz is compared with data from National Health and Nutrition Examination survey (NHANES).</text></passage><passage><infon key="file">table2.xml</infon><infon key="id">table2</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>14367</offset><text>Representative comments from the reddit post of the calorie estimation quiz.</text></passage><passage><infon key="file">table2.xml</infon><infon key="id">table2</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot; width=&quot;1000&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot; border=&quot;1&quot;&gt;&lt;col width=&quot;100&quot; span=&quot;1&quot;/&gt;&lt;col width=&quot;900&quot; span=&quot;1&quot;/&gt;&lt;thead&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Type&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Example&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Fun&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;list list-type=&quot;bullet&quot;&gt;&lt;list-item&gt;&lt;p&gt;“That was fun! I think the folks in ‘loseIt’ [another subreddit] and on various MFP [MyFitnessPal] forums would enjoy taking this, too.”&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Surprise&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;list list-type=&quot;bullet&quot;&gt;&lt;list-item&gt;&lt;p&gt;“I’m really really doubtful that burger is only 270 cal.”&lt;/p&gt;&lt;/list-item&gt;&lt;list-item&gt;&lt;p&gt;“[N]o way are two red onions 200 calories.”&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Units&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;list list-type=&quot;bullet&quot;&gt;&lt;list-item&gt;&lt;p&gt;“[C]ountries other than the US use the actual unit of energy- Joules”&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Scale&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;list list-type=&quot;bullet&quot;&gt;&lt;list-item&gt;&lt;p&gt;“It would have been great to have a ruler next to the food.”&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;break/&gt;&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;list list-type=&quot;bullet&quot;&gt;&lt;list-item&gt;&lt;p&gt;“[I]f you show me a plate of rice, I can’t guess how much rice are on the plate because I don’t know how big the plate is.”&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Difficulty&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;list list-type=&quot;bullet&quot;&gt;&lt;list-item&gt;&lt;p&gt;“Shoot, got 1 right out of 20 LOL. No wonder my BMI is 29.”&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr valign=&quot;top&quot;&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;break/&gt;&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;list list-type=&quot;bullet&quot;&gt;&lt;list-item&gt;&lt;p&gt;“I dont know if there was mayo on [the submarine sandwiches] or not, which changes things a lot.”&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>14444</offset><text>Type	Example	 	Fun	“That was fun! I think the folks in ‘loseIt’ [another subreddit] and on various MFP [MyFitnessPal] forums would enjoy taking this, too.”	 	Surprise	“I’m really really doubtful that burger is only 270 cal.”“[N]o way are two red onions 200 calories.”	 	Units	“[C]ountries other than the US use the actual unit of energy- Joules”	 	Scale	“It would have been great to have a ruler next to the food.”	 		“[I]f you show me a plate of rice, I can’t guess how much rice are on the plate because I don’t know how big the plate is.”	 	Difficulty	“Shoot, got 1 right out of 20 LOL. No wonder my BMI is 29.”	 		“I dont know if there was mayo on [the submarine sandwiches] or not, which changes things a lot.”	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>15205</offset><text>How Good Are People at Estimating Calories?</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>15249</offset><text>The participants' estimates had a mean absolute error (|e|) of 57.9% (136 kcal). In terms of discrete accuracy (D), the mean participant answered 5.15 questions correctly out of 20. Figure 6 shows the distribution of correct responses. Absolute error varied considerably by item from the most accurate item—a turkey sandwich, with a mean absolute error of 23.0% (39 kcal)—to the least—green tea cake, at 241.0% (327 kcal) absolute error. Figure 7 illustrates the variety of estimates and percent error (η) distributions for different items. Together, these facts show that human calorie estimates are both inaccurate overall and inconsistent in their inaccuracies.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>15921</offset><text>Does the Wisdom of the Crowd Phenomenon Apply Here?</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>15973</offset><text>A consensus formed rapidly for each food, as shown in Figure 8 (see the dashed orange line in the figure), so that 10 responses gave a very good estimate of the next 1000 responses. In fact, a bootstrap significance test shows that the average of 10 randomly selected participants’ guesses is no more (or less) accurate than the average of those of 1000 random participants (P=.36). Moreover, the consensus responses had greater discrete accuracy (D) than that of the individual participants, achieving 7 correct responses out of 20, a 36% relative improvement over the 5.15 correct among individual participants. This result is consistent with previous studies demonstrating the wisdom of the crowd, in which the accuracy of consensus judgments exceeds that of individual judgments (see Comparison With Prior Work).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>16792</offset><text>Another important observation is that although error was high for individual responses and individual foods, the bias in the errors was low overall across all questions, such that the median of the error across items and participants is 0 (when using crowdsourcing over 2028 participants). Although this result is not actionable in itself, as it is averaged across all questions, it does demonstrate the power of crowds to converge toward high-accuracy judgments.</text></passage><passage><infon key="file">ijmr_v7i2e17_fig6.jpg</infon><infon key="id">figure6</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>17256</offset><text>A histogram of the number of correct estimates each participant made. See Patterns and Analysis for the definition of this measure, D.</text></passage><passage><infon key="file">ijmr_v7i2e17_fig7.jpg</infon><infon key="id">figure7</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>17391</offset><text>Calorie estimates and percent error (η) for each food item. For each food item, the violin plots represent the distribution of the calorie estimates by the participants and their percent error. The bottom and top of the boxes represent the first and third quartile, and the red band represents the mean of the calorie estimates, respectively. The green band represents the actual calorie value for each food item.</text></passage><passage><infon key="file">ijmr_v7i2e17_fig8.jpg</infon><infon key="id">figure8</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>17807</offset><text>Mean estimates for each food as more participants are added show that a consensus forms rapidly. The dotted blue lines show the true calorie value for each food. The x-axis uses a logarithmic scale. The orange dashed line indicates the estimates of nonexperts. The green continuous line represents the estimates of nutrition science experts. Note that the range of acceptable calorie estimates was 50 to 800 calories for each food item.</text></passage><passage><infon key="file">ijmr_v7i2e17_fig9.jpg</infon><infon key="id">figure9</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>18244</offset><text>Participants underestimated the calorie content of calorie-sparse foods and overestimated that of calorie-rich foods.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>18362</offset><text>Do the Nutritional Experts Outperform the Crowd?</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>18411</offset><text>In addition to redditors, we solicited participation from 5 nutritional experts. We recruited a faculty on a voluntary basis from the Department of Nutritional Science at the University of Arizona and the School of Nutrition and Health Promotion at Arizona State University. Somewhat surprisingly, neither the absolute error of their responses nor their discrete accuracy was statistically different from those of the average nonexpert participant (P=.19). In fact, a small crowd of only 2 randomly selected nonexperts was required to outperform the highest performing expert, achieving an average absolute error (|e|) of 119.3 (52.3%) compared with the expert’s 130.2 (55.3%). Expert performance is shown in comparison with nonexpert performance in Figure 8. This result is consistent with the hypothesis that the sources of error (eg, erroneous volume estimation due to a notion of typical portion size) apply equally to experts and nonexperts. Prior work in many domains of estimation has supported the notion that a relatively small group of nonexperts can estimate just as well as a single expert (see also Comparison With Prior Work).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>19554</offset><text>Does Having an Object for Scale in the Picture Help?</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>19607</offset><text>Several comments in the reddit thread expressed the hypothesis that pictures featuring a standard-sized reference object (such as a credit card) were easier to answer. The results showed that reference objects, far from aiding estimation, increased absolute error (|e|) by a mean 4.6 kcal (P=.01, R2=.31). Our hypothesis is that participants used background knowledge about the typical size of foods to scale foods but were not able to profit from comparison against the reference objects. This is statistically significant evidence for the notion that scale information does not aid calorie estimation in digital images (compare). However, it is important to note that this was a post hoc analysis only; the experiment was not designed to analyze this hypothesis. For example, we included objects that come in many different sizes (eg, forks) as reference objects, which may have confused the quiz takers. We leave a more careful evaluation of this particular observation as future work.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>20596</offset><text>Does Energy Density of Foods Predict Estimation Error?</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>20651</offset><text>As shown in Figure 9, the caloric content of energy-dense foods was systematically overestimated, and that of energy-sparse foods underestimated, as measured by error (e, P=.02, R2=.57). This bias is similar to one found by Almiron-Roig et al in estimating in-person portion sizes and could reflect 2 nonexclusive sources. First, it could result from the perceived healthiness of the food items. For example, broccoli is a prototypically healthy food but is not devoid of calories; conversely, prototypically unhealthy foods such as cheeseburgers have often been “engineered” for low calories. This explanation aligns with the results of Carels et al, who found that college students overestimated the caloric content of foods considered to be unhealthy while they underestimated the number of calories in healthy foods. Second, the bias could result from an assumption that the items would have a similar weight to one another, when in fact there was an inverse relationship between the energy density and weight of the items (Pearson correlation: ρ=–.70). We hypothesize that inelastic adjustment of portion size according to energy density could contribute to obesity.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>21830</offset><text>Does Body Mass Index Predict Estimation Errors?</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>21878</offset><text>BMI itself does not predict accuracy or bias in these data, similar to Blake et al and Chandon and Wansink. Other studies show that overweight and obese individuals consistently under-report calorie intake to a greater degree than nonoverweight individuals. However, BMI does significantly interact with energy density in predicting percent error (η, P=.002, R2=.57), such that the higher a participant's BMI, the more they exaggerated the calorie content of calorie-rich foods. We hypothesize that overweight individuals are more sensitive to perceptions of food.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>22445</offset><text>Do Gender and Age Predict Estimation Errors?</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>22490</offset><text>No biasing effect (toward underestimation, for example) was found, but absolute error (|e|) was greater for men than for women (P&lt;.001, R2=.31), similar to the portion judgment result by Almiron-Roig et al. In addition, the absolute error was greater for older participants (P&lt;.001, R2=.31), but these effects did not interact. Figures 10 and 11 summarize these differences. We hypothesize that the primary reason for these differences is cultural, reflecting gender norms and the relatively recent cultural emphasis on calories as a measure of healthiness.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>23048</offset><text>Do Estimation Errors Cluster by Food Type?</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>23091</offset><text>The over- and underestimation of errors for some foods correlate with those for others. For example, a participant who underestimates the calories in broccoli is likely to do so for cauliflower as well. Figure 12 shows an automatically generated map illustrating these correlations, with clusters showing similar subnetworks. A larger map with more food items would be a strong basis for predicting human bias on clusters of food types (eg, vegetables).</text></passage><passage><infon key="file">ijmr_v7i2e17_fig10.jpg</infon><infon key="id">figure10</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>23545</offset><text>The absolute error (|e|) of participants differs by gender. Box edges show the first and third quartiles and are split by the median. The boxes’ whiskers extend to the farthest point within 1.5 times the interquartile range from the box ends. The notches denote the 95% CI of the median. The y-axis is on a square-root scale.</text></passage><passage><infon key="file">ijmr_v7i2e17_fig11.jpg</infon><infon key="id">figure11</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>23873</offset><text>The absolute error (|e|) of participants differs by age. Box edges show the first and third quartiles and are split by the median. The boxes’ whiskers extend to the farthest point within 1.5 times the interquartile range from the box ends. The notches denote the 95% CI of the median. The y-axis is on a square-root scale.</text></passage><passage><infon key="file">ijmr_v7i2e17_fig12.jpg</infon><infon key="id">figure12</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>24198</offset><text>This map shows a network of food items in our survey based on correlation of estimation errors. Pairs of strongly correlated foods are connected by edges. The stronger the correlation, the closer the two (distances are inverse to correlation) are. Clusters show groups of similar subnetworks.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>24491</offset><text>Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>24502</offset><text>Principal Findings</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>24521</offset><text>The above analysis identifies several patterns that are important for the design of calorie estimation apps.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>24630</offset><text>First and foremost, our study demonstrates that individuals are poor judges of calorie content in images, and prior work has shown that they are poor judges of portion size in real-life situations (see Comparison With Prior Work). This suggests the utility of an ML approach to calorie estimation to facilitate meal planning. Keeping track of calories by describing foods and guessing quantities and values is a tedious and inaccurate strategy, yet it is the strategy most commonly used in apps today. Given that “a picture is worth a thousand words,” our initial hypothesis was that using images (rather than descriptions of foods) should lead to better estimates. Our results, however, do not support this hypothesis: on average, participants performed poorly at estimating the amount of calories in pictures of food, answering 5.15 of 20 questions correctly on average. Our analysis indicates that participants in our dataset tended to exaggerate common dietary knowledge; they underestimated the number of calories in energy-sparse foods and overestimated them in energy-dense ones.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>25721</offset><text>Our related work discussion (Comparison With Prior Work, below) highlights that estimating calories using ML remains an open research problem. However, our work suggests that such apps could take advantage of the wisdom of the crowd for estimation. We showed that the crowd performs better than experts, on average, even when the crowd is small. This suggests that this annotation could be implemented accurately and at low cost.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>26151</offset><text>The results suggest that for apps that focus on calorie monitoring (including self-reporting), it might be a good idea to characterize the users’ demographic data (age, gender, and BMI) shown to influence the accuracy of calorie estimates either directly or when combined with other factors such as energy density.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>26468</offset><text>We identified additional patterns that simplify the design and implementation of calorie-tracking apps. The first such pattern is that scale information does not improve estimation accuracy. The second is that estimation errors cluster by food types, which indicates that the app may extrapolate user patterns between foods in the same group.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>26811</offset><text>It is important to note that the observations of this study are statistically significant and applicable to the population of interest to us (ie, individuals likely to participate in crowdsourced annotations). This population is considerably younger than the US population (χ26=3362.5, P&lt;.001) and contains more women proportionally (χ21=81.0, P&lt;.001). In future work, we aim to repeat this study for a larger population that matches known demographics to verify the validity of our analysis on such populations.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>27328</offset><text>Comparison With Prior Work</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>27355</offset><text>Related work includes prior work in nutritional sciences, ML, image processing, and crowdsourcing. We review a small but representative subset below.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_3</infon><offset>27505</offset><text>Nutrition and Diet</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>27524</offset><text>Bandini et al and Schoeller et al have reported that individuals tend to selectively under-report the energy intake when these data are manually logged. This seems to be especially true for overweight and obese individuals and could be associated with a failure to accurately estimate portions, although Blake et al and Chandon and Wansink found that BMI does not correlate with the ability to estimate calories when this task is conducted in person. Portion estimation of in-person food remains poor, whether in reference to images on computer screens or on printed images. However, calorie estimation of large meals may be worse than that of small meals.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>28181</offset><text>To monitor dietary intake more accurately, third-party automated food analysis systems have been proposed. Martin et al used the remote food photography method (RFPM), which requires individuals to upload 3 pictures when having a meal: the plate of the foods selected by an individual, standard portions of known quantities of the foods, and the leftovers. These pictures are sent to trained dietitians who verify portions with participants and analyze these data using a standardized nutrient database. This approach relies on the judgment of trained nutrition professionals and argues for the validity of RFPM. Providing all 3 pictures for each meal is a challenge, as indicated by Williamson et al. Beltran et al tested the reliability of the eButton system, in which a camera worn on the chest records images continuously. The images are captured passively while the participant goes about their day, but such a system still requires experts to identify foods in the images and confirm them with participants. Similar to the RFPM employed by Martin et al, the eButton system requires valid pictures before and after each meal, camera placement at a certain angle, and proper lighting. Although promising, such systems are unlikely to scale to the millions of people who would like to accurately track their nutritional intake.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_3</infon><offset>29512</offset><text>Machine Learning and Image Processing</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>29550</offset><text>Given the challenges of the systems described above, a system that can automatically measure calories in pictures of food would be in great demand. Image processing techniques can be used to recognize food in images, and ML can be used to estimate the calories in the food.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>29824</offset><text>Menu-Match uses a database of restaurants and Global Positioning System locations and attempts to guess what is in the picture, using image features such as color and scale-invariant feature transforms. It has not been made available to the general public. Im2Calories is built on the work of Menu-Match. A multi-label classifier is trained on a collection of images of food. The app locates the restaurant a user is dining in and, given an image from the user, the classifier (running on the user’s phone) guesses which foods are present in the meal. Looking up the nutritional facts provided by the restaurant, using the resulting estimates, yields good results. Note, however, that Im2Calories has not been made available to the general public or even for research purposes.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>30604</offset><text>Bettadapura et al show that food recognition using location data improves accuracy. Such systems, however, are inherently limited to the restaurants whose menus are in the database. These also assume that menus do not change often and that the volume of food is the same from plate to plate. In reality, most meals are eaten either outside of restaurants or in restaurants whose menus are not included in some dataset. The “in the wild” problem is more natural but also more difficult.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>31094</offset><text>The Web app Foodlog divides food images into 300 blocks each and extracts discrete cosine transform coefficients and color histogram from each block. Using these data, Foodlog classifies the food into 5 categories according to the USDA's My Pyramid system. Experimental results report 88% accuracy in the extraction of food and 73% accuracy in food balance estimation. The FoodCam system segments the region of each food by GrabCut (an image segmentation approach based on iterative graph-cuts), extracts image features of histogram of oriented gradients and color patches with the Fisher Vector (an image representation obtained by pooling local image features), and finally classifies it into 1 of 100 food categories using linear support vector machines.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>31852</offset><text>With the exception of Im2Calories, the systems above achieve relatively good food recognition but without volume estimation. To estimate volume, Chae et al minimize the false-segmented regions, smooth the segmentation boundaries of food, and reconstruct 3D primitive shapes from a single food image. He et al estimate the weight of food given a single image using a shape template for regular-shaped foods and area-based weight estimation for irregularly shaped food. The Im2Calories system estimates the distance of every pixel from the camera by using a convolutional neural net architecture, converts the depth map into a voxel representation, and estimates the volume of the food. Although such approaches are effective, there is no app for estimation of food volumes available to the general public.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_3</infon><offset>32657</offset><text>Crowdsourcing</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>32671</offset><text>Crowdsourcing sometimes makes it possible to use multiple nonexpert judgments to approach the high quality of expert annotation. Surowiecki argues that in many instances, the average nonexpert estimates can even outperform a single expert. Watson has shown that the average of the individual judgments can be equal or superior to the judgment of the best individual within the group. Moreover, the validity of judgments increases with more judges. The strength of the wisdom of the crowd over ML is well understood and exploited in industry. For example, CardMunch (now a service of Evernote) uses crowdsourcing with Amazon Mechanical Turk to convert pictures of business cards into digital contact information. Eloquent Labs uses a mix of crowdsourcing with an artificial intelligence to implement a conversational assistant for customer service.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>33519</offset><text>In the nutrition domain, Mamykina et al show that crowdsourced ingredient annotations from food images are improved by expert annotation and by showing the annotators previous annotations of the images. The PlateMate app leverages crowdsourcing to implement the first step in the RFPM. Rather than typing names of foods and estimating portions, users take photographs of their plates both at the beginning of the meal and at the end to accurately capture how much food was actually eaten. PlateMate uses annotations from nonexpert Amazon Mechanical Turk workers instead of expert dietitians to estimate the composition of foods in static images. PlateMate's results are as accurate as the experts. Similarly, the Im2Calories project uses crowdsourcing to annotate all the food terms that apply to an image. Manually merging synonymous terms, they create the Food201-Multilabel dataset for training. Compared with the original Food101 classes, the new classes of Food201-Multilabel do better according to mean average precision, as they often correspond to side dishes or small food items.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>34608</offset><text>In sum, despite the abundance of interest in this and related topics, including calorie-tracking apps with manual entry, there exists no publicly available app that will accurately estimate calories from a single image. Likewise, although there are many studies of human bias in tracking calories and lack of skill in estimating portion sizes, no previous work establishes the accuracy and biases of crowdsourcing for calorie estimation, or what demographic factors might correlate with accuracy.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>35105</offset><text>Learning from our study, we envision a very simple app, where the only action required from the user is to take a picture of her or his food. The estimation logic, driven by the wisdom of the crowd and ML, would be transparent to the user, that is, it would be triggered automatically when the camera is used. The logic includes (1) detecting if the picture is a picture of food using image classification and (2) routing the image for crowd annotations (similar to CardMunch, which routes the task of processing images of business cards to the crowd). We hope that this simplicity will yield wide adoption, which, in turn, will lead to measurable effects in dietary choices.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>35781</offset><text>Limitations</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>35793</offset><text>Participants were not directly informed that some images were of fast food and thus more likely to be subject to food engineering, for example, replacing sugar or using sweetness enhancers, or adding water or protein to enhance food properties and palatability. The fact that this was not explicitly mentioned to the participants raises the possibility that participants might have considered these foods as “homemade,” which may have influenced perceived energy density and calories. However, since a majority of hamburgers are eaten at restaurants rather than homemade, judgments about engineered foods are as or more relevant than home-cooked foods for both naturalistic and app-related purposes</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>36496</offset><text>Conclusions</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>36508</offset><text>We described a study measuring the ability of over 2000 individuals to estimate calories in 20 pictures of food chosen to capture the building blocks of a healthy diet. We believe this study should be read as an analysis that drives the design of future food-related apps, with additional impacts on crowdsourcing strategies and the design of human-computer interfaces.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>36878</offset><text>Our analysis confirms some earlier observations (eg, calorie estimation is a difficult task, even for the experts) and offers new insights:</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>37018</offset><text>Even a small crowd of 2 nonexperts achieves calorie estimation accuracy greater than that of the expert annotators. This suggests that semiautomated food labeling apps can be implemented at a low cost by harnessing the wisdom of the crowd, even when the crowd is small. Note that some prior approaches in this space, such as PlateMate, use crowdsourcing to provide calorie information to users. To the best of our knowledge, the crowdsourcing method has never been tested as a source of data for algorithmic calorie estimation before.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>37553</offset><text>We found new type-of-food effects, with energy-dense foods (such as hamburgers) being consistently overestimated and energy-sparse foods (such as broccoli) consistently underestimated. Future crowdsourcing (or ML) projects aiming to annotate food for calorie content will benefit from correction using these biases.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>37869</offset><text>We found the absence of some expected correlations. For example, the presence of reference objects for scale does not improve accuracy but rather slightly decreases accuracy, and the BMI is not correlated with accuracy. These observations impact the design of interfaces for annotation apps, as well as data collection protocols.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>38199</offset><text>All in all, this work suggests that calorie-estimation apps are needed and can be built at low cost (eg, using small annotator groups, and without the overhead of including reference objects in images, or controlling for the BMI of users).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>38439</offset><text>Several interesting research questions remain. First, given the low calorie estimation accuracy (5 out of 20) and some clear patterns (underestimating “healthy” foods and overestimating “unhealthy” foods), it is natural to ask whether simple training with feedback can help improve accuracy for nonexperts. If so, how much training is required, what gains in accuracy can be obtained, and how much further can the crowd boost the results? Second, can we factor in biases (eg, age, gender) to obtain better crowdsourced prediction? Third, can better (more consistent) reference objects lead to improvements in accuracy? Fourth, assuming the baseline accuracy for “simple” foods (eg, fruits, vegetables, and sandwiches) can be improved with some of the ideas above, can we hope to tackle more difficult challenges, such as amorphous foods (porridge, mashed potatoes) and liquids (soups, smoothies) in which ingredients and volume are less obvious? Lastly, but perhaps most importantly, we aim to apply the knowledge gained from this study beyond the understanding of how (or how well) people estimate calories to include assessment of diet quality, which has become a dietary construct of interest in the past 5 years. This change has occurred because dietary patterns and dietary quality (eg, increased nutrient density, nutrient diversity, and nutrient adequacy) have been strongly associated with health and disease outcomes. This information provides potentially more meaningful metrics than the number of calories (which says nothing about the quality or “healthiness” of the food) when providing participants or patients with feedback.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>40095</offset><text>We believe this study should be read as an analysis that informs the design of future food-related apps (in particular, apps that feature calorie estimation), with additional potential impacts on crowdsourcing strategies and the design of human-computer interfaces. Our future goal is to provide estimates about judging calories from images for the purpose of mass annotation (eg, in support of a calorie-estimation app), which, in turn, is part of a larger system that analyzes text, images, and videos to estimate risk of diet-sensitive diseases such as type 2 diabetes mellitus.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>40677</offset><text>Conflicts of Interest: DB and MS disclose a financial interest in lum.ai. This interest has been disclosed to the University of Arizona Institutional Review Committee and is being managed in accordance with its conflict of interest policies.</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">title</infon><offset>40919</offset><text>Abbreviations</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>40933</offset><text>BMI</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>40937</offset><text>body mass index</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>40953</offset><text>ML</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>40956</offset><text>machine learning</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>40973</offset><text>RFPM</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>40978</offset><text>remote food photography method</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>41009</offset><text>USDA</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>41014</offset><text>United States Department of Agriculture</text></passage><passage><infon key="fpage">450</infon><infon key="issue">2</infon><infon key="lpage">8</infon><infon key="name_0">surname:Carels;given-names:RA</infon><infon key="name_1">surname:Konrad;given-names:K</infon><infon key="name_2">surname:Harper;given-names:J</infon><infon key="pub-id_doi">10.1016/j.appet.2007.02.009</infon><infon key="pub-id_medline">17428574</infon><infon key="pub-id_pmid">17428574</infon><infon key="section_type">REF</infon><infon key="source">Appetite</infon><infon key="type">ref</infon><infon key="volume">49</infon><infon key="year">2007</infon><offset>41054</offset><text>Individual differences in food perceptions and calorie estimation: an examination of dieting status, weight, and gender</text></passage><passage><infon key="fpage">199</infon><infon key="issue">2</infon><infon key="lpage">206</infon><infon key="name_0">surname:Carels;given-names:RA</infon><infon key="name_1">surname:Harper;given-names:J</infon><infon key="name_2">surname:Konrad;given-names:K</infon><infon key="pub-id_doi">10.1016/j.appet.2005.12.002</infon><infon key="pub-id_medline">16466830</infon><infon key="pub-id_pmid">16466830</infon><infon key="section_type">REF</infon><infon key="source">Appetite</infon><infon key="type">ref</infon><infon key="volume">46</infon><infon key="year">2006</infon><offset>41174</offset><text>Qualitative perceptions and caloric estimations of healthy and unhealthy foods by behavioral weight loss participants</text></passage><passage><infon key="fpage">f2907</infon><infon key="name_0">surname:Block;given-names:JP</infon><infon key="name_1">surname:Condon;given-names:SK</infon><infon key="name_2">surname:Kleinman;given-names:K</infon><infon key="name_3">surname:Mullen;given-names:J</infon><infon key="name_4">surname:Linakis;given-names:S</infon><infon key="name_5">surname:Rifas-Shiman;given-names:S</infon><infon key="name_6">surname:Gillman;given-names:MW</infon><infon key="pub-id_doi">10.1136/bmj.f2907</infon><infon key="pub-id_pmid">23704170</infon><infon key="section_type">REF</infon><infon key="source">Br Med J</infon><infon key="type">ref</infon><infon key="volume">346</infon><infon key="year">2013</infon><offset>41292</offset><text>Consumers' estimation of calorie content at fast food restaurants: cross sectional observational study</text></passage><passage><infon key="fpage">521</infon><infon key="issue">3</infon><infon key="lpage">526</infon><infon key="name_0">surname:Brown;given-names:RE</infon><infon key="name_1">surname:Canning;given-names:KL</infon><infon key="name_2">surname:Fung;given-names:M</infon><infon key="name_3">surname:Jiandani;given-names:D</infon><infon key="name_4">surname:Riddell;given-names:MC</infon><infon key="name_5">surname:Macpherson;given-names:AK</infon><infon key="name_6">surname:Kuk;given-names:JL</infon><infon key="pub-id_doi">10.1249/MSS.0000000000000796</infon><infon key="pub-id_medline">26469988</infon><infon key="pub-id_pmid">26469988</infon><infon key="section_type">REF</infon><infon key="source">Med Sci Sports Exerc</infon><infon key="type">ref</infon><infon key="volume">48</infon><infon key="year">2016</infon><offset>41395</offset><text>Calorie estimation in adults differing in body weight class and weight loss status</text></passage><passage><infon key="fpage">450</infon><infon key="lpage">451</infon><infon key="name_0">surname:Galton;given-names:F</infon><infon key="pub-id_doi">10.1038/075450a0</infon><infon key="section_type">REF</infon><infon key="source">Nature</infon><infon key="type">ref</infon><infon key="volume">75</infon><infon key="year">1907</infon><offset>41478</offset><text>Vox Populi</text></passage><passage><infon key="fpage">796</infon><infon key="issue">8</infon><infon key="lpage">804</infon><infon key="name_0">surname:Marbach;given-names:D</infon><infon key="name_1">surname:Costello;given-names:JC</infon><infon key="name_2">surname:Küffner;given-names:R</infon><infon key="name_3">surname:Vega;given-names:NM</infon><infon key="name_4">surname:Prill;given-names:RJ</infon><infon key="name_5">surname:Camacho;given-names:DM</infon><infon key="name_6">surname:Allison;given-names:KR</infon><infon key="name_7">surname:Kellis;given-names:M</infon><infon key="name_8">surname:Collins;given-names:JJ</infon><infon key="name_9">surname:Stolovitzky;given-names:G</infon><infon key="pub-id_doi">10.1038/nmeth.2016</infon><infon key="pub-id_medline">22796662</infon><infon key="pub-id_pmid">22796662</infon><infon key="section_type">REF</infon><infon key="source">Nat Methods</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2012</infon><offset>41489</offset><text>Wisdom of crowds for robust gene network inference</text></passage><passage><infon key="fpage">452</infon><infon key="issue">3</infon><infon key="lpage">470</infon><infon key="name_0">surname:Yi;given-names:SK</infon><infon key="name_1">surname:Steyvers;given-names:M</infon><infon key="name_2">surname:Lee;given-names:MD</infon><infon key="name_3">surname:Dry;given-names:MJ</infon><infon key="pub-id_doi">10.1111/j.1551-6709.2011.01223.x</infon><infon key="pub-id_medline">22268680</infon><infon key="pub-id_pmid">22268680</infon><infon key="section_type">REF</infon><infon key="source">Cogn Sci</infon><infon key="type">ref</infon><infon key="volume">36</infon><infon key="year">2012</infon><offset>41540</offset><text>The wisdom of the crowd in combinatorial problems</text></passage><passage><infon key="comment">/r/SampleSize: Where your opinions actually matter!
https://www.reddit.com/r/SampleSize/</infon><infon key="section_type">REF</infon><infon key="source">Reddit</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41590</offset></passage><passage><infon key="fpage">1205</infon><infon key="issue">7</infon><infon key="lpage">17</infon><infon key="name_0">surname:Huang;given-names:TT</infon><infon key="name_1">surname:Roberts;given-names:SB</infon><infon key="name_2">surname:Howarth;given-names:NC</infon><infon key="name_3">surname:McCrory;given-names:MA</infon><infon key="pub-id_doi">10.1038/oby.2005.143</infon><infon key="pub-id_medline">16076990</infon><infon key="pub-id_pmid">16076990</infon><infon key="section_type">REF</infon><infon key="source">Obes Res</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2005</infon><offset>41591</offset><text>Effect of screening out implausible energy intake reports on relationships between diet and BMI</text></passage><passage><infon key="comment">MyPlate Model
https://www.choosemyplate.gov/MyPlate</infon><infon key="section_type">REF</infon><infon key="source">Choosemyplate</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41687</offset></passage><passage><infon key="fpage">71155</infon><infon key="issue">230</infon><infon key="lpage">71259</infon><infon key="section_type">REF</infon><infon key="source">Fed Reg</infon><infon key="type">ref</infon><infon key="volume">79</infon><infon key="year">2014</infon><offset>41688</offset><text>Food labeling; nutrition labeling of standard menu items in restaurants and similar retail food establishments. Final rule</text></passage><passage><infon key="comment">What does 200 Calories Look Like?
http://www.wisegeek.com/what-does-200-calories-look-like.htm</infon><infon key="section_type">REF</infon><infon key="source">wiseGEEK</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41811</offset></passage><passage><infon key="comment">300 Calorie Food Picture Gallery
http://www.healthassist.net/food/300kcal/300.shtml</infon><infon key="section_type">REF</infon><infon key="source">HealthAssist</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41812</offset></passage><passage><infon key="comment">Brown Steamed Rice
https://www.pandaexpress.com/menu/sides/brown-steamed-rice</infon><infon key="section_type">REF</infon><infon key="source">Panda Express</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41813</offset></passage><passage><infon key="comment">Foods with 100 Calories
http://www.foodnetwork.com/healthy/photos/foods-with-100-calories</infon><infon key="section_type">REF</infon><infon key="source">Food Network</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41814</offset></passage><passage><infon key="comment">https://www.bk.com/</infon><infon key="section_type">REF</infon><infon key="source">Burger King</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41815</offset></passage><passage><infon key="comment">Matcha calorie calculation of cake
http://www.asken.jp/calculate/meal/94371</infon><infon key="section_type">REF</infon><infon key="source">Wit Co, Ltd</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41816</offset></passage><passage><infon key="comment">https://www.papajohns.com/</infon><infon key="section_type">REF</infon><infon key="source">Papa John's Pizza</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41817</offset></passage><passage><infon key="comment">Food nutrients can be seen calorie calculation at a glance
http://calorie.slism.jp/200528/</infon><infon key="section_type">REF</infon><infon key="source">Slism</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41818</offset></passage><passage><infon key="comment">Jimmy John's Gourmet Sandwiches
https://www.jimmyjohns.com/</infon><infon key="section_type">REF</infon><infon key="source">Jimmy John's</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>41819</offset></passage><passage><infon key="issue">1</infon><infon key="name_0">surname:Bates;given-names:D</infon><infon key="name_1">surname:Mächler;given-names:M</infon><infon key="name_2">surname:Bolker;given-names:B</infon><infon key="name_3">surname:Walker;given-names:S</infon><infon key="pub-id_doi">10.18637/jss.v067.i01</infon><infon key="section_type">REF</infon><infon key="source">J Stat Softw</infon><infon key="type">ref</infon><infon key="volume">67</infon><infon key="year">2015</infon><offset>41820</offset><text>Fitting linear mixed-effects models using lme4</text></passage><passage><infon key="fpage">1</infon><infon key="issue">13</infon><infon key="lpage">26</infon><infon key="name_0">surname:Kuznetsova;given-names:A</infon><infon key="name_1">surname:Brockhoff;given-names:PB</infon><infon key="name_2">surname:Christensen;given-names:R</infon><infon key="pub-id_doi">10.18637/jss.v082.i13</infon><infon key="section_type">REF</infon><infon key="source">J Stat Softw</infon><infon key="type">ref</infon><infon key="volume">82</infon><infon key="year">2017</infon><offset>41867</offset><text>lmerTest Package: tests in linear mixed effects models</text></passage><passage><infon key="fpage">23</infon><infon key="lpage">28</infon><infon key="name_0">surname:Bell;given-names:D</infon><infon key="name_1">surname:Fried;given-names:D</infon><infon key="name_2">surname:Huangfu;given-names:L</infon><infon key="name_3">surname:Surdeanu;given-names:M</infon><infon key="name_4">surname:Kobourov;given-names:S</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>41922</offset><text>Towards using social media to identify individuals at risk for preventable chronic illness</text></passage><passage><infon key="comment">Who in the World is reddit? Results are in
https://redditblog.com/2011/09/12/who-in-the-world-is-reddit-results-are-in/</infon><infon key="section_type">REF</infon><infon key="source">Reddit</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>42013</offset></passage><passage><infon key="name_0">surname:Surowiecki;given-names:J</infon><infon key="section_type">REF</infon><infon key="source">The Wisdom of Crowds: Why the Many Are Smarter Than the Few and How Collective Wisdom Shapes Business, Economies, Societies and Nations</infon><infon key="type">ref</infon><infon key="year">2004</infon><offset>42014</offset></passage><passage><infon key="fpage">328</infon><infon key="issue">3</infon><infon key="lpage">336</infon><infon key="name_0">surname:Watson;given-names:GB</infon><infon key="pub-id_doi">10.1037/h0072661</infon><infon key="section_type">REF</infon><infon key="source">J Abnorm Soc Psychol</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">1928</infon><offset>42015</offset><text>Do groups think more efficiently than individuals?</text></passage><passage><infon key="fpage">S14</infon><infon key="lpage">S21</infon><infon key="name_0">surname:Hernández;given-names:T</infon><infon key="name_1">surname:Wilder;given-names:L</infon><infon key="name_2">surname:Kuehn;given-names:D</infon><infon key="name_3">surname:Rubotzky;given-names:K</infon><infon key="name_4">surname:Moser-Veillon;given-names:P</infon><infon key="name_5">surname:Godwin;given-names:S</infon><infon key="name_6">surname:Thompson;given-names:C</infon><infon key="name_7">surname:Wang;given-names:C</infon><infon key="pub-id_doi">10.1016/j.jfca.2006.02.010</infon><infon key="section_type">REF</infon><infon key="source">J Food Compos Anal</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2006</infon><offset>42066</offset><text>Portion size estimation and expectation of accuracy</text></passage><passage><infon key="fpage">95</infon><infon key="lpage">103</infon><infon key="name_0">surname:Almiron-Roig;given-names:E</infon><infon key="name_1">surname:Solis-Trapala;given-names:I</infon><infon key="name_2">surname:Dodd;given-names:J</infon><infon key="name_3">surname:Jebb;given-names:SA</infon><infon key="pub-id_doi">10.1016/j.appet.2013.07.012</infon><infon key="pub-id_pmid">23932948</infon><infon key="section_type">REF</infon><infon key="source">Appetite</infon><infon key="type">ref</infon><infon key="volume">71</infon><infon key="year">2013</infon><offset>42118</offset><text>Estimating food portions. Influence of unit number, meal type and energy density</text></passage><passage><infon key="fpage">106</infon><infon key="issue">1</infon><infon key="lpage">112</infon><infon key="name_0">surname:Faulkner;given-names:GP</infon><infon key="name_1">surname:Pourshahidi;given-names:LK</infon><infon key="name_2">surname:Wallace;given-names:JM</infon><infon key="name_3">surname:Kerr;given-names:MA</infon><infon key="name_4">surname:McCaffrey;given-names:TA</infon><infon key="name_5">surname:Livingstone;given-names:MBE</infon><infon key="pub-id_doi">10.1038/ijo.2013.69</infon><infon key="section_type">REF</infon><infon key="source">Int J Obes Relat Metab Disord</infon><infon key="type">ref</infon><infon key="volume">38</infon><infon key="year">2013</infon><offset>42199</offset><text>Perceived ‘healthiness’ of foods can influence consumers’ estimations of energy density and appropriate portion size</text></passage><passage><infon key="fpage">a</infon><infon key="issue">5</infon><infon key="name_0">surname:Pérez-Escamilla;given-names:R</infon><infon key="name_1">surname:Obbagy;given-names:JE</infon><infon key="name_2">surname:Altman;given-names:JM</infon><infon key="name_3">surname:Essery;given-names:EV</infon><infon key="name_4">surname:McGrane;given-names:MM</infon><infon key="name_5">surname:Wong;given-names:YP</infon><infon key="name_6">surname:Spahn;given-names:JM</infon><infon key="name_7">surname:Williams;given-names:CL</infon><infon key="pub-id_medline">22480489</infon><infon key="section_type">REF</infon><infon key="source">J Acad Nutr Diet</infon><infon key="type">ref</infon><infon key="volume">112</infon><infon key="year">2012</infon><offset>42322</offset><text>Dietary energy density and body weight in adults and children: a systematic review</text></passage><passage><infon key="fpage">962</infon><infon key="issue">7</infon><infon key="lpage">4</infon><infon key="name_0">surname:Blake;given-names:AJ</infon><infon key="name_1">surname:Guthrie;given-names:HA</infon><infon key="name_2">surname:Smiciklas-Wright;given-names:H</infon><infon key="pub-id_medline">2745915</infon><infon key="pub-id_pmid">2745915</infon><infon key="section_type">REF</infon><infon key="source">J Am Diet Assoc</infon><infon key="type">ref</infon><infon key="volume">89</infon><infon key="year">1989</infon><offset>42405</offset><text>Accuracy of food portion estimation by overweight and normal-weight subjects</text></passage><passage><infon key="fpage">84</infon><infon key="issue">1</infon><infon key="lpage">99</infon><infon key="name_0">surname:Chandon;given-names:P</infon><infon key="name_1">surname:Wansink;given-names:B</infon><infon key="pub-id_doi">10.1509/jmkr.44.1.84</infon><infon key="section_type">REF</infon><infon key="source">J Mark Res</infon><infon key="type">ref</infon><infon key="volume">44</infon><infon key="year">2007</infon><offset>42482</offset><text>Is obesity caused by calorie underestimation? A psychophysical model of meal size estimation</text></passage><passage><infon key="fpage">64</infon><infon key="issue">1</infon><infon key="lpage">71</infon><infon key="name_0">surname:Bailey;given-names:RL</infon><infon key="name_1">surname:Mitchell;given-names:DC</infon><infon key="name_2">surname:Miller;given-names:C</infon><infon key="name_3">surname:Smiciklas-Wright;given-names:H</infon><infon key="pub-id_doi">10.1016/j.jada.2006.10.009</infon><infon key="pub-id_pmid">17197273</infon><infon key="section_type">REF</infon><infon key="source">J Am Diet Assoc</infon><infon key="type">ref</infon><infon key="volume">107</infon><infon key="year">2007</infon><offset>42575</offset><text>Assessing the effect of underreporting energy intake on dietary patterns and weight status</text></passage><passage><infon key="fpage">300</infon><infon key="issue">3</infon><infon key="lpage">306</infon><infon key="name_0">surname:Kretsch;given-names:MJ</infon><infon key="name_1">surname:Fong;given-names:AK</infon><infon key="name_2">surname:Green;given-names:MW</infon><infon key="pub-id_doi">10.1016/s0002-8223(99)00078-4</infon><infon key="pub-id_pmid">10076581</infon><infon key="section_type">REF</infon><infon key="source">J Am Diet Assoc</infon><infon key="type">ref</infon><infon key="volume">99</infon><infon key="year">1999</infon><offset>42666</offset><text>Behavioral and body size correlates of energy intake underreporting by obese and normal-weight women</text></passage><passage><infon key="name_0">surname:Kobourov;given-names:SG</infon><infon key="name_1">surname:Pupyrev;given-names:S</infon><infon key="name_2">surname:Simonetto;given-names:P</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2014</infon><offset>42767</offset><text>Visualizing graphs as maps with contiguous regions</text></passage><passage><infon key="fpage">421</infon><infon key="issue">3</infon><infon key="lpage">5</infon><infon key="name_0">surname:Bandini;given-names:LG</infon><infon key="name_1">surname:Schoeller;given-names:DA</infon><infon key="name_2">surname:Cyr;given-names:HN</infon><infon key="name_3">surname:Dietz;given-names:WH</infon><infon key="pub-id_doi">10.1093/ajcn/52.3.421</infon><infon key="pub-id_medline">2393004</infon><infon key="pub-id_pmid">2393004</infon><infon key="section_type">REF</infon><infon key="source">Am J Clin Nutr</infon><infon key="type">ref</infon><infon key="volume">52</infon><infon key="year">1990</infon><offset>42818</offset><text>Validity of reported energy intake in obese and nonobese adolescents</text></passage><passage><infon key="fpage">941</infon><infon key="issue">7</infon><infon key="lpage">949</infon><infon key="name_0">surname:Schoeller;given-names:DA</infon><infon key="name_1">surname:Bandini;given-names:LG</infon><infon key="name_2">surname:Dietz;given-names:WH</infon><infon key="pub-id_doi">10.1139/y90-143</infon><infon key="pub-id_pmid">2200586</infon><infon key="section_type">REF</infon><infon key="source">Can J Physiol Pharmacol</infon><infon key="type">ref</infon><infon key="volume">68</infon><infon key="year">1990</infon><offset>42887</offset><text>Inaccuracies in self-reported intake identified by comparison with the doubly labelled water method</text></passage><passage><infon key="fpage">S14</infon><infon key="lpage">S21</infon><infon key="name_0">surname:Hernández;given-names:T</infon><infon key="name_1">surname:Wilder;given-names:L</infon><infon key="name_2">surname:Kuehn;given-names:D</infon><infon key="name_3">surname:Rubotzky;given-names:K</infon><infon key="name_4">surname:Moser-Veillon;given-names:P</infon><infon key="name_5">surname:Godwin;given-names:S</infon><infon key="name_6">surname:Thompson;given-names:C</infon><infon key="name_7">surname:Wang;given-names:C</infon><infon key="section_type">REF</infon><infon key="source">J Food Comp Anal</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2006</infon><offset>42987</offset><text>Portion size estimation and expectation of accuracy</text></passage><passage><infon key="fpage">326</infon><infon key="issue">5</infon><infon key="name_0">surname:Wansink;given-names:B</infon><infon key="name_1">surname:Chandon;given-names:P</infon><infon key="pub-id_doi">10.7326/0003-4819-145-5-200609050-00005</infon><infon key="pub-id_pmid">16954358</infon><infon key="section_type">REF</infon><infon key="source">Ann Intern Med</infon><infon key="type">ref</infon><infon key="volume">145</infon><infon key="year">2006</infon><offset>43039</offset><text>Meal size, not body size, explains errors in estimating the calorie content of meals</text></passage><passage><infon key="fpage">446</infon><infon key="issue">3</infon><infon key="lpage">56</infon><infon key="name_0">surname:Martin;given-names:CK</infon><infon key="name_1">surname:Han;given-names:H</infon><infon key="name_2">surname:Coulon;given-names:SM</infon><infon key="name_3">surname:Allen;given-names:HR</infon><infon key="name_4">surname:Champagne;given-names:CM</infon><infon key="name_5">surname:Anton;given-names:SD</infon><infon key="pub-id_doi">10.1017/S0007114508027438</infon><infon key="pub-id_medline">18616837</infon><infon key="pub-id_pmid">18616837</infon><infon key="section_type">REF</infon><infon key="source">Br J Nutr</infon><infon key="type">ref</infon><infon key="volume">101</infon><infon key="year">2009</infon><offset>43124</offset><text>A novel method to remotely measure food intake of free-living individuals in real time: the remote food photography method</text></passage><passage><infon key="fpage">24</infon><infon key="issue">1</infon><infon key="lpage">28</infon><infon key="name_0">surname:Williamson;given-names:DA</infon><infon key="name_1">surname:Allen;given-names:HR</infon><infon key="name_2">surname:Martin;given-names:PD</infon><infon key="name_3">surname:Alfonso;given-names:A</infon><infon key="name_4">surname:Gerald;given-names:B</infon><infon key="name_5">surname:Hunt;given-names:A</infon><infon key="pub-id_doi">10.1007/bf03325041</infon><infon key="section_type">REF</infon><infon key="source">Eat Weight Disord</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2013</infon><offset>43247</offset><text>Digital photography: a new method for estimating food intake in cafeteria settings</text></passage><passage><infon key="fpage">25</infon><infon key="lpage">27</infon><infon key="name_0">surname:Beltran;given-names:A</infon><infon key="name_1">surname:Dadabhoy;given-names:H</infon><infon key="name_2">surname:Chen;given-names:T</infon><infon key="name_3">surname:Lin;given-names:C</infon><infon key="name_4">surname:Jia;given-names:W</infon><infon key="name_5">surname:Baranowski;given-names:J</infon><infon key="name_6">surname:Yan;given-names:G</infon><infon key="name_7">surname:Sun;given-names:M</infon><infon key="name_8">surname:Baranowski;given-names:T</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>43330</offset><text>Adapting the eButton to the abilities of children for diet assessment</text></passage><passage><infon key="name_0">surname:Beijbom;given-names:O</infon><infon key="name_1">surname:Joshi;given-names:N</infon><infon key="name_2">surname:Morris;given-names:D</infon><infon key="name_3">surname:Saponas;given-names:S</infon><infon key="name_4">surname:Khullar;given-names:S</infon><infon key="pub-id_doi">10.1109/wacv.2015.117</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>43400</offset><text>Menu-Match: Restaurant-Specific Food Logging from Images</text></passage><passage><infon key="name_0">surname:Lowe;given-names:D</infon><infon key="pub-id_doi">10.1109/iccv.1999.790410</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">1999</infon><offset>43457</offset><text>Object recognition from local scale-invariant features</text></passage><passage><infon key="name_0">surname:Myers;given-names:A</infon><infon key="name_1">surname:Johnston;given-names:N</infon><infon key="name_2">surname:Rathod;given-names:V</infon><infon key="name_3">surname:Korattikara;given-names:A</infon><infon key="name_4">surname:Gorban;given-names:A</infon><infon key="name_5">surname:Silberman;given-names:N</infon><infon key="name_6">surname:Guadarrama;given-names:S</infon><infon key="name_7">surname:Papandreou;given-names:G</infon><infon key="name_8">surname:Huang;given-names:J</infon><infon key="name_9">surname:Murphy;given-names:K</infon><infon key="pub-id_doi">10.1109/iccv.2015.146</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>43512</offset><text>Im2Calories: Towards an Automated Mobile Vision Food Diary</text></passage><passage><infon key="name_0">surname:Bettadapura;given-names:V</infon><infon key="name_1">surname:Thomaz;given-names:E</infon><infon key="name_2">surname:Parnami;given-names:A</infon><infon key="name_3">surname:Abowd;given-names:G</infon><infon key="name_4">surname:Essa;given-names:I</infon><infon key="pub-id_doi">10.1109/wacv.2015.83</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>43571</offset><text>Leveraging Context to Support Automated Food Recognition in Restaurants</text></passage><passage><infon key="name_0">surname:Kitamura;given-names:K</infon><infon key="name_1">surname:Yamasaki;given-names:T</infon><infon key="name_2">surname:Aizawa;given-names:K</infon><infon key="pub-id_doi">10.1145/1459359.1459548</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2008</infon><offset>43643</offset><text>Food log by analyzing food images</text></passage><passage><infon key="name_0">surname:Kitamura;given-names:K</infon><infon key="name_1">surname:Yamasaki;given-names:T</infon><infon key="name_2">surname:Aizawa;given-names:K</infon><infon key="pub-id_doi">10.1145/1630995.1631001</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2009</infon><offset>43677</offset><text>FoodLog</text></passage><passage><infon key="fpage">5263</infon><infon key="issue">14</infon><infon key="lpage">5287</infon><infon key="name_0">surname:Kawano;given-names:Y</infon><infon key="name_1">surname:Yanai;given-names:K</infon><infon key="pub-id_doi">10.1007/s11042-014-2000-8</infon><infon key="section_type">REF</infon><infon key="source">Multimed Tools Appl</infon><infon key="type">ref</infon><infon key="volume">74</infon><infon key="year">2014</infon><offset>43685</offset><text>FoodCam: A real-time food recognition system on a smartphone</text></passage><passage><infon key="fpage">309</infon><infon key="issue">3</infon><infon key="lpage">314</infon><infon key="name_0">surname:Rother;given-names:C</infon><infon key="name_1">surname:Kolmogorov;given-names:V</infon><infon key="name_2">surname:Blake;given-names:A</infon><infon key="pub-id_doi">10.1145/1015706.1015720</infon><infon key="section_type">REF</infon><infon key="source">ACM Trans Graph</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2004</infon><offset>43746</offset><text>Grabcut: interactive foreground extraction using iterated graph cuts</text></passage><passage><infon key="name_0">surname:Dalal;given-names:N</infon><infon key="name_1">surname:Triggs;given-names:B</infon><infon key="pub-id_doi">10.1109/CVPR.2005.177</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2005</infon><offset>43815</offset><text>Histograms of oriented gradients for human detection</text></passage><passage><infon key="fpage">28</infon><infon key="lpage">42</infon><infon key="name_0">surname:Csurka;given-names:G</infon><infon key="name_1">surname:Perronnin;given-names:F</infon><infon key="section_type">REF</infon><infon key="source">Communications in Computer and Information Science Computer Vision, Imaging and Computer Graphics Theory and Applications</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>43868</offset><text>Fisher vectors: beyond bag-of-visual-words image representations</text></passage><passage><infon key="fpage">78730K</infon><infon key="name_0">surname:Chae;given-names:J</infon><infon key="name_1">surname:Woo;given-names:I</infon><infon key="name_2">surname:Kim;given-names:S</infon><infon key="name_3">surname:Maciejewski;given-names:R</infon><infon key="name_4">surname:Zhu;given-names:F</infon><infon key="name_5">surname:Delp;given-names:EJ</infon><infon key="name_6">surname:Boushey;given-names:CJ</infon><infon key="name_7">surname:Ebert;given-names:DS</infon><infon key="pub-id_doi">10.1117/12.876669</infon><infon key="pub-id_medline">22025936</infon><infon key="section_type">REF</infon><infon key="source">Proc SPIE Int Soc Opt Eng</infon><infon key="type">ref</infon><infon key="volume">7873</infon><infon key="year">2011</infon><offset>43933</offset><text>Volume estimation using food specific shape templates in mobile image-based dietary assessment</text></passage><passage><infon key="name_0">surname:He;given-names:Y</infon><infon key="name_1">surname:Xu;given-names:C</infon><infon key="name_2">surname:Khanna;given-names:N</infon><infon key="name_3">surname:Boushey;given-names:CJ</infon><infon key="name_4">surname:Delp;given-names:EJ</infon><infon key="pub-id_doi">10.1109/icme.2013.6607548</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>44028</offset><text>Food image analysis: Segmentation, identification and weight estimation</text></passage><passage><infon key="fpage">75</infon><infon key="issue">1</infon><infon key="lpage">90</infon><infon key="name_0">surname:Brabham;given-names:DC</infon><infon key="pub-id_doi">10.1177/1354856507084420</infon><infon key="section_type">REF</infon><infon key="source">Convergence</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2008</infon><offset>44100</offset><text>Crowdsourcing as a model for problem solving: an introduction and cases</text></passage><passage><infon key="fpage">398</infon><infon key="issue">5</infon><infon key="lpage">400</infon><infon key="name_0">surname:Gordon;given-names:K</infon><infon key="pub-id_doi">10.1037/h0074666</infon><infon key="section_type">REF</infon><infon key="source">J Exp Psychol</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">1924</infon><offset>44172</offset><text>Group judgments in the field of lifted weights</text></passage><passage><infon key="comment">Get organized. Work smarter. Remember everything
http://evernote.com</infon><infon key="section_type">REF</infon><infon key="source">Evernote</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>44219</offset></passage><passage><infon key="comment">https://www.eloquent.ai/</infon><infon key="section_type">REF</infon><infon key="source">Eloquent Labs</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>44220</offset></passage><passage><infon key="name_0">surname:Mamykina;given-names:L</infon><infon key="name_1">surname:Smyth;given-names:T</infon><infon key="name_2">surname:Dimond;given-names:J</infon><infon key="name_3">surname:Gajos;given-names:K</infon><infon key="pub-id_doi">10.1145/2858036.2858560</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>44221</offset><text>Learning from the crowd: Observational learning in crowdsourcing communities</text></passage><passage><infon key="name_0">surname:Noronha;given-names:J</infon><infon key="name_1">surname:Hysen;given-names:E</infon><infon key="name_2">surname:Zhang;given-names:H</infon><infon key="name_3">surname:Gajos;given-names:K</infon><infon key="pub-id_doi">10.1145/2047196.2047198</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>44298</offset><text>Platemate</text></passage><passage><infon key="fpage">350</infon><infon key="lpage">357</infon><infon key="name_0">surname:Kagaya;given-names:H</infon><infon key="name_1">surname:Aizawa;given-names:K</infon><infon key="pub-id_doi">10.1007/978-3-319-23222-5_43</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>44308</offset><text>Highly accurate food/non-food image classification based on a deep convolutional neural network</text></passage><passage><infon key="name_0">surname:Kagaya;given-names:H</infon><infon key="name_1">surname:Aizawa;given-names:K</infon><infon key="name_2">surname:Ogawa;given-names:M</infon><infon key="pub-id_doi">10.1145/2647868.2654970</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2014</infon><offset>44404</offset><text>Food Detection and Recognition Using Convolutional Neural Network</text></passage><passage><infon key="comment">https://www.scribd.com/document/37170221/Obesity-and-Food-Technology</infon><infon key="name_0">surname:Meister;given-names:K</infon><infon key="name_1">surname:Doyle;given-names:M</infon><infon key="section_type">REF</infon><infon key="source">Obesity and Food Technology. American Council on Science and Health; 2009</infon><infon key="type">ref</infon><offset>44470</offset></passage><passage><infon key="fpage">445</infon><infon key="issue">3</infon><infon key="lpage">54</infon><infon key="name_0">surname:Tapsell;given-names:LC</infon><infon key="name_1">surname:Neale;given-names:EP</infon><infon key="name_2">surname:Satija;given-names:A</infon><infon key="name_3">surname:Hu;given-names:FB</infon><infon key="pub-id_doi">10.3945/an.115.011718</infon><infon key="pub-id_medline">27184272</infon><infon key="pub-id_pmid">27184272</infon><infon key="section_type">REF</infon><infon key="source">Adv Nutr</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2016</infon><offset>44471</offset><text>Foods, nutrients, and dietary patterns: interconnections and implications for dietary guidelines</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">8</infon><infon key="name_0">surname:Rains;given-names:SA</infon><infon key="name_1">surname:Hingle;given-names:MD</infon><infon key="name_2">surname:Surdeanu;given-names:M</infon><infon key="name_3">surname:Bell;given-names:D</infon><infon key="name_4">surname:Kobourov;given-names:S</infon><infon key="pub-id_doi">10.1080/10410236.2018.1431024</infon><infon key="pub-id_medline">29373042</infon><infon key="section_type">REF</infon><infon key="source">Health Commun</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>44568</offset><text>A test of the risk perception attitude framework as a message tailoring strategy to promote diabetes screening</text></passage></document></collection>
