<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20210131</date><key>pmc.key</key><document><id>7524768</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.1038/s41598-020-72690-4</infon><infon key="article-id_pmc">7524768</infon><infon key="article-id_pmid">32994447</infon><infon key="article-id_publisher-id">72690</infon><infon key="elocation-id">15940</infon><infon key="kwd">Human behaviour Applied mathematics Computer science Information technology</infon><infon key="license">Open AccessThis article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.</infon><infon key="name_0">surname:Abeliuk;given-names:Andrés</infon><infon key="name_1">surname:Benjamin;given-names:Daniel M.</infon><infon key="name_2">surname:Morstatter;given-names:Fred</infon><infon key="name_3">surname:Galstyan;given-names:Aram</infon><infon key="section_type">TITLE</infon><infon key="title">Subject terms</infon><infon key="type">front</infon><infon key="volume">10</infon><infon key="year">2020</infon><offset>0</offset><text>Quantifying machine influence over human forecasters</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>53</offset><text>Crowdsourcing human forecasts and machine learning models each show promise in predicting future geopolitical outcomes. Crowdsourcing increases accuracy by pooling knowledge, which mitigates individual errors. On the other hand, advances in machine learning have led to machine models that increase accuracy due to their ability to parameterize and adapt to changing environments. To capitalize on the unique advantages of each method, recent efforts have shown improvements by “hybridizing” forecasts—pairing human forecasters with machine models. This study analyzes the effectiveness of such a hybrid system. In a perfect world, independent reasoning by the forecasters combined with the analytic capabilities of the machine models should complement each other to arrive at an ultimately more accurate forecast. However, well-documented biases describe how humans often mistrust and under-utilize such models in their forecasts. In this work, we present a model that can be used to estimate the trust that humans assign to a machine. We use forecasts made in the absence of machine models as prior beliefs to quantify the weights placed on the models. Our model can be used to uncover other aspects of forecasters’ decision-making processes. We find that forecasters trust the model rarely, in a pattern that suggests they treat machine models similarly to expert advisors, but only the best forecasters trust the models when they can be expected to perform well. We also find that forecasters tend to choose models that conform to their prior beliefs as opposed to anchoring on the model forecast. Our results suggest machine models can improve the judgment of a human pool but highlight the importance of accounting for trust and cognitive biases involved in the human judgment process.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1853</offset><text>Many high stakes intelligence decisions rely on accurate predictions. Forecasting future political and economic events is notoriously difficult. The forecasts of individuals tend to be inaccurate and unreliable, even if they are experts. When tracked over time, experts exhibit forecasting accuracy not significantly better than a random guess in many domains, including politics. Two solutions have emerged that reliably improve prediction accuracy: eliciting and aggregating forecasts from a pool of forecasters (crowdsourcing) and using machine learning to improve time-series models. Combining even a small number of judgments can lead to stark, stable improvements in accuracy. Statistically aggregating large pools of public forecasts has recently been shown to improve upon individual forecasts. Concurrently, advances in machine learning have led to improvements in feature identification and prediction, provided data is available and favorably structured. Finally, recent work on human–machine ensemble methods shows that aggregating a crowd of forecasts together with machine models can outperform each of the individual components.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2999</offset><text>We present the results of a hybrid system aimed at harnessing the unique benefits of crowdsourcing and machine models. We address open questions about the efficiency of human–machine combinations. Do human forecasters incorporate model predictions in ways that improve their own forecasts, or does bias in their reactions hurt performance? In this work, we study the problem of measuring the influence of machine models on the human-generated forecasts in a hybrid forecasting platform. In order to learn the weight that users assign to machine forecasts, we propose a model that compares the forecasts of users who are exposed to the machines with those who are not. We analyze the weights to uncover patterns about how humans interact with the machine models throughout the course of an eight-month-long forecasting tournament. We show how individuals assign weights, quantify the degree of (dis-)trust in the models, and test the extent to which cognitive biases are prevalent. We conclude by analyzing the impact of trust and biased processing on our systems’ performance.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>4081</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>4094</offset><text>Crowdsourcing predictions</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4120</offset><text>Crowdsourcing, a method of engaging many individuals, often via a network, to jointly perform a task, has been demonstrated to solve a variety of innovative and strategic problems. These methods have become popular among organizations because they can perform complex tasks quickly and cheaply. Under the right circumstances, crowdsourcing can achieve a level of collective intelligence when disparate knowledge or skills are combined to perform in seemingly intelligent ways. A successful crowd includes engaged members who are motivated to improve their performance possibly by competing against one another as well as a diversity of appropriate knowledge and expertise. Harnessing a crowd is particularly efficient when the knowledge to solve a certain task is broadly dispersed and not necessarily identifiable in advance.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4947</offset><text>One common use of crowdsourcing is to forecast future outcomes by collecting forecasts from large groups of individuals about the same outcomes sometimes over a long timeframe. Crowdsourced forecasting requires a system capable of tracking individual performance and motivation over time. Individual inputs can be combined in adept ways including adjusting for detectable biases and leveraging the better forecasters and newer forecasts in the pool. In a recent political forecasting tournament , combining independent forecasts led to substantial improvements in accuracy and reliability. Crowdsourcing can improve upon individual judgments because it: a) amalgamates disparate knowledge, b) cancels individual errors, and c) builds credibility of the group judgment. This “wisdom of the crowd“ (WOC) effect has been demonstrated as a successful approach in diverse domains, even including solving complex, multi-faceted problems. The benefits of such combinations can be achieved with non-expert populations.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>5962</offset><text>Human versus machine prediction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5994</offset><text>Recent gains in computational power paired with advances in machine learning and modeling methods suggest that computers may be a suitable alternative to accurately predicting many economic and political outcomes. Machine prediction has advanced from the typical assumptions (e.g., linearity) to create more flexible tools that adjust to changes in the data. Real-time availability of data allows model parameters and predictions to be responsive to data changes. For example, adaptable feature selection and noise reduction techniques help improve upon static models. Indeed, recent works describe such advances in machine-generated prediction accuracy.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6649</offset><text>Both WOC and machine models have a number of limitations. WOC relies not just on the pool sharing sufficient knowledge about the topic, but also on the diversity of knowledge and expertise which can be difficult to assess. Human pools are also prone to cognitive biases that impact the quality of their judgments. Individual biases like base-rate neglect and overconfidence, as well as group biases like social influence, can negatively impact the judgment of opinion pools. Machine-generated predictions succeed in certain settings, especially when an outcome is autoregressive, but show limited success when causal factors are not well understood or multi-faceted. Other limitations arise from time-series with more difficult structures, such as zero-inflated time-series.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>7424</offset><text>Developing a hybrid system</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7451</offset><text>Prediction problems that are relevant for political and economic decision-making rely on a complex global system with poorly understood causal structures. Moreover, applicable data sources vary in volatility, structure, and format. Two methods have been proposed for combining judgmental (subjective) and statistical (objective) forecasts: adjustment and combination. We take a “hybrid” approach by building a system aimed at leveraging the strengths of machine models and crowdsourcing to balance generalizability across data sources and problem-types with the flexibility to tackle new, unforeseen problems. We make machine time-series predictions available to human forecasters to help them anchor on a statistical estimate based on historical base rates and recent trends. Empirical tests have found structured combinations of judgmental adjustments to model predictions improve upon time-series models when the data is highly volatile.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8396</offset><text>Successful hybrid systems have been demonstrated in modeling infectious disease trajectories using social signals and expert forecasts. The success of such a hybrid approach hinges on whether human forecasters trust and choose to utilize the model predictions. Despite recent advances in machine modeling in the forecasting domain, there has been ample research in recent years showing that humans have a reluctance to embrace machine models. Clinicians are reluctant to rely on statistical methods for high stakes decisions, like mental health diagnoses, despite accumulated evidence showing the superiority of statistical methods across studies. Forecasters put more weight on advice from human experts than statistical models, and discount models more when the same advice is labeled as a statistical prediction. Algorithm aversion, a phenomenon where people punish machine models disproportionately to humans for making the same mistakes, can inhibit the adoption of machine models in forecast generation and may ultimately lead to suboptimal forecasts.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9454</offset><text>Hybrid forecasting requires individuals to combine the model prediction with their beliefs. Our hybrid system (called SAGE), allows forecasters to choose how to weight the model prediction to maximize the diversity required for the WOC effect. However, this freedom raises concerns about suboptimal and biased information processing. Specifically, individuals might overweight either the advice or their preexisting beliefs. Our system is designed to invoke the anchoring heuristic by exposing forecasters to a formalized, impartial baseline. However, anchoring can lead to systematic under-adjustment from the advice. Conversely, egocentric discounting is prevalent when individuals show a clear preference for congenial information. Confirmation bias is one such bias, resulting in overweighting confirmatory and discrediting conflicting information.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>10307</offset><text>Advice taking</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10321</offset><text>A key assumption in our hybrid system is that users will incorporate machine models with their own beliefs. Heeding advice tends to improve the accuracy of individual judgments and increases confidence. Situational factors play a role in whether individual trust and use advice. The decision to use a piece of advice relies on both confidence in one’s beliefs and trust in the advice. Generally, individuals overweight their own information and underweight the advice of others. One concern is whether advice impacts how people form judgments. One study made advice available at different stages and found it has a smaller impact on research (termed “hypothesis generation”) than it has on judgment formation (termed “hypothesis testing”). Advice usage also changes with experience; as judges gain experience, they evaluate advice more carefully and are more likely to use it when it is helpful.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11227</offset><text>Not surprisingly, judges evaluate advisers based on their expertise. However, other factors influence the evaluation of advisers even when performance does not vary. Judges evaluate the experience of an adviser relative to themselves and only use advice when it achieves a perceived gain in expertise. There is growing evidence that human judges view statistical advice differently than human advice. When the same information is described as either human or statistical, judges adjust less toward the statistical advice. The reasons for human preference are debatable and may include an egocentric bias, anchoring on pre-existing beliefs, and better access to self or human justifications.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>11918</offset><text>Social influence</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11935</offset><text>In a hybrid system, it is also important to account for the influence users have on one another. Influence modeling is the body of work concerned with understanding how consensus is reached through the exchange of information among rational actors. Social influence can be beneficial or harmful within a large network. In forecasting, whether influence is beneficial to prediction is an open question. The benefit of social influence is a function of the group’s initial belief’s distance from the correct outcome. When the group begins further away from the true outcome, the group benefits more from social influence. Consistent with our findings, earlier work shows a decreasing social influence effect as the distance from the initial beliefs increases. However, social influence can also be harmful; it can produce herd-behavior or social loafing, decrease diversity, and lead to inaccurate forecasts.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>12846</offset><text>Most work on social influence is devoted to the study of influence coming from other (human) participants. Our model takes a new approach by quantifying the influence of independent machine forecasts. We build upon the DeGroot model. The DeGroot model leverages a network, where nodes are individuals and edges indicate information sharing between individuals. The DeGroot model is an iterative model that, at each step, updates each individual’s belief by calculating a simple average among their neighbors. Several extensions to this model have been presented. For example, one adjustment to the model considers the process by which opinions form provides an optimal solution to a specific type of game. Indeed, while a Bayesian information aggregation rule may be more appropriate, it’s not clear that agents would use such a complex computation. Further, there is experimental evidence supporting that the DeGroot model is a good approximation of the underlying aggregation process.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>13838</offset><text>Quantifying machine influence</text></passage><passage><infon key="file">41598_2020_72690_Fig1_HTML.jpg</infon><infon key="id">Fig1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>13868</offset><text>The figure shows the probability distribution projected on the correct option (hence, closer to one is more accurate) for the same question at two different time windows. The reference line represents the model prediction, and the colored histograms correspond to the two conditions. This example corresponds to the following question: “What will be the South Korean Won to one U.S. Dollar daily exchange rate on 29 June 2018?”.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14301</offset><text>In this work, we study forecasts about geopolitical events. These forecasts are created on a hybrid forecasting platform, Synergistic Anticipation of Geopolitical Events (SAGE), designed for this purpose. One of the key innovations of SAGE is that it allows forecasters to interact with computer-generated output during their process of generating forecasts. This computer-generated output can take the form of historical data pertaining to the question, or machine models that show a machine-generated prediction regarding its outcome. We assigned users to two conditions: a treatment condition where forecasters are exposed to machine models and a control condition where machine models are absent (both are shown in Fig. 5). In both conditions, participants saw historical data charts.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15091</offset><text>Belief updating is a process in which individuals start with prior beliefs about a subject, and then update them as new information is made available. One widely used process for combining the priors and new information is the DeGroot model of belief updating, described above. Despite its simplicity, DeGroot’s model generates accurate theoretical predictions of opinion formation in social networks, and acts as a reasonable non-Bayesian one-step update rule.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15555</offset><text>Here we use DeGroot’s model to quantify the influence of being exposed to machine forecasts when producing predictions on our platform. We assume that agent i’s forecast, , at time t is a weighted combination of his prior belief  and the current machine forecast , i.e.,where  is the weight that the agent assigns to the machine forecast, and  determines the individual’s confidence in their own belief.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15965</offset><text>In many experimental studies of judge-advisor systems (JAS) with human advisors or algorithmic ones, participants explicitly reveal their prior beliefs with the option to update them as new information is revealed. In our experimental design, agents’ prior beliefs are not directly observable, and thus, we need to infer them with a statistical approach. We use the control group, as opposed to individual forecasters, to estimate the prior beliefs of the group. We further assume the population is homogeneous, such that priors are normally distributed as , where the mean and variance can be approximated from the realized forecasts of the control group. This with Equation (1) yields agents’ forecasts when exposed to machine models. This can be represented asThe following example illustrates how influence perpetuates our system. Reviewing one specific question: “What will be the South Korean Won to one U.S. Dollar daily exchange rate on 29 June 2018?”. Naturally, new information about the price is available each day, which consequently can change the prior beliefs and the machine model predictions. Figure 1 depicts an example of the effects of being exposed to a machine forecast in one question, by comparing the distribution of forecasts between the control and treatment group at two different times. The figure shows the probability distribution projected on the correct option (hence, closer to one is more accurate) for one question at a specific time window. At the beginning (left figure), both the control and treatment group have similar distributions; as time goes by (right figure), the control group forecasts’ (i.e., prior beliefs) shift towards the correct option, however, participants exposed to the machine forecasts remain closer to the machine. This example shows a clear shift of mean and decrease of variance as a consequence of exposing participants to a reference forecast. The empirical evidence suggests that the weights participants put on the machine models are going to vary across time as a function of both the available information and the updated machine forecasts.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>18088</offset><text>Model estimation</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>18105</offset><text> To estimate the weights on prior beliefs (), we train the model for each question using a rolling window using three different settings (see “Methods” section for more details). That is, for each question q we use maximum likelihood estimation to find  for each day t, using all the forecasts in the corresponding time window to infer the average weight  forecasters assign to their prior beliefs. Model estimation is detailed in the “Methods” section. We incorporate forecast skill into our model to account for interactions between highly and less engaged users. Knowledge and expertise plays a role in the differential discounting of advice, and highly skilled forecasters interact with information and environments differently than typical forecasters. To incorporate expertise in our analysis, we identify high and low skilled forecasters by assessing the prediction accuracy of users on a set of independent forecasting questions. Participants from both conditions also produced forecasts on a set of 126 independent questions, mostly categorical, that had no historical data or machine forecasts available—due to inaccessible data, impediments in ingesting data or response format. These independent items allow us to split the population into low (lower 50th percentile) and high (upper 50th percentile) levels of skill, based on participants’ accuracy in terms of normalized Brier scores (see definition of Brier score in Methods). We estimated a different prior for each of the two skill levels using the control group. This estimate enables us to quantify the machine influence uniquely for each question and subpopulation.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>19753</offset><text>Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>19761</offset><text>Empirical validation of model</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>19791</offset><text> Social influence studies on the wisdom of the crowds have shown that aggregated knowledge of individual information narrows the diversity of predictions without improvements in accuracy. In our experimental setting, we have replaced “social influence” taking the form of an aggregate, with “machine influence” taking the form of a machine model prediction. The key difference is that machine forecasts are independent of the forecasts produced by the participants. Thus, we expect not only a decrease in diversity/variance, but a shift of the mean opinion when influenced by machine forecasts. Our model quantifies these two effects with a single parameter . Notice also that, based on Equation (2), the model always predicts a decrease of variance given by the relationship , where  are the variance of the treatment and control condition, respectively. Indeed, when comparing the mean variance of forecasts between conditions across all questions, we find a significant (p-value  with a t-test) decrease from  to .</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>20818</offset><text>Cognitive hypotheses</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>20839</offset><text>Next, we analyze the observed weights to explore plausible cognitive mechanisms that drive the use and discounting of machine models and quantify their effects on the accuracy of users’ predictions. First, we present our hypotheses and in the following section, we present the results in a single analysis that addresses each hypothesis concurrently. We divide our hypotheses into two subcategories—strategies and biases—to analyze both the intentions and reactions of the users. First, we break down whether individuals intend to use the model and whether trust increases when the model is better. Then, due to the complexity of combining machine models with one’s prior beliefs, we cannot ignore the likelihood that estimates reflect biases in information processing. We test whether users are over-reliant on a) the model (anchoring) or b) their prior belief (confirmation bias).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>21730</offset><text>User strategy</text></passage><passage><infon key="file">41598_2020_72690_Fig2_HTML.jpg</infon><infon key="id">Fig2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>21744</offset><text>Distribution of the weight users put on their prior belief, αs. The average  is 0.86, where  means users ignored the models, and  means they used the model prediction as their own.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>21929</offset><text>Do users trust the model predictions? Figure 2 shows the distribution of s, i.e. the weight participants put on their prior beliefs compared to machine predictions. The distribution is highly skewed towards 1 with an average  of 0.86, suggesting that participants are not very likely to incorporate the new information into their predictions. Such discounting of advice is consistent with prior work showing an “egocentric” bias in social settings, where participants place similar high weights on their own opinion over others’ advice. The reputation of an adviser is another important indicator of trust in advice. It is easier to lose trust than it is to gain it, and in a similar setting, assessors are sensitive to the accuracy and calibration of probabilistic forecasts. Finally, we include difficulty into our model because advisees tend to overweight advice for difficult tasks and underweight advice for easy tasks. We use the question’s difficulty based on the Brier scores (see Methods) of the control group forecasts. Brier scores are a measure of accuracy, which is naturally used to assess the quality of a probabilistic forecast. Our two primary hypotheses are that model’s trust should decrease (higher ) for more difficult questions, and when the reputation of the models is lower. We define the reputation of a model as it’s average Brier score on all resolved questions.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>23332</offset><text>Savviness</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>23342</offset><text>Are users savvy in choosing when to use the model? Can they perceive which models are more helpful? Our theoretical savviness hypothesis is that users will use the model when it performs better relative to the other human forecasters. We operationalize machine helpfulness as the percentage of people that had an inferior performance compared to the machine for a specific question and time window. We use the quantile metric to compare the performance of machine forecasts relative to the human forecasts, which essentially is the machine’s relative position on the cumulative distribution of the corresponding individual accuracy histogram (see Supplementary Figure S3). Our primary hypothesis is that we will observe greater model influence (a lower ) when the model is more helpful (relative to humans). Our secondary hypothesis is that forecaster’s skill will interact with helpfulness, so better forecasters should trust the model more when it’s more helpful.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>24315</offset><text>Anchoring effect</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>24332</offset><text>Anchoring is a judgmental bias describing how individuals under-adjust from arbitrary and random anchors when estimating a quantity, even when it is known that the anchor is arbitrary. While there is debate about the mechanism(s) that produces anchoring effects, it is clear that increasing uncertainty and increasing effort decreases the impact of anchoring effects. To quantify participant’s uncertainty we use variability (i.e. variance) of the group forecasts for a given question to measure the degree of consensus. Our primary hypothesis is that model influence should decrease (higher ) for more uncertain questions. Our secondary hypothesis is that anchors will have an asymmetrical effect based on forecasting skill, so that better forecasters are more prone to adjust.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>25114</offset><text>Egocentric discounting (confirmation bias)</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25157</offset><text>Confirmation bias is the tendency to acquire or process new information in a way that confirms one’s preconceptions and avoids contradiction with prior beliefs. Here we account for the possible asymmetric nature of confirmation bias on the differential weighting by users on the machine models. It is thus an open question to determine whether confirmation bias plays an important role in hybrid forecasting systems. Our primary hypothesis is that trust in the model should increase (lower ) when the models confirms the prior beliefs of the participants.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25715</offset><text>The distance or discrepancy between priors and a reference opinion is also known to have an impact on the change of opinion. Thus, we measure the interaction between the Euclidean distance and confirmation bias. Our secondary hypotheses are that (1) confirmation bias should be stronger for more skilled forecasters because more knowledge and experience is associated with stronger prior beliefs and greater egocentric discounting; (2) confirmation bias should have an asymmetrical effect depending on the distance from the prior beliefs to the machine advice.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>26278</offset><text>Cognitive analysis</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26297</offset><text>User strategy. The baseline level of trust in users’ priors for high-skill forecasters are less than the levels in low-skill forecasters. More skilled forecasters put more weight in the machine models than lower-skilled forecasters. In all three models, this is observed by comparing the skill (low and high) coefficients. We validate our hypothesis, finding forecasters trust their priors more and trust the machine advice less for more difficult questions. Moreover, we find trust is sensitive to the reputation of the model. When we account for changes in the model’s average performance (the model’s reputation), we find that users trust the model less after they see it perform poorly.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26994</offset><text>Savviness. Forecasters are savvy enough to perceive when a machine model will be helpful. The negative coefficient for helpfulness indicates that as the machine models are more helpful, forecasters trust the models more. Moreover, there is evidence to suggest that high-skill users are savvier (approximately 4 times more) than low-skill users (see Model 2 in Table 1).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27365</offset><text>Anchoring. The anchoring hypothesis indicates that increased uncertainty mitigates the effect size of model influence. The negative coefficients indicate that the relationship is reversed (i.e., more trust in the model for more uncertain questions). Regarding our secondary hypothesis, Model 2 highlights that better forecasters are more sensitive to the anchoring effects and higher uncertainty. Skilled users adjust more in the direction of the machine model as uncertainty increases.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27852</offset><text>Confirmation bias. Our primary hypothesis on egocentric discounting is confirmed as trust in the machine model increases (i.e., lower ) when the model confirms the prior beliefs of the forecasters. This is observed in the negative coefficients in all three models. Our secondary hypotheses are also validated by the significant interaction between confirmation, skill, and distance. Indeed, the effect size of confirmation bias is almost twice as large for low-skill forecasters. Second, we observe in Model 3, an asymmetric effect on distance when the model confirms the prior beliefs (distanceconfirming = ***) compared to cases when it is disconfirming (distance = ***). Figure 3 depicts the relationships between distance, confirmation bias and skill. The interaction effect with confirmation bias is greater for low-skill forecasters and mostly negligible for high-skill users. Yet, the effect of distance is greater for high-skilled forecasters. Thus, suggesting that high-skilled forecasters are more flexible but less biased by confirmation when assigning trust to the machine models, consistent with superforecasters’ tendency to revise their forecast frequently and incrementally.</text></passage><passage><infon key="file">41598_2020_72690_Fig3_HTML.jpg</infon><infon key="id">Fig3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>29046</offset><text>Relationship between weights s and the distance between prior beliefs and the machine forecasts. The y-axis is shared between the two plots. The left plot shows the relationship for the high-skill users, and the right plot for the low-skill users. The blue color depicts when the machine forecasts don’t confirm the prior beliefs, and the orange color shows when the machine forecasts confirm the priors of the group.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29466</offset><text>Three regression models predicting prior belief relative to machine influence () are reported in Table 1. Our main dependent variable is the machine influence weight (). We use the predictor variables defined above to test our cognitive hypothesis adding potentially confounding variables such as the lifetime of a question. Model 1 includes only our primary hypotheses. Models 2 and 3 are extensions to test our secondary hypotheses. Model 2 includes interactions with forecaster skill to test our secondary hypothesis on savviness and anchoring effects. Egocentric discounting’s secondary hypothesis is tested in Model 3 by adding an interaction between distance from model to prior and confirmation bias. To minimize collinearity between the predictors, we mean-centered the measures by converting them to z-scores. We highlight the following findings:</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>30325</offset><text>Assessing the impact of cognitive biases</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>30366</offset><text>Regression analysis.</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Variable&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Model 1&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Model 2&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Model 3&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Skill:high&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.848***&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.846***&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.842***&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.015)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.015)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.018)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Skill:low&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.932***&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.930***&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.943***&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.015)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.015)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.017)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Uncertainty&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.011&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.0181*&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.01)&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.010)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Difficulty&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.021*&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;0.023**&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.012)&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.012)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Confirming&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.058***&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.06***&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.017)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.017)&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Helpfulness&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.031***&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.032***&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.010)&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.010)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Lifetime&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.002&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.002&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.006&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.009)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.009)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.009)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Distance&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.060***&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.058***&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.037***&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.008)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.008)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.011)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Machine reputation&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.021**&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.021**&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;− 0.025***&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;(0.009)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.009)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;(0.009)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Interactions: distance &lt;inline-formula id=&quot;IEq33&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M67&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M68&quot;&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq33.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; confirming&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.057***&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.017)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Interactions with skill helpful &lt;inline-formula id=&quot;IEq34&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M69&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M70&quot;&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq34.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; skill:high&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.046***&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.013)&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;helpful &lt;inline-formula id=&quot;IEq35&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M71&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M72&quot;&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq35.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; skill:low&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.015&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.013)&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Uncertainty &lt;inline-formula id=&quot;IEq36&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M73&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M74&quot;&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq36.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; skill:high&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.011&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.013)&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Uncertainty &lt;inline-formula id=&quot;IEq37&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M75&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M76&quot;&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq37.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; skill:low&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.003&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.013)&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;confirming &lt;inline-formula id=&quot;IEq38&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M77&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M78&quot;&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq38.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; skill:high&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.044*&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.024)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;confirming &lt;inline-formula id=&quot;IEq39&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M79&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M80&quot;&gt;&lt;mml:mo&gt;×&lt;/mml:mo&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq39.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; skill:low&lt;/td&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;− 0.076***&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;/&gt;&lt;td align=&quot;left&quot;&gt;(0.023)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Observations&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;526&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;526&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;526&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;&lt;inline-formula id=&quot;IEq40&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M81&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hbox {R}^{2}$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M82&quot;&gt;&lt;mml:msup&gt;&lt;mml:mtext&gt;R&lt;/mml:mtext&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq40.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt;&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.165&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.171&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.183&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Adjusted &lt;inline-formula id=&quot;IEq41&quot;&gt;&lt;alternatives&gt;&lt;tex-math id=&quot;M83&quot;&gt;\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hbox {R}^{2}$$\end{document}&lt;/tex-math&gt;&lt;mml:math id=&quot;M84&quot;&gt;&lt;mml:msup&gt;&lt;mml:mtext&gt;R&lt;/mml:mtext&gt;&lt;mml:mn&gt;2&lt;/mml:mn&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=&quot;41598_2020_72690_Article_IEq41.gif&quot;/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt;&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.152&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.155&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;0.167&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>30387</offset><text>Variable	Model 1	Model 2	Model 3	 	Skill:high	0.848***	0.846***	0.842***	 	(0.015)	(0.015)	(0.018)	 	Skill:low	0.932***	0.930***	0.943***	 	(0.015)	(0.015)	(0.017)	 	Uncertainty	− 0.011		− 0.0181*	 	(0.01)		(0.010)	 	Difficulty	0.021*		0.023**	 	(0.012)		(0.012)	 	Confirming	− 0.058***	− 0.06***		 	(0.017)	(0.017)		 	Helpfulness	− 0.031***		− 0.032***	 	(0.010)		(0.010)	 	Lifetime	0.002	0.002	0.006	 	(0.009)	(0.009)	(0.009)	 	Distance	− 0.060***	− 0.058***	− 0.037***	 	(0.008)	(0.008)	(0.011)	 	Machine reputation	− 0.021**	− 0.021**	− 0.025***	 	(0.009)	(0.009)	(0.009)	 	Interactions: distance  confirming			− 0.057***	 			(0.017)	 	Interactions with skill helpful  skill:high		− 0.046***		 		(0.013)		 	helpful  skill:low		− 0.015		 		(0.013)		 	Uncertainty  skill:high		− 0.011		 		(0.013)		 	Uncertainty  skill:low		− 0.003		 		(0.013)		 	confirming  skill:high			− 0.044*	 			(0.024)	 	confirming  skill:low			− 0.076***	 			(0.023)	 	Observations	526	526	526	 		0.165	0.171	0.183	 	Adjusted 	0.152	0.155	0.167	 	</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table_foot</infon><offset>31483</offset><text>The dependent variable is the percentage weight on human beliefs (). All independent variables were standardized, thus the coefficients describe how a one standard deviation change in a predictor variable affects the model influence. Binary predictors were dummy coded. Standard errors are displayed in parentheses.</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table_foot</infon><offset>31799</offset><text>***; **; *.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>31811</offset><text>It is important to quantify the effect of the cognitive biases on the accuracy of the forecasts to assess the efficiency of our hybrid system. The main premise behind the SAGE system is that machine predictions will enhance human forecasters. However, machine models can harm the final forecasts if the human participants do not incorporate the advice from the machine models deliberately and effectively. Ecological rationality is achieved when the interaction between an environment and heuristics in decision-making enables effective behavior to be produced. Providing end-users with objective evidence is not sufficient to assume it will be used well. Moreover, suboptimal decision processes can be overcome by the design of the decision structure. Thus, understanding barriers to how humans incorporate model predictions into their forecast is vital to unearthing possible policies and interventions that can increase the efficiency of the system.</text></passage><passage><infon key="file">41598_2020_72690_Fig4_HTML.jpg</infon><infon key="id">Fig4</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>32765</offset><text>The impact of cognitive biases on forecast accuracy when exposed to high and low quality machine models. Each panel quantifies the impact (in terms of percentage Brier score difference) of exposing the control group to the machine models by changing the value of each of the coefficients (x-axis) in Eq. 3. The y-axis measures the difference in Brier scores, so positive values correspond to a decrease in accuracy, and negative values reflect an improvement. The colored lines show the medians; the shaded region depicts the interquartile range; the vertical line depicts the learned coefficient. The blue line depicts the impact on the questions that had high quality machine models, defined as those who performed better than 50% of individuals in the control group (i.e., “helpfulness” &gt; 0.5); the orange line is the median change on questions with low quality machine models (i.e., “helpfulness”).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>33678</offset><text>Impact of model influence</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>33704</offset><text>To asses whether the strategies and biases we observed are meaningful, we evaluate whether their impact is large enough to discriminate high-skill user’s from baseline influence. That is, we consider a factor to have a meaningful impact if its associated coefficient is greater than half the difference between the mean baseline influence and mean weight of high-skill users, . The difference between our high and low skill users, , represents a ceiling to the effect size that should outpace the impact of biases on the system because better forecasters consistently excel in ability and are less prone to harmful biases. The results in Table 1 indicate that confirmation bias (operationalized by the “confirming” and “distance” variables) has a large effect on the weights in all models. Then, to a lesser extent, savviness (“helpfulness”) and trust (“machine reputation”) have a moderate impact on the model influence weights.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>34653</offset><text>Impact on performance</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>34675</offset><text>To evaluate the the impact of cognitive biases on forecast accuracy, we use the behavioral patterns uncovered by our cognitive models in Table 1, to create a counterfactual framework to quantify the effects of the different biases. We use the following model trained on the data,to predict the respective human and machine influence weights (s) for each question and time window. Then, according to Equation 1, we use the learned weights to infer the final prediction of users exposed to machine models. In other words, based on the prior beliefs, we simulate how these beliefs change when being exposed to the machine model’s advice. We use our framework to quantify the difference in accuracy between two artificial treatment groups exposed to machine models with the same prior beliefs, by modulating the coefficients associated with each cognitive bias.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>35538</offset><text>Figure 4 depicts the impact of cognitive biases by measuring the percentage accuracy difference between forecasts done with the learned model and those attained by changing the coefficients, respectively. We performed a parameter-based exploration of the  coefficients in Equation 3, one at a time, to quantify the effect on forecast accuracy. We use percent change in Brier scores as a measure of gain in accuracy, so positive values mean a decrease of accuracy. The vertical lines in the figure depict the learned coefficient based on the data. Finally, under the ecological rationality framework, the impact of the biases depends on the environment where the decision are being made, which can be represented by the distribution of the machine models performance relative to the humans’ prior beliefs (see Supplementary Figure S3). Thus, we asses the impact of the biases differentiating between being exposed to low and high quality machine models based on the “helpfulness” variable. See Supplementary Figure S4 for the average impact on performance in our platform.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>36619</offset><text>Looking at the confirmation bias and distance panels in Fig. 4, we first notice that, in contrast to confirmation bias having the most impact on the weights that humans assign to machines, their effect on the accuracy is marginal and most importantly, driven mostly by the low-quality models. The intuition behind this is that if a high-quality model is confirming someone’s prior beliefs, then both the model and the human prior must be accurate. However, when a low-quality model confirms the priors, then trusting the model can only decrease accuracy. Thus, we conclude confirmation bias in our environment is detrimental to performance. Next, we look into trust in the model based on machine reputation. As expected, increased trust in the models (i.e., a lower coefficient) as a function of their past performance only improves accuracy when the models are helpful. What is important to highlight is that the potential gains of trust in reputation coming from high-quality models are balanced by the losses of low-quality models. We see a similar effect for the baseline influence levels, although, less symmetrical as the impact of low-quality effects is higher. So, unless users have a strong belief that machine models are going to outperform humans, high levels of trust in humans priors, as we observed, are desired. In terms of savviness, we find that the strategies the human forecasters deployed are able to infer the relative “helpfulness” of machine models (given the negative coefficient), and increasing this competence would have a positive impact on performance. Finally, we observe that difficulty and uncertainty show minimal impact and room for improvement.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>38306</offset><text>Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>38317</offset><text>We investigate the problem of measuring how much trust human forecasters in a hybrid forecasting platform assign to a particular machine model. We develop a model that compares the forecasts of users who are exposed to the model with those who are not in order to learn the weight that the users assign to the model. Analyzing these weights helps uncover patterns about how humans interact with machine models throughout a forecasting tournament. Studying the trust between humans and machines reveals that users who can identify when the model is helpful are more accurate. We also leverage these weights to detect confirmation bias in our system which is detrimental only when machine models under-perform.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>39026</offset><text>We divide our cognitive hypotheses into two categories, strategic and biases. From the strategic analysis, we find that users engage with machine model predictions similarly to how individuals use expert advice. They use their own information the majority of the time and only incorporate the advice in certain situations—when the task is difficult. Only the best human forecasters intuitively recognize when the model is more helpful compared to other questions. Our impact analysis suggests there are interventions that could improve the performance of our system. When the machine model works well, the model reputation and relative helpfulness show the most room for improvement. This provides an opportunity to improve the system by providing information to the human forecasters about how well the model is expected to perform for a given question, such as based on the data source and question format, as well as highlighting the questions that seem to be most uncertain. We could also develop training based on these results to aid forecasters in how to assess the performance of a model prospectively.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>40139</offset><text>From the biases analysis, we find that confirmation bias has a stronger effect than anchoring implying that forecasters are influenced more by their prior than by the model prediction. Where the machine models are suboptimal, cognitive biases are most detrimental to the system. In these cases, users would do better to trust their prior and only use the model when the question is highly uncertain. These improvements can be achieved by nudging users in the correct direction, via interventions or statistical debasing. On the other hand, it is difficult to mitigate the impact of deficient prior beliefs. A more realistic intervention would be to improve the reliability of priors. A forecasting system can be improved by encouraging, if not requiring, human forecasters to conduct comprehensive research prior to making a forecast. A hybrid system could further assist users in accessing better information. Priors could also improve with careful matching of forecaster expertise to question topics. Additionally, providing information about which questions are more difficult for the model relative to the humans would help encourage anchoring on the model when it is appropriate and to do more research when it is not.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>41363</offset><text>This is a first step towards quantifying the impact of algorithms on forecast generation. We acknowledge some limitations of our approach and propose future research directions. First, we clarify that while DeGroot’s model may be unrealistically simple and naive about the learning process for individual agents, we use it to model the change of opinion in a population, not a single individual. Our empirical validations suggest the model is a good approximation of the average impact of being exposed to new information in the form of machine forecasts. Nevertheless, future work should be devoted to modeling the heterogeneity of the population, exploring better approximations using Bayesian inference techniques, and using different distributions as priors like the Dirichlet.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>42147</offset><text>Our ability to track user behavior over a long-term forecasting tournament allowed us to quantify how model influence develops over time. Unfortunately, there are trade-offs with what could be achieved in a narrow, controlled environment. Primarily, it is difficult to decipher the difference between high confidence in the prior and low trust in the model. Both scenarios will produce an  close to 1.0. Additionally, we are unable to determine causality for some effects; notably, more engaged forecasters are better able to identify helpful models, or the ability to identify when a model is helpful makes a forecaster more accurate. We also cannot exclude that some factors deluge others, like we might have trouble detecting anchoring on the models because of the prevailing impact of confirmation bias. Future work should isolate the most relevant factors and biases in more targeted experimentation.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>43053</offset><text>Finally, while our model is a major stride in quantifying model impact, we urge caution in generalizing to other settings. Research on trust in automation and algorithms often makes an assumption that all algorithms should be treated similarly. Trust in a model is governed by the ability of the model to serve the user’s needs. However, trust in humans and organizations is capricious and easily lost. The results apply only to situations with similar model performance relative to humans. Appreciable changes to the structure or quality of models should alter trust in the models appreciably. Future research should explore how trust can be manipulated with increased transparency about the models’ past performance as well as studying the factors that affect how detectable model quality is to human judges.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>43868</offset><text>As machine learning continues to progress, introducing data-driven algorithmic predictions to aid human decisions will become ubiquitous. For example, in bail decisions, large welfare gains are predicted by integrating machine predictions in the decision making process. Algorithmic predictions are widely believed to outperform human predictions, and much attention has been devoted to the fact that humans fail to adjust their original judgments to incorporate the new information given to them. Yet, algorithms are far from perfect and do not necessarily beat humans in some deeply uncertain settings. Our results shed new light on the importance of accounting for situational factors that influence model reputation as well as biases in processing and aggregating evidence. In this setting, where model and human performance are comparable, the success of certain strategies and biases depends on their relative performance. The ability to detect when a model will be helpful is closely associated with the ability to make accurate forecasts, and overconfidence on algorithms may lead to detrimental results. A deeper understanding of the interaction of multiple cognitive biases is needed to build the path for human–machine hybrid decision systems.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>45125</offset><text>Methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>45133</offset><text>Experimental design</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>45153</offset><text>The study was approved by the ethics committee of the USC University Park Institutional Review Board (USC UPIRB # UP-17-00527). Methods were carried out in accordance with relevant guidelines and regulations. Subjects gave written informed consent prior to participation. Participants were recruited by the Intelligence Advanced Research Projects Activity (IARPA) HFC Test and Evaluation Team. Participants participated on a voluntary basis and did not receive compensation for their participation.</text></passage><passage><infon key="file">41598_2020_72690_Fig5_HTML.jpg</infon><infon key="id">Fig5</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>45652</offset><text>Comparison of the information displayed in the two conditions in the SAGE platform on the same question. Panel A is our control condition which had access to historical data charts. Panel B is our experimental condition which also had access to machine model predictions.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>45924</offset><text>All of the forecasting problems in SAGE take the following form. First, each question pertains to a quantity. For example, the question pertains to a price prediction of Japan’s Nikkei 225 index. A list of all questions can be seen in Supplementary Table S2. Second, there is a time span for the questions to be answered. For a given question, these times are fixed for all users across the system. Third, the resolution criteria provides the user with an explicit link to the piece of evidence that will be used to decide the correct answer to the question, in this example Google Finance. Finally, users enter their forecasts by assigning a probability to a set of answer options. Each question contains between 2 to 5 answer options, inclusive. The answer options are non-overlapping and are generated based upon historical data values for the quantity in question. Users enter their forecasts by assigning a probability to each answer option. When the question closes, exactly one answer option is selected as the correct answer.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>46960</offset><text>In Fig. 5a, we see information shown in the control condition. In this condition, users are exposed to the historical data of the quantity that they are asked to forecast in the form of a chart. The chart shown in the figure is the only information they are shown; no additional information such as summary statistics are provided. Furthermore, this chart is exactly what users on the site see.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>47356</offset><text>Figure 5b shows additional information shown in the treatment condition. Here, users see all of the information in the control condition, but the historical data is augmented with a machine prediction. The green line shows the machine model’s prediction about the quantity, and the shaded green region around it is the 95% confidence interval. This additional information can be used by the forecasters in generating their prediction, but it is not required or encouraged beyond the display of this plot.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>47864</offset><text>User recruitment</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>47881</offset><text>The participants of the study were recruited through public recruitment carried out on blogs, web sites, and other geopolitical forecasting platforms. Each member of this outsourced pool of people was randomly assigned to either the treatment or control condition. Recruitment was done exclusively before the beginning of the study. The study lasted approximately 7 months, in which new questions were added to the platform each week. Participation was unpaid and voluntary and relied purely on the engagement of users. Engagement was encouraged through the use of weekly emails notifying users of new questions. On the platform itself, a leaderboard was maintained to give credit to users who made accurate forecasts. Supplementary Table S1 shows a summary of the participant in each of the conditions and the number of total predictions made. Supplementary Figures S1–S2 depicts the demographic characteristics of the participants. We conducted a survival analysis to confirm that users in each condition showed no significant difference in attrition (see Supplementary Figure S5). Providing access to machine models did not influence engagement meaningfully.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>49045</offset><text>Machine predictions</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>49065</offset><text>Given that questions covered a broad set of geopolitical topics and different data sources, we used a general approach to forecast time series. Specifically, we use the AutoRegressive Integrated Moving Average (ARIMA) model to produce machine forecasts from the historical data relevant to each question. The parameter selection for the ARIMA model was done automatically using a standard R-package described in. Recently, the M4 competition measured the performance of machine models across over 100,000 problems, many related to the geopolitical events discussed in this paper. They found that general models, like the ARIMA one used in this work, perform the best across a wide array of problems, even in comparison to more complex machine learning models.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>49825</offset><text>While ARIMA is often used for obtaining pointwise estimates, here we need to generate probabilistic forecasts over the possible answers, i.e., the answer options shown in Fig. 5b. We do this by calculating the prediction intervals under the somewhat standard assumption that the residuals are normally distributed and uncorrelated with each other. The resulting probabilistic forecasts are then shown to the human forecaster as indicated in Fig. 5b.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>50277</offset><text>As new data for an active question became available, or existing data was updated, we updated the machine models with the latest data. This is done so that, in the treatment condition, the machine model that is presented to the users is based on the most recent version of the data. In both conditions, this is done so that the forecasters can make an informed forecast using the latest historical data.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>50681</offset><text>An important note about our machine models. Most of the experimental work in the literature assume that machine models are superior to humans. This is not true in this work. Due to the difficulty in predicting outcomes of geopolitical events, there are problems where machines under-perform compared to humans. Part of our analysis will focus on humans’ ability to identify models that performed poorly.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>51087</offset><text>Model estimation</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>51104</offset><text>Here, we formalize how to quantify the average weight that a population of forecasters puts on the machine models. Let  be the prior and realized forecast of agent i at time t. Agent i arrives and his forecast is influenced by the current machine forecast  as follows,where the key idea is to use the control group to estimate the group prior beliefs . Thus, agents’ forecasts when exposed to machine models follows the following distribution,We can now formulate the probability density, under the model, of seeing data ,where . Then, to estimate the parameter  for each question, we use a non-linear optimization algorithm to maximize the log-likelihood. To avoid problems with the sparseness of data and singular matrices, we transform questions with multiple answer options into a binary question where the two answer options correspond to the probability of the correct option and the probability of the incorrect option, respectively.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>52047</offset><text>Time window length</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>52066</offset><text>Given that the duration of the questions varies greatly (mean is 53 days and standard deviation is 33) and longer questions have sparser forecasts, we use three different settings for the length of the time window when estimating on each question. Time windows with less than four forecasts per condition were discarded. Our three approaches consisted of: (1) Using a weekly rolling window; (2) Utilizing a rolling window of length equal to one fourth of the duration of each question. This setting is useful for long questions that have sparse forecasts; (3) Applying the maximum between weekly or quarterly time windows. Results presented here are using the last approach, however, the conclusions are consistent across all three approaches (Supplementary Figures S6–S8 depict the results for all three settings).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>52884</offset><text>Independent variables</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>52906</offset><text>For evaluating accuracy, we extend the notion of Brier scores to account for ordinal questions. To address the fact that some forecasting questions have ordered outcomes, for example predicting the price of the Nikkei, we use a variant of the Brier score that uses the cumulative probabilities instead of the densities.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>53226</offset><text>Definition 1</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>53239</offset><text>(Brier Score). Given a question of duration T, forecasts , , and the actual outcome , we use the Brier score B(p) as a measure of accuracy:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>53379</offset><text>We define a dummy variable, ’confirming’, to represent whether the machine is supporting the beliefs of the group according to Definition 2 or not.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>53531</offset><text>Definition 2</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>53544</offset><text>(Confirmation Bias). Let  be a probability forecasts, we define  as the closest extreme (i.e., where all the probability mass is assigned to one option). Formally,We define a machine forecast m to be confirming one’s prior beliefs if the new information is closer to your extreme probability than your priors, i.e.,</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>53862</offset><text>Skill</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>53868</offset><text>Dummy variable representing if a user belongs to the top or lower 50th percentile on a set of independent forecasting questions.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>53997</offset><text>Uncertainty</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54009</offset><text>Defined as the average of the diagonal elements in the covariance matrix for users forecasts from the control group.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54126</offset><text>Difficulty</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54137</offset><text>Average Brier score of users’ forecasts from the control group (i.e., priors beliefs ).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54227</offset><text>Confirming</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54238</offset><text>Confirmation Bias (Definition 2) between the model’s forecasts and the mean forecast from the treatment group.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54352</offset><text>Confirming</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54363</offset><text>Dummy variable representing the confirmation bias (Definition 2) between the model’s forecasts and the mean forecast from the treatment group.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54509</offset><text>Helpfulness</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54521</offset><text>Defined as the percentage of users from the control group that had an inferior performance compared to the machine model.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54643</offset><text>Lifetime</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54652</offset><text>The percentage of days out of the total that a question has been open for forecasts.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54737</offset><text>Distance</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54746</offset><text>Average Euclidean distance, using the cumulative probabilities, between the machine model’s forecasts and the users’ forecasts from the control group.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54901</offset><text>Machine reputation</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>54920</offset><text>Past performance of the machine models. Defined as the negative of the average Brier Score of the machine forecasts for questions that had resolved by the beginning of the current question.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title_1</infon><offset>55110</offset><text>Supplementary information</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">footnote</infon><offset>55136</offset><text>Publisher's note</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">footnote</infon><offset>55153</offset><text>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title_1</infon><offset>55272</offset><text>Supplementary information</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>55298</offset><text>is available for this paper at 10.1038/s41598-020-72690-4.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title</infon><offset>55357</offset><text>Author contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>55378</offset><text>A.A., F.M., D.B. and A.G. designed the research; A.A. analyzed the data with modeling suggestions from F.M. and D.B.; A.A., D.B. and F.M. prepared the manuscript. All authors reviewed and edited the manuscript.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title</infon><offset>55589</offset><text>Data availability</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>55607</offset><text>The data that support the findings of this study are available from the corresponding author upon request.</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title</infon><offset>55714</offset><text>Competing interests</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>55734</offset><text>The authors declare no competing interests.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>55778</offset><text>References</text></passage><passage><infon key="fpage">195</infon><infon key="lpage">217</infon><infon key="name_0">surname:Camerer;given-names:CF</infon><infon key="name_1">surname:Johnson;given-names:EJ</infon><infon key="section_type">REF</infon><infon key="source">Res. Judgment Decis. Mak. Curr. Conn. Controv.</infon><infon key="type">ref</infon><infon key="volume">342</infon><infon key="year">1997</infon><offset>55789</offset><text>The process-performance paradox in expert judgment: How can experts know so much and predict so badly</text></passage><passage><infon key="name_0">surname:Tetlock;given-names:PE</infon><infon key="section_type">REF</infon><infon key="source">Expert Political Judgment: How Good Is It? How Can We Know?</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>55891</offset></passage><passage><infon key="fpage">111</infon><infon key="lpage">127</infon><infon key="name_0">surname:Larrick;given-names:RP</infon><infon key="name_1">surname:Soll;given-names:JB</infon><infon key="pub-id_doi">10.1287/mnsc.1050.0459</infon><infon key="section_type">REF</infon><infon key="source">Manag. Sci.</infon><infon key="type">ref</infon><infon key="volume">52</infon><infon key="year">2006</infon><offset>55892</offset><text>Intuitions about combining opinions: Misappreciation of the averaging principle</text></passage><passage><infon key="fpage">290</infon><infon key="lpage">295</infon><infon key="name_0">surname:Tetlock;given-names:PE</infon><infon key="name_1">surname:Mellers;given-names:BA</infon><infon key="name_2">surname:Rohrbaugh;given-names:N</infon><infon key="name_3">surname:Chen;given-names:E</infon><infon key="pub-id_doi">10.1177/0963721414534257</infon><infon key="section_type">REF</infon><infon key="source">Curr. Dir. Psychol. Sci.</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2014</infon><offset>55972</offset><text>Forecasting tournaments: Tools for increasing transparency and improving the quality of debate</text></passage><passage><infon key="fpage">187</infon><infon key="lpage">205</infon><infon key="name_0">surname:Chong;given-names:E</infon><infon key="name_1">surname:Han;given-names:C</infon><infon key="name_2">surname:Park;given-names:FC</infon><infon key="pub-id_doi">10.1016/j.eswa.2017.04.030</infon><infon key="section_type">REF</infon><infon key="source">Expert Syst. Appl.</infon><infon key="type">ref</infon><infon key="volume">83</infon><infon key="year">2017</infon><offset>56067</offset><text>Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>56184</offset><text>Huang, Y., Abeliuk, A., Morstatter, F., Atanasov, P. &amp; Galstyan, A. Anchor attention for hybrid crowd forecasts aggregation (2020). arXiv:2020.03762.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>56334</offset><text>Miyoshi, T. &amp; Matsubara, S. Dynamically forming a group of human forecasters and machine forecaster for forecasting economic indicators. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18, 461–467. 10.24963/ijcai.2018/64 (International Joint Conferences on Artificial Intelligence Organization, 2018).</text></passage><passage><infon key="fpage">343</infon><infon key="lpage">363</infon><infon key="name_0">surname:Ghezzi;given-names:A</infon><infon key="name_1">surname:Gabelloni;given-names:D</infon><infon key="name_2">surname:Martini;given-names:A</infon><infon key="name_3">surname:Natalicchio;given-names:A. Crowdsourcing</infon><infon key="pub-id_doi">10.1111/ijmr.12135</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Manag. Rev.</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2018</infon><offset>56692</offset><text>A review and suggestions for future research</text></passage><passage><infon key="fpage">45</infon><infon key="name_0">surname:Bonabeau;given-names:E</infon><infon key="section_type">REF</infon><infon key="source">MIT Sloan Manag. Rev.</infon><infon key="type">ref</infon><infon key="volume">50</infon><infon key="year">2009</infon><offset>56737</offset><text>Decisions 2.0: The power of collective intelligence</text></passage><passage><infon key="fpage">38</infon><infon key="lpage">52</infon><infon key="name_0">surname:Malone;given-names:TW</infon><infon key="name_1">surname:Laubacher;given-names:R</infon><infon key="name_2">surname:Dellarocas;given-names:C</infon><infon key="pub-id_doi">10.1109/EMR.2010.5559142</infon><infon key="section_type">REF</infon><infon key="source">IEEE Eng. Manag. Rev.</infon><infon key="type">ref</infon><infon key="volume">38</infon><infon key="year">2010</infon><offset>56789</offset><text>The collective intelligence genome</text></passage><passage><infon key="name_0">surname:Armstrong;given-names:JS</infon><infon key="section_type">REF</infon><infon key="source">Principles of Forecasting: A Handbook for Researchers and Practitioners</infon><infon key="type">ref</infon><infon key="year">2001</infon><offset>56824</offset></passage><passage><infon key="fpage">559</infon><infon key="lpage">583</infon><infon key="name_0">surname:Clemen;given-names:RT</infon><infon key="pub-id_doi">10.1016/0169-2070(89)90012-5</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Forecast.</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">1989</infon><offset>56825</offset><text>Combining forecasts: A review and annotated bibliography—ScienceDirect</text></passage><passage><infon key="fpage">1</infon><infon key="name_0">surname:Mellers;given-names:B</infon><infon key="pub-id_doi">10.1037/xap0000040</infon><infon key="pub-id_pmid">25581088</infon><infon key="section_type">REF</infon><infon key="source">J. Exp. Psychol. Appl.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2015</infon><offset>56898</offset><text>The psychology of intelligence analysis: Drivers of prediction accuracy in world politics</text></passage><passage><infon key="fpage">327</infon><infon key="lpage">352</infon><infon key="name_0">surname:Budescu;given-names:DV</infon><infon key="name_1">surname:Fiedler;given-names:K</infon><infon key="name_2">surname:Juslin;given-names:P</infon><infon key="section_type">REF</infon><infon key="source">Information Sampling and Adaptive Cognition</infon><infon key="type">ref</infon><infon key="year">2006</infon><offset>56988</offset><text>Confidence in aggregation of opinions from multiple sources</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>57048</offset><text>Surowiecki, J. The wisdom of crowds: Why the Many are Smarter than the Few and How Collective Wisdom Shapes Business, Economics, Societies and Nations (Little and Brown, 2004).</text></passage><passage><infon key="fpage">452</infon><infon key="lpage">470</infon><infon key="name_0">surname:Yi;given-names:SKM</infon><infon key="name_1">surname:Steyvers;given-names:M</infon><infon key="name_2">surname:Lee;given-names:MD</infon><infon key="name_3">surname:Dry;given-names:MJ</infon><infon key="pub-id_doi">10.1111/j.1551-6709.2011.01223.x</infon><infon key="pub-id_pmid">22268680</infon><infon key="section_type">REF</infon><infon key="source">Cogn. Sci.</infon><infon key="type">ref</infon><infon key="volume">36</infon><infon key="year">2012</infon><offset>57225</offset><text>The wisdom of the crowd in combinatorial problems</text></passage><passage><infon key="fpage">389</infon><infon key="lpage">405</infon><infon key="name_0">surname:Wolfe;given-names:C</infon><infon key="name_1">surname:Flores;given-names:B</infon><infon key="pub-id_doi">10.1002/for.3980090407</infon><infon key="section_type">REF</infon><infon key="source">J. Forecast.</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">1990</infon><offset>57275</offset><text>Judgmental adjustment of earnings forecasts</text></passage><passage><infon key="fpage">194</infon><infon key="lpage">211</infon><infon key="name_0">surname:Cavalcante;given-names:RC</infon><infon key="name_1">surname:Brasileiro;given-names:RC</infon><infon key="name_2">surname:Souza;given-names:VLF</infon><infon key="name_3">surname:Nobrega;given-names:JP</infon><infon key="name_4">surname:Oliveira;given-names:ALI</infon><infon key="pub-id_doi">10.1016/j.eswa.2016.02.006</infon><infon key="section_type">REF</infon><infon key="source">Expert Syst. Appl.</infon><infon key="type">ref</infon><infon key="volume">55</infon><infon key="year">2016</infon><offset>57319</offset><text>Computational intelligence and financial markets: A survey and future directions</text></passage><passage><infon key="name_0">surname:Kahneman;given-names:D</infon><infon key="section_type">REF</infon><infon key="source">Thinking, Fast and Slow</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>57400</offset></passage><passage><infon key="fpage">29</infon><infon key="lpage">36</infon><infon key="name_0">surname:Makridakis;given-names:S</infon><infon key="name_1">surname:Spiliotis;given-names:E</infon><infon key="name_2">surname:Assimakopoulos;given-names:V</infon><infon key="pub-id_doi">10.1016/j.ijforecast.2019.02.012</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Forecast.</infon><infon key="type">ref</infon><infon key="volume">36</infon><infon key="year">2020</infon><offset>57401</offset><text>Predicting/hypothesizing the findings of the m4 competition</text></passage><passage><infon key="fpage">91</infon><infon key="lpage">118</infon><infon key="name_0">surname:Webby;given-names:R</infon><infon key="name_1">surname:O’Connor;given-names:M</infon><infon key="pub-id_doi">10.1016/0169-2070(95)00644-3</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Forecast.</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">1996</infon><offset>57461</offset><text>Judgemental and statistical time series forecasting: A review of the literature</text></passage><passage><infon key="name_0">surname:Paul;given-names:MJ</infon><infon key="name_1">surname:Dredze;given-names:M</infon><infon key="name_2">surname:Broniatowski;given-names:D</infon><infon key="pub-id_doi">10.1371/currents.outbreaks.90b9ed0f59bae4ccaa683a39865d9117</infon><infon key="pub-id_pmid">25642377</infon><infon key="section_type">REF</infon><infon key="source">PLoS Curr.</infon><infon key="type">ref</infon><infon key="year">2014</infon><offset>57541</offset><text>Twitter improves influenza forecasting</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">19</infon><infon key="name_0">surname:Farrow;given-names:DC</infon><infon key="pub-id_doi">10.1371/journal.pcbi.1005248</infon><infon key="section_type">REF</infon><infon key="source">PLOS Comput. Biol.</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2017</infon><offset>57580</offset><text>A human judgment approach to epidemiological forecasting</text></passage><passage><infon key="fpage">1668</infon><infon key="lpage">1674</infon><infon key="name_0">surname:Dawes;given-names:RM</infon><infon key="name_1">surname:Faust;given-names:D</infon><infon key="name_2">surname:Meehl;given-names:PE</infon><infon key="pub-id_doi">10.1126/science.2648573</infon><infon key="pub-id_pmid">2648573</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">243</infon><infon key="year">1989</infon><offset>57637</offset><text>Clinical versus actuarial judgment</text></passage><passage><infon key="fpage">390</infon><infon key="lpage">409</infon><infon key="name_0">surname:Önkal;given-names:D</infon><infon key="name_1">surname:Goodwin;given-names:P</infon><infon key="name_2">surname:Thomson;given-names:M</infon><infon key="name_3">surname:Gönül;given-names:S</infon><infon key="name_4">surname:Pollock;given-names:A</infon><infon key="pub-id_doi">10.1002/bdm.637</infon><infon key="section_type">REF</infon><infon key="source">J. Behav. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">22</infon><infon key="year">2009</infon><offset>57672</offset><text>The relative influence of advice from human experts and statistical methods on forecast adjustments</text></passage><passage><infon key="fpage">114</infon><infon key="name_0">surname:Dietvorst;given-names:BJ</infon><infon key="name_1">surname:Simmons;given-names:JP</infon><infon key="name_2">surname:Massey;given-names:C</infon><infon key="pub-id_doi">10.1037/xge0000033</infon><infon key="pub-id_pmid">25401381</infon><infon key="section_type">REF</infon><infon key="source">J. Exp. Psychol. Gen.</infon><infon key="type">ref</infon><infon key="volume">144</infon><infon key="year">2015</infon><offset>57772</offset><text>Algorithm aversion: People erroneously avoid algorithms after seeing them err</text></passage><passage><infon key="fpage">1155</infon><infon key="lpage">1170</infon><infon key="name_0">surname:Dietvorst;given-names:BJ</infon><infon key="name_1">surname:Simmons;given-names:JP</infon><infon key="name_2">surname:Massey;given-names:C</infon><infon key="pub-id_doi">10.1287/mnsc.2016.2643</infon><infon key="section_type">REF</infon><infon key="source">Manag. Sci.</infon><infon key="type">ref</infon><infon key="volume">64</infon><infon key="year">2016</infon><offset>57850</offset><text>Overcoming algorithm aversion: People will use imperfect algorithms if they can (even slightly) modify them</text></passage><passage><infon key="fpage">403</infon><infon key="lpage">414</infon><infon key="name_0">surname:Yeomans;given-names:M</infon><infon key="name_1">surname:Shah;given-names:A</infon><infon key="name_2">surname:Mullainathan;given-names:S</infon><infon key="name_3">surname:Kleinberg;given-names:J</infon><infon key="pub-id_doi">10.1002/bdm.2118</infon><infon key="section_type">REF</infon><infon key="source">J. Behav. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">32</infon><infon key="year">2019</infon><offset>57958</offset><text>Making sense of recommendations</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>57990</offset><text>Morstatter, F. et al. Sage: A hybrid geopolitical event forecasting system. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19, 6557–6559, 10.24963/ijcai.2019/955 (International Joint Conferences on Artificial Intelligence Organization, 2019).</text></passage><passage><infon key="fpage">127</infon><infon key="lpage">151</infon><infon key="name_0">surname:Bonaccio;given-names:S</infon><infon key="name_1">surname:Dalal;given-names:RS</infon><infon key="pub-id_doi">10.1016/j.obhdp.2006.07.001</infon><infon key="section_type">REF</infon><infon key="source">Organ. Behav. Hum. Decis. Process.</infon><infon key="type">ref</infon><infon key="volume">101</infon><infon key="year">2006</infon><offset>58289</offset><text>Advice taking and decision-making: An integrative literature review, and implications for the organizational sciences</text></passage><passage><infon key="fpage">173</infon><infon key="lpage">190</infon><infon key="name_0">surname:Sniezek;given-names:JA</infon><infon key="name_1">surname:Schrah;given-names:GE</infon><infon key="name_2">surname:Dalal;given-names:RS</infon><infon key="pub-id_doi">10.1002/bdm.468</infon><infon key="section_type">REF</infon><infon key="source">J. Behav. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">17</infon><infon key="year">2004</infon><offset>58407</offset><text>Improving judgement with prepaid expert advice</text></passage><passage><infon key="fpage">288</infon><infon key="lpage">307</infon><infon key="name_0">surname:Sniezek;given-names:JA</infon><infon key="name_1">surname:Van Swol;given-names:LM</infon><infon key="pub-id_doi">10.1006/obhd.2000.2926</infon><infon key="pub-id_pmid">11277673</infon><infon key="section_type">REF</infon><infon key="source">Organ. Behav. Hum. Decis. Process.</infon><infon key="type">ref</infon><infon key="volume">84</infon><infon key="year">2001</infon><offset>58454</offset><text>Trust, confidence, and expertise in a judge-advisor system</text></passage><passage><infon key="name_0">surname:Wang;given-names:X</infon><infon key="name_1">surname:Du;given-names:X</infon><infon key="pub-id_doi">10.3389/fpsyg.2018.02381</infon><infon key="pub-id_pmid">30719016</infon><infon key="section_type">REF</infon><infon key="source">Front. Psychol.</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>58513</offset><text>Why does advice discounting occur? The combined roles of confidence and trust</text></passage><passage><infon key="fpage">117</infon><infon key="lpage">133</infon><infon key="name_0">surname:Harvey;given-names:N</infon><infon key="name_1">surname:Fischer;given-names:I</infon><infon key="pub-id_doi">10.1006/obhd.1997.2697</infon><infon key="section_type">REF</infon><infon key="source">Organ. Behav. Hum. Decis. Process.</infon><infon key="type">ref</infon><infon key="volume">70</infon><infon key="year">1997</infon><offset>58591</offset><text>Taking advice: Accepting help, improving judgment, and sharing responsibility</text></passage><passage><infon key="fpage">43</infon><infon key="lpage">60</infon><infon key="name_0">surname:Schrah;given-names:GE</infon><infon key="name_1">surname:Dalal;given-names:RS</infon><infon key="name_2">surname:Sniezek;given-names:JA</infon><infon key="pub-id_doi">10.1002/bdm.514</infon><infon key="section_type">REF</infon><infon key="source">J. Behav. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2006</infon><offset>58669</offset><text>No decision-maker is an island: Integrating expert advice with information acquisition</text></passage><passage><infon key="fpage">585</infon><infon key="lpage">590</infon><infon key="name_0">surname:Krueger;given-names:JI</infon><infon key="pub-id_doi">10.1037/0033-295X.110.3.585</infon><infon key="pub-id_pmid">12885117</infon><infon key="section_type">REF</infon><infon key="source">Psychol. Rev.</infon><infon key="type">ref</infon><infon key="volume">110</infon><infon key="year">2003</infon><offset>58756</offset><text>Return of the ego-self-referent information as a filter for social prediction: Comment on Karniol</text></passage><passage><infon key="fpage">149</infon><infon key="lpage">168</infon><infon key="name_0">surname:Lim;given-names:J</infon><infon key="name_1">surname:O’Connor;given-names:M</infon><infon key="pub-id_doi">10.1002/bdm.3960080302</infon><infon key="section_type">REF</infon><infon key="source">J. Behav. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">1995</infon><offset>58854</offset><text>Judgemental adjustment of initial forecasts: Its effectiveness and biases</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">13</infon><infon key="name_0">surname:Yaniv;given-names:I</infon><infon key="pub-id_doi">10.1016/j.obhdp.2003.08.002</infon><infon key="section_type">REF</infon><infon key="source">Organ. Behav. Hum. Decis. Process.</infon><infon key="type">ref</infon><infon key="volume">93</infon><infon key="year">2004</infon><offset>58928</offset><text>Receiving other people’s advice: Influence and benefit</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>58985</offset><text>Mavrodiev, P., Tessone, C. J. &amp; Schweitzer, F. Effects of social influence on the wisdom of crowds. In Collective Intelligence 2012 (Massachusetts Institute of Technology (MIT), 2012).</text></passage><passage><infon key="fpage">9020</infon><infon key="lpage">9025</infon><infon key="name_0">surname:Lorenz;given-names:J</infon><infon key="name_1">surname:Rauhut;given-names:H</infon><infon key="name_2">surname:Schweitzer;given-names:F</infon><infon key="name_3">surname:Helbing;given-names:D</infon><infon key="pub-id_doi">10.1073/pnas.1008636108</infon><infon key="pub-id_pmid">21576485</infon><infon key="section_type">REF</infon><infon key="source">Proc. Natl. Acad. Sci.</infon><infon key="type">ref</infon><infon key="volume">108</infon><infon key="year">2011</infon><offset>59170</offset><text>How social influence can undermine the wisdom of crowd effect</text></passage><passage><infon key="fpage">118</infon><infon key="lpage">121</infon><infon key="name_0">surname:DeGroot;given-names:MH</infon><infon key="pub-id_doi">10.1080/01621459.1974.10480137</infon><infon key="section_type">REF</infon><infon key="source">J. Am. Stat. Assoc.</infon><infon key="type">ref</infon><infon key="volume">69</infon><infon key="year">1974</infon><offset>59232</offset><text>Reaching a consensus</text></passage><passage><infon key="fpage">193</infon><infon key="lpage">206</infon><infon key="name_0">surname:Friedkin;given-names:NE</infon><infon key="name_1">surname:Johnsen;given-names:EC</infon><infon key="pub-id_doi">10.1080/0022250X.1990.9990069</infon><infon key="section_type">REF</infon><infon key="source">J. Math. Sociol.</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">1990</infon><offset>59253</offset><text>Social influence and opinions</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>59283</offset><text>Liakos, P. &amp; Papakonstantinopoulou, K. On the impact of social cost in opinion dynamics.  in Tenth International AAAI Conference on Web and Social Media ICWSM, 631–634 (2016).</text></passage><passage><infon key="fpage">2220</infon><infon key="lpage">2259</infon><infon key="name_0">surname:Grimm;given-names:V</infon><infon key="name_1">surname:Mengel;given-names:F</infon><infon key="pub-id_doi">10.1016/j.jet.2012.05.011</infon><infon key="section_type">REF</infon><infon key="source">J. Econ. Theory</infon><infon key="type">ref</infon><infon key="volume">147</infon><infon key="year">2012</infon><offset>59462</offset><text>An experiment on learning in a multiple games environment</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>59520</offset><text>Mueller-Frank, M. &amp; Neri, C. Social learning in networks: Theory and experiments. Available at SSRN: https://ssrn.com/abstract=2328281 (2013).</text></passage><passage><infon key="fpage">E5070</infon><infon key="issue">26</infon><infon key="lpage">E5076</infon><infon key="name_0">surname:Becker;given-names:J</infon><infon key="name_1">surname:Brackbill;given-names:D</infon><infon key="name_2">surname:Centola;given-names:D</infon><infon key="pub-id_pmid">28607070</infon><infon key="section_type">REF</infon><infon key="source">Proc. Natl. Acad. Sci.</infon><infon key="type">ref</infon><infon key="volume">114</infon><infon key="year">2017</infon><offset>59663</offset><text>Network dynamics of social influence in the wisdom of crowds</text></passage><passage><infon key="fpage">112</infon><infon key="lpage">49</infon><infon key="name_0">surname:Golub;given-names:B</infon><infon key="name_1">surname:Jackson;given-names:MO</infon><infon key="pub-id_doi">10.1257/mic.2.1.112</infon><infon key="section_type">REF</infon><infon key="source">Am. Econ. J. Microecon.</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2010</infon><offset>59724</offset><text>Naive learning in social networks and the wisdom of crowds</text></passage><passage><infon key="fpage">3</infon><infon key="lpage">49</infon><infon key="name_0">surname:Acemoglu;given-names:D</infon><infon key="name_1">surname:Ozdaglar;given-names:A</infon><infon key="pub-id_doi">10.1007/s13235-010-0004-1</infon><infon key="section_type">REF</infon><infon key="source">Dyn. Games Appl.</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2011</infon><offset>59783</offset><text>Opinion dynamics and learning in social networks</text></passage><passage><infon key="fpage">260</infon><infon key="lpage">281</infon><infon key="name_0">surname:Yaniv;given-names:I</infon><infon key="name_1">surname:Kleinberger;given-names:E</infon><infon key="pub-id_doi">10.1006/obhd.2000.2909</infon><infon key="pub-id_pmid">11056071</infon><infon key="section_type">REF</infon><infon key="source">Organ. Behav. Hum. Decis. Process.</infon><infon key="type">ref</infon><infon key="volume">83</infon><infon key="year">2000</infon><offset>59832</offset><text>Advice taking in decision making: Egocentric discounting and reputation formation</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>59914</offset><text>Logg, J. M. Theory of Machine: When Do People Rely on Algorithms? (2017). Working Paper.</text></passage><passage><infon key="fpage">267</infon><infon key="lpage">281</infon><infon key="name_0">surname:Mellers;given-names:B</infon><infon key="pub-id_doi">10.1177/1745691615577794</infon><infon key="pub-id_pmid">25987508</infon><infon key="section_type">REF</infon><infon key="source">Perspect. Psychol. Sci.</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2015</infon><offset>60003</offset><text>Identifying and cultivating superforecasters as a method of improving probabilistic predictions</text></passage><passage><infon key="fpage">647</infon><infon key="lpage">651</infon><infon key="name_0">surname:Muchnik;given-names:L</infon><infon key="name_1">surname:Aral;given-names:S</infon><infon key="name_2">surname:Taylor;given-names:SJ</infon><infon key="pub-id_doi">10.1126/science.1240466</infon><infon key="pub-id_pmid">23929980</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">341</infon><infon key="year">2013</infon><offset>60099</offset><text>Social influence bias: A randomized experiment</text></passage><passage><infon key="fpage">41</infon><infon key="lpage">56</infon><infon key="name_0">surname:Yates;given-names:JF</infon><infon key="name_1">surname:Price;given-names:PC</infon><infon key="name_2">surname:Lee;given-names:J-W</infon><infon key="name_3">surname:Ramirez;given-names:J</infon><infon key="pub-id_doi">10.1016/0169-2070(95)00636-2</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Forecast.</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">1996</infon><offset>60146</offset><text>The ‘consumer’s’ perspective</text></passage><passage><infon key="fpage">21</infon><infon key="lpage">35</infon><infon key="name_0">surname:Gino;given-names:F</infon><infon key="name_1">surname:Moore;given-names:DA</infon><infon key="pub-id_doi">10.1002/bdm.539</infon><infon key="section_type">REF</infon><infon key="source">J. Behav. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2007</infon><offset>60181</offset><text>Effects of task difficulty on use of advice</text></passage><passage><infon key="fpage">395</infon><infon key="name_0">surname:Han;given-names:Y</infon><infon key="name_1">surname:Budescu;given-names:D</infon><infon key="section_type">REF</infon><infon key="source">Judgm. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2019</infon><offset>60225</offset><text>A universal method for evaluating the quality of aggregators</text></passage><passage><infon key="fpage">35</infon><infon key="lpage">42</infon><infon key="name_0">surname:Furnham;given-names:A</infon><infon key="name_1">surname:Boo;given-names:HC</infon><infon key="pub-id_doi">10.1016/j.socec.2010.10.008</infon><infon key="section_type">REF</infon><infon key="source">J. Socio-Econ.</infon><infon key="type">ref</infon><infon key="volume">40</infon><infon key="year">2011</infon><offset>60286</offset><text>A literature review of the anchoring effect</text></passage><passage><infon key="fpage">1124</infon><infon key="lpage">1131</infon><infon key="name_0">surname:Tversky;given-names:A</infon><infon key="name_1">surname:Kahneman;given-names:D</infon><infon key="pub-id_doi">10.1126/science.185.4157.1124</infon><infon key="pub-id_pmid">17835457</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">185</infon><infon key="year">1974</infon><offset>60330</offset><text>Judgment under uncertainty: Heuristics and biases</text></passage><passage><infon key="fpage">199</infon><infon key="lpage">212</infon><infon key="name_0">surname:Epley;given-names:N</infon><infon key="name_1">surname:Gilovich;given-names:T</infon><infon key="pub-id_doi">10.1002/bdm.495</infon><infon key="section_type">REF</infon><infon key="source">J. Behav. Decis. Mak.</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2005</infon><offset>60380</offset><text>When effortful thinking influences judgmental anchoring: Differential effects of forewarning and incentives on self-generated and externally provided anchors</text></passage><passage><infon key="fpage">917</infon><infon key="name_0">surname:Simmons;given-names:JP</infon><infon key="name_1">surname:LeBoeuf;given-names:RA</infon><infon key="name_2">surname:Nelson;given-names:LD</infon><infon key="pub-id_doi">10.1037/a0021540</infon><infon key="pub-id_pmid">21114351</infon><infon key="section_type">REF</infon><infon key="source">J. Pers. Soc. Psychol.</infon><infon key="type">ref</infon><infon key="volume">99</infon><infon key="year">2010</infon><offset>60538</offset><text>The effect of accuracy motivation on anchoring and adjustment: Do people adjust from provided anchors?</text></passage><passage><infon key="fpage">175</infon><infon key="name_0">surname:Nickerson;given-names:RS</infon><infon key="pub-id_doi">10.1037/1089-2680.2.2.175</infon><infon key="section_type">REF</infon><infon key="source">Rev. Gen. Psychol.</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">1998</infon><offset>60641</offset><text>Confirmation bias: A ubiquitous phenomenon in many guises</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">14</infon><infon key="name_0">surname:Allahverdyan;given-names:AE</infon><infon key="name_1">surname:Galstyan;given-names:A</infon><infon key="pub-id_doi">10.1371/journal.pone.0099557</infon><infon key="section_type">REF</infon><infon key="source">PLoS ONE</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2014</infon><offset>60699</offset><text>Opinion dynamics with confirmation bias</text></passage><passage><infon key="fpage">379</infon><infon key="lpage">394</infon><infon key="name_0">surname:Hardt;given-names:O</infon><infon key="name_1">surname:Pohl;given-names:R</infon><infon key="pub-id_doi">10.1080/09658210244000504</infon><infon key="pub-id_pmid">14562869</infon><infon key="section_type">REF</infon><infon key="source">Memory</infon><infon key="type">ref</infon><infon key="volume">11</infon><infon key="year">2003</infon><offset>60739</offset><text>Hindsight bias as a function of anchor distance and anchor plausibility</text></passage><passage><infon key="name_0">surname:Tetlock;given-names:PE</infon><infon key="name_1">surname:Gardner;given-names:D</infon><infon key="section_type">REF</infon><infon key="source">Superforecasting: The Art and Science of Prediction</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>60811</offset></passage><passage><infon key="fpage">167</infon><infon key="lpage">171</infon><infon key="name_0">surname:Todd;given-names:PM</infon><infon key="name_1">surname:Gigerenzer;given-names:G</infon><infon key="pub-id_doi">10.1111/j.1467-8721.2007.00497.x</infon><infon key="section_type">REF</infon><infon key="source">Curr. Dir. Psychol. Sci.</infon><infon key="type">ref</infon><infon key="volume">16</infon><infon key="year">2007</infon><offset>60812</offset><text>Environments that make us smart: Ecological rationality</text></passage><passage><infon key="fpage">569</infon><infon key="lpage">598</infon><infon key="name_0">surname:Kramer;given-names:RM</infon><infon key="pub-id_doi">10.1146/annurev.psych.50.1.569</infon><infon key="pub-id_pmid">15012464</infon><infon key="section_type">REF</infon><infon key="source">Annu. Rev. Psychol.</infon><infon key="type">ref</infon><infon key="volume">50</infon><infon key="year">1999</infon><offset>60868</offset><text>Trust and distrust in organizations: Emerging perspectives, enduring questions</text></passage><passage><infon key="fpage">237</infon><infon key="lpage">293</infon><infon key="name_0">surname:Kleinberg;given-names:J</infon><infon key="name_1">surname:Lakkaraju;given-names:H</infon><infon key="name_2">surname:Leskovec;given-names:J</infon><infon key="name_3">surname:Ludwig;given-names:J</infon><infon key="name_4">surname:Mullainathan;given-names:S</infon><infon key="pub-id_pmid">29755141</infon><infon key="section_type">REF</infon><infon key="source">Q. J. Econ.</infon><infon key="type">ref</infon><infon key="volume">133</infon><infon key="year">2017</infon><offset>60947</offset><text>Human decisions and machine predictions</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">22</infon><infon key="name_0">surname:Hyndman;given-names:R</infon><infon key="name_1">surname:Khandakar;given-names:Y</infon><infon key="pub-id_doi">10.18637/jss.v027.i03</infon><infon key="section_type">REF</infon><infon key="source">J. Stat. Softw.</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2008</infon><offset>60987</offset><text>Automatic time series forecasting: The forecast package for r</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">26</infon><infon key="name_0">surname:Makridakis;given-names:S</infon><infon key="name_1">surname:Spiliotis;given-names:E</infon><infon key="name_2">surname:Assimakopoulos;given-names:V</infon><infon key="pub-id_doi">10.1371/journal.pone.0194889</infon><infon key="section_type">REF</infon><infon key="source">PLoS ONE</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2018</infon><offset>61049</offset><text>Statistical and machine learning forecasting methods: Concerns and ways forward</text></passage><passage><infon key="fpage">802</infon><infon key="lpage">808</infon><infon key="name_0">surname:Makridakis;given-names:S</infon><infon key="name_1">surname:Spiliotis;given-names:E</infon><infon key="name_2">surname:Assimakopoulos;given-names:V</infon><infon key="pub-id_doi">10.1016/j.ijforecast.2018.06.001</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Forecast.</infon><infon key="type">ref</infon><infon key="volume">34</infon><infon key="year">2018</infon><offset>61129</offset><text>The m4 competition: Results, findings, conclusion and way forward</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">3</infon><infon key="name_0">surname:Brier;given-names:GW</infon><infon key="pub-id_doi">10.1175/1520-0493(1950)078&lt;0001:VOFEIT&gt;2.0.CO;2</infon><infon key="section_type">REF</infon><infon key="source">Mon. Weather Rev.</infon><infon key="type">ref</infon><infon key="volume">78</infon><infon key="year">1950</infon><offset>61195</offset><text>Verification of forecasts expressed in terms of probability</text></passage><passage><infon key="fpage">582</infon><infon key="lpage">590</infon><infon key="name_0">surname:Jose;given-names:VRR</infon><infon key="name_1">surname:Nau;given-names:RF</infon><infon key="name_2">surname:Winkler;given-names:RL</infon><infon key="pub-id_doi">10.1287/mnsc.1080.0955</infon><infon key="section_type">REF</infon><infon key="source">Manag. Sci.</infon><infon key="type">ref</infon><infon key="volume">55</infon><infon key="year">2009</infon><offset>61255</offset><text>Sensitivity to distance and baseline distributions in forecast evaluation</text></passage></document></collection>
