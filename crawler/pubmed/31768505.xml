<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20210104</date><key>pmc.key</key><document><id>6876631</id><infon key="license">author_manuscript</infon><passage><infon key="article-id_doi">10.1145/3311350.3347153</infon><infon key="article-id_manuscript">NIHMS1056427</infon><infon key="article-id_pmc">6876631</infon><infon key="article-id_pmid">31768505</infon><infon key="fpage">135</infon><infon key="kwd">Applied games human computation accelerometers data annotation activity recognition crowdsourcing</infon><infon key="license">
          This file is available for text mining. It may also be used consistent with the principles of fair use under the copyright law.
        </infon><infon key="lpage">147</infon><infon key="name_0">surname:Ponnada;given-names:Aditya</infon><infon key="name_1">surname:Cooper;given-names:Seth</infon><infon key="name_2">surname:Thapa-Chhetry;given-names:Binod</infon><infon key="name_3">surname:Miller;given-names:Josh Aaron</infon><infon key="name_4">surname:John;given-names:Dinesh</infon><infon key="name_5">surname:Intille;given-names:Stephen</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">2019</infon><infon key="year">2019</infon><offset>0</offset><text>Designing Videogames to Crowdsource Accelerometer Data Annotation for Activity Recognition Research</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>100</offset><text>Human activity recognition using wearable accelerometers can enable in-situ detection of physical activities to support novel human-computer interfaces and interventions. However, developing valid algorithms that use accelerometer data to detect everyday activities often requires large amounts of training datasets, precisely labeled with the start and end times of the activities of interest. Acquiring annotated data is challenging and time-consuming. Applied games, such as human computation games (HCGs) have been used to annotate images, sounds, and videos to support advances in machine learning using the collective effort of “non-expert game players.” However, their potential to annotate accelerometer data has not been formally explored. In this paper, we present two proof-of-concept, web-based HCGs aimed at enabling game players to annotate accelerometer data. Using results from pilot studies with Amazon Mechanical Turk players, we discuss key challenges, opportunities, and, more generally, the potential of using applied videogames for annotating raw accelerometer data to support activity recognition research.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1234</offset><text>INTRODUCTION</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1247</offset><text>Sensor-based activity recognition algorithms use data from mobile and wearable devices to detect physical activities and other behaviors of people in everyday settings. The data are collected from miniature accelerometers embedded in phones, smartwatches, fitness bands, and special-purpose activity trackers used for research studies. Recognition algorithms process raw data gathered from three-axis, high-sampling-rate wearable accelerometers using extracted signal features (e.g., frequency) and then detect/classify activities of interest to researchers. The output from these algorithms may include step counts, labels of specific activities, or energy expenditure. Activities of special interest are physical activities, sedentary behaviors, and sleep (e.g.,). The field is highly active, with researchers proposing algorithms based on popular techniques such as support vector machines, decision trees, and ensemble methods, as well as newer variants on neural-network-based deep learning (e.g.,). In most cases, and especially with deep learning, these algorithms require large training datasets, where periods of raw data have been labeled with the target activities that were performed during data collection. Researchers typically gather data from devices worn by participants in controlled settings and then annotate the precise start and end times of each target activity (e.g.,). However, manually annotating raw accelerometer data is challenging and time-consuming. As the need for large amounts of high-quality, labeled training data has intensified, researchers have started to explore new data annotation tools/methods to expedite activity recognition research.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2927</offset><text>Therefore, we are investigating the potential of using videogames to annotate accelerometer data to support research in activity recognition. Videogames offer engaging ways of solving complex problems. Videogame players have advanced science by solving puzzles (e.g.,) and by annotating images, videos, and other forms of data (e.g.,). In fact, crowdsourcing such tasks using applied human computation games (HCGs) allows a large number of casual players to collectively accomplish scientific tasks that are computationally intractable by leveraging the skills of game players. Therefore, in this paper, we present two web-based HCGs; we use these proof-of-concept game prototypes to demonstrate how videogames played by non-expert players in the “crowd” can be used to annotate triaxial accelerometer data gathered from a wearable wrist sensor – the type of data increasingly used for activity recognition from wearable sensors. Players observe the data and using game mechanics, annotate the start and end times of the everyday physical activities (e.g., walking or sitting) performed at the time of data collection. We present the preliminary evaluations of our game prototypes using Amazon Mechanical Turk and discuss the game design challenges and potential of using videogames to crowdsource accelerometer data annotation. In addition, we explore the game design opportunities of gathering raw data annotations using the joint effort of activity recognition algorithms and labels from casual videogame players.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>4450</offset><text>BACKGROUND</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4461</offset><text>Our game design prototypes are based on prior research in accelerometry, annotation practices, and HCG designs.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>4573</offset><text>Raw Accelerometer Data</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4596</offset><text>Accelerometers (e.g., the commonly used ActiGraph in physical activity research) measure acceleration along the X, Y, and Z axes, typically between ±2 and ±16 g (g = 9.8 ms-2). Accelerometer data can be used to infer the amount or type of physical activity a person wearing the sensor may have engaged in (e.g.,). Accelerometers are popular in research studies because they are affordable, low-powered, and easy to maintain. These devices can be comfortably worn on locations such as the wrist, ankle, hip, or thigh, and can be used to collect data for days or weeks. Different movements generate distinctive patterns. For instance, ambulation activities such as running or walking generate a rhythmic pattern with spikes from a wrist-sensor (e.g., Figure 1, top). Similarly, sedentary activities such as sitting or resting generate low-amplitude, non-rhythmic wrist movements (e.g., Figure 1, bottom). When patterns are sufficiently distinct, different activities can be automatically detected by an algorithm (or a trained expert). Higher sampling rates (e.g., 20-80 Hz) allow detection of movement changes with high temporal fidelity (e.g., every 10 s), whereas, lower sampling rates (e.g., 0.1 Hz) may be sufficient for detecting some types of prolonged activities (e.g., sleeping for hours).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>5895</offset><text>Current Accelerometer Annotation Practices</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5938</offset><text>In a typical training data collection session, participants are asked to perform a set of real-world activities and researchers log timestamps of these activities (e.g.,). Often, researchers use manual notes, spreadsheets, or custom-built software for annotation. Observers must be trained to annotate data, which require time and resources not available to every research group. Because of the effort and cost involved, most annotated datasets are small – involving fewer than 100 participants performing only a handful of activities for only a few minutes each (e.g.,). Using cross-validation techniques, it is possible to train supervised learning algorithms on these small datasets, but machine learning algorithms work best with large, high-quality training data (e.g.,).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6717</offset><text>Thus, research is underway to reduce the effort required to annotate sensor datasets. For example, Barz et al. developed a multimodal multi-sensor annotation tool that uses video and raw sensor data to assist researchers annotating data retrospectively. Similarly, Diete et al. developed a semi-supervised labeling tool for video and inertial sensor annotation, where a semi-supervised learning algorithm provides labeling assistance. However, the tools designed for data annotations have only focused on gathering annotations from a single expert, which may introduce bias. Thus, the challenges of subjective biases, scalability of data, cost, and annotation consistency loom large for researchers, but are yet to be formally addressed.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>7455</offset><text>Applied Videogames for Data Annotation</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7494</offset><text>Videogames can be used to leverage the problem-solving abilities of players to solve computationally challenging tasks; such applied games are known as HCGs. They have been used to accomplish tasks such as labeling objects in images (e.g., ESP game and KissKissBan), annotating audio files (e.g., Tag-A-Tune), and classifying animal species (e.g., Forgotten Island). In these games, players use their common-sense knowledge, and the gameplay encourages player inputs that can be used to build knowledge important to researchers. Data are filtered for accuracy through techniques such as player agreement. The labeled output from these games then could serve as training data for machine learning algorithms. Other HCGs also teach new skills as part of the game, for example, protein and RNA folding (e.g. Foldit and EteRNA), mapping the 3D structure of neurons (e.g. Eyewire), or gene-disease annotation (e.g. Dizeez). In these games, the players learn new skills through tutorials, enabling them to creatively solve challenging problems that are typically solved only by domain experts. Like the tasks targeted by these skill-training HCGs, understanding and labeling accelerometer data requires experience observing the raw signal for different activities before those signals can be differentiated correctly. The task is challenging because the accelerometer signal can include complexities such as ambiguous activity transitions (e.g., sitting to sleeping) and wear-location effects (e.g., acceleration measured from the wrist when cycling), which even experts can find difficult to identify and annotate. In fact, HCGs could be cost-effective compared to hiring domain-experts for similar tasks (e.g., ~500K Foldit players so far have played protein molecular puzzles for free).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9278</offset><text>In non-accelerometer data domains, several citizen science games have trained players to annotate complex data such as finding patterns in mammal sounds (e.g., Bat Detective and Whale FM), labeling transit photometry data of planets (e.g., Planet Hunters and Project Discovery’s Exoplanets), and aligning gene sequences (e.g., Phylo and Fraxinus). Thus, it may be possible to train casual game players to annotate accelerometer data using applied videogames (i.e. HCGs).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>9751</offset><text>GAME PROTOTYPE REQUIREMENTS</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9779</offset><text>To focus our investigation, we gathered data annotation requirements from an exercise physiologist who processes accelerometer data using activity recognition algorithms, and a game design researcher (both co-authors of this paper). These discussions allowed us to iterate through preliminary game ideas and extract the basic requirements for accelerometer data annotation games intended to help players label data to be used in activity recognition research, especially for large wrist-worn datasets such as NHANES and UK Biobank. These requirements relate to identifying the activities of interest for annotation, visualizing accelerometer data in the games, providing feedback to players using validation data, and gathering sample data to be used for pilot testing of the games.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>10562</offset><text>Activities to Annotate Using the Applied Games</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10609</offset><text>Physical activity researchers using raw accelerometer data are interested in classifying behavior into broad classes of physical activities, as well as specific activities (e.g., those listed in the Compendium of Physical Activities). Researchers are also interested in developing sleep detection algorithms using low-cost wrist-accelerometers (e.g.,). Moreover, detecting sensor non-wear for wrist-worn accelerometers can allow researchers to distinguish sensor wear data before training algorithms. Thus, for our initial game prototypes, we chose the following broad activities to annotate: ambulation (e.g., walking and running), sedentary (e.g., sitting, resting, working on PC), sleep, and sensor non-wear. However, the game designs ought to be sufficiently flexible to accommodate finer activity category labeling as well (e.g., brisk walking and bicycling).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>11474</offset><text>Accelerometer Data Visualization for Games</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11517</offset><text>Raw, triaxial (X, Y, and Z axes) accelerometer data visualization contains more information than summary data (e.g., step counts) computed from the raw data. Therefore, it may be necessary to train game players to annotate activity using raw accelerometer data. Raw data visualization not only provides information on the intensity of movement during an activity, but also the orientation of the sensor. In fact, low-intensity activities such as sleep and sensor non-wear can be hard to distinguish from one another with summary data, whereas raw data may be used to visually differentiate between these activities.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>12133</offset><text>Validation and Unknown Accelerometer Data for Games</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>12185</offset><text>When annotating raw accelerometer data, the game players must differentiate between different behaviors just by inspecting the raw data. Thus, instructions on using raw data representations of activities to annotate, followed by practice with corrective feedback on actual examples, could help players develop the required skills (e.g., as in the Foldit and EteRNA games). For this purpose, we employed the strategy of integrating data with known annotations with unlabeled data into the gameplay. A block of either type of accelerometer data will be referred to as a fragment. In our games, we will refer to the two different data-types:</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>12824</offset><text>Validation data have pre-assigned labels (i.e., ground-truth) pre-programmed in the game to validate player responses. Validation data are also used in the tutorial phases of the game for training purposes.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>13031</offset><text>Unknown data are the accelerometer data to be labeled by the players.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>13101</offset><text>This approach of simultaneously mixing validation and unknown data into gameplay is similar to the approach used by reCAPTCHA, where the validation and unknown text are displayed together to verify inputs on validation text and get human input on the unknown text in captchas.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>13378</offset><text>Sample Accelerometer Data for Game Testing</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>13421</offset><text>Wrist-based accelerometers are increasingly being used in activity recognition research because this body location results in higher wear compliance and comfort as compared to ankle, thigh, or hip locations. In addition, the NHANES and UK Biobank studies have collected wrist-worn data from over 115K participants, collectively. Thus, to evaluate our games, we chose a raw accelerometer dataset from one of the authors’ unpublished studies, where 50 participants wearing the accelerometer (Actigraph, 80 Hz) on the wrist carried out a protocol of real-world activities such as walking, sitting, and typing. Researchers annotated the activities in real time using a custom, tablet-based application. A subsample of these data was used as validation data in the games with the pre-programmed labels, and another subsample was stripped of annotations and used in the games as unknown data. Because the true labels for all the data are known, player performance in labeling the unknown data can be assessed post hoc.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>14436</offset><text>GAME PROTOTYPES: OVERVIEW</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14462</offset><text>We designed two games – Mobots and Signaligner. Mobots is an action-based game, where small moving fragments of data are labeled by shading/coloring one at a time (inspired by Guitar Hero). Signaligner is a pattern-matching puzzle game, where players take their time to cut and align fragments of matching activities (inspired by Phylo). The key design challenge in both the games is to enable players to correctly label the unknown data, and to provide feedback using validation data to improve their labeling skills. The purpose of designing two different games was to explore different genres (e.g., action vs. puzzle), mechanics (coloring vs. pattern alignment), and pace (fast vs. self-exploratory) for the accelerometer data annotation task.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>15212</offset><text>Mobots: An Action Annotation Game</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15246</offset><text>Mobots is similar to a rhythm-based game, where players annotate short windows of accelerometer data. Fragments of data (unknown and validation) travel along a track (from right to left) and the players must press and hold (the core game mechanic) a button on the keyboard (e.g., F for “walk/run”) as the signal fragment crosses a line in order to color (i.e., annotate) the data fragment with a label (Figure 2). Players can change labels midway through a data fragment by pressing a different key if multiple labels are required for that fragment (e.g., transitions between activities). This game mechanic was chosen to enable independent labeling of small, zoomed-in fragments of data. Accuracy of labeling is assessed by examining player performance in labelling the seeded validation data. Players, however, are not informed about the presence of different types of data (validation and unknown data) to ensure unbiased labeling during the gameplay. Each fragment displayed in the game constitutes 10 s of data (sampled at 16 Hz). Different game levels ask players to identify different activities. Levels introduce new activities gradually so as to maximize player learning about how the data for different labels appear in the raw signal. The player’s goal is to successfully complete as many levels as possible.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>16572</offset><text>Game-progression</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>16589</offset><text>When a validation data fragment is labeled correctly, a green “power-bar” in the level is increased (Figure 2, bottom of left panel) and the pace of the moving fragments increases, making the level more challenging to play. The level is accomplished when the power bar fills up completely. The game provides data fragments until the level is completed or the player quits or pauses the level. Subsequently tougher levels are longer in duration with more data fragments (both validation and unknown) to annotate.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>17105</offset><text>In-game feedback</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>17122</offset><text>When a fragment of data is not labeled, or when a fragment of validation data is labeled incorrectly, that fragment is highlighted and on-screen text feedback (e.g., “Please try again” or “This was Ambulation”) highlights the correct annotation for that fragment (Figure 2, left). An incorrect label on validation data decreases the level’s power bar, delaying level completion.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>17511</offset><text>Game tutorials</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>17526</offset><text>The first three levels of the game are tutorial levels and use only validation data to teach the game mechanics that allow the player to label fragments. These levels teach: 1) how to label a fragment correctly, 2) how to change keys to label different activities in different fragments, and 3) how to change keys to label different activities within the same fragment. Following these levels, whenever a new activity label (e.g., ambulation) is introduced, it is done so using its own dedicated level comprising only of the validation data of that activity. This allows players to learn the visual pattern of this new activity before being presented with unknown data to label. At the beginning of each level, an instruction screen provides a description of what each category of label represents, complemented with a video of the activity and its acceleration pattern (Figure 2, right panel). This instruction screen is always accessible to the players during gameplay.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>18498</offset><text>Signaligner: A Pattern Matching Puzzle Game</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>18542</offset><text>Signaligner is a pattern-matching puzzle game that allows players to view hours of data at once and determine the best annotations for different time windows. Players can use the mouse pointer to cut, slide, and join data fragments on the screen, labeling them with a background color; the core game mechanics are like the mechanics in typical sound editing software, such as Adobe Soundbooth. When cut, the fragment is divided into two, and then players can drag to slide the cut fragments across the screen. When a fragment is moved to abut another fragment, the fragments merge into one fragment again. This mechanic permits players to match acceleration patterns in multiple fragments of raw data that are stacked vertically. Some fragments can have validation data; this information is hidden from the players during gameplay, similar to Mobots. We chose a sampling rate of 0.2 Hz for the game’s data to be able to display ~60 min of data at once on the web. Unlike Mobots, Signaligner does not train players to match fragments with activities directly; rather, it asks them to match the visual patterns with the template patterns provided for different activities (Figure 3).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>19726</offset><text>The game checks if fragments are aligned vertically. The player can click on the background of this column to color it (with the background color of the sample patterns), indicating that all fragments in this column share the same activity label (and that the activity the data represent is different from data labeled with different colors).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>20069</offset><text>Game progression</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>20086</offset><text>The goal in each level is to organize the cut fragments into independent columns, where each column (colored with one color) represents a particular activity label (Figure 3, left). At any time, players can click the “Check!” button at the bottom of the screen to verify if all the fragments are correctly organized. The game proceeds to the next level if all the validation fragments are correctly aligned. The harder levels contain more variety, where data from more activity types are mixed up. A player’s overall goal is to successfully complete the final level.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>20659</offset><text>In-game feedback</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>20676</offset><text>If the players have mislabeled a fragment that has validation data (e.g., if a column has two different activities’ data), they receive feedback; the background color of the validation data fragment is highlighted, and correct label is displayed.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>20925</offset><text>Game tutorials</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>20940</offset><text>Tutorial levels, which contain only validation data, include instructional text about how to complete the level. Players can re-check their solutions in tutorial levels as many times as they wish and then proceed to the next level once they have a correct solution. These levels were intended to both train the players and increase the likelihood that players who reach their challenge level could label data accurately. The game tutorial sequence introduces the game’s mechanics as follows, with one tutorial level for each stage. Players must 1) change the assigned label by recoloring the fragment, 2) split a fragment into multiple fragments and reassign a new label, 3) un-align stacked fragments into different columns so they can be assigned different labels, and 4) split, un-align, as well as relabel multiple fragments (Figure 3, left panel). Following the tutorial levels, players are given one challenge level, randomly selected from a pool of challenge levels (e.g., Figure 3, right panel). Each challenge level has at least one validation and one unknown data fragment. Players only have one chance to submit a solution to their final challenge level, after which they finish the game.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>22142</offset><text>GAME PROTOTYPE EVALUATION</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>22168</offset><text>We assessed our game designs with players from Amazon Mechanical Turk (MTurk). MTurk is a commonly used platform to crowdsource tasks in human-subjects research (including the HCGs).The goal was to assess the feasibility of using videogames to gather annotations on raw accelerometer data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>22458</offset><text>Game Evaluation Methodology</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>22486</offset><text>We used MTurk and its TurkPrime interface to recruit crowd players and the games were made accessible to players via a hyperlink. Player labels and interaction time were logged to a remote database with a unique identifier for each play session.; Each consenting player on MTurk was given a token code for $0.50 and was allowed to submit the code for payment before or after playing the game. We provided the code before the game to ensure that 1) there was no external motivation while playing and 2) players could play the game for as long as they wanted, with no pre-defined completion time. In addition, Signaligner players also received an additional bonus of $0.50 for completing the challenge level. Finally, players also had the opportunity to provide optional, open-ended feedback about the game they played via a survey, but no additional compensation was provided for this feedback.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>23380</offset><text>Game Evaluation Variables</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>23406</offset><text>The games were assessed for feasibility using labeling accuracy and inter-player labelling agreement. In addition, we captured play-session times and gathered subjective user experiences from the survey.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>23610</offset><text>Play-session times</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>23629</offset><text>We measured session times as total time spent playing the game (including game tutorials) and time spent on the labeling tasks (excluding the tutorials).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>23783</offset><text>Inter-player agreement</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>23806</offset><text>The inter-player agreement, or player consensus (between 0 and 1), was estimated as the proportion of the most frequently labeled activity from all the player labels for a given second of unknown data. For instance, if a given second of unknown data had four ambulation votes and one sedentary vote, then the final annotation was ambulation with an inter-player agreement of 0.8. In Mobots, unknown data samples with less than five player labels were not considered labeled. Higher inter-player agreement indicates more labeling consensus from independent players.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>24371</offset><text>Labeling accuracy</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>24389</offset><text>Labeling accuracy measures correctness of the player annotation on the unknown data in the games compared with ground-truth labels. Labeling accuracy is assessed for the smallest time-window (1 s for Mobots and 5 s for Signaligner) aggregated (with consensus) from all the players for that sample. Higher accuracy indicates better quality labeling of unknown data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_3</infon><offset>24754</offset><text>Subjective game experience</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>24781</offset><text>Subjective game experience was assessed qualitatively based on the open-ended feedback from the survey, which asked the players to describe their most positive and negative experiences of playing the games.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>24988</offset><text>Exploration with an Activity Recognition Algorithm</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>25039</offset><text>We also compared labels from players with label output by an activity recognition algorithm to explore 1) how an algorithm predicts activities in the same unknown data used in the game and labeled by players, and 2) design opportunities for algorithm-assisted annotation games for activity recognition. Although physical activity researchers are now commonly collecting raw wrist-accelerometer data, as of writing this paper, there are few sufficiently validated algorithms that use raw wrist accelerometer data to predict labels of specific activities. We first modified the algorithm by Mannini et al. that uses support vector machines to classify ambulation, sedentary, and sleep activities. The model was trained on a 25-participant subset of the sample data used for pilot testing our games and had 85% overall accuracy with leave-one-subject-out (LOSO) testing. We then modified this algorithm to use a random forest (RF) classifier with frequency domain features (i.e., dominant frequency, power of dominant frequency, and total power); using 30 s windows of data, it yielded 99% accuracy using the same LOSO test. The RF model provides the likelihood of each classification for the 30-s window, and the classification with the highest likelihood is selected. Due to its superior performance, we chose the RF classifier against which to compare player labels obtained from the games.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>26430</offset><text>However, our focus was not to evaluate a particular algorithm. In practice, applied games for crowdsourcing annotation would be deployed to help with labeling data only when machines are unable to confidently label certain data fragments. Thus, for any labeling task, it is likely that investigators will run one or more algorithms, assess the confidence levels of the resulting labels, and then deploy games to fix or verify the uncertain labels. Thus, we are most interested in situations where the algorithm is uncertain, and the players are not, and how to design games to elicit high-quality labels from players.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>27048</offset><text>GAME PROTOTYPE EVALUATION RESULTS</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27082</offset><text>We evaluated player labels on unknown data from both the games and then compared these labels with the algorithm-inferred labels on the same unknown data.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>27237</offset><text>Mobots Game Evaluation Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27268</offset><text>The Mobots game prototype was designed with 30 levels, including the three tutorials. We received labels for ambulation and sedentary activities, and sensor non-wear.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>27435</offset><text>Mobots play session times</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27461</offset><text>For the MTurk task with 100 assignments, there were 82 sessions played. Thus, some players entered their code without playing the game. Mobots players spent a total of 520.80 min (8.70 h) playing the game. This time includes the short game introduction scene (that took a mean of 5 s per player to view). Players spent a median of 3.10 min (IQR = 4.70 min, range = 0.11-39.70 min) per player playing the game, resulting in a median pay rate of $9.70 per hour for labeling activities. The median time spent playing per level, for levels with both validation and unknown data (i.e., non-tutorial levels), was 0.97 min (IQR = 0.67 min, range = 0.002-18.90 min). Three players reached level 20, and 52 players played until level four or higher; level four is the first level with validation and unknown data, after tutorials. Players labeled 9.50 min of the unknown data (with 5 or more player labels per sample) displayed in the game.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>28393</offset><text>Mobots inter-player agreement</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>28423</offset><text>The inter-player agreement for all the labels on unknown data was 0.73; 0.76 for ambulation, 0.68 for sedentary, and 0.89 for sensor non-wear activities (Figure 4, bottom).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>28596</offset><text>Mobots labeling accuracy</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>28621</offset><text>Labels from Mobots are aggregated across players through player consensus and compared with ground truth labels for each second of unknown data labeled (Table 1). Fifty-three seconds of sedentary data (17.7%; out of 5 min of actual sedentary data labeled) were mislabeled as ambulation. Even though the game did not have the opportunity to present any sensor non-wear unknown data fragments, we received 6 s of sedentary data labeled as sensor non-wear as well. Figure 4 shows a snapshot of data labeled (aggregated) aligned with the raw accelerometer data (16 Hz) and the corresponding ground-truth labels. The accuracy of labeling unknown data when compared with their ground truth labels was 89.7%; 100% for ambulation and 78.1% for sedentary labels.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>29375</offset><text>Subjective game experience</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29402</offset><text>Fifteen out of 82 players provided voluntary feedback on Mobots. Ten players reported contributing to research as their motivation to play the game. Five players reported accurately detecting different activities within a fragment as their most positive experience. However, 11 players reported having difficulty mastering keyboard key-pressing when they identified changes in a pattern within a fragment; they expressed they needed more practice. Two participants expressed a desire for more positive reinforcement in the game for longer levels. Seven participants reported that the in-level increase in fragment speed made it harder for the them to keep track of different keyboard keys to press.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>30101</offset><text>Signaligner Game Evaluation Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30137</offset><text>Labels were logged when the players clicked “Check!” in the challenge level (Fig 3). The unknown data fragments each contained 20-59 min of data, with individual activity fragments of 9-40 min in length. The validation data in each challenge level was 8.25 min long. We received labels on ambulation, sedentary, and sleep activities.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>30475</offset><text>Signaligner play session times</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30506</offset><text>Although the MTurk task had 100 assignments, there were a total of 148 sessions logged. It is possible that some players tried exploring the game before deciding whether to submit their code; logs indicate nearly all sessions that did not have a code submission ended within the first two tutorials. For completeness, we present data on all 148 sessions for a total of 11.69 h of play time. Players spent a median of 3.11 min (IQR = 3.60 min, range = 0.10-55.20 min) playing the tutorial levels. Those who reached their challenge level spent a median of 0.6 min (IQR = 0.42 min, range = 0.25-0.95 min) playing their challenge level. Fifty-five players reached their challenge level. Of these, nine were assigned the sleep-only level, three the sedentary-only level, five the ambulation-only level, four the sleep/sedentary level, eight the sedentary/ambulation level, nine the ambulation/sleep level, and 17 the level containing all three activities. Players who completed the challenge level played for median 3.60 min and those who did not played for median 4.0 min, resulting in an estimated median pay rate of $ 16.70 and $7.50 per hour respectively.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>31661</offset><text>Signaligner inter-player agreement</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>31696</offset><text>Signaligner players labeled the unknown data fragments with an agreement of 0.94 (Figure 5, bottom); 0.96 for ambulation, 0.99 for sedentary, and 0.88 for sleep activities.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>31869</offset><text>Signaligner labeling accuracy</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>31899</offset><text>Signaligner’s logs allowed us to compare players’ labels on unknown data fragments in three ways (Table 2): 1) using data from all players, regardless of whether they labeled the validation fragment correctly or not, 2) using data only from the individual players who labeled the validation fragment correctly (i.e., trusted players), and 3) using the most often chosen label per sample aggregated across all the trusted players who labeled the validation data fragment correctly (i.e., trusted players’ consensus) (Table 3). Data were displayed at a lower sampling rate than Mobots (0.2 Hz), so the label comparison unit was a 5 s window. Figure 5 shows aggregated player annotations with the raw data and their corresponding ground truth labels on a 20-min sample used in the game. The players were collectively confident in differentiating between sleep, sedentary, and ambulation fragments in the unknown data. Players had an overall accuracy of 90.7% (from all the players), 94.6% (from trusted players), and 99.5% (from the trusted players’ consensus). Labeling accuracy on the unknown data was higher when considering trusted players’ consensus.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_3</infon><offset>33062</offset><text>Subjective game experience</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>33089</offset><text>For Signaligner, we received feedback from 10 players. Four players expressed finding matching patterns in data fragments a positive experience. However, six players reported having difficulty getting used to the labeling instructions in the early stages. For instance, one player mentioned having difficulty performing cut, slide, and join actions using the touchpad on his/her laptop. However, four players reported cutting data fragments accurately to be challenging and expected the game to be more lenient when evaluating players’ inputs.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>33635</offset><text>Player labels vs activity recognition algorithm</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>33683</offset><text>The overall labeling accuracy of the algorithm on the unknown data used in the games was 89.9%; 90.6% for ambulation, 89.8% for sedentary, and 94.5% for sleep activity classification. We summarize the player and algorithm labeling for the unknown data (compared with its ground truth for each second) from both the games in Tables 4 and 5. In case of Mobots, the algorithm misclassified 128 s of unknown data (i.e., 22.40% of total unknown data labeled), out of which the Mobots players provided correct labels for 110 s (85.90% of 128 s) of unknown data. The mean inter-player agreement among Mobots players for these correct labels (where the algorithm misclassified) was 0.60 (SD = 0.20). Likewise, in Signaligner, the algorithm misclassified 690 s of the unknown data (i.e., 5% of the total unknown data labeled), out of which the Signaligner players provided correct labels for 510 s (73.9% of 690 s) of the data. The mean inter-player agreement among Signaligner players for these correct labels (where the algorithm misclassified) was 0.92 (SD = 0.12). In fact, the instances where algorithm had moderate likelihood (&lt;0.66) of correct prediction and players provided correct labels for that unknown data, Signaligner players had higher mean inter-player agreement (0.98, SD = 0.05) compared to Mobots (0.49, SD = 0.04).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>35010</offset><text>DISCUSSION</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>35021</offset><text>In this paper, we presented two HCG design prototypes intended to motivate players to annotate raw accelerometer data—Mobots and Signaligner (of different game genres, mechanics, and pace). We assessed their feasibility using MTurk players (summarized in Table 6).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>35288</offset><text>Signaligner players may have had higher labeling accuracy and inter-player agreement than Mobots players because, in Signaligner, players could use more signal context (and visual patterns) to match with an on-screen reference (Figure 3) of a similar acceleration pattern using their pattern recognition abilities. However, in Mobots, players were labeling short (~10 s) fragments of data using only the memories of signals and their corresponding activity categories (described in the activity tutorial). In Mobots, this learning and retaining of activity signal characteristics may be challenging for players. Moreover, it is possible that the additional bonus for completing the challenge level in Signaligner might have motivated the players to label more unknown data compared to Mobots players.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>36089</offset><text>Mobots displayed 10 s fragments of the data (at 16 Hz) that allowed players to identify small bouts of ambulation and sedentary behavior. These bouts can get ignored in the zoomed-out view of Signaligner, where 0.2 Hz data are displayed so a 1 h view is shown. Nevertheless, Signaligner seems more suitable to label activities such as sleep, long sedentary behaviors, or sensor non-wear. Likewise, with such small data fragments, Mobots players might not be able to reliably differentiate sleep and sensor non-wear, because doing so may require observing longer windows (e.g., 30-60 min); anecdotally, our expert typically needs this context. Signaligner players could label more data because each fragment contains 20-59 min of data, more than the 10 s windows in Mobots.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>36862</offset><text>Mobots and Signaligner players both reported having difficulty accurately identifying transitions between activities. Both the games had low tolerance for errors at transitions and thus provided feedback when there were errors on the validation data. In Mobots, despite using zoomed-in data that might have made it easier to perfectly mark a transition using the raw signal, the moving fragments (designed to increase engagement) made it harder for the players to master the skill of accurately changing keyboard keys at activity transitions. In Signaligner, despite having a much slower and self-directed pace, the zoomed-out view might have obscured the precise transitions between one activity and another and back (possible to see in Mobots) making it harder for Signaligner players to be able to cut the fragments at the right places. One approach to improve this game experience might be to allow more tolerance for transitions in the initial levels/stages of the game, and then to decrease the tolerance as the players improve their labeling skills. Alternatively, players promoted to be experts (after extended gameplay) might be sent data with the difficult transitions after it has been flagged from novice players due to lack of labeling consensus (inter-player agreement).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>38147</offset><text>Mobots level design could be perceived as repetitive. Although new labels were introduced in the first ten levels, thereby improving player knowledge and skills and providing new game content, in later levels new skills were not required. Later levels only increased in difficulty (combining increases in speed and more complex combinations of activities to label); new skills/requirements were not introduced – thereby potentially not creating a desired cognitive flow experience. Alternatively, Signaligner allowed players to explore tutorial levels for as long as they wished with unlimited attempts. Therefore, Signaligner players could master their skills at their own pace and try the challenge level only after they felt confident about their labeling skills. This self-direction may have helped sustain interest.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>38970</offset><text>Comparing players’ labels with an activity recognition algorithm presents several game design opportunities. Fortunately, the algorithm could reliably detect activities for the bulk of the unknown data. Algorithm pre-processing will be required to process datasets from large studies such as the UK Biobank (~100k participants). However, this pilot study does suggest that there will be instances where game players can help to verify or fix computer-generated labels. We observed three ways an activity recognition algorithm and labels by casual game players could be combined to produce well-labeled training data. First, there were instances where the algorithm misclassified an activity and player annotations had high inter-player agreement (e.g., Figure 6, left (1)). In such cases, future games could filter these instances, assign more players to annotate them, and then provide these examples as new training data to potentially improve the algorithm. Second, there were instances where the algorithm made correct predictions with high confidence but the players’ annotations where wrong (e.g., Figure 6, left (2)). Such instances can be used in future games to provide game feedback to the players when labeling unknown data using algorithm’s labels. Third, there are instances where the algorithm made low-confidence predictions, but the players’ agreement was high (Figure 6, right (3)). In such cases, the player annotations can be used in future games to confirm algorithm output, which is how these types of crowd-based labeling systems would be used in practice. Algorithms would take preliminary labeling passes on huge datasets such as the NHANES and UK Biobank. Then, the crowd would label data where the algorithms are uncertain. This strategy requires, of course, that the algorithms be capable of outputting not only inferred labels, but likelihood scores for those labels on the unknown data. After players additionally label data, experts might then use the same tools for an additional labeling pass on only the data where non-experts (i.e. algorithms and players) do not agree. Engaging domain-experts could create an algorithms-players-experts loop for annotating raw data to improve activity recognition. The resulting massive datasets might then be used to further refine new algorithms using data-hungry methods such as deep learning.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>41343</offset><text>In brief, our pilot testing of Mobots and Signaligner game prototypes presents an opportunity for game designers and researchers who might work together to further explore videogames to crowdsource accelerometer data annotation.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>41572</offset><text>LIMITATIONS AND FUTURE WORK</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>41600</offset><text>Our pilot study and game prototypes have several limitations. First, Mobots players labeled only 9.5 min of data compared to Signaligner (3.8 h). Mobots was serving small amounts (10 s) of data in each fragment and ultimately, we decided this game mechanic would not be feasible to label large quantities of data. As discussed above, an algorithm-assisted labeling game could filter the target data fragments that need labels from players because of incorrect or low likelihood automatic labeling.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>42098</offset><text>Second, both Signaligner and Mobots games were designed with fixed zoom (i.e., visualization of data subsampled at a constant rate for each game) that did not allow players to explore data on their own at different zoom levels. A dynamic data zooming/panning interface, given that a single week-long dataset has ~2 GB of data, is complex to engineer because it requires extensive signal precomputation and caching to function effectively. We have since built such a tool, however, that can quickly fetch, subsample, and display the high-sampling-rate accelerometer data during the game sessions to allow rapid data visualization at any desired scale. This tool will allow us to develop a new type of game that might combine the best components of Mobots and Signaligner—the ability to zoom out and use large amounts of signal context to label some activities, and the ability to zoom in to mark activity transitions precisely.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>43027</offset><text>Finally, our purpose in this pilot study was to assess the feasibility of our game prototypes to gather annotations from casual game players. Moving forward, our game prototypes could also further explore game engagement elements such as reward structures and game economy for long-term play as well as traditional social computing tools such as discussion forums, collaborations, and leaderboards that allow players to form an active citizen science gaming community (e.g.,). As we continue development on our games, we aim to give the players a stronger connection to the science behind the games.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>43627</offset><text>REFERENCES</text></passage><passage><infon key="section_type">REF</infon><infon key="source">Accelerometer Technologies, Specifications, and Limitations: A presentation by ActiGraph at ICAMPAM</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>43638</offset></passage><passage><infon key="comment">https://www.batdetective.org/#!/home</infon><infon key="section_type">REF</infon><infon key="source">The Bat Detective</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>43639</offset></passage><passage><infon key="comment">https://www.guitarhero.com/game.</infon><infon key="section_type">REF</infon><infon key="source">Guitar Hero</infon><infon key="type">ref</infon><infon key="year">2005</infon><offset>43640</offset></passage><passage><infon key="comment">https://www.zooniverse.org/projects/nora-dot-eisner/planet-hunters-tess.</infon><infon key="section_type">REF</infon><infon key="source">Planet Hunters</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>43641</offset></passage><passage><infon key="comment">https://whale.fm/.</infon><infon key="section_type">REF</infon><infon key="source">Whale FM</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>43642</offset></passage><passage><infon key="fpage">58</infon><infon key="issue">8</infon><infon key="lpage">67</infon><infon key="name_0">surname:von Ahn;given-names:Luis</infon><infon key="name_1">surname:Dabbish;given-names:Laura</infon><infon key="section_type">REF</infon><infon key="source">Commun. ACM</infon><infon key="type">ref</infon><infon key="volume">51</infon><infon key="year">2008</infon><offset>43643</offset><text>Designing games with a purpose</text></passage><passage><infon key="fpage">1575</infon><infon key="issue">8</infon><infon key="lpage">81</infon><infon key="name_0">surname:Ainsworth;given-names:BE</infon><infon key="name_1">surname:Haskell;given-names:WL</infon><infon key="name_2">surname:Herrmann;given-names:SD</infon><infon key="name_3">surname:Meckes;given-names:N</infon><infon key="name_4">surname:Bassett;given-names:DR;suffix:Jr.</infon><infon key="name_5">surname:Tudor-Locke;given-names:C</infon><infon key="name_6">surname:Greer;given-names:JL</infon><infon key="name_7">surname:Vezina;given-names:J</infon><infon key="name_8">surname:Whitt-Glover;given-names:MC</infon><infon key="name_9">surname:Leon;given-names:AS</infon><infon key="pub-id_pmid">21681120</infon><infon key="section_type">REF</infon><infon key="source">Med Sci Sports Exerc</infon><infon key="type">ref</infon><infon key="volume">43</infon><infon key="year">2011</infon><offset>43674</offset><text>2011 Compendium of physical activities: A second update of codes and MET values</text></passage><passage><infon key="name_0">surname:Anguita;given-names:Davide</infon><infon key="name_1">surname:Ghio;given-names:Alessandro</infon><infon key="name_2">surname:Oneto;given-names:Luca</infon><infon key="name_3">surname:Parra;given-names:Xavier</infon><infon key="name_4">surname:Reyes-Ortiz;given-names:Jorge Luis</infon><infon key="section_type">REF</infon><infon key="source">ESANN</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>43754</offset><text>A public domain dataset for human activity recognition using smartphones</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">17</infon><infon key="name_0">surname:Bao;given-names:L</infon><infon key="name_1">surname:Intille;given-names:SS</infon><infon key="name_2">surname:Ferscha;given-names:A</infon><infon key="name_3">surname:Mattern;given-names:F</infon><infon key="section_type">REF</infon><infon key="source">Pervasive Computing</infon><infon key="type">ref</infon><infon key="year">2004</infon><offset>43827</offset></passage><passage><infon key="fpage">17</infon><infon key="lpage">20</infon><infon key="name_0">surname:Barz;given-names:Michael</infon><infon key="name_1">surname:Mohammad Mehdi Moniri;given-names:Markus Weber</infon><infon key="name_2">surname:Sonntag;given-names:Daniel</infon><infon key="section_type">REF</infon><infon key="source">Multimodal multisensor activity annotation tool</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>43828</offset></passage><passage><infon key="fpage">323</infon><infon key="issue">3</infon><infon key="lpage">30</infon><infon key="name_0">surname:Bassey;given-names:EJ</infon><infon key="name_1">surname:Dallosso;given-names:HM</infon><infon key="name_2">surname:Fentem;given-names:PH</infon><infon key="name_3">surname:Irving;given-names:JM</infon><infon key="name_4">surname:Patrick;given-names:JM</infon><infon key="pub-id_pmid">3569241</infon><infon key="section_type">REF</infon><infon key="source">Eur J Appl Physiol Occup Physiol</infon><infon key="type">ref</infon><infon key="volume">56</infon><infon key="year">1987</infon><offset>43829</offset><text>Validation of a simple mechanical accelerometer (pedometer) for the estimation of walking activity</text></passage><passage><infon key="fpage">136</infon><infon key="issue">3</infon><infon key="lpage">47</infon><infon key="name_0">surname:Bouten;given-names:CV</infon><infon key="name_1">surname:Koekkoek;given-names:KT</infon><infon key="name_2">surname:Verduin;given-names:M</infon><infon key="name_3">surname:Kodde;given-names:R</infon><infon key="name_4">surname:Janssen;given-names:JD</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans. on Bio-Medical Engineering</infon><infon key="type">ref</infon><infon key="volume">44</infon><infon key="year">1997</infon><offset>43928</offset><text>A triaxial accelerometer and portable data processing unit for the assessment of daily physical activity</text></passage><passage><infon key="fpage">1516</infon><infon key="issue">12</infon><infon key="lpage">1523</infon><infon key="name_0">surname:Bouten;given-names:CV</infon><infon key="name_1">surname:Westerterp;given-names:KR</infon><infon key="name_2">surname:Verduin;given-names:M</infon><infon key="name_3">surname:Janssen;given-names:JD</infon><infon key="pub-id_pmid">7869887</infon><infon key="section_type">REF</infon><infon key="source">Med. Sci. Sports Exerc</infon><infon key="type">ref</infon><infon key="volume">26</infon><infon key="year">1994</infon><offset>44033</offset><text>Assessment of energy expenditure for physical activity using a triaxial accelerometer</text></passage><passage><infon key="fpage">1</infon><infon key="issue">CSCW</infon><infon key="lpage">17</infon><infon key="name_0">surname:Callaghan;given-names:William</infon><infon key="name_1">surname:Goh;given-names:Joslin</infon><infon key="name_2">surname:Mohareb;given-names:Michael</infon><infon key="name_3">surname:Lim;given-names:Andrew</infon><infon key="name_4">surname:Law;given-names:Edith</infon><infon key="section_type">REF</infon><infon key="source">Proc. ACM Hum.-Comput. Interact</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2018</infon><offset>44119</offset><text>MechanicalHeart: A Human-Machine Framework for the Classification of Phonocardiograms</text></passage><passage><infon key="comment">http://www.cdc.gov/nchs/nhanes.htm.</infon><infon key="section_type">REF</infon><infon key="source">NHANES - National Health and Nutrition Examination Survey Homepage</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>44205</offset></passage><passage><infon key="fpage">32</infon><infon key="issue">2</infon><infon key="lpage">41</infon><infon key="name_0">surname:Choudhury;given-names:T</infon><infon key="name_1">surname:Consolvo;given-names:S</infon><infon key="name_2">surname:Harrison;given-names:B</infon><infon key="name_3">surname:Hightower;given-names:J</infon><infon key="name_4">surname:LaMarca;given-names:A</infon><infon key="name_5">surname:LeGrand;given-names:L</infon><infon key="name_6">surname:Rahimi;given-names:A</infon><infon key="name_7">surname:Rea;given-names:A</infon><infon key="section_type">REF</infon><infon key="source">Pervasive Comp</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2008</infon><offset>44206</offset><text>The mobile sensing platform: An embedded activity recognition system</text></passage><passage><infon key="fpage">756</infon><infon key="issue">7307</infon><infon key="lpage">60</infon><infon key="name_0">surname:Cooper;given-names:S</infon><infon key="name_1">surname:Khatib;given-names:F</infon><infon key="name_2">surname:Treuille;given-names:A</infon><infon key="name_3">surname:Barbero;given-names:J</infon><infon key="name_4">surname:Lee;given-names:J</infon><infon key="name_5">surname:Beenen;given-names:M</infon><infon key="name_6">surname:Leaver-Fay;given-names:A</infon><infon key="name_7">surname:Baker;given-names:D</infon><infon key="name_8">surname:Popović;given-names:Z</infon><infon key="pub-id_pmid">20686574</infon><infon key="section_type">REF</infon><infon key="source">Nature</infon><infon key="type">ref</infon><infon key="volume">466</infon><infon key="year">2010</infon><offset>44275</offset><text>Predicting protein structures with a multiplayer online game</text></passage><passage><infon key="name_0">surname:Cooper;given-names:Seth</infon><infon key="section_type">REF</infon><infon key="source">Association for Computing Machinery and Morgan &amp;; Claypool</infon><infon key="type">ref</infon><infon key="volume">133</infon><infon key="year">2014</infon><offset>44336</offset><text>A Framework for Scientific Discovery through Video Games</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">6</infon><infon key="name_0">surname:Cooper;given-names:Seth</infon><infon key="name_1">surname:Sterling;given-names:Amy L. R.</infon><infon key="name_2">surname:Kleffner;given-names:Robert</infon><infon key="name_3">surname:Silversmith;given-names:William M.</infon><infon key="name_4">surname:Siegel;given-names:Justin B.</infon><infon key="section_type">REF</infon><infon key="source">Repurposing citizen science games as software tools for professional scientists</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>44393</offset></passage><passage><infon key="fpage">40</infon><infon key="lpage">47</infon><infon key="name_0">surname:Cooper;given-names:Seth</infon><infon key="name_1">surname:Treuille;given-names:Adrien</infon><infon key="name_10">surname:Popović;given-names:Zoran</infon><infon key="name_2">surname:Barbero;given-names:Janos</infon><infon key="name_3">surname:Leaver-Fay;given-names:Andrew</infon><infon key="name_4">surname:Tuite;given-names:Kathleen</infon><infon key="name_5">surname:Khatib;given-names:Firas</infon><infon key="name_6">surname:Snyder;given-names:Alex Cho</infon><infon key="name_7">surname:Beenen;given-names:Michael</infon><infon key="name_8">surname:Salesin;given-names:David</infon><infon key="name_9">surname:Baker;given-names:David</infon><infon key="section_type">REF</infon><infon key="source">The challenge of designing scientific discovery games</infon><infon key="type">ref</infon><infon key="year">2010</infon><offset>44394</offset></passage><passage><infon key="name_0">surname:Costa;given-names:J</infon><infon key="name_1">surname:Silva;given-names:C</infon><infon key="name_2">surname:Antunes;given-names:M</infon><infon key="name_3">surname:Ribeiro;given-names:B</infon><infon key="section_type">REF</infon><infon key="source">On using crowdsourcing and active learning to improve classification performance</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>44395</offset></passage><passage><infon key="name_0">surname:Csikszentmihalyi;given-names:Mihaly</infon><infon key="section_type">REF</infon><infon key="source">Finding flow: The psychology of engagement with everyday life</infon><infon key="type">ref</infon><infon key="year">1997</infon><offset>44396</offset></passage><passage><infon key="fpage">1</infon><infon key="lpage">1</infon><infon key="name_0">surname:De la Hoz;given-names:E</infon><infon key="name_1">surname:Ariza;given-names:P</infon><infon key="name_2">surname:Medina;given-names:J</infon><infon key="name_3">surname:Espinilla;given-names:M</infon><infon key="section_type">REF</infon><infon key="source">Sensor-based datasets for human activity recognition – A systematic review of literature</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>44397</offset></passage><passage><infon key="name_0">surname:DeVaul;given-names:RW</infon><infon key="name_1">surname:Dunn;given-names:S</infon><infon key="section_type">REF</infon><infon key="source">Real-Time Motion Classification for Wearable Computing Applications</infon><infon key="type">ref</infon><infon key="year">2001</infon><offset>44398</offset></passage><passage><infon key="name_0">surname:Diete;given-names:A</infon><infon key="name_1">surname:Sztyler;given-names:T</infon><infon key="name_2">surname:Stuckenschmidt;given-names:H</infon><infon key="section_type">REF</infon><infon key="source">A smart data annotation tool for multi-sensor activity recognition</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>44399</offset></passage><passage><infon key="fpage">1200</infon><infon key="issue">7</infon><infon key="lpage">4</infon><infon key="name_0">surname:Esliger;given-names:DW</infon><infon key="name_1">surname:Probert;given-names:A</infon><infon key="name_2">surname:Gorber;given-names:SC</infon><infon key="name_3">surname:Bryan;given-names:S</infon><infon key="name_4">surname:Laviolette;given-names:M</infon><infon key="name_5">surname:Tremblay;given-names:MS</infon><infon key="pub-id_pmid">17596790</infon><infon key="section_type">REF</infon><infon key="source">Med. Sci. Sports Exerc</infon><infon key="type">ref</infon><infon key="volume">39</infon><infon key="year">2007</infon><offset>44400</offset><text>Validity of the Actical accelerometer step-count function</text></passage><passage><infon key="fpage">777</infon><infon key="issue">5</infon><infon key="lpage">781</infon><infon key="name_0">surname:Freedson;given-names:PS</infon><infon key="name_1">surname:Melanson;given-names:E</infon><infon key="name_2">surname:Sirard;given-names:J</infon><infon key="pub-id_pmid">9588623</infon><infon key="section_type">REF</infon><infon key="source">Med. Sci. Sports Exerc</infon><infon key="type">ref</infon><infon key="volume">30</infon><infon key="year">1998</infon><offset>44458</offset><text>Calibration of the Computer Science and Applications (CSA), Inc. accelerometer</text></passage><passage><infon key="fpage">209</infon><infon key="issue">2</infon><infon key="lpage">216</infon><infon key="name_0">surname:Full;given-names:Kelsie M.</infon><infon key="name_1">surname:Kerr;given-names:Jacqueline</infon><infon key="name_2">surname:Grandner;given-names:Michael A.</infon><infon key="name_3">surname:Malhotra;given-names:Atul</infon><infon key="name_4">surname:Moran;given-names:Kevin</infon><infon key="name_5">surname:Godoble;given-names:Suneeta</infon><infon key="name_6">surname:Natarajan;given-names:Loki</infon><infon key="name_7">surname:Soler;given-names:Xavier</infon><infon key="section_type">REF</infon><infon key="source">Sleep Health: Journal Nat. Sleep Found</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2018</infon><offset>44537</offset><text>Validation of a physical activity accelerometer device worn on the hip and wrist against polysomnography</text></passage><passage><infon key="fpage">21</infon><infon key="issue">1</infon><infon key="lpage">24</infon><infon key="name_0">surname:Ho;given-names:Chien-Ju</infon><infon key="name_1">surname:Chang;given-names:Tao-Hsuan</infon><infon key="name_2">surname:Lee;given-names:Jong-Chuan</infon><infon key="name_3">surname:Hsu;given-names:Jane Yung-jen</infon><infon key="name_4">surname:Chen;given-names:Kuan-Ta</infon><infon key="section_type">REF</infon><infon key="source">SIGKDD Explor. Newsl</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2010</infon><offset>44642</offset><text>KissKissBan: a competitive human computation game for image annotation</text></passage><passage><infon key="name_0">surname:Iacovides;given-names:Ioanna</infon><infon key="name_1">surname:Jennett;given-names:Charlene</infon><infon key="name_2">surname:Cornish-Trestrail;given-names:Cassandra</infon><infon key="name_3">surname:Cox;given-names:Anna L</infon><infon key="section_type">REF</infon><infon key="source">Do games attract or sustain engagement in citizen science?: a study of volunteer motivations</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>44713</offset></passage><passage><infon key="issue">3</infon><infon key="name_0">surname:Jennett;given-names:Charlene</infon><infon key="name_1">surname:Kloetzer;given-names:Laure</infon><infon key="name_2">surname:Schneider;given-names:Daniel</infon><infon key="name_3">surname:Iacovides;given-names:Ioanna</infon><infon key="name_4">surname:Cox;given-names:Anna</infon><infon key="name_5">surname:Gold;given-names:Margaret</infon><infon key="name_6">surname:Fuchs;given-names:Brian</infon><infon key="name_7">surname:Eveleigh;given-names:Alexandra</infon><infon key="name_8">surname:Methieu;given-names:Kathleen</infon><infon key="name_9">surname:Ajani;given-names:Zoya</infon><infon key="section_type">REF</infon><infon key="source">Journal of Sci. Comm</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2016</infon><offset>44714</offset><text>Motivations, learning and creativity in online citizen science</text></passage><passage><infon key="fpage">e31362</infon><infon key="issue">3</infon><infon key="name_0">surname:Kawrykow;given-names:A</infon><infon key="name_1">surname:Roumanis;given-names:G</infon><infon key="name_2">surname:Kam;given-names:A</infon><infon key="name_3">surname:Kwak;given-names:D</infon><infon key="name_4">surname:Leung;given-names:C</infon><infon key="name_5">surname:Wu;given-names:C</infon><infon key="name_6">surname:Zarour;given-names:E</infon><infon key="name_7">surname:Sarmenta;given-names:L</infon><infon key="name_8">surname:Blanchette;given-names:M</infon><infon key="name_9">surname:Waldispuhl;given-names:J</infon><infon key="pub-id_pmid">22412834</infon><infon key="section_type">REF</infon><infon key="source">PLoS One</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2012</infon><offset>44777</offset><text>Phylo: a citizen science approach for improving multiple sequence alignment</text></passage><passage><infon key="fpage">1175</infon><infon key="issue">10</infon><infon key="lpage">7</infon><infon key="name_0">surname:Khatib;given-names:F</infon><infon key="name_1">surname:DiMaio;given-names:F</infon><infon key="name_10">surname:Jaskolski;given-names:M</infon><infon key="name_11">surname:Baker;given-names:D</infon><infon key="name_2">surname:Cooper;given-names:S</infon><infon key="name_3">surname:Kazmierczyk;given-names:M</infon><infon key="name_4">surname:Gilski;given-names:M</infon><infon key="name_5">surname:Krzywda;given-names:S</infon><infon key="name_6">surname:Zabranska;given-names:H</infon><infon key="name_7">surname:Pichova;given-names:I</infon><infon key="name_8">surname:Thompson;given-names:J</infon><infon key="name_9">surname:Popović;given-names:Z</infon><infon key="pub-id_pmid">21926992</infon><infon key="section_type">REF</infon><infon key="source">Nat Struct Mol Biol</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2011</infon><offset>44853</offset><text>Crystal structure of a monomeric retroviral protease solved by protein folding game players</text></passage><passage><infon key="fpage">331</infon><infon key="issue">7500</infon><infon key="lpage">6</infon><infon key="name_0">surname:Kim;given-names:JS</infon><infon key="name_1">surname:Greene;given-names:MJ</infon><infon key="name_10">surname:Campos;given-names:M</infon><infon key="name_11">surname:Denk;given-names:W</infon><infon key="name_12">surname:Seung;given-names:HS</infon><infon key="name_2">surname:Zlateski;given-names:A</infon><infon key="name_3">surname:Lee;given-names:K</infon><infon key="name_4">surname:Richardson;given-names:M</infon><infon key="name_5">surname:Turaga;given-names:SC</infon><infon key="name_6">surname:Purcaro;given-names:M</infon><infon key="name_7">surname:Balkam;given-names:M</infon><infon key="name_8">surname:Robinson;given-names:A</infon><infon key="name_9">surname:Behabadi;given-names:BF</infon><infon key="pub-id_pmid">24805243</infon><infon key="section_type">REF</infon><infon key="source">Nature</infon><infon key="type">ref</infon><infon key="volume">509</infon><infon key="year">2014</infon><offset>44945</offset><text>Space-time wiring specificity supports direction selectivity in the retina</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">5</infon><infon key="name_0">surname:Kosmadopoulos;given-names:A</infon><infon key="name_1">surname:Darwent;given-names:D</infon><infon key="name_2">surname:Roach;given-names:GD</infon><infon key="section_type">REF</infon><infon key="source">Chronobiology International</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>45020</offset><text>Is it on? An algorithm for discerning wrist-accelerometer non-wear times from sleep/wake activity</text></passage><passage><infon key="name_0">surname:Krüger;given-names:F</infon><infon key="name_1">surname:Heine;given-names:C</infon><infon key="name_2">surname:Bader;given-names:S</infon><infon key="name_3">surname:Hein;given-names:A</infon><infon key="name_4">surname:Teipel;given-names:S</infon><infon key="name_5">surname:Kirste;given-names:T</infon><infon key="section_type">REF</infon><infon key="source">On the applicability of clinical observation tools for human activity annotation</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>45118</offset></passage><passage><infon key="fpage">1192</infon><infon key="issue">3</infon><infon key="lpage">1209</infon><infon key="name_0">surname:Lara;given-names:Oscar D.</infon><infon key="name_1">surname:Labrador;given-names:Miguel A.</infon><infon key="section_type">REF</infon><infon key="source">IEEE Communications Surveys and Tutorials</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2013</infon><offset>45119</offset><text>A survey on human activity recognition using wearable sensors</text></passage><passage><infon key="name_0">surname:Law;given-names:Edith LM</infon><infon key="name_1">surname:Ahn;given-names:Luis Von</infon><infon key="name_2">surname:Dannenberg;given-names:Roger B</infon><infon key="name_3">surname:Crawford;given-names:Mike</infon><infon key="section_type">REF</infon><infon key="source">ISMIR</infon><infon key="type">ref</infon><infon key="year">2007</infon><offset>45181</offset><text>TagATune: A Game for Music and Sound Annotation</text></passage><passage><infon key="fpage">2122</infon><infon key="issue">6</infon><infon key="lpage">7</infon><infon key="name_0">surname:Lee;given-names:J</infon><infon key="name_1">surname:Kladwang;given-names:W</infon><infon key="name_2">surname:Lee;given-names:M</infon><infon key="name_3">surname:Cantu;given-names:D</infon><infon key="name_4">surname:Azizyan;given-names:M</infon><infon key="name_5">surname:Kim;given-names:H</infon><infon key="name_6">surname:Limpaecher;given-names:A</infon><infon key="name_7">surname:Yoon;given-names:S</infon><infon key="name_8">surname:Treuille;given-names:A</infon><infon key="name_9">surname:Das;given-names:R</infon><infon key="pub-id_pmid">24469816</infon><infon key="section_type">REF</infon><infon key="source">Proc Natl Acad Sci U S A</infon><infon key="type">ref</infon><infon key="volume">111</infon><infon key="year">2014</infon><offset>45229</offset><text>RNA design rules from a massive open laboratory</text></passage><passage><infon key="fpage">433</infon><infon key="issue">2</infon><infon key="lpage">442</infon><infon key="name_0">surname:Litman;given-names:L</infon><infon key="name_1">surname:Robinson;given-names:J</infon><infon key="name_2">surname:Abberbock;given-names:T</infon><infon key="pub-id_pmid">27071389</infon><infon key="section_type">REF</infon><infon key="source">Behav Res Methods</infon><infon key="type">ref</infon><infon key="volume">49</infon><infon key="year">2017</infon><offset>45277</offset><text>TurkPrime.com: A versatile crowdsourcing data acquisition platform for the behavioral sciences</text></passage><passage><infon key="fpage">e71171</infon><infon key="issue">8</infon><infon key="name_0">surname:Loguercio;given-names:S</infon><infon key="name_1">surname:Good;given-names:BM</infon><infon key="name_2">surname:Su;given-names:AI</infon><infon key="pub-id_pmid">23951102</infon><infon key="section_type">REF</infon><infon key="source">PLoS One</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2013</infon><offset>45372</offset><text>Dizeez: an online game for human gene-disease annotation</text></passage><passage><infon key="fpage">801</infon><infon key="issue">4</infon><infon key="lpage">812</infon><infon key="name_0">surname:Mannini;given-names:A</infon><infon key="name_1">surname:Rosenberger;given-names:M</infon><infon key="name_2">surname:Haskell;given-names:WL</infon><infon key="name_3">surname:Sabatini;given-names:AM</infon><infon key="name_4">surname:Intille;given-names:SS</infon><infon key="pub-id_pmid">27820724</infon><infon key="section_type">REF</infon><infon key="source">Med. Sci. Sports Exerc</infon><infon key="type">ref</infon><infon key="volume">49</infon><infon key="year">2017</infon><offset>45429</offset><text>Activity recognition in youth using single accelerometer placed at wrist or ankle</text></passage><passage><infon key="fpage">221</infon><infon key="issue">3</infon><infon key="lpage">9</infon><infon key="name_0">surname:Meijer;given-names:GA</infon><infon key="name_1">surname:Westerterp;given-names:KR</infon><infon key="name_2">surname:Verhoeven;given-names:FM</infon><infon key="name_3">surname:Koper;given-names:HB</infon><infon key="name_4">surname:ten Hoor;given-names:F</infon><infon key="pub-id_pmid">2066134</infon><infon key="section_type">REF</infon><infon key="source">IEEE Trans Biomed Eng</infon><infon key="type">ref</infon><infon key="volume">38</infon><infon key="year">1991</infon><offset>45511</offset><text>Methods to assess physical activity with special reference to motion sensors and accelerometers</text></passage><passage><infon key="name_0">surname:Méndez;given-names:Ana Elisa Méndez</infon><infon key="name_1">surname:Cartwright;given-names:Mark</infon><infon key="name_2">surname:Bello;given-names:Juan Pablo</infon><infon key="section_type">REF</infon><infon key="source">CHI’19 Extended Abstracts</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>45607</offset></passage><passage><infon key="name_0">surname:Miller;given-names:Jeff</infon><infon key="section_type">REF</infon><infon key="source">Accelerometer technologies, specfications, and limitations</infon><infon key="type">ref</infon><offset>45608</offset></passage><passage><infon key="fpage">2643</infon><infon key="lpage">2646</infon><infon key="name_0">surname:Prestopnik;given-names:Nathan</infon><infon key="name_1">surname:Souid;given-names:Dania</infon><infon key="section_type">REF</infon><infon key="source">Forgotten island: a story-driven citizen science adventure</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>45609</offset></passage><passage><infon key="name_0">surname:Quinn;given-names:Alexander J</infon><infon key="name_1">surname:Bederson;given-names:Benjamin B</infon><infon key="section_type">REF</infon><infon key="source">Human computation: a survey and taxonomy of a growing field</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>45610</offset></passage><passage><infon key="fpage">e07460</infon><infon key="name_0">surname:Rallapalli;given-names:G</infon><infon key="name_1">surname:Saunders;given-names:DG</infon><infon key="name_10">surname:Downie;given-names:JA</infon><infon key="name_11">surname:Kamoun;given-names:S</infon><infon key="name_12">surname:MacLean;given-names:D</infon><infon key="name_2">surname:Yoshida;given-names:K</infon><infon key="name_3">surname:Edwards;given-names:A</infon><infon key="name_4">surname:Lugo;given-names:CA</infon><infon key="name_5">surname:Collin;given-names:S</infon><infon key="name_6">surname:Clavijo;given-names:B</infon><infon key="name_7">surname:Corpas;given-names:M</infon><infon key="name_8">surname:Swarbreck;given-names:D</infon><infon key="name_9">surname:Clark;given-names:M</infon><infon key="pub-id_pmid">26219214</infon><infon key="section_type">REF</infon><infon key="source">Elife</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2015</infon><offset>45611</offset><text>Lessons from Fraxinus, a crowd-sourced citizen science game in genomics</text></passage><passage><infon key="fpage">1541</infon><infon key="lpage">1546</infon><infon key="name_0">surname:Ravi;given-names:Nishkam</infon><infon key="name_1">surname:Dandekar;given-names:Nikhil</infon><infon key="name_2">surname:Mysore;given-names:Preetham</infon><infon key="name_3">surname:Littman;given-names:Michael</infon><infon key="name_4">surname:Jacobstein;given-names:N</infon><infon key="name_5">surname:Porter;given-names:B</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of Innovative Applications of Artificial Intelligence</infon><infon key="type">ref</infon><infon key="year">2005</infon><offset>45683</offset></passage><passage><infon key="fpage">457</infon><infon key="issue">3</infon><infon key="lpage">65</infon><infon key="name_0">surname:Rosenberger;given-names:ME</infon><infon key="name_1">surname:Buman;given-names:MP</infon><infon key="name_2">surname:Haskell;given-names:WL</infon><infon key="name_3">surname:McConnell;given-names:MV</infon><infon key="name_4">surname:Carstensen;given-names:LL</infon><infon key="pub-id_pmid">26484953</infon><infon key="section_type">REF</infon><infon key="source">Med Sci Sports Exerc</infon><infon key="type">ref</infon><infon key="volume">48</infon><infon key="year">2016</infon><offset>45684</offset><text>24 hours of sleep, sedentary behavior, and physical activity with nine wearable devices</text></passage><passage><infon key="fpage">26</infon><infon key="issue">1</infon><infon key="name_0">surname:Rowles;given-names:Thomas A.</infon><infon key="pub-id_pmid">24148199</infon><infon key="section_type">REF</infon><infon key="source">BMC Biochem</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2013</infon><offset>45772</offset><text>Power to the people: Does Eterna signal the arrival of a new wave of crowd-sourced projects?</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">9</infon><infon key="name_0">surname:Sarkar;given-names:Anurag</infon><infon key="name_1">surname:Cooper;given-names:Seth</infon><infon key="section_type">REF</infon><infon key="source">Comparing paid and volunteer recruitment in human computation games</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>45865</offset></passage><passage><infon key="fpage">3</infon><infon key="issue">2</infon><infon key="name_0">surname:Shcherbina;given-names:Anna</infon><infon key="name_1">surname:Mattsson;given-names:C. Mikael</infon><infon key="name_2">surname:Waggott;given-names:Daryl</infon><infon key="name_3">surname:Salisbury;given-names:Heidi</infon><infon key="name_4">surname:Christle;given-names:Jeffrey W.</infon><infon key="name_5">surname:Hastie;given-names:Trevor</infon><infon key="name_6">surname:Wheeler;given-names:Matthew T.</infon><infon key="name_7">surname:Ashley;given-names:Euan A.</infon><infon key="section_type">REF</infon><infon key="source">Journal of Pers. Med</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2017</infon><offset>45866</offset><text>Accuracy in Wrist-Worn, Sensor-Based Measurements of Heart Rate and Energy Expenditure in a Diverse Cohort</text></passage><passage><infon key="section_type">REF</infon><infon key="source">Dev-Blogs</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>45973</offset></passage><passage><infon key="fpage">244</infon><infon key="lpage">258</infon><infon key="name_0">surname:Song;given-names:Jinhua</infon><infon key="name_1">surname:Wang;given-names:Hao</infon><infon key="name_2">surname:Gao;given-names:Yang</infon><infon key="name_3">surname:An;given-names:Bo</infon><infon key="section_type">REF</infon><infon key="source">Knowledge-Based Systems</infon><infon key="type">ref</infon><infon key="volume">159</infon><infon key="year">2018</infon><offset>45974</offset><text>Active learning with confidence-based answers for crowdsourcing labeling tasks</text></passage><passage><infon key="fpage">156</infon><infon key="lpage">173</infon><infon key="name_0">surname:Stikic;given-names:Maja</infon><infon key="name_1">surname:Schiele;given-names:Bernt</infon><infon key="section_type">REF</infon><infon key="source">Location and Context Awareness</infon><infon key="type">ref</infon><infon key="year">2009</infon><offset>46053</offset></passage><passage><infon key="fpage">e1001779</infon><infon key="issue">3</infon><infon key="name_0">surname:Sudlow;given-names:Cathie</infon><infon key="name_1">surname:Gallacher;given-names:John</infon><infon key="name_10">surname:Liu;given-names:Bette</infon><infon key="name_11">surname:Matthews;given-names:Paul</infon><infon key="name_12">surname:Ong;given-names:Giok</infon><infon key="name_13">surname:Pell;given-names:Jill</infon><infon key="name_14">surname:Silman;given-names:Alan</infon><infon key="name_15">surname:Young;given-names:Alan</infon><infon key="name_16">surname:Sprosen;given-names:Tim</infon><infon key="name_17">surname:Peakman;given-names:Tim</infon><infon key="name_18">surname:Collins;given-names:Rory</infon><infon key="name_2">surname:Allen;given-names:Naomi</infon><infon key="name_3">surname:Beral;given-names:Valerie</infon><infon key="name_4">surname:Burton;given-names:Paul</infon><infon key="name_5">surname:Danesh;given-names:John</infon><infon key="name_6">surname:Downey;given-names:Paul</infon><infon key="name_7">surname:Elliott;given-names:Paul</infon><infon key="name_8">surname:Green;given-names:Jane</infon><infon key="name_9">surname:Landray;given-names:Martin</infon><infon key="pub-id_pmid">25826379</infon><infon key="section_type">REF</infon><infon key="source">PLoS Med</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2015</infon><offset>46054</offset><text>UK biobank: an open access resource for identifying the causes of a wide range of complex diseases of middle and old age</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">4</infon><infon key="name_0">surname:Tong;given-names:Chuxuan</infon><infon key="name_1">surname:Zhang;given-names:Jinglan</infon><infon key="name_2">surname:Chowdhury;given-names:Alok</infon><infon key="name_3">surname:Trost;given-names:Stewart G.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the Australasian Computer Science Week Multiconference</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>46175</offset></passage><passage><infon key="fpage">92</infon><infon key="issue">6</infon><infon key="lpage">94</infon><infon key="name_0">surname:von Ahn;given-names:L</infon><infon key="section_type">REF</infon><infon key="source">Computer</infon><infon key="type">ref</infon><infon key="volume">39</infon><infon key="year">2006</infon><offset>46176</offset><text>Games with a purpose</text></passage><passage><infon key="fpage">1465</infon><infon key="issue">5895</infon><infon key="lpage">8</infon><infon key="name_0">surname:von Ahn;given-names:L</infon><infon key="name_1">surname:Maurer;given-names:B</infon><infon key="name_2">surname:McMillen;given-names:C</infon><infon key="name_3">surname:Abraham;given-names:D</infon><infon key="name_4">surname:Blum;given-names:M</infon><infon key="pub-id_pmid">18703711</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">321</infon><infon key="year">2008</infon><offset>46197</offset><text>reCAPTCHA: human-based character recognition via Web security measures</text></passage><passage><infon key="name_0">surname:von Ahn;given-names:Luis</infon><infon key="section_type">REF</infon><infon key="source">Human computation</infon><infon key="type">ref</infon><infon key="year">2008</infon><offset>46268</offset></passage><passage><infon key="fpage">319</infon><infon key="lpage">326</infon><infon key="name_0">surname:von Ahn;given-names:Luis</infon><infon key="name_1">surname:Dabbish;given-names:Laura</infon><infon key="section_type">REF</infon><infon key="source">Labeling images with a computer game</infon><infon key="type">ref</infon><infon key="year">2004</infon><offset>46269</offset></passage><passage><infon key="fpage">3</infon><infon key="lpage">11</infon><infon key="name_0">surname:Wang;given-names:Jindong</infon><infon key="name_1">surname:Chen;given-names:Yiqiang</infon><infon key="name_2">surname:Hao;given-names:Shuji</infon><infon key="name_3">surname:Peng;given-names:Xiaohui</infon><infon key="name_4">surname:Hu;given-names:Lisha</infon><infon key="section_type">REF</infon><infon key="source">Pattern Recognition Letters</infon><infon key="type">ref</infon><infon key="volume">119</infon><infon key="year">2019</infon><offset>46270</offset><text>Deep learning for sensor-based activity recognition: A survey</text></passage><passage><infon key="name_0">surname:Yordanova;given-names:Kristina</infon><infon key="name_1">surname:Paiement;given-names:Adeline</infon><infon key="name_2">surname:Schröder;given-names:Max</infon><infon key="name_3">surname:Tonkin;given-names:Emma</infon><infon key="name_4">surname:Woznowski;given-names:Przemyslaw</infon><infon key="name_5">surname:Olsson;given-names:Carl Magnus</infon><infon key="name_6">surname:Rafferty;given-names:Joseph</infon><infon key="name_7">surname:Sztyler;given-names:Timo</infon><infon key="section_type">REF</infon><infon key="source">arXiv preprint arXiv:1803.05843</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>46332</offset><text>Challenges in annotation of user data for ubiquitous systems: Results from the 1st ARDUOUS workshop</text></passage><passage><infon key="file">nihms-1056427-f0001.jpg</infon><infon key="id">F1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>46432</offset><text>10 s sample of raw acceleration (g) from the wrist for running (top) and sitting (bottom) activities.</text></passage><passage><infon key="file">nihms-1056427-f0002.jpg</infon><infon key="id">F2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>46534</offset><text>Screenshots from Mobots. (Left) Highlights a player’s incorrect label on validation data fragment and shows the correct label. The green power bar at the bottom diminishes with player errors; (Right) Activity tutorial at the beginning of a level.</text></passage><passage><infon key="file">nihms-1056427-f0003.jpg</infon><infon key="id">F3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>46783</offset><text>Screenshots from Signaligner. (Left) Completed state of the final tutorial level, labeled with correct activities in different columns; (Right) Starting state of the challenge level with one unknown data and one validation data fragment row. The sample signal-patterns to label are presented at the bottom with their unique background color for labeling.</text></passage><passage><infon key="file">nihms-1056427-f0004.jpg</infon><infon key="id">F4</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>47138</offset><text>A 4-min sample of raw data labeled by Mobots players; (top) Raw accelerometer fragment of unknown data; (middle) ground-truth labels of unknown data; (bottom) Player labels with inter-player agreement on the unknown data.</text></passage><passage><infon key="file">nihms-1056427-f0005.jpg</infon><infon key="id">F5</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>47360</offset><text>20-min sample of raw data labeled by Signaligner players; (top) Raw accelerometer fragment of unknown data; (middle) ground-truth labels of unknown data; (bottom) Player labels with inter-player agreement on the unknown data.</text></passage><passage><infon key="file">nihms-1056427-f0006.jpg</infon><infon key="id">F6</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>47586</offset><text>Player labels on unknown data vs. activity recognition algorithm. (Left) 2-min sample used in Mobots game. In (1), the algorithm misclassified sedentary as sleep, but the players labeled it correctly. In (2), the algorithm was confident in classifying sedentary, but players incorrectly labeled it as ambulation. (Right) 2-min sample used in Signaligner game. In (3), the algorithm was less confident in classifying sedentary behavior, but players had high agreement for that label.</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>48069</offset><text>Comparing Mobots player annotations on unknown data with ground-truth labels for ambulation (amb.), sensor non-wear, and sedentary (sed.) activities.</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th rowspan=&quot;2&quot; colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot;&gt;Aggregate annotations&lt;/th&gt;
            &lt;th colspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-bottom: solid 1px&quot; rowspan=&quot;1&quot;&gt;Ground-truth reference&lt;/th&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Amb.&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Non-wear&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sed.&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; colspan=&quot;1&quot;&gt;
              &lt;bold&gt;Player annotations&lt;/bold&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Amb.&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;303&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;53&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Non-wear&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sed.&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;211&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>48219</offset><text>Aggregate annotations	Ground-truth reference	 	Amb.	Non-wear	Sed.	 	Player annotations	Amb.	303	0	53	 	Non-wear	0	0	6	 	Sed.	0	0	211	 	</text></passage><passage><infon key="file">T2.xml</infon><infon key="id">T2</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>48355</offset><text>Labeling accuracy on unknown data from all players, trusted players, and trusted players’ consensus</text></passage><passage><infon key="file">T2.xml</infon><infon key="id">T2</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;All&lt;break/&gt;players&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Trusted&lt;break/&gt;players&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Trusted&lt;break/&gt;players’&lt;break/&gt;consensus&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;bold&gt;Sleep&lt;/bold&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;95.9%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;88.3%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;100%&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;bold&gt;Ambulation&lt;/bold&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;89.7%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;98.8%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;98.8%&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-bottom: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;bold&gt;Sedentary&lt;/bold&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-bottom: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;84.2%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-bottom: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;98.8%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-bottom: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;99.3%&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
              &lt;bold&gt;Overall&lt;/bold&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;90.7%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;94.6%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;99.5%&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>48457</offset><text>	Allplayers	Trustedplayers	Trustedplayers’consensus	 	Sleep	95.9%	88.3%	100%	 	Ambulation	89.7%	98.8%	98.8%	 	Sedentary	84.2%	98.8%	99.3%	 	Overall	90.7%	94.6%	99.5%	 	</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>48628</offset><text>Comparing player labels on unknown data with ground truth reference from trusted players’ consensus</text></passage><passage><infon key="file">T3.xml</infon><infon key="id">T3</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th rowspan=&quot;2&quot; colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Trusted players’&lt;break/&gt;consensus&lt;/th&gt;
            &lt;th colspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-bottom: solid 1px&quot; rowspan=&quot;1&quot;&gt;Ground truth reference&lt;/th&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sleep&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Amb.&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sed.&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td rowspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; colspan=&quot;1&quot;&gt;
              &lt;bold&gt;Player annotations&lt;/bold&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sleep&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1193&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Amb.&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;718&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sed.&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;822&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>48730</offset><text>Trusted players’consensus	Ground truth reference	 	Sleep	Amb.	Sed.	 	Player annotations	Sleep	1193	3	4	 	Amb.	0	718	2	 	Sed.	0	6	822	 	</text></passage><passage><infon key="file">T4.xml</infon><infon key="id">T4</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>48868</offset><text>Players vs. algorithm labeling on the unknown data</text></passage><passage><infon key="file">T4.xml</infon><infon key="id">T4</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th rowspan=&quot;2&quot; colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Players vs. algorithm labeling&lt;break/&gt;for Mobots game&lt;/th&gt;
            &lt;th colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-bottom: solid 1px&quot; rowspan=&quot;1&quot;&gt;Algorithm labels are&lt;/th&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Correct&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Incorrect&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; colspan=&quot;1&quot;&gt;
              &lt;bold&gt;Player labels are&lt;/bold&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Correct&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;401&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;110&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Incorrect&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;44&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;18&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>48919</offset><text>Players vs. algorithm labelingfor Mobots game	Algorithm labels are	 	Correct	Incorrect	 	Player labels are	Correct	401	110	 	Incorrect	44	18	 	</text></passage><passage><infon key="file">T5.xml</infon><infon key="id">T5</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>49063</offset><text>Players vs. algorithm labeling on the unknown data</text></passage><passage><infon key="file">T5.xml</infon><infon key="id">T5</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th rowspan=&quot;2&quot; colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;Players vs. algorithm labeling&lt;break/&gt;for Signaligner game&lt;/th&gt;
            &lt;th colspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-bottom: solid 1px&quot; rowspan=&quot;1&quot;&gt;Algorithm labels are&lt;/th&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Correct&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Incorrect&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td rowspan=&quot;2&quot; align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; colspan=&quot;1&quot;&gt;
              &lt;bold&gt;Player labels are&lt;/bold&gt;
            &lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Correct&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;12525&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;510&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; style=&quot;border-right: solid 1px&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Incorrect&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;45&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;180&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>49114</offset><text>Players vs. algorithm labelingfor Signaligner game	Algorithm labels are	 	Correct	Incorrect	 	Player labels are	Correct	12525	510	 	Incorrect	45	180	 	</text></passage><passage><infon key="file">T6.xml</infon><infon key="id">T6</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>49266</offset><text>Comparison of Mobots and Signaligner games.</text></passage><passage><infon key="file">T6.xml</infon><infon key="id">T6</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;rows&quot;&gt;
        &lt;colgroup span=&quot;1&quot;&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
          &lt;col align=&quot;left&quot; valign=&quot;middle&quot; span=&quot;1&quot;/&gt;
        &lt;/colgroup&gt;
        &lt;thead&gt;
          &lt;tr&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mobots game&lt;/th&gt;
            &lt;th align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Signaligner game&lt;/th&gt;
          &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
          &lt;tr&gt;
            &lt;td colspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot;&gt;
              &lt;bold&gt;Game features&lt;/bold&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Player goals&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Annotate moving data fragments with activity names&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Match fragment patterns with template visual patterns&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Game type&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Action&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Puzzle&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Displayed fragment size&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10 s&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20 – 59 min&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Level completion&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Fill the power bar through correct labels&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Identify all activity validation fragments correctly&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Raw data resolution&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;High (16 Hz)&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Low (0.2 Hz)&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td colspan=&quot;3&quot; align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot;&gt;
              &lt;bold&gt;Game labeling performance on the unknown data&lt;/bold&gt;
            &lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Data annotated&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;9.5 min&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3.8 h&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Play time&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;8.7 h&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;11.69 h&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Inter-player agreement&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.73&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.94&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Label accuracy&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;89.7%&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;99.5%&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Sessions played&lt;xref rid=&quot;TFN1&quot; ref-type=&quot;table-fn&quot;&gt;*&lt;/xref&gt;&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;82&lt;/td&gt;
            &lt;td align=&quot;left&quot; valign=&quot;top&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;148&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
      &lt;/table&gt;
</infon><offset>49310</offset><text>	Mobots game	Signaligner game	 	Game features	 	Player goals	Annotate moving data fragments with activity names	Match fragment patterns with template visual patterns	 	Game type	Action	Puzzle	 	Displayed fragment size	10 s	20 – 59 min	 	Level completion	Fill the power bar through correct labels	Identify all activity validation fragments correctly	 	Raw data resolution	High (16 Hz)	Low (0.2 Hz)	 	Game labeling performance on the unknown data	 	Data annotated	9.5 min	3.8 h	 	Play time	8.7 h	11.69 h	 	Inter-player agreement	0.73	0.94	 	Label accuracy	89.7%	99.5%	 	Sessions played*	82	148	 	</text></passage><passage><infon key="file">T6.xml</infon><infon key="id">T6</infon><infon key="section_type">TABLE</infon><infon key="type">table_footnote</infon><offset>49907</offset><text>Testing with 100 target MTurk players</text></passage></document></collection>
