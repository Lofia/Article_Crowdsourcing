<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20201220</date><key>pmc.key</key><document><id>7328405</id><infon key="license">CC BY</infon><passage><infon key="alt-title">Distorsions of political bias in crowdsourced misinformation flagging</infon><infon key="article-id_doi">10.1098/rsif.2020.0020</infon><infon key="article-id_pmc">7328405</infon><infon key="article-id_pmid">32517634</infon><infon key="article-id_publisher-id">rsif20200020</infon><infon key="elocation-id">20200020</infon><infon key="issue">167</infon><infon key="kwd">social media social networks content policing flagging fake news echo chambers</infon><infon key="license">Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.</infon><infon key="name_0">surname:Coscia;given-names:Michele</infon><infon key="name_1">surname:Rossi;given-names:Luca</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">17</infon><infon key="year">2020</infon><offset>0</offset><text>Distortions of political bias in crowdsourced misinformation flagging</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>70</offset><text>Many people view news on social media, yet the production of news items online has come under fire because of the common spreading of misinformation. Social media platforms police their content in various ways. Primarily they rely on crowdsourced ‘flags’: users signal to the platform that a specific news item might be misleading and, if they raise enough of them, the item will be fact-checked. However, real-world data show that the most flagged news sources are also the most popular and—supposedly—reliable ones. In this paper, we show that this phenomenon can be explained by the unreasonable assumptions that current content policing strategies make about how the online social media environment is shaped. The most realistic assumption is that confirmation bias will prevent a user from flagging a news item if they share the same political bias as the news source producing it. We show, via agent-based simulations, that a model reproducing our current understanding of the social media environment will necessarily result in the most neutral and accurate sources receiving most flags.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1173</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1186</offset><text>Social media have a central role to play in the dissemination of news. There is a general concern about the low quality and reliability of information viewed online: researchers have dedicated increasing amounts of attention to the problem of so-called fake news. Given the current ecosystem of news consumption and production, misinformation should be understood within the complex set of social and technical phenomena underlying online news propagation, such as echo chambers, platform-induced polarization and selective exposure.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1720</offset><text>Over the years two main approaches have emerged to try to address the problem of fake news by limiting its circulation: a technical approach and an expert-based approach. The technical approach aims at building predictive models able to detect misinformation. This is often done using one or more features associated with the message, such as content (through natural language processing (NLP) approaches), source reliability or network structure. While these approaches have often produced promising results, the limited availability of training data as well as the unavoidable subjectivity involved in labelling a news item as fake constitute a major obstacle to wider development.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2404</offset><text>The alternative expert-based approach consists of a fact-checker on the specific topic that investigates and evaluates each claim. While this could be the most accurate way to deal with misinformation, given the amount of news that circulates on social media every second, it is hard to imagine how this could scale to the point of being effective. For this reason, the dominant approach, which has recently also been adopted by Facebook,1 is based on a combination of methods that first use computationally detected crowd signals, often constituted by users flagging what they consider fake or misleading information, and then assigning selected news items to external professional fact-checkers for further investigation. Although flagging-based systems remain, to the best of our knowledge, widely used, many authors have questioned their reliability, showing how users can flag news items for reasons other than the ones intended. Recently, researchers proposed methods to identify reliable users and improve, in that way, the quality of the crowd signal.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3464</offset><text>Regardless of the ongoing efforts, fake news and misleading information still pollute online communications and no immediate solution seems to be available. In 2018, Facebook released, through the Social Science One initiative, the Facebook URL Shares dataset, a preview of the larger dataset released recently.2 The dataset contains the web page addresses (URLs) shared by at least 20 unique accounts on Facebook between January 2017 and June 2018. Together with the URLs, the dataset also details whether the specific link had been sent to the third-party fact-checkers that collaborate with Facebook.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4068</offset><text>We accessed the most shared links in the Italian subset, which revealed some curious patterns and inspired the present work. We exclusively use this dataset for the motivation and validation of our analysis, leaving the use of the newer full dataset for future work.</text></passage><passage><infon key="file">RSIF20200020TB1.xml</infon><infon key="id">RSIF20200020TB1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>4335</offset><text>The top 10 most flagged domains among the Italian links shared on the Facebook URL Shares dataset.</text></passage><passage><infon key="file">RSIF20200020TB1.xml</infon><infon key="id">RSIF20200020TB1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;colgroup span=&quot;1&quot;&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;/colgroup&gt;&lt;thead valign=&quot;bottom&quot;&gt;&lt;tr&gt;&lt;th rowspan=&quot;1&quot; colspan=&quot;1&quot;/&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;domain&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;reported&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;PVPM&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;type&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;repubblica.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;270.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;54.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national newspaper&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;ilfattoquotidiano.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;85.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;21.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national newspaper&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;corriere.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;83.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;30.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national newspaper&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;fanpage.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;49.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national news site&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;ansa.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;47.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;12.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national news site&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;huffingtonpost.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;40.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;7.20&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national news site&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;7&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;ilmessaggero.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;34.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national newspaper&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;8&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;ilsole24ore.com&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;32.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national newspaper&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;9&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;lercio.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;29.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;satire&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;tgcom24.mediaset.it&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;28.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;28.00&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;national news site&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>4434</offset><text>	domain	reported	PVPM	type	 	1	repubblica.it	270.00	54.00	national newspaper	 	2	ilfattoquotidiano.it	85.00	21.00	national newspaper	 	3	corriere.it	83.00	30.00	national newspaper	 	4	fanpage.it	49.00	5.00	national news site	 	5	ansa.it	47.00	12.00	national news site	 	6	huffingtonpost.it	40.00	7.20	national news site	 	7	ilmessaggero.it	34.00	2.00	national newspaper	 	8	ilsole24ore.com	32.00	4.00	national newspaper	 	9	lercio.it	29.00	3.00	satire	 	10	tgcom24.mediaset.it	28.00	28.00	national news site	 	</text></passage><passage><infon key="file">rsif20200020-g1.jpg</infon><infon key="id">RSIF20200020F1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>4945</offset><text>The relationship between the web traffic of a website (x-axis) and the number of flags it received on Facebook (y-axis). Traffic is expressed in PPVM, which indicates what fraction of all the page views by Alexa toolbar users go to a particular site.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5196</offset><text>Table 1 shows the top 10 most reported domains, which are exclusively major national newspapers, news sites and a satirical website. A further analysis of the data reveals, as figure 1 shows, a positive correlation ( fit, with slope α = 0.2, scale β = 1.22 and p &lt; 0.0013) between a source’s popularity and the number of times a domain has been checked by Facebook’s third-party fact-checkers. We measure the popularity of the source through Alexa’s () page views per million users (PVPM). It is worth observing that all the news reported in the top 10 most reported domains have been fact-checked as true legitimate news (with the obvious exception of the satirical website, which was fact-checked as satire).  </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5917</offset><text>These observations create the background for the present paper. Our hypothesis is that users are polarized and that polarization is an important driver of the decision of whether to flag or not a news item: a user will only flag it if it is not perceived truthful enough and if it has a significantly different bias from that of the user (polarity). Sharing the same bias would act against the user’s flagging action. Thus, we introduce a model of online news flagging that we call the ‘bipolar’ model, since we assume for simplicity that there are only two poles—roughly corresponding to ‘liberal’ and ‘conservative’ in the US political system. The bipolar model of news-flagging attempts to capture the main ingredients that we observe in empirical research on fake news and disinformation—echo chambers, confirmation bias, platform-induced polarization and selective exposure. We show how the proposed model provides a reasonable explanation of the patterns that we observe in Facebook data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6930</offset><text>The current crowdsourced flagging systems seem to assume a simpler flag-generating model. Despite being somehow similar to the bipolar model we propose, in this simple case the model does not account for users’ polarization, thus we will call it the ‘monopolar’ model. In the monopolar model, users do not gravitate around two poles and perceived truthfulness constitutes the only parameter. Users flag news items only if they perceive an excessive ‘fakeness’ of the news item, depending of their degree of scepticism. We show how the monopolar model relies on unrealistic expectations and that it is unable to reproduce the observed flag-generating patterns.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7600</offset><text>Lastly, we test the robustness of the bipolar model against various configurations of the underlying network structure and the actors’ behaviour. We show, on the one hand, how the model is always able to explain the observed flagging phenomenon and, on the other hand, that a complex social network structure is a core element of the system.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>7944</offset><text>Methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>7952</offset><text>In this section, we present the main model on which we base the results of this paper. It is possible to understand the bipolar and monopolar models as a single model with or without users’ polarization. However, a user’s polarization has a significant impact on the results, and it seriously affects the social network underlying the flagging and propagation processes. For these reasons, in the paper, we will refer to them as two different models with two different names, which makes the comparison easier to grasp.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8476</offset><text>In the following, we start by giving a general overview of the bipolar model (§2.1). In the subsequent sections, we provide the model details, motivating each choice on the basis of real-world data. We conclude by showing the crucial differences between the bipolar and monopolar models (§2.5).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8773</offset><text>We note that our model shares some commonalities with the bounded confidence model.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>8857</offset><text>Model overview</text></passage><passage><infon key="file">rsif20200020-g2.jpg</infon><infon key="id">RSIF20200020F2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>8872</offset><text>The overview of the bipolar model. From left to right, we show: the characteristics of the agents (source’s polarities, popularity and truthfulness; and user’s polarity); the model’s structures (the bipartite source–user follower network and the unipartite user–user social network); and the agents’ actions (source publishing and users resharing, consuming and flagging news items).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9268</offset><text>Figure 2 shows a general depiction of the bipolar model. In the bipolar model, we have two kinds of agents: news sources and users. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9401</offset><text>News sources are characterized by three values: popularity, polarity and truthfulness. The popularity distributes broadly: there are a few big players with a large following while the majority of sources are followed by only a few users. The polarity distributes quasi-normally. Most sources are neutral and there are progressively fewer and fewer sources that are more polarized. Truthfulness is linked to polarity, with more polarized sources tending to be less truthful. This implies that most news sources are truthful, and less trustworthy sources are more and more rare. Each news item has the same polarity and truthfulness values as the news source publishing it.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10073</offset><text>Users only have polarity. The polarity of the users distributes in the same way as that of the news sources. Most users are moderate and extremists are progressively more rare. Users follow news sources, preferentially those of similar polarity (selective exposure). Users embed in a social network, preferentially being friends of other users of similar polarity (homophily).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10450</offset><text>reshare—if the polarity of the item is sufficiently close to their own and the item is sufficiently truthful;</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10562</offset><text>flag—if the polarity of the item is sufficiently different from their own or the item is not truthful enough;</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10674</offset><text>consume—in all other cases, meaning that the item does not propagate and nor is it flagged.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10768</offset><text>A user can see a news item if the item is either published by a source the user is following or reshared by one of their friends. In either case, the user can do one of three things: </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10952</offset><text>We expect the bipolar model to produce mostly flags in the moderate and truthful part of the spectrum. We base this expectation on the following reasoning. Since most news sources are moderate and truthful, the few very popular sources are overwhelmingly more likely to be moderate and truthful. Thus we will see more moderate and truthful news items, which are more likely to be reshared. This resharing activity will cause the news items published by the moderate and truthful news sources to be shared to the polarized parts of the network. Here, given that the difference between the polarization of the user and the polarization of the source plays a role in flagging even relatively truthful items, moderate and truthful news items are likely to be flagged.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11716</offset><text>Polarized and untruthful items, on the other hand, are unlikely to be reshared. Because of the polarization homophily that characterizes the network structure, they are unlikely to reach the more moderate parts of the network. If polarized items are not shared, they cannot be flagged. A neutral item is more likely to be shared, and thus could reach a polarized user, who would flag it. Thus, most flags will hit moderate and truthful news items, rendering the whole flagging mechanism unsuitable for discovering untruthful items.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>12248</offset><text>Agents</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12255</offset><text>In this section, we detail how we build the main agents in our model: the news sources and the users.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12357</offset><text>As mentioned previously, news sources have a certain popularity. The popularity of a news source is the number of users following it. We generate the source popularity distribution as a power law. This means that the vast majority of news sources have a single follower, while the most popular sources have thousands of followers.</text></passage><passage><infon key="file">rsif20200020-g3.jpg</infon><infon key="id">RSIF20200020F3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>12688</offset><text>(a) The cumulative distribution of source popularity on Facebook in our dataset: the probability (y-axis) of a page to have a given number of followers or more (x-axis). (b) The polarity distribution in the USA from 1994 (light) to 2016 (dark). Biannual observation, except for missing years 2006, 2010 and 2014. EL, extremely liberal; L, liberal; SL, slightly liberal; M, moderate; DK, don’t know; SC, slightly conservative; C, conservative; EC, extremely conservative.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13161</offset><text>This is supported by real-world data. Figure 3a shows the complement cumulative distribution of the number of followers of Facebook pages. These data come from CrowdTangle.4 As we can see, the distribution has a long tail: two out of three Facebook pages have 10 000 followers or fewer. The most popular pages are followed by more than 60 million users. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13516</offset><text>As for the user and source polarities (pu and pi), we assume that they distribute quasi-normally. We create a normal distribution with average equal to zero and standard deviation equal to 1. Then we divide it by its maximum absolute value to ensure that the distribution fully lies between −1 and 1. In this way we ensure that most users are moderates; more extreme users/sources are progressively more rare, at both ends of the spectrum.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13958</offset><text>This is also supported by the literature and by real-world data. Figure 3b shows the distribution of political leaning in the USA across time, collected online.5 These data were collected by surveying a representative sample of the US electorate via phone and face-to-face interviews.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14243</offset><text>While not perfectly normally distributed, the data show that the majority of Americans either feel they are moderate or do not know to which side they lean. ‘Moderate’ or ‘don’t know’ is always the mode of the distribution, and their combination is always the plurality option.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14531</offset><text>Finally, sources have a degree of truthfulness ti. Here, we make the assumption that this is correlated with the news source’s polarity. The more a source is polarized, the less it is interested in the actual truth. A polarized source wants to bring readers onto their side, and their ideology clouds their best judgement of truthfulness. This reasonable assumption is also supported by the literature.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14936</offset><text>Mathematically, this means that ti = 1 − |pi| + ε, with −0.05 ≤ ε ≤ 0.05 being extracted uniformly at random, ensuring then that ti remains between 0 and 1 by capping it to these values.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>15137</offset><text>Structures</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15148</offset><text>There are two structures in the model: the user–source bipartite network and the user–user social network.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>15259</offset><text>User–source network</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15281</offset><text>The user–source network connects users to the news sources they are following. This is the primary channel through which users are exposed to news items.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15437</offset><text>We fix the degree distribution of the sources to be a power law, as we detailed in the previous section. The degree distribution of the user depends on the other rules of the model. There is a certain number of users with degree zero in this network. These users do not follow any news source and only react to what is shared by their circle of friends. We think this is reasonably realistic.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15830</offset><text>We connect users to sources to maximize polarity homophily. The assumption is that users will follow news organizations sharing their polarity. This assumption is supported by the literature.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16022</offset><text>For each source with a given polarity and popularity, we pick the required number of individuals with polarity values in an interval around the source polarity. For instance, if a source has popularity of 24 and polarity of 0.5, we will pick the 24 users whose polarity is closest to 0.5 and we will connect them to the source.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>16350</offset><text>Social network</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16365</offset><text>Users connect to each other in a social network. The social network is the channel through which users are exposed to news items from sources they are not following.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16531</offset><text>We aim at creating a social network with realistic characteristics. For this reason, we generate it via an Lancichinetti–Fortunato–Radicchi (LFR) benchmark6. The LFR benchmark ensures that the social network has a community structure, a broad degree distribution, and communities are overlapping, i.e. they can share nodes. All these characteristics are typical of real-world social networks. We fix the number of nodes to ≈16 000, while the number of communities is variable and not fixed by the LFR’s parameters.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17054</offset><text>We need an additional feature in the social network: polarity homophily. People are more likely to be friends with like-minded individuals. This is supported by studies of politics on social media. We ensure homophily by iterating over all communities generated by the LFR benchmark and assigning to users grouped in the same community a portion of the polarity distribution.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17430</offset><text>For instance, if a community includes 12 nodes, we take 12 consecutive values in the polarity distribution and we assign them to the users. This procedure generates extremely high polarity assortativity. The Pearson correlation of the polarity values at the two endpoints of each edge is ≈0.89.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>17727</offset><text>Actions</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17735</offset><text>A news source publishes to all the users following it an item i carrying the source’s polarity pi and truthfulness ti. Every time a user sees an item i, it calculates how acceptable the item is, using the function fi,u. An item is acceptable if it is (i) truthful and (ii) it is not far from the user in the polarity spectrum—experiments show how this is a reasonable mechanics: users tend to trust more sources with a similar polarity to their own. Mathematically, (i) means that fi,u is directly proportional to ti; while (ii) means that fi,u is inversely proportional to the difference between pi and pu</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18346</offset><text>The acceptability function fi,u has two issues: first, its domain spans from 0 (if ti = 0) to +∞ (if pi = pu). This can be solved by the standard transformation x/(x + 1), which is always between 0 and 1 if x ≥ 0.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18564</offset><text>Second, for the discussion of our parameters and results, it is more convenient to estimate a degree of ‘unacceptability’, which is the opposite of the acceptability fi,u. This can be achieved by the standard transformation 1 − x. Putting the two transformations together, the unacceptability  of item i for user u is</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18888</offset><text>Users have a finite tolerance for how unacceptable a news item can be. If the item exceeds this threshold, meaning , the user will flag the item. On the other hand, if the news item has low to zero unacceptability, meaning , the user will reshare it to their friends. If , the user will neither flag nor reshare the item.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19210</offset><text>The parameters ϕ and ρ regulate which and how many news items are flagged, and thus we need to tune them to generate realistic results—as we do in the Results section.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>19382</offset><text>Monopolar model</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19398</offset><text>The monopolar model is the result of removing everything related to polarity from the bipolar model. The sharing and flagging criteria are the same as in the bipolar model—testing  against the ρ and ϕ parameters, with the difference being in how  is calculated. The unacceptability of a news item is now simply the opposite of its truthfulness, i.e. .</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19754</offset><text>Moreover, in the monopolar model users connect to random news sources and there is no polarity homophily in the social network.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19882</offset><text>The monopolar model attempts to reproduce the assumption of real-world crowdsourced flagging systems: only the least truthful articles are flagged. However, we argue that it is not a good representation of reality because truthfulness assessment is not an objective process: it is a subjective judgement and it includes pre-existing polarization of both sources and users. The bipolar model can capture such polarization while the monopolar model cannot.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>20337</offset><text>Example</text></passage><passage><infon key="file">rsif20200020-g4.jpg</infon><infon key="id">RSIF20200020F4</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>20345</offset><text>Two simple structures with sources (squares) and users (circles). Edges connect sources to the users following them and users to their friends. Each source has an associated ti and pi value and each user has an associated pu value next to their respective nodes.</text></passage><passage><infon key="file">RSIF20200020TB2.xml</infon><infon key="id">RSIF20200020TB2</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>20608</offset><text>The  value for each user–source pair from figure 4 in the (a) bipolar and (b) monopolar models.</text></passage><passage><infon key="file">RSIF20200020TB2.xml</infon><infon key="id">RSIF20200020TB2</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;colgroup span=&quot;1&quot;&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;/colgroup&gt;&lt;thead valign=&quot;bottom&quot;&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; colspan=&quot;3&quot; rowspan=&quot;1&quot;&gt;(&lt;italic&gt;a&lt;/italic&gt;) bipolar’s &lt;inline-formula&gt;&lt;mml:math id=&quot;IM11&quot;&gt;&lt;mml:mover&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mo accent=&quot;false&quot;&gt;¯&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;hr/&gt;&lt;/th&gt;&lt;th align=&quot;left&quot; colspan=&quot;3&quot; rowspan=&quot;1&quot;&gt;(&lt;italic&gt;b&lt;/italic&gt;) monopolar’s &lt;inline-formula&gt;&lt;mml:math id=&quot;IM12&quot;&gt;&lt;mml:mover&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt; &lt;/mml:mo&gt;&lt;mml:msub&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;mml:mrow&gt;&lt;mml:mi&gt;i&lt;/mml:mi&gt;&lt;mml:mo&gt;,&lt;/mml:mo&gt;&lt;mml:mi&gt;u&lt;/mml:mi&gt;&lt;/mml:mrow&gt;&lt;/mml:msub&gt;&lt;/mml:mrow&gt;&lt;mml:mo accent=&quot;false&quot;&gt;¯&lt;/mml:mo&gt;&lt;/mml:mover&gt;&lt;/mml:math&gt;&lt;/inline-formula&gt;&lt;hr/&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;user&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;S1&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;S2&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;user&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;S1&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;S2&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.35&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.74&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.45&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.55&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.15&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.71&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.45&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.55&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U3&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.15&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.66&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U3&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.45&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.55&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U4&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.35&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.61&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U4&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.45&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.55&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U5&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.48&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.52&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U5&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.45&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.55&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U6&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.56&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.40&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U6&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.45&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.55&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U7&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.62&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.10&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;U7&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.45&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.55&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>20706</offset><text>(a) bipolar’s 	(b) monopolar’s 	 	user	S1	S2	user	S1	S2	 	U1	0.35	0.74	U1	0.45	0.55	 	U2	0.15	0.71	U2	0.45	0.55	 	U3	0.15	0.66	U3	0.45	0.55	 	U4	0.35	0.61	U4	0.45	0.55	 	U5	0.48	0.52	U5	0.45	0.55	 	U6	0.56	0.40	U6	0.45	0.55	 	U7	0.62	0.10	U7	0.45	0.55	 	</text></passage><passage><infon key="file">RSIF20200020TB3.xml</infon><infon key="id">RSIF20200020TB3</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>20965</offset><text>The number of flags each source in figure 4 gets in the (a) bipolar and (b) monopolar models, for varying values of ρ and ϕ.</text></passage><passage><infon key="file">RSIF20200020TB3.xml</infon><infon key="id">RSIF20200020TB3</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;colgroup span=&quot;1&quot;&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;col align=&quot;left&quot; span=&quot;1&quot;/&gt;&lt;/colgroup&gt;&lt;thead valign=&quot;bottom&quot;&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; colspan=&quot;4&quot; rowspan=&quot;1&quot;&gt;(&lt;italic&gt;a&lt;/italic&gt;) bipolar&lt;hr/&gt;&lt;/th&gt;&lt;th align=&quot;left&quot; colspan=&quot;4&quot; rowspan=&quot;1&quot;&gt;(&lt;italic&gt;b&lt;/italic&gt;) monopolar&lt;hr/&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;italic&gt;ρ&lt;/italic&gt;&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;italic&gt;ϕ&lt;/italic&gt;&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;S1&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;S2&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;italic&gt;ρ&lt;/italic&gt;&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;italic&gt;ϕ&lt;/italic&gt;&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;S1&lt;/th&gt;&lt;th align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;S2&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.67&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.67&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.7&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.57&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.57&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.49&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.54&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.49&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.54&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.36&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.44&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.36&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.44&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.3&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.2&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.3&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.6&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.5&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.14&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.1&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.14&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4&lt;/td&gt;&lt;td rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>21094</offset><text>(a) bipolar	(b) monopolar	 	ρ	ϕ	S1	S2	ρ	ϕ	S1	S2	 	0.67	0.7	0	2	0.67	0.7	0	0	 	0.57	0.6	1	1	0.57	0.6	0	0	 	0.49	0.54	1	1	0.49	0.54	0	1	 	0.36	0.44	2	0	0.36	0.44	4	1	 	0.2	0.3	2	1	0.2	0.3	4	1	 	0.1	0.6	0	0	0.1	0.6	0	0	 	0.1	0.5	0	0	0.1	0.5	0	1	 	0.1	0.14	4	0	0.1	0.14	4	1	 	</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21375</offset><text>To understand what happens in the bipolar and monopolar models, consider figure 4 as a toy example. Table 2a,b calculates  for all user–source pairs in the bipolar and monopolar models, respectively. Table 3a,b counts the number of flags received by each source for different combinations of the ρ and ϕ parameters in the bipolar and monopolar models, respectively. A few interesting differences between the bipolar and monopolar models appear.   </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21827</offset><text>In the monopolar model, only the direct audience of a source can flag its news items and, if one member of the direct audience flags, so will all of them. This is because  is equal for all nodes, thus either  and the entire audience will flag the item (and no one will reshare it) or  and the entire network—not just the audience—will reshare the item, and no one will ever flag it.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22214</offset><text>This is not true for the bipolar model. S1 (figure 4) can be either flagged by its entire audience (ϕ = 0.14); by part of its audience (ϕ = 0.3); or by nodes who are not in its audience at all (users U5 and U6 for ϕ = 0.44; or user U7 for ϕ = 0.6). On the other hand, in our examples, S2 is never flagged by its audience (U7). When S2 is flagged, it is always because it percolated to a user for which , via a chain of users for which , because  is not constant across users any longer.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>22709</offset><text>Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>22717</offset><text>Parameter tuning</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>22734</offset><text>Before looking at the results of the model, we need to identify the range of parameter values that can support robust and realistic results. The most important of the two parameters is ϕ, because it determines the number of flags generated in the system.</text></passage><passage><infon key="file">rsif20200020-g5.jpg</infon><infon key="id">RSIF20200020F5</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>22991</offset><text>(a) The number of flags (y-axis) in the bipolar model for different values of ϕ (x-axis). (b) The slope difference (colour; red = high, green = low) between the real world and the bipolar fit between the source popularity and the number of flags received, per combination of ϕ and ρ values (x–y axis).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>23299</offset><text>Figure 5a shows the total number of flags generated per value of ϕ. As expected, the higher the ϕ, the fewer the flags, as the user finds more news items acceptable. The sharp drop means that, for ϕ &gt; 0.6, we do not have a sufficient number of flags to support our observation of the model’s behaviour. Thus, hereafter, we will only investigate the behaviour of the model for ϕ ≤ 0.6. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>23694</offset><text>ρ is linked to ϕ; specifically, its value is capped by ϕ. A world with ρ ≥ ϕ is unreasonable, because it would be a scenario where a user feels enough indignation by an item that they will flag it, but then they will also reshare it to their social network. Thus, we only test scenarios in which ρ &lt; ϕ.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>24012</offset><text>Another important question is what combination of ϕ and ρ values generates flags that can reproduce the observed relation between source popularity and the number of flags we see in figure 1. To do so, we perform a grid search, testing many combinations of ϕ–ρ values. Our quality criterion is the absolute difference in the slope of the power fit between popularity and the number of flags. The lower the difference, the better the model is able to approximate reality.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>24491</offset><text>Figure 5b shows such a relationship. We can see that there is an area of high performance at all levels of ϕ.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>24603</offset><text>Bipolar model</text></passage><passage><infon key="file">rsif20200020-g6.jpg</infon><infon key="id">RSIF20200020F6</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>24617</offset><text>Flag count per polarity of items at different flaggability thresholds ϕ for the bipolar model. Reshareability parameter ρ = 0.08. Average of 50 runs. (a) ϕ = 0.1, (b) ϕ = 0.2, (c) ϕ = 0.3, (d) ϕ = 0.4, (e) ϕ = 0.5 and (f) ϕ = 0.6.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>24864</offset><text>Figure 6 shows the distribution of the polarity of the flagged news items, for different values of ϕ and setting ρ = 0.08, an interval including the widest spectrum of goodness of fit as shown in figure 5b. We run the model 50 times and take the average of the results, to smooth out random fluctuations. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25174</offset><text>We can see that our hypothesis is supported: in a polarized environment the vast majority of flagged news items are neutral. This happens for ϕ ≤ 0.3, which, as we saw in figure 5b, is the most realistic scenario. For ϕ ≥ 0.4, our hypothesis would not be supported, but, as we can see in figure 5b, this is the area in red, where the model is a bad fit for the observations anyway—since here we are looking at ρ = 0.08 results.</text></passage><passage><infon key="file">rsif20200020-g7.jpg</infon><infon key="id">RSIF20200020F7</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>25611</offset><text>Flag count per truthfulness of items at different flaggability thresholds ϕ for the bipolar model. Reshareability parameter ρ = 0.08. Average of 50 runs. (a) ϕ = 0.1, (b) ϕ = 0.2, (c) ϕ = 0.3, (d) ϕ = 0.4, (e) ϕ = 0.5 and (f) ϕ = 0.6.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>25862</offset><text>Figure 7 shows the distribution of truthfulness of the flagged items. These distributions show that, by flagging following their individual polarization, users in the bipolar model end up flagging the most truthful item they can—if ϕ is high enough, items with ti ∼ 1 cannot be flagged almost regardless of the polarity difference. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26200</offset><text>The two observations put together mean that, in the bipolar model, the vast majority of flags come from extremists who are exposed to popular neutral and truthful news. The extremists do not follow the neutral and truthful news sources, but get in contact with neutral and truthful viewpoints because of their social network.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>26526</offset><text>The bipolar model results—in accordance with the observation from figure 1—suggest that more popular items are shared more and thus flagged more. One could be tempted to identify and remove fake news items by taking the ones receiving more than their fair shares of flags given their popularity. However, such a simple system would not work in reality. Figure 1 is based on data coming after Facebook’s machine learning pre-processor, the aim of which is to minimize false positives.7 Thus, even after controlling for a number of factors—source popularity, reputation, etc.—most reported flags still end up attached to high-popularity, high-reputability sources.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>27199</offset><text>Monopolar model</text></passage><passage><infon key="file">rsif20200020-g8.jpg</infon><infon key="id">RSIF20200020F8</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>27215</offset><text>Flag count per truthfulness of items for the monopolar model for ϕ = 0.6. Average of 50 runs.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27311</offset><text>In the monopolar model, we remove all aspects related to polarity, thus we cannot show the polarity distribution of the flags. Moreover, as we have shown in §2.6, the effect of ρ and ϕ is marginal. Thus we only show in figure 8 the truthfulness distribution of the flags, for only ϕ = 0.1 and ρ = 0.08, noting that all other parameter combinations result in a practically identical distribution. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>27716</offset><text>The monopolar results show the flag truthfulness distribution as the ideal result. The distribution shows a disproportionate number of flags going to low truthfulness news items, as they should—the drop for the lowest truthfulness value is due to the fact that there are few items at that low level of truthfulness, and that they are not reshared.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>28066</offset><text>Is this ideal result realistic? If we use the same criterion as we used for the bipolar model to evaluate the quality of the monopolar model, the answer is no. The absolute slope difference in the popularity–flag regression between observation and the monopolar model is ≈0.798 for all ϕ–ρ combinations. This is a significantly worse performance than the worst-performing versions of the bipolar model—figure 5b shows that no bipolar version goes beyond a slope difference of 0.5.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>28557</offset><text>Thus we can conclude that the monopolar model is not a realistic representation of reality, even if we would expect it to correctly flag the untruthful news items. The bipolar model is a better approximation, and results in flagging truthful news items.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>28811</offset><text>Robustness</text></passage><passage><infon key="file">rsif20200020-g9.jpg</infon><infon key="id">RSIF20200020F9</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>28822</offset><text>(a) The cumulative distribution of source activity in Facebook in our dataset: the probability (y-axis) of a news source sharing a given number of items or more (x-axis). (b) The relationship between activity (x-axis) and popularity (y-axis) in our Facebook dataset.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29089</offset><text>Our bipolar model makes a number of simplifying assumptions that we need to test. First, we are showing results for a model in which all news sources have the same degree of activity, meaning that each source will publish exactly one news item. This is not realistic: data from Facebook pages show that there is a huge degree of activity heterogeneity (figure 9a). </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29455</offset><text>There is a mild positive correlation between the popularity of a page and its degree of activity (log-log Pearson correlation of ≈0.12; figure 9b). For this reason, we use the real-world distribution of page popularity and we lock it in with its real-world activity level. This is the weighted bipolar model, in which each synthetic news source is the model’s equivalent of a real page, with its popularity and activity.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>29880</offset><text>A second simplifying assumption of the bipolar model is that the reshareability and flaggability parameters ρ and ϕ are the same for every individual in the social network. However, people might have different trigger levels. Thus we create the variable bipolar model, where each user has its own ρu and ϕu. These values are distributed normally, with their average  (and standard deviation 0.01) and  depending on which average value of ϕ we are interested in studying (with the standard deviation set to one-eighth of ).</text></passage><passage><infon key="file">rsif20200020-g10.jpg</infon><infon key="id">RSIF20200020F10</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>30413</offset><text>Dispersion of polarization (a) and average truthfulness (b) of the flagged items in the bipolar model and its weighted and variable variants.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30555</offset><text>Figure 10 shows the result of the weighted and variable variants against the original bipolar model. In figure 10a, we report the dispersion (standard deviation) of the polarization values of the flags. A low dispersion means that flags cluster in the neutral portion of the polarity spectrum, meaning that most flags signal neutral news items. In figure 10b, we report the average truthfulness of flagged items. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>30969</offset><text>We can see that taking into account the pages’ activities increases the dispersion by a negligible amount and only for high values of ϕ. This happens because there could be some extremely active fringe pages spamming fake content, which increases the likelihood of extreme flags. There is no difference in the average truthfulness of flagged items.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>31321</offset><text>Having variable ϕ and ρ values, instead, actually decreases dispersion, making the problem worse—although only for larger values of ϕ. In this configuration, a very tolerant society with high (average) ϕ would end up flagging mostly neutral reporting—as witnessed by the higher average truthfulness of the reported items. This is because lower-than-average ρu users will be even less likely to reshare the most extreme news items.</text></passage><passage><infon key="file">rsif20200020-g11.jpg</infon><infon key="id">RSIF20200020F11</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>31762</offset><text>Dispersion of polarization (a) and average truthfulness (b) of the flagged items for different values of reshareability ρ.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>31887</offset><text>So far we have kept the reshareability parameter constant at ρ = 0.08. If we change ρ (figure 11) the dispersion of a flag’s polarity (figure 11a) and its average truthfulness value (figure 11b) do not significantly change. The changes are due to the fact that ρ simply affects the number of flags: a higher ρ means that users are more likely to share news items. More shares imply more news items percolating through the social network and thus more flags. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>32354</offset><text>The bipolar model contains many elements besides the ρ and ϕ parameters. For instance, it imposes that the social network has several communities and that social relationships are driven by homophily. These two elements are based on existing literature, yet we should test their impact on the model.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>32658</offset><text>First, keeping everything else constant, the no-homophily variant allows users to connect to friends ignoring their polarity value. In other words, polarity is randomly distributed in the network. Second, keeping everything else constant, the no-community variant uses an Erdős–Rényi random graph as the social network instead of an LFR benchmark. The Erdős–Rényi graph extracts connections between nodes uniformly at random and thus it has, by definition, no community structure.</text></passage><passage><infon key="file">rsif20200020-g12.jpg</infon><infon key="id">RSIF20200020F12</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>33147</offset><text>Dispersion of polarization (a) and average truthfulness (b) of the flagged items in the bipolar and alternative models.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>33267</offset><text>Figure 12 shows the impact on flag polarity dispersion (figure 12a) and average truthfulness (figure 12b). The no-homophily variant of the bipolar model has a significantly higher dispersion in the flag polarity distribution, and lower truthfulness average, and the difference is stable (though stronger for values of ρ above 0.3). This means that polarity homophily is playing a key role in ensuring that flags are predominantly assigned to neutral news items: if we remove it, the accuracy in spotting fake news increases. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>33795</offset><text>In contrast, removing the community structure from the network will result in a slightly smaller dispersion of flag’s polarity and higher average flag truthfulness. The lack of communities might cause truthful items to spread more easily, and thus be flagged, increasing the average flag truthfulness.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>34099</offset><text>Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>34110</offset><text>In this paper, we show how the assumption of traditional crowdsourced content policing systems is unreasonable. Expecting users to flag content carries the problematic assumption that a user will genuinely attempt to estimate the veracity of a news item to the best of their capacity. Even if that was a reasonable expectation to have, a user’s estimation of veracity will be made within their individual view of the world and variable polarization. This will result in assessments that will give an easier pass to biased content if they share such bias. This hypothesis is supported by our bipolar agent-based model. The model shows that even contexts that are extremely tolerant towards different opinions, represented by our flaggability parameter ϕ, would still mostly flag neutral content, and produce results that fit well with observed real-world data. Moreover, by testing the robustness of our model, we show how our results hold both for the amount of heterogeneity of source activity and for individual differences in both tolerance and propagation attitudes.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>35184</offset><text>Removing polarization from the model, and thus testing what we defined as the monopolar model, attempts to reproduce the assumptions that would make a classical content policy system work. The monopolar model, while seemingly based on reasonable assumptions, is not largely supported by established literature in the area of online behaviour and social interaction, differently from the bipolar model. Moreover, it is not able to deliver on its promises in terms of ability to represent real-world data.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>35688</offset><text>Our paper has a number of weaknesses and possible future directions. First, our main results are based on a simulated agent-based model. The results hold as long as the assumptions and the dynamics of the models are an accurate approximation of reality. We provided evidence to motivate the bipolar model’s assumptions, but there could still be factors unaccounted for, such as the role of originality or of spreaders’ effort in making content go viral. Second, many aspects of the model were fixed and should be investigated. For instance, there is a strong polarity homophily between users and news sources, and in user–user connections in the social network. We should investigate whether such strong homophily is really supported in real-world scenarios. Third, the model has an essentially static structure. The users will never start/stop following news sources, nor befriend/unfriend fellow users. Such actions are common in real-world social systems and should be taken into account. Fourth the model only assumes news stories worth interacting with. This is clearly different from the reality where, in a context of overabundant information, most stories are barely read and collect few reshares or flags. Including those news stories in the model could certainly affect the overall visibility of other items. Finally, the model does not take into account reward and cost functions for both users and news sources. What are the repercussions for a news source of having its content flagged? Should news sources attempt to become mainstream and gather following? Such reward/cost mechanisms are likely to greatly influence our outcomes. We plan to address the last two points in future expansions of our model.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title</infon><offset>37413</offset><text>Endnotes</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>37422</offset><text> (April 2017, date of access 3 March 2020).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>37466</offset><text> (February 2020, date of access 3 March 2020).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>37513</offset><text>From a least-squares fit in a log-log space. Alternative hypotheses such as linear relationship or exponential relationship are discarded, with p-values approximately 0.98 and 0.34, respectively.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>37709</offset><text> (date of access 11 November 2019).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>37745</offset><text> (date of access 7 January 2020).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>37779</offset><text>Ethics</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>37786</offset><text>No individual-level data have been accessed in the development of this paper. The paper’s experiments rely on synthetic simulations. Motivating data provided by the Social Science Research Council fulfil the ethical criteria required by Social Science One.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>38045</offset><text>Data accessibility</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>38064</offset><text>The archive containing the data and code necessary for the replication of our results can be found at </text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title_1</infon><offset>38167</offset><text>Authors' contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>38190</offset><text>L.R. collected the data. M.C. performed the experiments. M.C. and L.R. jointly designed the study, analysed the data, prepared the figures, and wrote and approved the manuscript.</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title_1</infon><offset>38369</offset><text>Competing interests</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>38389</offset><text>We declare we have no competing interest.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title_1</infon><offset>38431</offset><text>Funding</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>38439</offset><text>No funding has been received for this article.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>38486</offset><text>References</text></passage><passage><infon key="comment">Reuters institute digital news report 2019, vol. 2019. Oxford, UK: Reuters Institute for the Study of Journalism</infon><infon key="name_0">surname:Newman;given-names:N</infon><infon key="name_1">surname:Fletcher;given-names:R</infon><infon key="name_2">surname:Kalogeropoulos;given-names:A</infon><infon key="name_3">surname:Nielsen;given-names:R</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>38497</offset></passage><passage><infon key="fpage">211</infon><infon key="lpage">36</infon><infon key="name_0">surname:Allcott;given-names:H</infon><infon key="name_1">surname:Gentzkow;given-names:M</infon><infon key="pub-id_doi">10.1257/jep.31.2.211</infon><infon key="section_type">REF</infon><infon key="source">J. Econ. Perspect.</infon><infon key="type">ref</infon><infon key="volume">31</infon><infon key="year">2017</infon><offset>38498</offset><text>Social media and fake news in the 2016 election</text></passage><passage><infon key="fpage">1094</infon><infon key="lpage">1096</infon><infon key="name_0">surname:Lazer;given-names:DMJ</infon><infon key="pub-id_doi">10.1126/science.aao2998</infon><infon key="pub-id_pmid">29590025</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">359</infon><infon key="year">2018</infon><offset>38546</offset><text>The science of fake news</text></passage><passage><infon key="fpage">1146</infon><infon key="lpage">1151</infon><infon key="name_0">surname:Vosoughi;given-names:S</infon><infon key="name_1">surname:Roy;given-names:D</infon><infon key="name_2">surname:Aral;given-names:S</infon><infon key="pub-id_doi">10.1126/science.aap9559</infon><infon key="pub-id_pmid">29590045</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">359</infon><infon key="year">2018</infon><offset>38571</offset><text>The spread of true and false news online</text></passage><passage><infon key="comment">The political blogosphere and the 2004 US election: divided they blog. In Proc. of the 3rd Int. Workshop on Link Discovery, Chicago, IL, 21–24 August 2005, pp. 36–43. New York, NY: ACM</infon><infon key="name_0">surname:Adamic;given-names:LA</infon><infon key="name_1">surname:Glance;given-names:N</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2005</infon><offset>38612</offset></passage><passage><infon key="fpage">265</infon><infon key="lpage">285</infon><infon key="name_0">surname:Garrett;given-names:RK</infon><infon key="pub-id_doi">10.1111/j.1083-6101.2009.01440.x</infon><infon key="section_type">REF</infon><infon key="source">J. Comput.-Mediated Commun.</infon><infon key="type">ref</infon><infon key="volume">14</infon><infon key="year">2009</infon><offset>38613</offset><text>Echo chambers online? Politically motivated selective exposure among internet news users</text></passage><passage><infon key="fpage">e38</infon><infon key="name_0">surname:Nikolov;given-names:D</infon><infon key="name_1">surname:Oliveira;given-names:DFM</infon><infon key="name_2">surname:Flammini;given-names:A</infon><infon key="name_3">surname:Menczer;given-names:F</infon><infon key="pub-id_doi">10.7717/peerj-cs.38</infon><infon key="section_type">REF</infon><infon key="source">PeerJ Comput. Sci.</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2015</infon><offset>38702</offset><text>Measuring online social bubbles</text></passage><passage><infon key="comment">Echo chambers on Facebook. See </infon><infon key="name_0">surname:Quattrociocchi;given-names:W</infon><infon key="name_1">surname:Scala;given-names:A</infon><infon key="name_2">surname:Sunstein;given-names:CR</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2016</infon><offset>38734</offset></passage><passage><infon key="fpage">298</infon><infon key="lpage">320</infon><infon key="name_0">surname:Flaxman;given-names:S</infon><infon key="name_1">surname:Goel;given-names:S</infon><infon key="name_2">surname:Rao;given-names:JM</infon><infon key="pub-id_doi">10.1093/poq/nfw006</infon><infon key="section_type">REF</infon><infon key="source">Public Opin. Q.</infon><infon key="type">ref</infon><infon key="volume">80</infon><infon key="year">2016</infon><offset>38735</offset><text>Filter bubbles, echo chambers, and online news consumption</text></passage><passage><infon key="fpage">729</infon><infon key="lpage">745</infon><infon key="name_0">surname:Dubois;given-names:E</infon><infon key="name_1">surname:Blank;given-names:G</infon><infon key="pub-id_doi">10.1080/1369118X.2018.1428656</infon><infon key="section_type">REF</infon><infon key="source">Inf. Commun. Soc.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2018</infon><offset>38794</offset><text>The echo chamber is overstated: the moderating effect of political interest and diverse media</text></passage><passage><infon key="fpage">37825</infon><infon key="name_0">surname:Del Vicario;given-names:M</infon><infon key="name_1">surname:Vivaldo;given-names:G</infon><infon key="name_2">surname:Bessi;given-names:A</infon><infon key="name_3">surname:Zollo;given-names:F</infon><infon key="name_4">surname:Scala;given-names:A</infon><infon key="name_5">surname:Caldarelli;given-names:G</infon><infon key="name_6">surname:Quattrociocchi;given-names:W</infon><infon key="pub-id_doi">10.1038/srep37825</infon><infon key="pub-id_pmid">27905402</infon><infon key="section_type">REF</infon><infon key="source">Sci. Rep.</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2016</infon><offset>38888</offset><text>Echo chambers: emotional contagion and group polarization on Facebook</text></passage><passage><infon key="comment">Political discourse on social media: echo chambers, gatekeepers, and the price of bipartisanship. In Proc. of the 2018 World Wide Web Conference, Lyon, France, 23–27 April 2018, pp. 913–922. Geneva, Switzerland: International World Wide Web Conferences Steering Committee</infon><infon key="name_0">surname:Garimella;given-names:K</infon><infon key="name_1">surname:De Francisci Morales;given-names:G</infon><infon key="name_2">surname:Gionis;given-names:A</infon><infon key="name_3">surname:Mathioudakis;given-names:M</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>38958</offset></passage><passage><infon key="comment">Fragmented social media: a look into selective exposure to political news. In Proc. of the 22nd Int. Conf. on World Wide Web, Rio de Janeiro, Brazil, 13–17 May 2013, pp. 51–52. New York, NY: ACM</infon><infon key="name_0">surname:An;given-names:J</infon><infon key="name_1">surname:Quercia;given-names:D</infon><infon key="name_2">surname:Crowcroft;given-names:J</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>38959</offset></passage><passage><infon key="fpage">1130</infon><infon key="lpage">1132</infon><infon key="name_0">surname:Bakshy;given-names:E</infon><infon key="name_1">surname:Messing;given-names:S</infon><infon key="name_2">surname:Adamic;given-names:LA</infon><infon key="pub-id_doi">10.1126/science.aaa1160</infon><infon key="pub-id_pmid">25953820</infon><infon key="section_type">REF</infon><infon key="source">Science</infon><infon key="type">ref</infon><infon key="volume">348</infon><infon key="year">2015</infon><offset>38960</offset><text>Exposure to ideologically diverse news and opinion on Facebook</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">4</infon><infon key="name_0">surname:Conroy;given-names:NJ</infon><infon key="name_1">surname:Rubin;given-names:VL</infon><infon key="name_2">surname:Chen;given-names:Y</infon><infon key="pub-id_doi">10.1002/pra2.2015.145052010082</infon><infon key="section_type">REF</infon><infon key="source">Proc. Assoc. Inf. Sci. Technol.</infon><infon key="type">ref</infon><infon key="volume">52</infon><infon key="year">2015</infon><offset>39023</offset><text>Automatic deception detection: methods for finding fake news</text></passage><passage><infon key="fpage">22</infon><infon key="lpage">36</infon><infon key="name_0">surname:Shu;given-names:K</infon><infon key="name_1">surname:Sliva;given-names:A</infon><infon key="name_2">surname:Wang;given-names:S</infon><infon key="name_3">surname:Tang;given-names:J</infon><infon key="name_4">surname:Liu;given-names:H</infon><infon key="pub-id_doi">10.1145/3137597.3137600</infon><infon key="section_type">REF</infon><infon key="source">ACM SIGKDD Explor. Newsl.</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2017</infon><offset>39084</offset><text>Fake news detection on social media: a data mining perspective</text></passage><passage><infon key="comment">Learning to identify ambiguous and misleading news headlines. In Proc. of the 26th Int. Joint Conf. on Artificial Intelligence, Melbourne, Australia, 19–25 August 2017, pp. 4172–4178. Palo Alto, CA: AAAI Press</infon><infon key="name_0">surname:Wei;given-names:W</infon><infon key="name_1">surname:Wan;given-names:X</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2017</infon><offset>39147</offset></passage><passage><infon key="comment">On the discovery of evolving truth. In Proc. of the 21th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining, Sydney, Australia, 10–13 August 2015, pp. 675–684. New York, NY: ACM</infon><infon key="name_0">surname:Li;given-names:Y</infon><infon key="name_1">surname:Li;given-names:Q</infon><infon key="name_2">surname:Gao;given-names:J</infon><infon key="name_3">surname:Su;given-names:L</infon><infon key="name_4">surname:Zhao;given-names:B</infon><infon key="name_5">surname:Fan;given-names:W</infon><infon key="name_6">surname:Han;given-names:J</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>39148</offset></passage><passage><infon key="comment">Tracing fake-news footprints: characterizing social media messages by how they propagate. In Proc. of the 11th ACM Int. Conf. on Web Search and Data Mining, Los Angeles, CA, 5–9 February 2018, pp. 637–645. New York, NY: ACM</infon><infon key="name_0">surname:Wu;given-names:L</infon><infon key="name_1">surname:Liu;given-names:H</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>39149</offset></passage><passage><infon key="comment">Fake news detection in social networks via crowd signals. In Companion Proc. of the Web Conf. 2018, Lyon, France, 23–27 April 2018, pp. 517–524. Geneva, Switzerland: International World Wide Web Conferences Steering Committee</infon><infon key="name_0">surname:Tschiatschek;given-names:S</infon><infon key="name_1">surname:Singla;given-names:A</infon><infon key="name_2">surname:Gomez Rodriguez;given-names:M</infon><infon key="name_3">surname:Merchant;given-names:A</infon><infon key="name_4">surname:Krause;given-names:A</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>39150</offset></passage><passage><infon key="fpage">625</infon><infon key="lpage">642</infon><infon key="name_0">surname:Giglietto;given-names:F</infon><infon key="name_1">surname:Iannelli;given-names:L</infon><infon key="name_2">surname:Valeriani;given-names:A</infon><infon key="name_3">surname:Rossi;given-names:L</infon><infon key="section_type">REF</infon><infon key="source">Curr. Sociol.</infon><infon key="type">ref</infon><infon key="volume">67</infon><infon key="year">2019</infon><offset>39151</offset><text>‘Fake news’ is the invention of a liar: how false information circulates within the hybrid news system</text></passage><passage><infon key="comment">Social media fact checking method and system, 4 June 2013. US Patent 8,458,046</infon><infon key="name_0">surname:Myslinski;given-names:LJ</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>39258</offset></passage><passage><infon key="comment">Leveraging the crowd to detect and reduce the spread of fake news and misinformation. In Proc. of the 11th ACM Int. Conf. on Web Search and Data Mining, Los Angeles, 5–9 February 2018, pp. 324–332. New York, NY: ACM</infon><infon key="name_0">surname:Kim;given-names:J</infon><infon key="name_1">surname:Tabibian;given-names:B</infon><infon key="name_2">surname:Oh;given-names:A</infon><infon key="name_3">surname:Schölkopf;given-names:B</infon><infon key="name_4">surname:Gomez-Rodriguez;given-names:M</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>39259</offset></passage><passage><infon key="fpage">410</infon><infon key="lpage">428</infon><infon key="name_0">surname:Crawford;given-names:K</infon><infon key="name_1">surname:Gillespie;given-names:T</infon><infon key="pub-id_doi">10.1177/1461444814543163</infon><infon key="section_type">REF</infon><infon key="source">New Media Soc.</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2016</infon><offset>39260</offset><text>What is a flag for? Social media reporting tools and the vocabulary of complaint</text></passage><passage><infon key="name_0">surname:Gillespie;given-names:T</infon><infon key="section_type">REF</infon><infon key="source">Custodians of the Internet: platforms, content moderation, and the hidden decisions that shape social media</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>39341</offset></passage><passage><infon key="comment">Facebook URL Shares. See </infon><infon key="name_0">surname:Messing;given-names:S</infon><infon key="name_1">surname:State;given-names:B</infon><infon key="name_2">surname:Nayak;given-names:C</infon><infon key="name_3">surname:King;given-names:G</infon><infon key="name_4">surname:Persily;given-names:N</infon><infon key="pub-id_doi">10.7910/DVN/EIAACS</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>39342</offset></passage><passage><infon key="fpage">6</infon><infon key="name_0">surname:Mathias;given-names:J-D</infon><infon key="name_1">surname:Huet;given-names:S</infon><infon key="name_2">surname:Deffuant;given-names:G</infon><infon key="pub-id_doi">10.18564/jasss.2967</infon><infon key="section_type">REF</infon><infon key="source">J. Artif. Soc. Soc. Simul.</infon><infon key="type">ref</infon><infon key="volume">19</infon><infon key="year">2016</infon><offset>39343</offset><text>Bounded confidence model with fixed uncertainties and extremists: the opinions can keep fluctuating indefinitely</text></passage><passage><infon key="comment">Mapping italian news media political coverage in the lead-up to 2018 general election. See </infon><infon key="name_0">surname:Giglietto;given-names:F</infon><infon key="name_1">surname:Iannelli;given-names:L</infon><infon key="name_2">surname:Rossi;given-names:L</infon><infon key="name_3">surname:Valeriani;given-names:A</infon><infon key="name_4">surname:Righetti;given-names:N</infon><infon key="name_5">surname:Carabini;given-names:F</infon><infon key="name_6">surname:Marino;given-names:G</infon><infon key="name_7">surname:Usai;given-names:S</infon><infon key="name_8">surname:Zurovac;given-names:E</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2018</infon><offset>39456</offset></passage><passage><infon key="comment">The ANES guide to public opinion and electoral behavior. See </infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2008</infon><offset>39457</offset></passage><passage><infon key="fpage">353</infon><infon key="lpage">369</infon><infon key="name_0">surname:Lewandowsky;given-names:S</infon><infon key="name_1">surname:Ecker;given-names:UKH</infon><infon key="name_2">surname:Cook;given-names:J</infon><infon key="pub-id_doi">10.1016/j.jarmac.2017.07.008</infon><infon key="section_type">REF</infon><infon key="source">J. Appl. Res. Memory Cogn.</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2017</infon><offset>39458</offset><text>Beyond misinformation: understanding and coping with the ‘post-truth’ era</text></passage><passage><infon key="fpage">186</infon><infon key="lpage">200</infon><infon key="name_0">surname:Iyengar;given-names:S</infon><infon key="name_1">surname:Hahn;given-names:KS</infon><infon key="name_2">surname:Krosnick;given-names:JA</infon><infon key="name_3">surname:Walker;given-names:J</infon><infon key="pub-id_doi">10.1017/S0022381607080139</infon><infon key="section_type">REF</infon><infon key="source">J. Politics</infon><infon key="type">ref</infon><infon key="volume">70</infon><infon key="year">2008</infon><offset>39536</offset><text>Selective exposure to campaign communication: the role of anticipated agreement and issue public membership</text></passage><passage><infon key="fpage">341</infon><infon key="lpage">366</infon><infon key="name_0">surname:Stroud;given-names:NJ</infon><infon key="pub-id_doi">10.1007/s11109-007-9050-9</infon><infon key="section_type">REF</infon><infon key="source">Pol. Behav.</infon><infon key="type">ref</infon><infon key="volume">30</infon><infon key="year">2008</infon><offset>39644</offset><text>Media use and political predispositions: revisiting the concept of selective exposure</text></passage><passage><infon key="fpage">046110</infon><infon key="name_0">surname:Lancichinetti;given-names:A</infon><infon key="name_1">surname:Fortunato;given-names:S</infon><infon key="name_2">surname:Radicchi;given-names:F</infon><infon key="pub-id_doi">10.1103/PhysRevE.78.046110</infon><infon key="section_type">REF</infon><infon key="source">Phys. Rev. E</infon><infon key="type">ref</infon><infon key="volume">78</infon><infon key="year">2008</infon><offset>39730</offset><text>Benchmark graphs for testing community detection algorithms</text></passage><passage><infon key="comment">Political polarization on twitter. In Proc. 5th Int. AAAI Conf. on Weblogs and Social Media, Barcelona, Spain, 17–21 July 2011. Palo Alto: AAAI Press</infon><infon key="name_0">surname:Conover;given-names:MD</infon><infon key="name_1">surname:Ratkiewicz;given-names:J</infon><infon key="name_2">surname:Francisco;given-names:M</infon><infon key="name_3">surname:Gonçalves;given-names:B</infon><infon key="name_4">surname:Menczer;given-names:F</infon><infon key="name_5">surname:Flammini;given-names:A</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>39790</offset></passage><passage><infon key="fpage">160802</infon><infon key="name_0">surname:Swire;given-names:B</infon><infon key="name_1">surname:Berinsky;given-names:AJ</infon><infon key="name_2">surname:Lewandowsky;given-names:S</infon><infon key="name_3">surname:Ecker;given-names:UKH</infon><infon key="pub-id_doi">10.1098/rsos.160802</infon><infon key="pub-id_pmid">28405366</infon><infon key="section_type">REF</infon><infon key="source">R. Soc. open sci.</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2017</infon><offset>39791</offset><text>Processing political misinformation: comprehending the Trump phenomenon</text></passage><passage><infon key="fpage">70</infon><infon key="lpage">77</infon><infon key="name_0">surname:Coscia;given-names:M</infon><infon key="pub-id_doi">10.1145/3158227</infon><infon key="section_type">REF</infon><infon key="source">Commun. ACM</infon><infon key="type">ref</infon><infon key="volume">61</infon><infon key="year">2017</infon><offset>39863</offset><text>Popularity spikes hurt future chances for viral propagation of protomemes</text></passage><passage><infon key="comment">The three dimensions of social prominence. In Proc. Int. Conf. on Social Informatics, Kyoto, Japan, 25–27 November 2013, pp. 319–332. New York, NY: Springer</infon><infon key="name_0">surname:Pennacchioli;given-names:D</infon><infon key="name_1">surname:Rossetti;given-names:G</infon><infon key="name_2">surname:Pappalardo;given-names:L</infon><infon key="name_3">surname:Pedreschi;given-names:D</infon><infon key="name_4">surname:Giannotti;given-names:F</infon><infon key="name_5">surname:Coscia;given-names:M</infon><infon key="section_type">REF</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>39937</offset></passage></document></collection>
