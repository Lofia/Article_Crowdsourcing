<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20220813</date><key>pmc.key</key><document><id>8831872</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.1007/s13369-021-06449-y</infon><infon key="article-id_pmc">8831872</infon><infon key="article-id_pmid">35194540</infon><infon key="article-id_publisher-id">6449</infon><infon key="fpage">10453</infon><infon key="issue">8</infon><infon key="kwd">Natural language processing Machine learning Deceptive text Fake news</infon><infon key="license">Open AccessThis article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.</infon><infon key="lpage">10469</infon><infon key="name_0">surname:Himdi;given-names:Hanen</infon><infon key="name_1">surname:Weir;given-names:George</infon><infon key="name_2">surname:Assiri;given-names:Fatmah</infon><infon key="name_3">surname:Al-Barhamtoshy;given-names:Hassanin</infon><infon key="section_type">TITLE</infon><infon key="title">Keywords</infon><infon key="type">front</infon><infon key="volume">47</infon><infon key="year">2022</infon><offset>0</offset><text>Arabic Fake News Detection Based on Textual Analysis</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>53</offset><text>Over the years, social media has had a considerable impact on the way we share information and send messages. With this comes the problem of the rapid distribution of fake news which can have negative impacts on both individuals and society. Given the potential negative influence, detecting unmonitored ‘fake news’ has become a critical issue in mainstream media. While there are recent studies that built machine learning models that detect fake news in several languages, lack of studies in detecting fake news in the Arabic language is scare. Hence, in this paper, we study the issue of fake news detection in the Arabic language based on textual analysis. In an attempt to address the challenges of authenticating news, we introduce a supervised machine learning model that classifies Arabic news articles based on their context’s credibility. We also introduce the first dataset of Arabic fake news articles composed through crowdsourcing. Subsequently, to extract textual features from the articles, we create a unique approach of forming Arabic lexical wordlists and design an Arabic Natural Language Processing tool to perform textual features extraction. The findings of this study promises great results and outperformed human performance in the same task.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1327</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1340</offset><text>The digitalization of communication is no longer a phenomenon confined to Western countries. Social media is almost dominating the Arab regions; 79% of people in the Middle East use social media or direct messaging at least once a day.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1576</offset><text>In recent years, the widespread use of social media and chat messaging applications has not only changed how people communicate, but also how they access news stories, and the trust they place in its content. An estimated 66% of people in the Middle East use social media to look for news daily.1 Social media is considered as an essential source of news and information among young adults. Popular chat messaging applications such as WhatsApp, Facebook messenger, Snapchat, and LINE have become popular ways for users to curate their own news consumption by default. Users see those news stories (and only those news stories) that their hand-selected network of friends deem worth sharing with them.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2277</offset><text>This decentralization of news sources from the newsroom to the living room has many advantages, but also drawbacks. The ubiquitous presence of bots on these messaging platforms greatly increases the likelihood that news stories in a users’ feed have not been written and vetted by journalists, but are sensationalized, emotionally charged stories created by sophisticated AI programs—fake news. The dissemination of fake news has variously succeeded in disrupting organizations, damaging the reputations of individuals, and threatening democratic elections and other political processes.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2869</offset><text>When these stories gain mass circulation, as these platforms allow for, this becomes a concern of citizens, corporations and even governments. Monitoring all the information distributed through social media or messaging platforms is virtually an impossible task without automation. Social media has garnered worldwide attention in the past decade due to the permissive production and distribution of fake news quickly.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3288</offset><text>Regardless of whether the news is spread via social media or online websites, identifying fake news is the first step in either eliminating its potential harmful effects or in at least reducing the potential negative impact on individuals, companies and governments. Fake news is a fabricated media content that mimics the form of original content but may have different organization processes or intent. Fake news is not an entirely homogeneous term. It differs based on its intent: misinformation, disinformation, and malinformation. Misinformation does not have harmful intent; disinformation has harmful intent; and malformation shares genuine information in order to cause harm. It also differs in terms of its purpose: satire, parody, fabrication, manipulation, advertising, and propaganda. The overarching commonality, however, boils down to facticity and deception.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4162</offset><text>Communities and governments that are affected by fake news use other sources of real news to clarify or explain the critique or the credibility of a fake story. However, manual fact-checking is not always possible due to the massive amount of information written to be fake or even using machine-generated news. The stylistic differences from human-written text is not always apparent as misinformation may be related to source or authorship attribution.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4617</offset><text>Computational linguists have thrown a great deal of time and resources toward addressing this growing problem from numerous angles. One of the most common starting points has been to focus on reader response cues related to fake news articles. Both the metadata and comments section in various social media platforms have proved to be valuable contextual indicators that the main post consists of a fake news article. This work has often preceded the more difficult work involved in analyzing and identifying fake news directly. One reason for the lag is that such work requires substantive and reliable benchmark datasets containing fake news articles and real news articles. Once these datasets are in place, researchers can begin identifying diagnostic features that distinguish fake news articles from real news articles.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5443</offset><text>Research in the English-speaking world has accumulated quickly, where researchers have had access to robust datasets for years now and have been steadily identifying diagnostic features across numerous linguistic parameters. Research on this subject in the Arabic-speaking world, however, has lagged, not only from it being a low-resource language, but from unique challenges presented by the cultural responses to Arabic fake news. Many governments in the Arab world have banned fake news and placed stiff penalties on their production and distribution. Unfortunately, from a research perspective, these bans have repressed, if not entirely eradicated, the types of collated sites that English-language researchers have found so useful for creating reliable benchmark datasets.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6222</offset><text>These cultural factors have inhibited the level of research on Arabic fake news, largely restricting that research to the low hanging fruit of reader response cues and metadata. Our idea involves harnessing the relatively recent, innovative model of crowdsourcing, in an effort to clear those hurdles that have scared off other researchers and produce a reliable dataset consisting of real and fake news articles in Arabic as a foundation to our research. Once this subject specific dataset is in place, the more general tools for text-linguistic analysis in Arabic, including stemming, normalization, POS tagging, along with sentiment, emotion, and subjectivity lexicons, are readily available for us to use, though it may prove useful to supplement these with more nuanced lexicons of our own design. Furthermore, the general findings from deception detection research can provide the framework necessary for the supervised machine learning we will need to use.</text></passage><passage><infon key="file">13369_2021_6449_Fig1_HTML.jpg</infon><infon key="id">Fig1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>7186</offset><text>Process map for supervised Arabic deception detection module</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7247</offset><text>The purpose of this research is to build an automated classification model to classify Arabic fake news based on Arabic textual analysis using natural language processing (NLP) and supervised machine learning methods. News articles that contain any wrong information (false) is considered fake, while news articles that contain all verified information (true) are considered real. The objective is to find specific cues that can serve as deceptive linguistic markers and thereby detect fake news articles. Since there are no Arabic fake news datasets available, we will create a dataset using crowdsourcing adapted from. We specify this problem using Posit in conjunction with an Arabic natural language processing (ANLP) tool developed by the researchers (Fig. 1).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8013</offset><text>Build an Arabic fake news dataset based on crowdsourcing.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8071</offset><text>Develop lexical wordlists for Arabic textual analysis.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8126</offset><text>Design an ANLP prototype to conduct several textual features extraction.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8199</offset><text>Build a classification model that classifies Arabic news based on its context as real or fake.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8294</offset><text>Compare our model with human performance.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8336</offset><text>To achieve the goal of this research, the research contributions are as follows:</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8417</offset><text>The remainder of this paper proceeds as follows. Section 2 outlines a methodology drawing upon previous research. The general approach to the problem and the procedures followed encompass Sect. 3. Section 4 describes the performance and evaluation of our system. Finally, Sect. 5 concludes the study further specifying the scope of future work.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>8766</offset><text>Developing a Methodology for Deception Detection in Arabic News Reports</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8838</offset><text>In tackling this topic, there are a number of considerations and hurdles to address. There is the need to establish a methodology for approaching deception detection in general. There are the problems associated with supervised machine learning that others developing deception detection programs have encountered. These are compounded by the problems related to working in a low-resource language, like Arabic. Thinking through these issues with the help of previous studies is important for conceptualizing the best approach to take to accomplish the goal of producing an automation NLP system for identifying fake news in Arabic.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>9471</offset><text>Questions Related to Deception Detection</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9512</offset><text>In this section, we present some topics related to deception detection as it shares the mutual aspect that fake news has in terms of its deceptive text. This entails that several works done for detecting deception may be applicable to detect fake news.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>9765</offset><text>The Importance of Genre in Deception Detection</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9812</offset><text>Before getting into the specifics of deception and deception detection, it is important to acknowledge the important role played by genre and context. All communication relies on context and genre. The academic literature devoted to deception detection spans numerous genres. There is obviously a big difference between deception detection techniques that are appropriate for law enforcement interrogations and those that work with written text. Even studies focused on social media can focus on such different genres as: opinion spam; product reviews; and fake news. But even studies on fake news make a distinction between fake news that does not have a harmful intent (misinformation), like satire and parody news sites, and those that have nefarious intents, like propaganda and fabrication.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10608</offset><text>The reason why genre is so important in this discussion is that the process of detecting deception in written text by computational textual analysis relies on establishing a genre specific linguistic profile. In this study, authentic news stories will function as the baseline linguistic profile. Automated deception detection attempts to identify common tendencies that differentiate the linguistic profiles of fake news articles from the baseline linguistic profile. Care must be taken in adopting insights from research on deception detection that use other genres as a baseline. The insights may not always be transferrable.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11237</offset><text>Lahlou et al. highlighted the restrictions that this problem has placed on existing automated fake news detection programs. They are primarily restricted to only one platform (one context or genre). When these programs run on other platforms, even focused on the same subgenre, they exhibit poor performance.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>11546</offset><text>Unintentional Components of Deception</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>11584</offset><text>Much of human society is based upon the presumption of honesty in communication. Humans assume that others are being honest by default. Human society breaks down in the face of deception. This is why so much of primary and secondary socialization of children is dedicated to reinforcing the importance of honesty in language and behavior. Children begin telling lies as early as age 2. Since humans are adapt at telling lies, we are obsessed with being able to identify deception in order to prevent being deceived.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>12100</offset><text>Physiological Responses and Deception</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12138</offset><text>Deception carries with it the fear of being found out—of getting caught. Fear produces distinct physiological responses. Law enforcement agencies have relied on such responses for years in developing their interrogation techniques. Intuitively, we associate this with non-verbal cues: elevated heartrate; sweating; fidgeting; eye contact or lack thereof; etc. These responses are subconscious and involuntary. Therefore, investigators refer to them as ‘leakage’.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>12607</offset><text>Verbal cues, however, have always been a focus of deception detection. Most verbal cues have other causes not related to fear, but the use of certainty words in a deceptive context likely stems from this fear element. Certainty words are generally weak oaths that speakers add to statements in a context where lying is either expected or where there are high stakes in the truth of a statement. The high stakes produce anxiety, which results in in the use of certainty words. In other words, in the context of a law enforcement interrogation, both honest and dishonest subjects would be expected to use certainty words because of the stakes involved in the situation. When certainty terms appear in other environments, like news stories would not fit into either category, this can be a case of ‘leakage’ resulting from fear of being caught.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>13453</offset><text>In addition to fear, guilt is another emotion that deceptive acts elicit. This sense of guilt creates an emotional ‘leakage’ that expresses itself with more emotional expressiveness on the part of deceivers as compared with truth-tellers. Newman, et al. argued that it is not just the expression of emotion in general that characterizes deceptive speech, but specifically negative emotion. Either way, since news stories are generally meant to be informative and not convey high levels of emotion, the presence of emotion words may be indicative of a fake news story.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>14025</offset><text>The Imagination and Deception</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14055</offset><text>Deception always relies on the imagination rather than memory. This is why conscientious fabricators attempt to anchor their deception in real items or memories that they can reference more easily. Imagination and memory access completely different parts of the brain. This is why interrogators have focused on whether subjects look up and to the right to access a memory or up and to the left to access their imagination.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>14478</offset><text>This also means that imaginative language has a different character than descriptive language, even in written texts. With the aid of computational linguistics, these differences are even more apparent. In a fascinating study, Rayson et al. studied the text typology of various genres side-by-side looking at the proportional distribution of parts of speech. In the head-to-head comparison between informative writing and imaginative writing, the informative writing contained more nouns and adjectives, while the imaginative writing contained more verbs and adverbs. There were a few nuances they highlighted as well. While adverbs in general were more common in imaginative writing, comparatives and superlatives were more common in informative writing.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15234</offset><text>These findings relate to some of the core differences between memory and imagination. Memory (and informative writing) tends to be more concrete and can easily elaborate descriptively. Imagination, as more of an abstraction focuses on the movement and action of a scene, without the need to fill in details. This helps to explain the comparatives and superlatives, which are descriptive details less focused on broad actions and events.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>15671</offset><text>The Intentional Components of Deception</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>15711</offset><text>While deception does result in some subconscious and involuntary responses, with the exception of self-deception, deception is an intentional act. The communication goals that are present in fake news production are different from the goals that animate informative news production. These distinct communication goals leave different linguistic signatures in the profile.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>16083</offset><text>Persuasion</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16094</offset><text>Fake news and genuine news simply have two different objectives. Genuine news seeks to inform the reader. Journalists provide factual information to the best of their ability about an event and try to place it into a wider context for understanding. Their target audience not only wants to be informed about the details of a specific event but wants to understand its causes and implications as best as possible. Fake news, on the other hand, uses speculation to create events that feed into fears and biases of their target audience. The goal is to persuade the target audience that their fears and biases are legitimate and rooted in fact. This subtle deceptive persuasion leaves appear in the language of fake news articles.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>16822</offset><text>Word Count Analyses as a Window into Situational and Psychological States</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>16896</offset><text>Back in 1999, Pennebaker and King conducted a study that focused on personal lexical stylistic differences. They found that using various analytical word count methods, they could identify individual writing styles based on statistical analysis of the language in texts they had written. In a subsequent study, Pennebaker et al. expanded this analysis to cover not only individual differences, but differences in language that appeared in specific situations or psychological states. The task of writing fake news is unique situation with an accompanying psychological state marked primarily by the deception described above.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>17522</offset><text>While studies on deception detection have only used some of the features that Pennebaker and King designated as ‘Psychological Processes’ and ‘Relativity,’ we will attempt to cast a broader net encompassing all of these features, whether they make intuitive sense as unique features of deceptive text or not. For instance, something like certainty terms produced in an effort to assure the reader of the truth of the statement makes intuitive sense as to why a deceptive text might have a higher frequency of these than a standard informative text. Relativity terms, however, like temporal references show up as stylistic features that differ in frequency between speakers.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>18204</offset><text>Previous Work in News-Related Deception Detection</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18254</offset><text>Due to the primary importance of genre in deception detection, as described in Sect. 2.1.1, the most relevant previous work in this field that should prove helpful for this study is the automated deception detection efforts focused on news articles specifically. Unfortunately, many of the articles whose titles promisingly suggest they relate to fake news detection are not actually directed toward analyzing the actual content of news articles. With a focus on social media, many studies rely heavily on paratextual information (emojis, hashtags and comments) that is often platform specific for clues to the veracity of the news posting. We are interested in conducting true content assessment that is applicable across platforms and contexts.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>19002</offset><text>Problems Arising from Working in a Low-Resource Language</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19059</offset><text>Most of the work performed to date on deception detection for news has focused on English text. Deception detection work in Arabic is minimal. To our knowledge, little has been work done to detect misinformation for Arabic text. The misinformation classification in Arabic content may be challenging due to the complexity of the Arabic language. The challenges include the non-concatenative morphology of Arabic. Another challenge is the lack of freely dedicated tools to process Arabic text.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>19552</offset><text>Developing a Relevant Corpus</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19581</offset><text>Bondielli and Marcelloni have highlighted the problems related to making a proper database of fake information that is relevant. Previous literature suggests two possible options for developing a database of fake information. Kapusta, et al. used a web browser plug-in called ‘BS Detector’ developed by Daniel Sieradski to identify a set of 244 web pages that were flagged as questionable. His team then used a scraper to extract 12,761 news articles that it labeled as fake news. The problem with the approach Kapusta and his team took is that just because a website is marked as a questionable source does not mean that every article on that website qualifies as fake news, in the same way that not every news article on trustworthy news site is unquestionably authentic. At no point did Kapusta et al. address this concern in their research. According to Chloe Lim, even fact-checking service websites like the Washington Post’s Fact Checker and PolitiFact have a low inter-rater reliability agreement score between fact-checkers in cases that are not blatant or black-and-white. Lim’s results suggest that existing fact-checking procedures are inadequate for providing impartial, independent verification of news statements that would engender agreement among the fact-checkers themselves.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20883</offset><text>While, using a fact-checking websites to identify a set of fake news articles would certainly circumvent this problem the time and effort involved in extracting these articles would be prohibitive. Torabi Asr and Taboada recognized the extent of this problem and created a dataset specifically to address the gap. Unfortunately, as with so many resources for this task, the dataset is in English.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21280</offset><text>Pérez-Rosas, et al. came up with a solution for the problem of obtaining a relevant database of fake news. Their solution was to use crowdsourcing to transform existing news stories into fake news stories, which is not all that different from the way in which fake news producers actually produce their content. This solution provided a cost-effective means for us to create the type of quality sample necessary for this task.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21708</offset><text>However, various concerns pertaining to the Covid-19 pandemic, including the vaccination process, led to the development of various studies, all of which classified the veracity of Arabic statements made with regard to the pandemic. However, they also dealt with the statements made in Twitter via tweets and rumors that spread across social media. As such, in both cases, it is important to note that the texts could not exceed 149 characters in length or were written in an informal way.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22198</offset><text>Of the various studies, ARanews, a dataset published by, used word substitution to create and distribute false versions of genuine statements. This entailed amassing in excess of 61,000 ‘fake,’ computer-manipulated articles in the dataset and, via the use of Word Embedding methods, automatically substituting the proper nouns, adjectives, adverbs, and digits in each article. Despite its benefits, the dataset suffers that some of the false articles were not structured reasonably. So, human readers could, in all likelihood, easily identify the fake statements.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22766</offset><text>In the same task, another dataset was created, specifically via one method: crowdsourcing. This dataset included news titles, all of which were paraphrased but, importantly, retained the essence of the original information. However, this work shares identical limitations to previous work conducted on tweets: in tweets, there are a limited number of words compared to news articles, for example.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23163</offset><text>So, despite the fact that studies have attempted to address the issue of building an Arabic fake news dataset, the aforementioned examples clearly illustrate that it is still lacking the resources compared to other types of text, such as news articles.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>23416</offset><text>Developing Lexical Resources</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23445</offset><text>Not only do low-resource languages like Arabic lack relevant corpora, which are currently proliferating in the high-resource language of English; they also lack basic lexical resources. Some Arabic lexical resources such as sentiments have been conducted, others were translated from other languages. While this lack of readily available lexical resources creates a challenge for this work, it will also create opportunities. Since we are creating these lexical resources from the ground up, we can craft them to meet our specifications and goals.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>23993</offset><text>Approach and Procedures</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24017</offset><text>With this paper we seek to contribute to the debate over the best strategy for Arabic text classification using NLP for deception detection by building an automated classifier to detect misinformation. This paper relies on imitating human judgment in classifying text based on several linguistic features that are useful in exploiting differences in writing style, language, and sentiment. This study is unique among the contributions to this problem for Arabic in its focus exclusively on fake news.</text></passage><passage><infon key="file">13369_2021_6449_Fig2_HTML.jpg</infon><infon key="id">Fig2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>24518</offset><text>Classifier building steps</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24544</offset><text>This section explains the preparation and pre-processing of our dataset for Arabic fake news detection. The first step involved building the classifier (Fig. 2). We generated a first-of-its-kind Arabic fake news dataset using crowdsourcing. Once this dataset was in place, the next step involved extracting diagnostic features of fake news in Arabic using a textual analysis approach. Using sets of linguistic markers proven to be effective in previous studies, which included emotional, linguistic, polarity, and part of speech markers, we applied a state-of-the-art machine learning analysis.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>25140</offset><text>Data Collection</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25156</offset><text>There are far fewer resources in Arabic to detect fake news than what already exists for other languages, which should not be surprising given its status as a low-resource language. Not only is Arabic a low-resource language, but because it belongs to a completely different language family than most high-resource languages, much of the work in constructing a resource must happen from the ground up, as explained in Sect. 2.3.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25586</offset><text>Rather than covering a broad range of topics, we decided to limit the dataset to one overarching topic—the Hajj. The idea was that delimiting the articles to the same broad topic would ensure the machine learning was not skewed by language differences generated by speaking about different topics. The Hajj is an annual pilgrimage when millions of Muslims worldwide travel to the holy site of Mecca, in Saudi Arabia. News organizations worldwide cover this event, which spans several discrete news domains, including politics, economics, and sports, each with a reasonable amount of information.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>26184</offset><text>Real News Dataset Collection</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>26213</offset><text>A Python scraper script gleaned these articles spanning the five-year period from October 2013 through October 2018, focusing on the topic of Hajj. In an effort to collect a diverse range of articles, the extraction targeted articles produced by news platforms from Arabic-speaking countries in three distinct geographical locations. Saudi Arabia represented the Arabian Gulf; Egypt represented northern Africa; and Jordan represented the Mediterranean. Throughout the data collection process, we made every possible effort to ensure the veracity of the articles incorporated in the dataset. Similar to work composed by, were they relied on fact checking platforms to collect real statements or verify their collected statements, we used four online fact-checking platforms: NO_RUMORS;2Falsoo;3AKEED,4 and Fatabyyano.5 These fact checking platforms are popular in the Arab region and Fatabyyano is certified by International Fact-Checking Network (IFCN). IFCN certifies that the website complies under the IFCN’s code of ethics. After running the articles through each fact checking platform, all the articles passed the verification process.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>27358</offset><text>Admittedly, however, the reliability of labeling articles from news agencies as real is a matter of much debate [81, 101]. Reliably establishing the ground truth of a given article in every detail is a difficult task at best. As highlighted above [2.3.1], the low inter-rater reliability score between professional fact checkers calls into question the possibility of objective reliability in this process. Nevertheless, we must make every effort to keep our data as reliable as possible.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>27847</offset><text>Our efforts to further ensure veracity of the real articles collected by the scraper, beyond cross-referencing fact checking platforms, involved manually cross-referencing each article with several sources following the methodology outlined by. Any article we were unable to cross-reference with even one separate article, we discarded as unreliable in its veracity. This culling process resulted in 1200 articles total (400 each) from the three nations identified above.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>28319</offset><text>Another challenge collecting real news articles presented related to content length. This is a problem that does not exist for the studies of tweets or even product reviews. Around 63% of real articles were more than seven paragraphs long, which is about 2000 words. Texts of this length would impede the falsifying process and cause overfitting when extracting features. Wang established a reasonable approach for tackling this issue. This approach involved limiting the dataset to those snippets of the news articles that contain statements from politicians, which one would want to fact check. This procedure helps to avoid the problem of overfitting.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>28974</offset><text>Following their lead, our research chose to collect excerpts from real news articles, rather than the articles in their entirety. We chose the first and second paragraphs from each article as news writers tend to front the bottom-line information statements within articles. News editors even have a name for this rule of thumb they call ‘not burying the lede,’ which is a pat phrase that appears in standard English dictionaries.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>29409</offset><text>This collection process resulted in 700 news excerpts. Throughout this paper, for simplicity, the collected news excerpts will be called articles. The dataset consisted of 700 real news articles. The 700 real news articles consisted of 244 Saudi, 220 Egyptian, 236 Jordanian.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>29685</offset><text>Fake News Collection Using Crowdsourcing</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>29726</offset><text>To the best of our knowledge, no fake news datasets yet existed for the Arabic language when we began this research. Previous studies investigating deceptive Arabic text have targeted online reviews, YouTube comments, news headlines, and tweets. In the absence of existing datasets, we were faced with the task of creating them. As discussed in Sect. 2.3.1, we followed Pérez-Rosas et al. in crowdsourcing the creation of these articles.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30166</offset><text>Maintain the existence of characters in the article.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30219</offset><text>Maintain the use of Modern Arabic language; slang, curse, and non-Arabic characters are not allowed.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30320</offset><text>Ensure the revised article remains approximately the same length as the original source article. Since the most comprehensive original source article excerpts consisted of 1000 words (around five sentences), this became the upper threshold for revised articles.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30582</offset><text>Changes should be realistic. Example of a non-realistic fake statement: ‘’ (‘Pilgrims performed Hajj on the moon!’)</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30706</offset><text>The following guidelines helped to avoid discrepancies between the participants’ writing style and the writing style contained in the original source article.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_4</infon><offset>30867</offset><text>Participant Selection</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30889</offset><text>It was important to establish several prerequisites for the fake news creation task advertisements before presenting them to a new crop of potential fake news producers. This involved anticipating possible objections from otherwise qualified producers. One such objection might stem from a strong desire to obtain anonymity. Since the production of fake news content generally involves nefarious goals, the activity constitutes a crime in many Arabic countries punishable with jail time. Therefore, abstaining from collecting any personal information is one way to allay fears of potential participants. A second objection may relate to the time and effort associated with falsifying the original source articles. Rewarding the participants for their time and effort with a small monetary incentive per submitted article should overcome that objection. Finally, some participants may fell that fabricating articles related to a religious topic like the Hajj would violate their moral or religious sensibilities. To overcome this anticipated objection, the consent form specifically including the following line: ‘this only a research task using textual analysis, not interfering with anyone’s belief or religion.’</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>32109</offset><text>With these prerequisites in place, a local university email system allowed us to invite native Arabic speakers consisting of university students and employees to participate in this task. Those who accepted the invitation will be designated ‘participants.’ Each participant received 20 original legitimate news articles. Distribution of the articles followed sequentially per reply. For example, participant 1 (who replied first) received articles 1–20. The second participant was given 21–40, and so on. More than 43% of these local participants either only submitted a subset of the 20 falsified articles requested or cancelled their participation entirely. In a period of 30 days, participants submitted about 200 falsified articles. This poor response rate led us to regroup and recruit more participants. This time, we used Fiverr’s service-paid platform for recruiting. This platform enabled us to reach a large and diverse number of participants worldwide and provided the participants an even greater level of personal anonymity than that provided by the university email system.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>33208</offset><text>Two Media undergraduate students and one Saudi journalist analyzed the falsified articles to reduce the likelihood of bias. We relied on their expert knowledge to sort the submitted falsified articles into three distinct buckets labelled: ‘all’; ‘partial’; and ‘none.’ Articles which met all the guidelines received the label ‘all.’ Conversely, the analysts reserved the label ‘none’ for those articles which did not meet any of the guidelines. This left the label ‘partial’ for those articles that only met some of the guidelines. All three analysts labeled each article independently. Articles only made it into the dataset if at least two of the three analysts gave it an ‘all’ label. We discarded all other articles. The inter-annotator agreement was measured as Fleiss’ Kappa of 0.714, which indicates a moderate to a substantial level of agreement beyond chance. We also discarded the corresponding original article in the authentic news dataset for any of the falsified articles that did not make the cut for the fake news dataset. This helped to ensure equality in the number of articles in both datasets to balance the two classifiers.</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>34383</offset><text>Sample of a real and corresponding fake article</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Real article&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Fake article&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;
&lt;inline-graphic xlink:href=&quot;13369_2021_6449_Figb_HTML.gif&quot; id=&quot;d32e812&quot;/&gt;&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;
&lt;inline-graphic xlink:href=&quot;13369_2021_6449_Figc_HTML.gif&quot; id=&quot;d32e817&quot;/&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;The Friday editions of the Saudi newspapers said that this year’s pilgrims will carry an electronic security bracelet, after the chaos that resulted from the bloody stampede during the Hajj season last year. &lt;italic&gt;Arab News&lt;/italic&gt; and the &lt;italic&gt;Saudi Gazette&lt;/italic&gt; said that resorting to this technology would help the authorities to handle the pilgrims and ‘get to know them.’ On September 24, 2015, during the last Hajj season, a massive stampede killed 2297 pilgrims, according to data collected from statistics compiled by foreign governments. The latter had difficulties in identifying the victims. According to the Saudi authorities, 769 people were killed in the tragic stampede, the most severe in the history of the Hajj&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;&lt;p&gt;The Saturday editions of the Saudi newspapers said that this year’s pilgrims will carry small electronic devices affixed to their mobile phones to locate them, after the chaos that resulted from the bloody stampede during the Hajj season last year&lt;/p&gt;&lt;p&gt;&lt;italic&gt;Arab News&lt;/italic&gt; and the &lt;italic&gt;Saudi Gazette&lt;/italic&gt; explained that resorting to this technology would alert the authorities to the whereabouts of the pilgrims by tracking their work and personal use on their mobile phones, making it easier for them to organize and coordinate between them&lt;/p&gt;&lt;p&gt;And on October 25, 2012, during the Hajj season, a huge stampede killed 3654 pilgrims, according to data from the Local Statistics Centre. The latter was distressed by the difficulty it found in identifying the victims, but we hope that these problems will abate after implementing these smart electronic devices&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>34431</offset><text>Real article	Fake article	 			 	The Friday editions of the Saudi newspapers said that this year’s pilgrims will carry an electronic security bracelet, after the chaos that resulted from the bloody stampede during the Hajj season last year. Arab News and the Saudi Gazette said that resorting to this technology would help the authorities to handle the pilgrims and ‘get to know them.’ On September 24, 2015, during the last Hajj season, a massive stampede killed 2297 pilgrims, according to data collected from statistics compiled by foreign governments. The latter had difficulties in identifying the victims. According to the Saudi authorities, 769 people were killed in the tragic stampede, the most severe in the history of the Hajj	The Saturday editions of the Saudi newspapers said that this year’s pilgrims will carry small electronic devices affixed to their mobile phones to locate them, after the chaos that resulted from the bloody stampede during the Hajj season last yearArab News and the Saudi Gazette explained that resorting to this technology would alert the authorities to the whereabouts of the pilgrims by tracking their work and personal use on their mobile phones, making it easier for them to organize and coordinate between themAnd on October 25, 2012, during the Hajj season, a huge stampede killed 3654 pilgrims, according to data from the Local Statistics Centre. The latter was distressed by the difficulty it found in identifying the victims, but we hope that these problems will abate after implementing these smart electronic devices	 	</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36007</offset><text>The result was a total number of 549 falsified articles (labeled ‘fake’), with the same number of original legitimate news articles (see Table 1 for an example). By adding classifier labels ‘real’ and ‘false’ to the articles in the corresponding sets, we were then able to merge both datasets. It is important to note here that due to the privacy of the participants, we did not publish the dataset.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>36419</offset><text>Pre-processing</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36434</offset><text>Tokenization: breaking a flow of text into fragments (words, symbols, phrases, etc.) called tokens.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36534</offset><text>Removing diacritical marks.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36562</offset><text>Removing non-Arabic characters, including English characters, website links, and symbols that do not correspond to punctuations.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36691</offset><text>Cleaning the data in preparation for the textual analysis included the following steps:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36779</offset><text>We made the decision not to apply normalization and stemming to the text in an effort to preserve each author’s stylistic writing as much as possible. Stemming would have produced words unrelated to the feature category, thus causing word ambiguity.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>37031</offset><text>Tagging the Textual Features</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>37060</offset><text>With a dataset in place, cleaned and ready for processing, the next step involved tagging the text in such a way that the algorithm could lump distinguishing features together higher than at the word level. The methodological discussion above indicated that many deceptive writers wind up using morphological features in predictably different ways than informative writers. Extracting these morphological features involves two different steps.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>37504</offset><text>The first step was to apply traditional POS tags following the traditional Stanford CoreNLP POS tagger conventions. The second step involved nuancing these tags further with some morpho-semantic categories that have proven useful in previous machine deception detection efforts.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>37783</offset><text>Part of Speech Tags</text></passage><passage><infon key="file">13369_2021_6449_Fig3_HTML.jpg</infon><infon key="id">Fig3</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>37803</offset><text>Example of Arabic POS tagged text file</text></passage><passage><infon key="file">13369_2021_6449_Fig4_HTML.jpg</infon><infon key="id">Fig4</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>37842</offset><text>POS count summary output</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>37867</offset><text>Using Posit, affixed with the Stanford CoreNLP Arabic Part-of-Speech Tagger, we added POS tags to each word. This process generated a POS tagged text file for all 1098 input files (see Fig. 3). After applying these tags, Posit displayed a set of frequencies that covered total instances (tokens) and unique instances (types). Posit displays this set of frequencies broken out across ten parts of speech (see Fig. 4), while also displaying seven aggregate statistics, including: the totals for the tokens, types, sentences and characters; the average length of sentences and words; and the ratio of types to tokens. In an effort to avoid the overfitting problem, we limited the analysis to those specific parts of speech that previous studies found useful in deception detection: nouns, verbs, prepositions, determiners, interjections, adverbs, adjectives; including some more refined subsets: articles, coordinating conjunctions, proper nouns, and cardinal numbers.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>38835</offset><text>Syntactic–Semantic Role Tags</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>38866</offset><text>In order for our NLP tool to cast as wide a net as possible, we did not restrict the analysis to only those stylistic features that other deception detection studies used, though we certainly included those.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>39074</offset><text>There were certain morpho-syntactic features that, although they represent standard morpho-syntactic categories, were too fine-grained to be captured by the Stanford CoreNLP POS tags. These features included: negatives [NEG]; relative pronouns [REL]; personal pronouns [PRP]; and superlative adjectives [JJS]. For the analysis, we lumped these more fine-grained POS elements with the following wordlists in the analysis, because our POS tagger did not allow us to separate these tags from their broader POS categories. In addition to these more fine-grained categories, there was another group of function words, which operate at a higher syntactic level that are captured more by their semantic role than by their morpho-syntax. These included: assurance adverbs; intensifiers (quantifiers and adverbs); modals (hedging); causal and purpose clause markers (persuading by showing cause or justification); temporal adverbs and clause markers; spatial clause markers; appositional markers (illustration); exceptive clause markers; and concessive or restrictive clause markers.</text></passage><passage><infon key="file">Tab2.xml</infon><infon key="id">Tab2</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>40149</offset><text>Sample of syntactic–semantic role categories with constituents</text></passage><passage><infon key="file">Tab2.xml</infon><infon key="id">Tab2</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Lexical wordlist&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Meaning&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Words example (translated in English)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Assurance&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Transitions used to indicate ensuring in events&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;&lt;p&gt;
&lt;inline-graphic xlink:href=&quot;13369_2021_6449_Figf_HTML.gif&quot; id=&quot;d32e954&quot;/&gt;&lt;/p&gt;&lt;p&gt;A’an – a’in – nafs&lt;/p&gt;&lt;p&gt;For sure, surely, certainly&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Hedges&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Soften/hesitation/uncertainty&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;&lt;p&gt;
&lt;inline-graphic xlink:href=&quot;13369_2021_6449_Figg_HTML.gif&quot; id=&quot;d32e970&quot;/&gt;&lt;/p&gt;&lt;p&gt;Ehtimal- yaji’b- min almomkin&lt;/p&gt;&lt;p&gt;Maybe/ should/ could/ may&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Persuasion&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Show cause/justification&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;&lt;p&gt;
&lt;inline-graphic xlink:href=&quot;13369_2021_6449_Figh_HTML.gif&quot; id=&quot;d32e986&quot;/&gt;&lt;/p&gt;&lt;p&gt;Bisabb- lithalik-min ajel&lt;/p&gt;&lt;p&gt;Because/ to/ for that&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>40214</offset><text>Lexical wordlist	Meaning	Words example (translated in English)	 	Assurance	Transitions used to indicate ensuring in events	A’an – a’in – nafsFor sure, surely, certainly	 	Hedges	Soften/hesitation/uncertainty	Ehtimal- yaji’b- min almomkinMaybe/ should/ could/ may	 	Persuasion	Show cause/justification	Bisabb- lithalik-min ajelBecause/ to/ for that	 	</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>40575</offset><text>One of the problems in working with a low-resource language like Arabic is the need to build even the most basic of tools that are readily available in high-resource languages. Along that vein, there is a dearth of Arabic lexicons designed for NLP. This required us to build Arabic wordlists that corresponded to these distinct grammatical functions. Most words in these wordlists were concrete words with the exception of three prefixes/suffixes. Using a range of reliable, well-known Arabic lexical resources, we collected all of the words/prefixes/suffixes corresponding to each grammatical function we identified (see Table 2 for examples).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>41220</offset><text>To reduce the likelihood of errors, three Arabic academics revised the wordlists for each linguistic category. Using their domain knowledge these individuals labelled each word in the initial draft wordlists as ‘approve’ or ‘not approve’ in reference to whether it fit the role specified by that linguistic category. The final lists were based on voting, where words remained in the list if a minimum of two academics agreed they belonged in the defined linguistic category. Finally, the inter-annotator agreement was measured as Fleiss’ Kappa is 0.842. This score indicates a moderate to a substantial level of agreement beyond chance alone. The result was a set of 14 wordlists, each corresponding to a specific linguistic function. These wordlists can now benefit future research related to Arabic textual analysis.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>42049</offset><text>Emotional Expressivity Tags</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>42077</offset><text>Emotional expressivity refers to the level of emotion displayed within a given text, which was noted above (Sect. 2.1.2.1) as a possible avenue for ‘leakage.’ Identifying and tagging the lexical items that fall into the six basic human emotions anger (), disgust (اشمئزاز), fear (), sadness (), joy (فرح), and surprise () provide a means to capture this component. In order to generate these tags, we used manually translated WordNet-Affect (WNA) emotion lexicon from English into Arabic.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>42581</offset><text>Contextual Polarity Tags</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>42606</offset><text>The alternative possibility was that deceptive text is not simply marked by more emotional language in general, but by specifically more negative emotional language. Therefore, we added a set of contextual polarity tags using a predefined lexicon, which labeled the data as ‘positive,’ ‘negative,’ or ‘neutral.’ This predefined lexicon was the Multi-Perspective Question Answering (MPQA) subjectivity lexicon, which contains more than 8000 English words, which Elarnaoty, Abdelrahman and Fahmy translated into Arabic.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>43136</offset><text>Proposed Arabic Natural Language Processing Tool (ANLP) Architecture</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43205</offset><text>Option 1: Performs exact string matching supporting the Arabic text by matching the string from right to left.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43316</offset><text>Option 2: Displays the total number of matched occurrences for all the words in the wordlist.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43410</offset><text>Option 3: Displays the number of word occurrence and their designation files.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43488</offset><text>Option 4: Performs stemming for multiple text files at once.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43549</offset><text>Option 5: Performs normalization for multiple text files at once.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43615</offset><text>Option 6: Performs Arabic prefix/suffix matching under specific taggers (nouns/verbs) at the user’s choice.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43725</offset><text>Option 7: Enables the user to input any wordlists with an unlimited number of words.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43810</offset><text>Option 8: Enables emotion words, lexical words, and polarity words tagging for each given text file.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>43911</offset><text>After preparing the emotional expressivity lexicon, the syntactic–semantic role wordlists, and the contextual polarity lexicon, we followed a principal quantitative text analysis methodology, called word count. As stated earlier, due to the scarcity of Arabic NLP tools, we did not find a suitable tool to serve our work. So, at the time of writing, the most competent method to acquire word count was to create a tool that enables Arabic word matching in a text document. In our work, we developed a prototype tool using Python programming language that includes the following options:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>44500</offset><text>Our tool followed a word matching method for extracting the target words of the wordlist. It searches each given word in the wordlist through the entire folder supplied with the given text files and outputs the number of occurrences of each word matched in the document and its source file name. One of the significant contributions of our tool is Option 6. As several Arabic prefixes/suffixes have the same grammatical role as some concrete words, it would be difficult to extract them when attached to words. Moreover, since ANLP performs exact word matching which mandates the words to be concrete, we added this feature to investigate prefixes/suffixes that have the same grammatical role as the concrete words but cannot be matched by word matching since they are not concrete, but they are linked to the word.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>45316</offset><text>To overcome this, we made use of the tagged text produced by Posit to decrease the search domain. When searching for prefixes/suffixes, we rely on Arabic grammar and use the tagged text files produced from Posit. For example, to search the prefix (ل/L), which implies persuasive intent when added to a verb, such as ‘to eat / li ya’akul (),’ we searched in the verb tagged text only. With that, we reduced the search size from more than 50,000 tagged words with different POS tags to 3000 specifically verb tagged words. This enables us to search for the prefix in a tighter domain and less time.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>45920</offset><text>Unfortunately, the homographic issue was not solved by ANLP tool. To overcome the problem of homographs, we manually checked the results of each word incoming from ANLP to ensure that it fits the right textual category.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>46140</offset><text>We used this prototype tool program to extract the textual features, whether they be POS, morpho-semantic, emotional expressivity or emotional sentiment polarity.</text></passage><passage><infon key="file">13369_2021_6449_Fig5_HTML.jpg</infon><infon key="id">Fig5</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>46303</offset><text>Example of tagged text file</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>46331</offset><text>Figure 5 shows an example of a text with the polarity and lexical words tagged, with the summary of the taggers below.</text></passage><passage><infon key="file">13369_2021_6449_Fig6_HTML.jpg</infon><infon key="id">Fig6</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>46451</offset><text>Set of textual features</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>46475</offset><text>In total, we extracted four textual features from all 549 real and 549 fake Arabic articles in the dataset (Fig. 6).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>46593</offset><text>Results and Discussion</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>46616</offset><text>Although we did not propose a new classification method in this study, we use the collected features to provide more accurate Arabic classifiers. In this section, we will discuss the lexical densities in the dataset for each textual feature. Then, we display our model’s prediction performance against each feature category individually and combined. Finally, we tested the prediction rate of our model against human performance.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>47048</offset><text>Dataset</text></passage><passage><infon key="file">Tab3.xml</infon><infon key="id">Tab3</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>47056</offset><text>Lexical density of each feature category</text></passage><passage><infon key="file">Tab3.xml</infon><infon key="id">Tab3</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Feature category&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Feature&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Fake articles (L%)&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Real articles (L%)&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;6&quot;&gt;Emotional expressiveness (E)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Anger&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.67&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.48&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Sad&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.268&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.25&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Fear&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.232&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.21&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Joy&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;1.08&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;1.40&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;disgust&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.056&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.03&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Surprise&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.175&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; colspan=&quot;2&quot;&gt;Totals&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;2.481&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;2.53&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;13&quot;&gt;Syntactic–semantic roles (R)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Assurance&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.734&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.43&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Negations&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.49&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.35&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Illustration&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.06&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.04&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Relative Pronouns&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.794&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.85&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Intensifiers&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.21&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.12&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Hedges&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.533&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.39&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Causation&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;1.596&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;1.20&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Temporal&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.853&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.65&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Spatial&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.514&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.50&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Exclusive&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.133&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.14&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Personal pronouns&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.077&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.05&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Superlative&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.364&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.45&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Contradiction&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.49&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.08&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; colspan=&quot;2&quot;&gt;Totals&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;6.848&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;5.25&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;10&quot;&gt;POS (S)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Noun&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;41.40&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;44.16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Verb&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;9.49&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;9.30&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Preposition&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;7.61&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;7.37&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Determiner&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.97&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.72&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Particle&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.45&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.34&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Interjection&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.01&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Adverb&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.90&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.68&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Adjective&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;10.70&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;11.12&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Coordinating conjunction&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;6.37&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;4.60&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Proper noun&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;9.64&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;10.59&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; colspan=&quot;2&quot;&gt;Totals&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;87.75&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;88.88&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;2&quot;&gt;Contextual polarity (P)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;Negative&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.20&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.16&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Positive&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.36&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.31&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; colspan=&quot;2&quot;&gt;Totals&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.56&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.47&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Total features&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;31&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;/&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;/&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>47097</offset><text>Feature category	Feature	Fake articles (L%)	Real articles (L%)	 	Emotional expressiveness (E)	Anger	0.67	0.48	 	Sad	0.268	0.25	 	Fear	0.232	0.21	 	Joy	1.08	1.40	 	disgust	0.056	0.03	 	Surprise	0.175	0.16	 	Totals	2.481	2.53	 	Syntactic–semantic roles (R)	Assurance	0.734	0.43	 	Negations	0.49	0.35	 	Illustration	0.06	0.04	 	Relative Pronouns	0.794	0.85	 	Intensifiers	0.21	0.12	 	Hedges	0.533	0.39	 	Causation	1.596	1.20	 	Temporal	0.853	0.65	 	Spatial	0.514	0.50	 	Exclusive	0.133	0.14	 	Personal pronouns	0.077	0.05	 	Superlative	0.364	0.45	 	Contradiction	0.49	0.08	 	Totals	6.848	5.25	 	POS (S)	Noun	41.40	44.16	 	Verb	9.49	9.30	 	Preposition	7.61	7.37	 	Determiner	0.97	0.72	 	Particle	0.45	0.34	 	Interjection	0.01	0.00	 	Adverb	0.90	0.68	 	Adjective	10.70	11.12	 	Coordinating conjunction	6.37	4.60	 	Proper noun	9.64	10.59	 	Totals	87.75	88.88	 	Contextual polarity (P)	Negative	0.20	0.16	 	Positive	0.36	0.31	 	Totals	0.56	0.47	 	Total features	31			 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>48062</offset><text>Our dataset includes 1098 records with 549 records classified as ‘false’ and 549 records classified as ‘real’ articles. The dataset distribution is shown in Table 3 using lexical densities concept. Lexical densities are the total number of lexical words divided by the total number of words. We calculated the average lexical density for each textual feature category with all the datasets in our work. We found that the number of verbs appeared more in fake news than in real news. This supports the findings of Rayson et al., cited in Sect. 2.1.2.2 regarding imaginative text compared to informative text and one of the studies conducted by Zhou et al. on deception detection, but not all of them.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>48771</offset><text>Analysis of Lexical Density of Each Textual Category</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>48824</offset><text>Overall, as previously demonstrated, fake articles contained lower emotional words compared to real ones. So, it can be said that the participants made an effort to avoid over-wording the fake articles with emotional words in an attempt to make them appear real. Furthermore, additional analysis has revealed that negative emotions, including sadness, fear, and anger, increased in the fake articles. The negative polarity found therein supports this insight: it is clear that the negative words increased in that category compared to the real articles. Having said this, positive words also increased in fake articles. So, this may lend credence to Li et al.’s idea that deceivers often tone down their articles in order to conceal their real aims. This is achieved via increasing positive/negative words in existing positive/negative articles. What is more, we found that causations, negations, assurance, intensifiers, hedges, and contradictions were frequently used in fake articles. After all, the participants aimed to make their articles ‘genuine’ by using the aforementioned linguistic functional terms, specifically by incorporating these terms as naturally as possible, all while avoiding exaggeration, which could potentially expose the deceit. On the one hand, in relation to POS, nouns and adjectives were frequently used in real articles compared to fake ones. This could result from the articles being about Hajj. This is a religious performance that, importantly, has a wide range of adjectives and nouns. On the other hand, associated adverbs and verbs were much more frequently used throughout the fake articles compared to the real ones. This finding supports Newman et al.’s belief that liars, as opposed to those speaking the truth, often use more verbs in order to provide concrete yet simple descriptions of their false statements.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>50687</offset><text>Training of Deception Detection</text></passage><passage><infon key="file">Tab4.xml</infon><infon key="id">Tab4</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>50719</offset><text>Classifier performance</text></passage><passage><infon key="file">Tab4.xml</infon><infon key="id">Tab4</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;left&quot;&gt;Classifier&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Feature&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;AUC&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;F1&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Precision&lt;/th&gt;&lt;th align=&quot;left&quot;&gt;Recall&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;Random (baseline)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;–&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.50&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.50&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.50&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;0.50&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;14&quot;&gt;Naïve Bayes (NB)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;E&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;71.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;65.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;65.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;65.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;65.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;60.1&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;60.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;71.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;65.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;66.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;66.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;69.5&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;72.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;69.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;63.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;63.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;72.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.6&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;72.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;55.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;54.5&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;54.5&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;54.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;64.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;14&quot;&gt;Random forest (RF)&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;E&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;59.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;59.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;74.1&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;66.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;75.5&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;72.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;65.1&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;65.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;65.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;84.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;78.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;78.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;78.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;74.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;73.5&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.5&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;74.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;69.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;68.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;85.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;78.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;78.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;78.6&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;85.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;&lt;bold&gt;79.0&lt;/bold&gt;&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;79.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;79.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;52.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;54.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;54.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;54.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;66.5&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.6&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;59.1&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; rowspan=&quot;14&quot;&gt;Support vector machine&lt;/td&gt;&lt;td align=&quot;left&quot;&gt;E&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;49.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;47.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;51.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;51.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;48.1&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;50.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;50.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;52.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;51.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;50.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.1&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;57.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;56.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;56.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;56.5&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + R + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;63.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;E + P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;59.6&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;56.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;57.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;57.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;41.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;57.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;49.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;59.1&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;58.9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;66.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;60.9&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;R + P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;67.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;61.7&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.5&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;62.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;P&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;51.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;47.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;47.4&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;47.4&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;P + S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;57.0&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;56.1&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;56.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;56.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;left&quot;&gt;S&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;53.2&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;55.3&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;55.8&lt;/td&gt;&lt;td char=&quot;.&quot; align=&quot;char&quot;&gt;55.6&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>50742</offset><text>Classifier	Feature	AUC	F1	Precision	Recall	 	Random (baseline)	–	0.50	0.50	0.50	0.50	 	Naïve Bayes (NB)	E	64.7	61.9	62.2	62.0	 	E + R	71.2	65.4	65.9	65.5	 	E + P	65.7	60.1	61.0	60.5	 	E + R + P	71.6	65.9	66.4	66.1	 	E + S	69.5	64.4	64.4	64.4	 	E + R + S	72.2	67.0	67.2	67.1	 	E + P + S	69.7	64.9	64.9	64.9	 	R	68.4	62.9	63.4	63.1	 	R + P	68.8	62.6	62.9	62.7	 	R + S	72.0	67.6	67.7	67.6	 	R + P + S	72.2	67.3	67.4	67.4	 	P	55.2	54.5	54.5	54.5	 	P + S	67.7	64.0	64.0	64.0	 	S	67.3	64.2	64.2	64.2	 	Random forest (RF)	E	61.3	58.9	59.7	59.3	 	E + R	74.1	67.8	67.8	67.8	 	E + P	66.3	61.9	61.9	61.9	 	E + R + P	75.5	68.7	68.7	68.7	 	E + S	72.0	65.1	65.3	65.2	 	E + R + S	84.3	78.2	78.2	78.2	 	E + P + S	74.8	68.2	68.4	68.3	 	R	73.5	68.4	68.5	68.4	 	R + P	74.0	68.9	69.0	68.9	 	R + S	85.0	78.6	78.6	78.6	 	R + P + S	85.3	79.0	79.0	79.0	 	P	52.6	54.6	54.8	54.8	 	P + S	66.5	62.3	62.8	62.6	 	S	62.9	58.7	59.1	58.9	 	Support vector machine	E	49.6	47.9	51.4	51.0	 	E + R	48.1	58.7	58.8	58.7	 	E + P	50.0	50.8	52.0	51.8	 	E + R + P	50.8	58.1	58.2	58.1	 	E + S	57.4	56.0	56.9	56.5	 	E + R + S	67.7	62.7	63.3	62.9	 	E + P + S	59.6	56.9	57.4	57.2	 	R	41.3	57.8	58.2	58.0	 	R + P	49.4	58.8	59.1	58.9	 	R + S	66.7	60.9	61.4	61.1	 	R + P + S	67.2	61.7	62.5	62.0	 	P	51.4	47.4	47.4	47.4	 	P + S	57.0	56.1	56.3	56.2	 	S	53.2	55.3	55.8	55.6	 	</text></passage><passage><infon key="file">Tab4.xml</infon><infon key="id">Tab4</infon><infon key="section_type">TABLE</infon><infon key="type">table_foot</infon><offset>52236</offset><text>E = Emotional expressivity, R = syntactic–semantic roles, P = contextual polarity S = part of speech</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>52355</offset><text>Our research applied NB, RF, and SVM classifiers. The selection of these machine learning algorithms is due to their performance identifying fake news in similar models (NB, RF, SVM), and are considered adequate in many classification applications. NB classification technique is based on Bayes’ Theorem with an assumption of independence among deception features, which holds for our 31 features. RF is an ensemble learning method for classification method based on training a multitude of decision trees and providing the predictor based on the classes’ mode or mean prediction of the individual trees. SVM is a set of algorithms that analyses data for classification and regression analysis and is commonly used in machine binary machine learning. All methods were compared to a baseline (random), where an article is assigned a class randomly (Table 4).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>53217</offset><text>We used the Scikit-learn library in our experiment. To validate our results, we applied 70% training 30% testing validation. For feature selection, we used the information gain method. Since the data size was small, we ran our experiment on a standard computer with 1 TB and 7 io dual core processor. We report Area Under Curve (AUC), Precision, Recall, and F1 measures.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>53589</offset><text>The contribution of the syntactic–semantic roles seems to have been the most productive for our model. F1 measure was 68.4%, 73.5%, 41.3% for NB, RF, SVM, respectively. The performance of RF was higher by approximately 15% than NB and by 22% from SVM. RF built balanced random trees from the 31 linguistic features, where all of them were equally distributed between the dataset, except for causation 1.6%. Similar results could be deduced for Emotional Expressiveness where F1 measure was 61.9%, 58.9%, 47.9% for NB, RF, SVM, respectively; however, since the densities were not high, NB was performing slightly better than the RF algorithm. P did not provide any valuable contribution compared to the baseline, which was 54.5%, 54.6%, 47.4% for NB, RF, SVM.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>54350</offset><text>Therefore, combining S and R increased the accuracy of the classifiers 67.6%, 78.6%, 60.9%, which are NB, RF, SVM. RF was able to build ensemble decision trees based on two different categories of features yielding the highest performance with an increase of approximately 10.2% compared to S alone and by 16.7% compared to R alone. The best performance was achieved by combining 25 features of R, P, and S. We note that the combined features of E, R, and P resulted in 67.0%, 68.7%, and 62.7% for NB, RF, and SVM. Also, combining all the investigated 31 features yielded F1 measure for RF accuracy of 78%.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>54957</offset><text>The dominant features for deception detection were the linguistic features, which yields the best performance (79%) compared to all other features. This is compatible with the Pérez-Rosas, et al. study where the psycholinguistics feature category was the most dominant in detecting fake news.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>55251</offset><text>Our findings show that the model’s best prediction accuracy involved combining the textual features: R, P, and S. Though 79% marks a high level of accuracy, there is room for improvement. We also found that our finding is consistent with Pennebaker and King that only words, conjunctions, and prepositions are associated with cognitive complexity, and the few bias markers, hedges, and subjective terms have been found useful. Also, the results are consistent with peculiar POS lexical markers. Our findings support the study that deceivers portrayed a more significant expressivity based on nouns and adjectives consistent with Zhou. Overall combining significant deceptive features enhances the classifiers.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>55963</offset><text>External Validation Using Human Performance</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>56007</offset><text>To measure the relative value of using an automated deception detection classifier for news articles, we compared it to unaided human judgment. For this test, we decided to focus on satirical news articles. One reason for this was that satirical news relies on distorting legitimate news making a one-to-one balance of fake news to real news straightforward for collecting the dataset.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>56393</offset><text>An objection may be made that satire is different in kind than more nefarious fake news and that deceptive intent and the accompanying psychological states are not present. While this is true, the reason so much study has been devoted to training automated detection classifiers to differentiate between satirical news and fake news is because the two are so similar. Therefore, we expect our classifier to perform similarly in this test. Moreover, satire most often relies on the reader’s knowledge of the satirical nature of the source. In social media, where articles are forwarded without the context of the website itself, accurate human judgment is required for it not to be harmful. Presumably, satirical news would be the one subset of fake news where human performance should be the best, thus raising the stakes for the accuracy of our classifier.</text></passage><passage><infon key="file">13369_2021_6449_Fig7_HTML.jpg</infon><infon key="id">Fig7</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>57253</offset><text>Classifier versus human performance</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>57289</offset><text>First, we collected fifty news articles from Arabic fake satire news website targeted at political issues.6 Then, we matched each false article with legitimate article from popular Arabic news agencies.7 In total, we had fifty fake articles, and corresponding to them were fifty real articles. We tried as much as possible to balance our dataset by matching each fake article with a real article that has the same length and details the same event or character in the fake article. The articles were distributed manually to 28 participants from our local university, with our work background. We asked them to label each article as real or fake based on their judgment. The same dataset was uploaded to the model, and the performance of our model was evaluated compared to human performance. Since we had narrowed down the best performance of our model to the RF model with 31 features, this was the model used in the test. The results showed that our RF model outperformed humans. Our model classified 86% of the articles correctly, while 23 humans classified 78% correctly and the rest of 6 classified less than that correctly. This highlights the fact that humans continue to struggle with deception detection and that automated computational linguistic aids like this can prove valuable in aiding humans in this task (Fig. 7).</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>58620</offset><text>Conclusion and Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>58646</offset><text>In this work, we have addressed the detection of Arabic fake news based on textual analysis. Our proposed model achieved more than 75% accuracy in predicting the veracity of Arabic news articles. To achieve this, we firstly collected real news articles from reliable news sources. Secondly, to imitate the fake news production in the real world, real news articles were manipulated into fake articles using crowdsourcing. Third, four textual features categories were extracted using an Arabic natural language processing tool designed by the researchers. Arabic linguistic wordlists were organized and professionally reviewed for use in our work and for future Arabic textual analysis projects. The textual features extracted were emotion, linguistics, polarity, and part of speech. Finally, these features were used to train our model to detect deceptive text, in our case fake news. As a result, we evaluated the model’s prediction accuracy which gave promising results, 78%. Our most intriguing finding is that linguistics features extracted were the most dominant cues used to detect deceptive text in fake news. Our model can be considered a significant step forward in detecting Arabic fake news. This is something that should be borne in mind in future studies with more textual features, when investigating new approaches to detect Arabic fake news.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>60006</offset><text>http://www.mideastmedia.org/survey/2017/chapter/social-media/#s225.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>60074</offset><text>http://norumors.net/.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>60096</offset><text>Falsoo.com.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>60108</offset><text>https://akeed.jo/ar/.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>60130</offset><text>https://fatabyyano.net/.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>60155</offset><text>www.alhudud.net.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">footnote</infon><offset>60172</offset><text>www.okaz.net, www.sabq.net, www.youm7.net.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>60215</offset><text>References</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>60226</offset><text>Radcliffe, D.; Abuhmaid, H.: Social media in the Middle East: 2019 in review. SSRN Electron. J. 2020</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>60327</offset><text>Zhou, X.; Zafarani, R.: Fake news: a survey of research, detection methods, and opportunities, 2018</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>60427</offset><text>Afroz, S.; Brennan, M.; Greenstadt, R.: Detecting hoaxes, frauds, and deception in writing style online. In: Proceedings of the IEEE Symposium on Security and Privacy, pp. 461–475, 2012</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>60615</offset><text>Ireton, C.; Posetti, J.: Journalism. ‘FAKE NEWS’ &amp; Handbook for Journalism Education and Training, 2018</text></passage><passage><infon key="name_0">surname:Collins;given-names:B</infon><infon key="name_1">surname:Hoang;given-names:DT</infon><infon key="name_2">surname:Nguyen;given-names:NT</infon><infon key="name_3">surname:Hwang;given-names:D</infon><infon key="section_type">REF</infon><infon key="source">Fake News Types and Detection Models on Social Media A State-of-the-Art Survey, CCIS</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>60723</offset></passage><passage><infon key="fpage">1</infon><infon key="issue">4</infon><infon key="lpage">22</infon><infon key="name_0">surname:Farghaly;given-names:A</infon><infon key="name_1">surname:Shaalan;given-names:K</infon><infon key="pub-id_doi">10.1145/1644879.1644881</infon><infon key="section_type">REF</infon><infon key="source">ACM Trans. Asian Lang. Inf. Process.</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2009</infon><offset>60724</offset><text>Arabic natural language processing: challenges and solutions</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>60785</offset><text>Pérez-Rosas, V.; Kleinberg, B.; Lefevre, A.; Mihalcea, R.: Automatic detection of fake news, 2017</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>60884</offset><text>Weir, G.R.S.: The posit text profiling toolset. In: Proceedings of the 12th Conference on Association of Applied Linguistics, 2007</text></passage><passage><infon key="fpage">1</infon><infon key="issue">4</infon><infon key="lpage">21</infon><infon key="name_0">surname:Rosso;given-names:P</infon><infon key="name_1">surname:Rangel;given-names:F</infon><infon key="name_2">surname:Farías;given-names:IH</infon><infon key="name_3">surname:Cagnina;given-names:L</infon><infon key="name_4">surname:Zaghouani;given-names:W</infon><infon key="name_5">surname:Charfi;given-names:A</infon><infon key="pub-id_doi">10.1111/lnc3.12275</infon><infon key="section_type">REF</infon><infon key="source">Lang. Linguist. Compass</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2018</infon><offset>61015</offset><text>A survey on author profiling, deception, and irony detection for the Arabic language</text></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">4</infon><infon key="name_0">surname:Rubin;given-names:VL</infon><infon key="name_1">surname:Chen;given-names:Y</infon><infon key="name_2">surname:Conroy;given-names:NK</infon><infon key="pub-id_doi">10.1002/pra2.2015.145052010083</infon><infon key="section_type">REF</infon><infon key="source">Proc. Assoc. Inf. Sci. Technol.</infon><infon key="type">ref</infon><infon key="volume">52</infon><infon key="year">2015</infon><offset>61100</offset><text>Deception detection for news: three types of fakes</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>61151</offset><text>Lahlou, Y.; El Fkihi, S.; Faizi, R.: Automatic detection of fake news on online platforms: a survey. In: ICSSD 2019—International Conference on Smart Systems and Data science, pp. 0–3, 2019</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">15</infon><infon key="name_0">surname:Levine;given-names:TR</infon><infon key="section_type">REF</infon><infon key="source">J. Lang. Soc. Psychol.</infon><infon key="type">ref</infon><infon key="volume">33</infon><infon key="year">2014</infon><offset>61345</offset><text>Truth-detection theory (TDT): a theory of human deception and deception detection</text></passage><passage><infon key="fpage">139</infon><infon key="lpage">179</infon><infon key="name_0">surname:Talwar;given-names:V</infon><infon key="name_1">surname:Crossman;given-names:A</infon><infon key="pub-id_doi">10.1016/B978-0-12-386491-8.00004-9</infon><infon key="pub-id_pmid">21887961</infon><infon key="section_type">REF</infon><infon key="source">Adv. Child Dev. Behav.</infon><infon key="type">ref</infon><infon key="volume">40</infon><infon key="year">2011</infon><offset>61427</offset><text>From little white lies to filthy liars: the evolution of honesty and deception in young children</text></passage><passage><infon key="fpage">28</infon><infon key="issue">2</infon><infon key="lpage">34</infon><infon key="name_0">surname:Demestichas;given-names:K</infon><infon key="name_1">surname:Remoundou;given-names:K</infon><infon key="name_2">surname:Adamopoulou;given-names:E</infon><infon key="pub-id_doi">10.1109/MITP.2020.2978043</infon><infon key="section_type">REF</infon><infon key="source">IT Prof.</infon><infon key="type">ref</infon><infon key="volume">22</infon><infon key="year">2020</infon><offset>61524</offset><text>Food for thought: fighting fake news and online disinformation</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>61587</offset><text>Mihalcea, R.; Strapparava, C.: The lie detector: explorations in the automatic recognition of deceptive language. In: ACL-IJCNLP 2009—Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics, 4th International Joint Conference on Natural Language Processing. AFNLP, Proceedings Conference, pp. 309–312, 2009</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>61935</offset><text>Burgoon, J.K.; Blair, J.P.; Qin, T.; Nunamaker, J.F.: Detecting deception through linguistic analysis. In Intelligence and Security Informatics: 1st NSF/NIJ Symposium, ISI 2003 Tucson, AZ, USA, June 2003, Proceedings, pp. 91–101. Springer, Berlin, 2003</text></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">23</infon><infon key="name_0">surname:Hancock;given-names:JT</infon><infon key="name_1">surname:Curry;given-names:LE</infon><infon key="name_2">surname:Goorha;given-names:S</infon><infon key="name_3">surname:Woodworth;given-names:M</infon><infon key="pub-id_doi">10.1080/01638530701739181</infon><infon key="section_type">REF</infon><infon key="source">Discourse Process.</infon><infon key="type">ref</infon><infon key="volume">45</infon><infon key="year">2008</infon><offset>62190</offset><text>On lying and being lied to: a linguistic analysis of deception in computer-mediated communication</text></passage><passage><infon key="fpage">665</infon><infon key="issue">5</infon><infon key="lpage">675</infon><infon key="name_0">surname:Newman;given-names:ML</infon><infon key="name_1">surname:Pennebaker;given-names:JW</infon><infon key="name_2">surname:Berry;given-names:DS</infon><infon key="name_3">surname:Richards;given-names:JM</infon><infon key="pub-id_doi">10.1177/0146167203029005010</infon><infon key="section_type">REF</infon><infon key="source">Personal. Soc. Psychol. Bull.</infon><infon key="type">ref</infon><infon key="volume">29</infon><infon key="year">2003</infon><offset>62288</offset><text>Lying words: predicting deception from linguistic styles</text></passage><passage><infon key="fpage">1</infon><infon key="issue">1</infon><infon key="lpage">14</infon><infon key="name_0">surname:Torabi Asr;given-names:F</infon><infon key="name_1">surname:Taboada;given-names:M</infon><infon key="pub-id_doi">10.1177/2053951719843310</infon><infon key="section_type">REF</infon><infon key="source">Big Data Soc</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2019</infon><offset>62345</offset><text>Big data and quality data for fake news and misinformation detection</text></passage><passage><infon key="fpage">64</infon><infon key="lpage">71</infon><infon key="name_0">surname:Berenzenko;given-names:VM</infon><infon key="section_type">REF</infon><infon key="source">Nauk. visnyk Kafedr. UNESCO KNLU</infon><infon key="type">ref</infon><infon key="volume">36</infon><infon key="year">2018</infon><offset>62414</offset><text>Verbal and nonverbal cues to deception in modern English discourse</text></passage><passage><infon key="fpage">295</infon><infon key="lpage">306</infon><infon key="name_0">surname:Rayson;given-names:P</infon><infon key="name_1">surname:Wilson;given-names:A</infon><infon key="name_2">surname:Leech;given-names:G</infon><infon key="name_3">surname:Peters;given-names:P</infon><infon key="name_4">surname:Collins;given-names:P</infon><infon key="name_5">surname:Smith;given-names:A</infon><infon key="section_type">REF</infon><infon key="source">New Frontiers of Corpus Research</infon><infon key="type">ref</infon><infon key="year">2002</infon><offset>62481</offset><text>Grammatical word class variation within the British national corpus sampler</text></passage><passage><infon key="fpage">1</infon><infon key="issue">8</infon><infon key="lpage">5</infon><infon key="name_0">surname:Markowitz;given-names:DM</infon><infon key="name_1">surname:Hancock;given-names:JT</infon><infon key="pub-id_doi">10.1371/journal.pone.0105937</infon><infon key="section_type">REF</infon><infon key="source">PLoS ONE</infon><infon key="type">ref</infon><infon key="volume">9</infon><infon key="year">2014</infon><offset>62557</offset><text>Linguistic traces of a scientific fraud: the case of diederik stapel</text></passage><passage><infon key="fpage">1296</infon><infon key="issue">6</infon><infon key="lpage">1312</infon><infon key="name_0">surname:Pennebaker;given-names:JW</infon><infon key="name_1">surname:King;given-names:LA</infon><infon key="pub-id_doi">10.1037/0022-3514.77.6.1296</infon><infon key="pub-id_pmid">10626371</infon><infon key="section_type">REF</infon><infon key="source">J. Pers. Soc. Psychol.</infon><infon key="type">ref</infon><infon key="volume">77</infon><infon key="year">1999</infon><offset>62626</offset><text>Linguistic styles: language use as an individual difference</text></passage><passage><infon key="fpage">547</infon><infon key="issue">1</infon><infon key="lpage">577</infon><infon key="name_0">surname:Pennebaker;given-names:JW</infon><infon key="name_1">surname:Mehl;given-names:MR</infon><infon key="name_2">surname:Niederhoffer;given-names:KG</infon><infon key="pub-id_doi">10.1146/annurev.psych.54.101601.145041</infon><infon key="pub-id_pmid">12185209</infon><infon key="section_type">REF</infon><infon key="source">Annu. Rev. Psychol.</infon><infon key="type">ref</infon><infon key="volume">54</infon><infon key="year">2003</infon><offset>62686</offset><text>Psychological aspects of natural language use: our words, our selves</text></passage><passage><infon key="fpage">292</infon><infon key="lpage">302</infon><infon key="name_0">surname:Alkhair;given-names:M</infon><infon key="name_1">surname:Meftouh;given-names:K</infon><infon key="name_2">surname:Smaïli;given-names:K</infon><infon key="name_3">surname:Othman;given-names:N</infon><infon key="section_type">REF</infon><infon key="source">Commun. Comput. Inf. Sci.</infon><infon key="type">ref</infon><infon key="volume">1108</infon><infon key="year">2019</infon><offset>62755</offset><text>An Arabic corpus of fake news: collection, analysis and classification</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>62826</offset><text>Manzoor, S.I.; Singla, J.; Nikita: Fake news detection using machine learning approaches: a systematic review. In: Proceedings of the International Conference on Trends Electron. Informatics, ICOEI 2019, ICOEI, pp. 230–234, 2019</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>63057</offset><text>Knshnan, S.; Chen, M.: Identifying tweets with fake news. In: Proceedings—2018 IEEE 19th International Conference on Information Reuse and Integration for Data Science. IRI 2018, vol. 67, pp. 460–464, 2018</text></passage><passage><infon key="name_0">surname:Attia;given-names:M</infon><infon key="section_type">REF</infon><infon key="source">Handling Arabic Morphological and Syntactic Ambiguity Within the LFG Framework with a View to Machine Translation</infon><infon key="type">ref</infon><infon key="year">2008</infon><offset>63267</offset></passage><passage><infon key="fpage">38</infon><infon key="lpage">55</infon><infon key="name_0">surname:Bondielli;given-names:A</infon><infon key="name_1">surname:Marcelloni;given-names:F</infon><infon key="pub-id_doi">10.1016/j.ins.2019.05.035</infon><infon key="section_type">REF</infon><infon key="source">Inf. Sci.</infon><infon key="type">ref</infon><infon key="volume">497</infon><infon key="year">2019</infon><offset>63268</offset><text>A survey on fake news and rumour detection techniques</text></passage><passage><infon key="fpage">2285</infon><infon key="lpage">2293</infon><infon key="name_0">surname:Kapusta;given-names:J</infon><infon key="name_1">surname:Hájek;given-names:P</infon><infon key="name_2">surname:Munk;given-names:M</infon><infon key="name_3">surname:Benko;given-names:Ľ</infon><infon key="pub-id_doi">10.1016/j.procs.2020.04.247</infon><infon key="section_type">REF</infon><infon key="source">Procedia Comput. Sci.</infon><infon key="type">ref</infon><infon key="volume">171</infon><infon key="year">2020</infon><offset>63322</offset><text>Comparison of fake and real news based on morphological analysis</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>63387</offset><text>Horne, B.D.; Adali, S.: This just in: fake news packs a lot in title, uses simpler, repetitive content in text body, more similar to satire than real news, 2017</text></passage><passage><infon key="fpage">205316801878684</infon><infon key="issue">3</infon><infon key="name_0">surname:Lim;given-names:C</infon><infon key="pub-id_doi">10.1177/2053168018786848</infon><infon key="section_type">REF</infon><infon key="source">Res. Polit.</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2018</infon><offset>63548</offset><text>Checking how fact-checkers check</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>63581</offset><text>Alsudias, L.; Rayson, P.: Classifying information sources in Arabic Twitter to support online monitoring of infectious diseases. In: Proceedings of the 3rd Working in Arabic Corpus Linguistics, pp. 22–30, 2019</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>63793</offset><text>Alqurashi, S.; Hamoui, B.; Alashaikh, A.; Alhindi, A.; Alanazi, E.: Eating garlic prevents COVID-19 infection: detecting misinformation on the Arabic content of Twitter, 2021</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>63968</offset><text>Haouari, F.; Hasanain, M.; Suwaileh, R.; Elsayed, T.: ArCOV19-rumors: Arabic COVID-19 Twitter dataset for misinformation detection, 2020</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>64105</offset><text>Mubarak, H.; Hassan, S.: ArCorona: analyzing Arabic tweets in the early days of coronavirus (COVID-19) pandemic, vol. 19, 2020</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>64232</offset><text>Nagoudi, E.M.B.; Elmadany, A.R.; Abdul-Mageed, M.; Alhindi, T.; Cavusoglu, H.: Machine generation and detection of Arabic manipulated and fake news. arXiv, pp. 69–84, 2020</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>64406</offset><text>Khouja, J.: Stance prediction and claim verification: an Arabic perspective, pp. 8–17, 2020</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>64500</offset><text>Mohammad, S.M.; Salameh, M.; Kiritchenko, S.: Sentiment lexicons for Arabic social media. In: Proceedings of the 10th International Conference on Language Resources and Evaluation, LR 2016, pp. 33–37, 2016</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>64708</offset><text>Mourad, A.; Darwish, K.: Subjectivity and sentiment annotation of modern standard Arabic newswire. In: Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pp. 55–64, 2013</text></passage><passage><infon key="fpage">161</infon><infon key="lpage">168</infon><infon key="name_0">surname:Karoui;given-names:J</infon><infon key="name_1">surname:Zitoune;given-names:FB</infon><infon key="name_2">surname:Moriceau;given-names:V</infon><infon key="pub-id_doi">10.1016/j.procs.2017.10.105</infon><infon key="section_type">REF</infon><infon key="source">Procedia Comput. Sci.</infon><infon key="type">ref</infon><infon key="volume">117</infon><infon key="year">2017</infon><offset>64908</offset><text>SOUKHRIA: towards an irony detection system for Arabic in social media</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>64979</offset><text>Sheikh Ali, Z.; Mansour, W.; Elsayed, T.; Al‐Ali, A.: AraFacts: the first large arabic dataset of naturally occurring claims. In: Proceedings of the Sixth Arabic Natural Language Processing Workshop, pp. 231–236, 2021.</text></passage><passage><infon key="fpage">165201</infon><infon key="lpage">165215</infon><infon key="name_0">surname:Elhadad;given-names:MK</infon><infon key="name_1">surname:Li;given-names:KF</infon><infon key="name_2">surname:Gebali;given-names:F</infon><infon key="pub-id_doi">10.1109/ACCESS.2020.3022867</infon><infon key="pub-id_pmid">34786288</infon><infon key="section_type">REF</infon><infon key="source">IEEE Access</infon><infon key="type">ref</infon><infon key="volume">8</infon><infon key="year">2020</infon><offset>65202</offset><text>Detecting misleading information on COVID-19</text></passage><passage><infon key="fpage">104945</infon><infon key="name_0">surname:Alzanin;given-names:SM</infon><infon key="name_1">surname:Azmi;given-names:AM</infon><infon key="pub-id_doi">10.1016/j.knosys.2019.104945</infon><infon key="section_type">REF</infon><infon key="source">Knowl. Based Syst.</infon><infon key="type">ref</infon><infon key="volume">185</infon><infon key="year">2019</infon><offset>65247</offset><text>Rumor detection in Arabic tweets using semi-supervised and unsupervised expectation–maximization</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>65346</offset><text>Wang, W.Y.: ‘Liar, liar pants on fire’: a new benchmark dataset for fake news detection. In: ACL 2017—55th Annual Meeting of the Association for Computational Linguistics Proceedings Conference (Long Papers), vol. 2, pp. 422–426, 2017</text></passage><passage><infon key="fpage">266</infon><infon key="issue">2</infon><infon key="lpage">274</infon><infon key="name_0">surname:Al-Barhamtoshy;given-names:HM</infon><infon key="name_1">surname:Hemdi;given-names:HT</infon><infon key="name_2">surname:Khamis;given-names:MM</infon><infon key="name_3">surname:Himdi;given-names:TF</infon><infon key="pub-id_doi">10.21786/bbrc/12.2/10</infon><infon key="section_type">REF</infon><infon key="source">Biosci. Biotechnol. Res. Commun.</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2019</infon><offset>65589</offset><text>Semantic and sentiment analysis for Arabic texts using intelligent model</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>65662</offset><text>Rangel, F.; Rosso, P.; Charfi, A.; Zaghouani, W.: Detecting deceptive tweets in Arabic for cyber-security. In: 2019 IEEE International Conference on Intelligence and Security Informatics, ISI 2019, pp. 86–91, 2019</text></passage><passage><infon key="fpage">2327</infon><infon key="issue">8</infon><infon key="lpage">2338</infon><infon key="name_0">surname:Sabbeh;given-names:SF</infon><infon key="name_1">surname:Baatwah;given-names:SY</infon><infon key="section_type">REF</infon><infon key="source">J. Theor. Appl. Inf. Technol.</infon><infon key="type">ref</infon><infon key="volume">96</infon><infon key="year">2018</infon><offset>65878</offset><text>Arabic news credibility on Twitter: an enhanced model using hybrid features</text></passage><passage><infon key="name_0">surname:Fleiss;given-names:JL</infon><infon key="name_1">surname:Levin;given-names:B</infon><infon key="name_2">surname:Paik;given-names:MC</infon><infon key="section_type">REF</infon><infon key="source">Statistical Methods for Rates and Proportions</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>65954</offset></passage><passage><infon key="fpage">39</infon><infon key="issue">02</infon><infon key="lpage">67</infon><infon key="name_0">surname:Mustafa;given-names:M</infon><infon key="name_1">surname:Eldeen;given-names:AS</infon><infon key="name_2">surname:Bani-Ahmad;given-names:S</infon><infon key="name_3">surname:Elfaki;given-names:AO</infon><infon key="section_type">REF</infon><infon key="source">Intell. Inf. Manag.</infon><infon key="type">ref</infon><infon key="volume">09</infon><infon key="year">2017</infon><offset>65955</offset><text>A comparative survey on Arabic stemming: approaches and challenges</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>66022</offset><text>Mubarak, H.: Build fast and accurate lemmatization for arabic, pp. 1128–1132, 2017</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>66107</offset><text>M. ibn M. Ibn Manzur, Lisan al-’Arab. Bayrut: Dar sadir, 2007</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>66171</offset><text>Ibrahim, M.: Al-Mu’jam al-Waseet. Instanbul: al Maktaba al Islamiyah, 1976</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>66248</offset><text>ʻAbd al-Ghanī Abū al-ʻAzm, Muʿjam al-Ghanī al-zāhir. al-Rabāṭ: Muʼassasat al-Ghanī lil-Nashr, 2013</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>66359</offset><text>Strapparava, C.; Mihalcea, R.: Learning to identify emotions in text. In: Proceedings of the ACM Symposium on Applied computing, pp. 1556–1560, 2008</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>66510</offset><text>Strapparava, C.; Valitutti, A.: Wordnet affect: an effective extension of wordnet. In: Fourth International Conference on Language Resources and Evaluation, vol. 4, pp. 1083–1086, 2004</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>66697</offset><text>Wilson, T.; Wiebe, J.; Hoffman, P.: Recognizing contextual polarity in phrase-level sentiment analysis. In: Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pp. 347–354, 2005</text></passage><passage><infon key="fpage">45</infon><infon key="issue">2</infon><infon key="lpage">63</infon><infon key="name_0">surname:Elarnaoty;given-names:M</infon><infon key="name_1">surname:Abdelrahman;given-names:S</infon><infon key="name_2">surname:Fahmy;given-names:A</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Artif. Intell. Appl.</infon><infon key="type">ref</infon><infon key="volume">3</infon><infon key="year">2012</infon><offset>66938</offset><text>A machine learning approach for opinion holder extraction in Arabic language</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>67015</offset><text>Johansson, V.: Lexical diversity and lexical density in speech and writing: a developmental perspective. In: Lund University, Department of Linguistics and Phonetics Working Papers, vol. 53, pp. 61–79, 2008</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>67224</offset><text>Zhou, L.; Twitchell, D.P.; Qin, T.; Burgoon, J.K.; Nunamaker, J.F.: An exploratory study into deception detection in text-based computer-mediated communication. In: Proceedings of the 36th Annual Hawaii International Conference on System Sciences, 2003</text></passage><passage><infon key="fpage">139</infon><infon key="issue">4</infon><infon key="lpage">166</infon><infon key="name_0">surname:Zhou;given-names:L</infon><infon key="name_1">surname:Burgoon;given-names:JK</infon><infon key="name_2">surname:Twitchell;given-names:DP</infon><infon key="name_3">surname:Qin;given-names:T</infon><infon key="name_4">surname:Nunamaker;given-names:JF</infon><infon key="pub-id_doi">10.1080/07421222.2004.11045779</infon><infon key="section_type">REF</infon><infon key="source">J. Manag. Inf. Syst.</infon><infon key="type">ref</infon><infon key="volume">20</infon><infon key="year">2004</infon><offset>67477</offset><text>A comparison of classification methods for predicting deception in computer-mediated communication</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>67576</offset><text>Li, J.; Ott, M.; Cardie, C.; Hovy, E.: Towards a general rule for identifying deceptive opinion spam. In: 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014—Proceedings of the Conference, vol. 1, pp. 1566–1576, 2014.</text></passage><passage><infon key="fpage">665</infon><infon key="issue">5</infon><infon key="lpage">675</infon><infon key="name_0">surname:Newman;given-names:ML</infon><infon key="name_1">surname:Pennebaker;given-names:JW</infon><infon key="name_2">surname:Berry;given-names:DS</infon><infon key="name_3">surname:Richards;given-names:JM</infon><infon key="pub-id_doi">10.1177/0146167203029005010</infon><infon key="section_type">REF</infon><infon key="source">Personal. Soc. Psychol. Bull.</infon><infon key="type">ref</infon><infon key="volume">29</infon><infon key="year">2003</infon><offset>67825</offset><text>Personality and social psychology bulletin lying words: predicting deception from linguistic styles</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>67925</offset><text>Vinit Bhoir, S.: An efficient fake news detector. In: 2020 International Conference on Computer Communication and Informatics, ICCCI 2020, 2020.</text></passage><passage><infon key="fpage">76</infon><infon key="issue">2</infon><infon key="lpage">81</infon><infon key="name_0">surname:Reis;given-names:JCS</infon><infon key="name_1">surname:Correia;given-names:A</infon><infon key="name_2">surname:Murai;given-names:F</infon><infon key="name_3">surname:Veloso;given-names:A</infon><infon key="name_4">surname:Benevenuto;given-names:F</infon><infon key="name_5">surname:Cambria;given-names:E</infon><infon key="pub-id_doi">10.1109/MIS.2019.2899143</infon><infon key="section_type">REF</infon><infon key="source">IEEE Intell. Syst.</infon><infon key="type">ref</infon><infon key="volume">34</infon><infon key="year">2019</infon><offset>68070</offset><text>Supervised learning for fake news detection</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>68114</offset><text>Volkova, S.; Shaffer, K.; Jang, J.Y.; Hodas, N.: Separating facts from fiction: linguistic models to classify suspicious and trusted news posts on twitter. In: Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pp. 647–653, 2017</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>68408</offset><text>Lagutina, K., et al.: A survey on stylometric text features, pp. 184–195, 2020</text></passage><passage><infon key="fpage">81</infon><infon key="issue">1</infon><infon key="lpage">106</infon><infon key="name_0">surname:Zhou;given-names:L</infon><infon key="name_1">surname:Burgoon;given-names:JK</infon><infon key="name_2">surname:Nunamaker;given-names:JF</infon><infon key="name_3">surname:Twitchell;given-names:D</infon><infon key="pub-id_doi">10.1023/B:GRUP.0000011944.62889.6f</infon><infon key="section_type">REF</infon><infon key="source">Group Decis. Negot.</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2004</infon><offset>68489</offset><text>Automating linguistics-based cues for detecting deception in text-based asynchronous computer-mediated communication</text></passage></document></collection>
