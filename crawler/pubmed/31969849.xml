<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20201221</date><key>pmc.key</key><document><id>6960264</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.3389/fpsyg.2019.02883</infon><infon key="article-id_pmc">6960264</infon><infon key="article-id_pmid">31969849</infon><infon key="elocation-id">2883</infon><infon key="kwd">reaction times crowdsourcing online experiment prolific PsyToolkit</infon><infon key="license">This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</infon><infon key="name_0">surname:Armitage;given-names:James</infon><infon key="name_1">surname:Eerola;given-names:Tuomas</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">10</infon><infon key="year">2019</infon><offset>0</offset><text>Reaction Time Data in Music Cognition: Comparison of Pilot Data From Lab, Crowdsourced, and Convenience Web Samples</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>116</offset><text>Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>129</offset><text>Reaction time (RT) methods have been a mainstay of research in cognitive psychology for over a century. RT methods have been applied in domains as diverse as visual perception (e.g., Ando et al.,), personality traits (e.g., Robinson and Tamir,), and social psychology (e.g., Wang et al.,). In music cognition, RT methods have been used as an indirect measure of several phenomena such as harmonic expectation (Bharucha and Stoeckig,), melodic expectation (Aarden,) cross modal priming (Goerlich et al.,), absolute pitch (Miyazaki,; Bermudez and Zatorre,), and emotional responses (Bishop et al.,).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>727</offset><text>Traditionally, reaction time data has been collected in a lab. However, recent years have seen the development of software capable of collecting accurate response time data online, for instance PsyToolkit (Stoet,), PsychoPy (Peirce et al.,), Gorilla (Anwyl-Irvine et al.,), and Qualtrics' QRTEngine (Barnhoorn et al.,) amongst others. In the early days of web-based reaction time studies, there was considerable skepticism about the viability of RT data collected online. Despite the prevalence of software specifically designed to collect reaction time data online, and the increasing incidence of Web-based data collection, there remains a degree of caution around online reaction time studies. However, recent research (Barnhoorn et al.,; de Leeuw and Motz,; Hilbig,) suggests that online reaction time data is perhaps more trustworthy than was previously thought, but these studies have not yet involved music as stimuli.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1653</offset><text>Alongside the developments in software, recruitment of participants in online studies has been made easier by the prevalence of social media and crowdsourcing platforms such as Amazon's MTurk service and Prolific. Not surprisingly, the use of crowdsourced samples by researchers is growing rapidly (Stewart et al.,).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1970</offset><text>However, to the authors' knowledge (with the exception of de Leeuw and Motz,) the comparisons of laboratory and online RT data have focused on descriptive measures of the RT distributions, and relatively little attention has been paid to the agreement between the RT distributions as a whole. Moreover, none of these studies considers phenomena associated with music cognition. Given the widespread use of RT methods in music cognition and the growth of crowdsourcing as a recruitment tool, the authors consider there to be a need to test the viability of online RT collection specifically in the case of music cognition.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2592</offset><text>The present data report offers the results of a response time task completed in three different contexts—in a standard lab setting (“Lab”), online recruited via “traditional” online techniques (“Web”) and crowdsourced vis Prolific.ac (“CS”). Below, we present summary data for the three data sets before testing the comparability of the three data sets on an item-by-item basis.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>2989</offset><text>Data Collection</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>3005</offset><text> Reaction Time Task and Stimuli</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3037</offset><text>Data was collected using PsyToolkit (Stoet,) for the lab and both online samples. PsyToolkit offers a choice of either a local installation in Linux or a browser-based version that can be used to collect data online. The PsyToolkit script used for the Lab, Web, and CS data collection was identical in all three cases. Participants completed an affective priming task in which they heard a short (~1,000 ms) extract of music (.wav files in the Lab sample; .mp3 in the Web and CS samples) before being presented with a visual target word. Participants had to classify each word as positive or negative as quickly and accurately as possible. There were eight music primes and eight target words resulting in 8 × 8 = 64 prime-target pairs. The music primes, which were drawn from Västfjäll and Eerola and Vuoskoski were controlled for valence and arousal, as were the eight target words, which were taken from Warriner et al.. There were two music primes in each valence-arousal condition: 2× positive-high, 2× positive-low, 2× negative-high, and 2× negative-low. The target words followed the same valence-arousal distribution. Following the Lab data collection, it was found that one of the target words, Lover, was associated with significantly faster reaction times than the other words and was subsequently replaced with Payday. Both Lover and Payday have been excluded from the analysis below, leaving 56 prime-target pairs. Details of how the music clips were chosen and rated and more precise information regarding the procedure are included as Supplementary Material.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>4618</offset><text>Lab Study</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4628</offset><text>Participants were all right-handed (Kalyanshetti and Vastrad,; Hardie and Wright,) with normal or corrected to normal vision and hearing; all were native English speakers and received £5 to complete the present study and a related study. Data were collected during June 2018. The experimental setup comprised a Lenovo laptop running Linux (Xubuntu 18.04) and PsyToolkit version 2.4.1. (Stoet,). Including form-filling, the section of the experimental sessions relating to this task took around 10 min.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>5131</offset><text>Convenience Web Sample</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5154</offset><text>The materials and procedure mirrored the lab data collection as closely as possible. However, one of the target words, Lover, was replaced with Payday as it was associated with significantly faster response times than any of the other target words. Additionally, audio files were converted to .mp3 format. Data was collected using the web-based version of PsyToolkit (version 2.5.2) (Stoet,) during July 2018. The script used was identical to the script used for the Lab experiment. PsyToolkit allows researchers to restrict which type of devices are used to carry out online experiments, so we excluded tablets and mobile phones in order to maintain as much similarity with the lab setup as possible.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5856</offset><text>Participants were recruited online via Reddit, SurveyTandem (a survey exchange website where researchers complete each others studies in exchange for points; when researchers have amassed enough points, their studies are made available for other researchers to complete) and student email distribution lists at the University of Durham. Participants received no direct payment for participating, but had the option of entering a draw for a £25 Amazon voucher. As with the Lab sample, the inclusion criteria was right-handed native speakers of English with normal or corrected to normal vision and hearing.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>6463</offset><text>Crowdsourced Sample</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6483</offset><text>Participants were recruited via Prolific (www.prolific.ac) and received a payment of £0.75. Owing to the similarity to a previous study that recruited via prolific, participants from this previous study were excluded from taking part. Participants were prescreened to be right-handed, native speakers of English. The stimuli and procedure were identical to those used for the convenience web sample. The PsyToolkit version was updated to 2.5.4: the differences between the versions focused on the user (i.e., researcher) interface and did not impact RT collection. Data collection took place during July 2019.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>7094</offset><text>Comparison of Data Sets</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>7118</offset><text>Data Pre-treatment</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7137</offset><text>Participants whose accuracy rate fell below 75% were excluded from the analysis. This resulted in no deletions from the Lab data, but six participants in the Web sample and two in the CS sample failed to reach the required accuracy threshold. For the remaining participants, timeouts and response times shorter than 250 ms were excluded from the analysis, as is common practice (e.g., Duckworth et al.,). To exclude upper outliers, individual participants' response time distributions were fitted with an exponentially modified Gaussian (ExGaussian) distribution (Ratcliff,). Responses above the 95th percentile of each ExGaussian distribution were removed from the data set. Removal of timeouts and outliers accounted for the deletion of 5.7, 6.3, and 6.1% of responses from the Lab, Web, and CS data sets, respectively.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>7959</offset><text>Comparison of Summary Data</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7986</offset><text>Following deletions, there were 32 participants (mean age = 24.0, 19 male) in the Lab sample, 33 (mean age = 25.1, 13 male) in the Web sample, and 34 (mean age = 32.7, 8 male) in the CS sample.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8180</offset><text>The three data sets are compared in accuracy, attrition rate, mean, and variance of response time in the 56 prime-target conditions. Summary data is contained in Table 1.</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>8351</offset><text>Summary statistics for RT distributions.</text></passage><passage><infon key="file">T1.xml</infon><infon key="id">T1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th valign=&quot;top&quot; align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Method&lt;/bold&gt;&lt;/th&gt;&lt;th valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Error rate (%)&lt;/bold&gt;&lt;/th&gt;&lt;th valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Mean&lt;/bold&gt;&lt;/th&gt;&lt;th valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Variance&lt;/bold&gt;&lt;/th&gt;&lt;th valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Median&lt;/bold&gt;&lt;/th&gt;&lt;th valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;IQR&lt;/bold&gt;&lt;/th&gt;&lt;th valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&lt;bold&gt;Timeouts (%)&lt;/bold&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot; align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Lab&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3.67&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;580.34&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;25959.44&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;538&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;161&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;5.75&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot; align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Web&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3.64&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;587.352&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;16278.84&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;564&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;133&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6.28&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot; align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;CS&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3.30&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;587.98&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;18741.63&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;564&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;140&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6.14&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot; align=&quot;left&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Combined&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;3.53&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;585.30&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;20267.40&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;557&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;148&lt;/td&gt;&lt;td valign=&quot;top&quot; align=&quot;center&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;6.06&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>8392</offset><text>Method	Error rate (%)	Mean	Variance	Median	IQR	Timeouts (%)	 	Lab	3.67	580.34	25959.44	538	161	5.75	 	Web	3.64	587.352	16278.84	564	133	6.28	 	CS	3.30	587.98	18741.63	564	140	6.14	 	Combined	3.53	585.30	20267.40	557	148	6.06	 	</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8620</offset><text>The mean (SD) percentage error rates for the Lab, Web, and CS samples were 3.67 (0.188), 3.64 (0.187), and 3.30 (0.179), respectively. Linear mixed effects modeling suggested that there was no significant differences in accuracy rates between the Lab, Web, and CS samples, F(2, 110) = 0.32, p = 0.728. A repeated measures Anova was carried out to compare the mean response time for each target-prime pair. The test proved non-significant, F(2, 54) = 1.883, p = 0.16. However, the result does perhaps suggest (non-significantly) slower mean response times in the Web and CS sample as compared to the Lab sample.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9231</offset><text>Similarly, a repeated measures Anova was carried out to compare the variances in response times for each target-prime pair. There was a highly significant difference in variances in response times between the Lab (mean Variance = 26,396) and Web (mean Variance = 16,227) or CS (mean Variance = 18,742) samples, F(2, 110) = 26.22, p &lt; 0.0001. Contrary to expectations, post-hoc testing indicated that variance in the Lab RTs was greater than the variance in Web or CS RTs.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>9703</offset><text>Comparison of RT Distributions</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9734</offset><text>In addition to the comparison of the summary data carried out above, we also carried out overall and per-item comparison of the RT distributions in the three data sets. Figure 1A shows the overall cumulative RT distributions of the three data sets.</text></passage><passage><infon key="file">fpsyg-10-02883-g0001.jpg</infon><infon key="id">F1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>9983</offset><text>(A–D) Cumulative RTs &amp; Prime Valence×Target Valence Interactions for Lab, Web, and CS samples.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10081</offset><text>Following the procedure set out by Voss et al. to compare response time distributions for binary choice data, incorrect responses were allocated a negative response time (for instance an incorrect answer with a response time of 450 ms was coded as –450). Next, Kolmogorov-Smirnov (KS) tests were carried out to compare the Web Convenience vs. Lab response time distributions for all 56 prime-target pairs. Eight out of the 56 results returned significant results, suggesting that, in these instances, the Web Convenience sample and the Lab sample could not be thought of as representing the same underlying RT distribution. A binomial test was carried out with n = 56, r = 8, and p = 0.05 to determine whether eight instances of disagreement between the Lab and Web Convenience samples is more than can be expected by chance. This test returned a significant (p = 0.006) result suggesting that the overall distributions of RTs for the prime-target pairs of the Web Convenience and Lab samples cannot be considered equivalent.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11109</offset><text>The same procedure was carried out to compare the RT distributions for the Lab and CS data sets. As before, we carried out KS testing to determine the goodness of fit between the two RT distributions for each prime-target pair. Two conditions yielded significant results. Binomial testing (n = 56, r = 2, p = 0.05) confirmed that two out of 56 conditions is below the threshold for significance (p = 1), suggesting a strong agreement between the Lab and CS data sets.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>11577</offset><text>Presence of Hypothesized Effects</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11610</offset><text>Although reporting the results of the priming studies per se is outside the scope of this data report, it is important to know whether the key effect under investigation is present and consistent across all three samples (in this case the presence of congruency effects—i.e., are positive words evaluated faster when preceded by positive music than negative music, and similarly for negative words and music). To this end, the authors offer a brief account of the crucial Prime Valence×Target Valence interaction. Prior to analysis, RTs were log transformed (Whelan,). Next, the transformed data were subjected to 2 (Prime Valence) ×2 (Target Valence) linear mixed effects modeling. In all three samples, the interaction was significant, although the effect is much more clearly visible in the Lab and CS samples [Lab: F(1, 62) = 10.92, p = 0.002,  = 0.15; Web: F(1, 64) = 6.42, p = 0.02,  = 0.09; CS: F(1, 66) = 10.04, p = 0.002,  = 0.13]. The difference in effect sizes is evident also in Figures 1B–D.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_2</infon><offset>12621</offset><text>Costs</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>12627</offset><text>A final consideration is of course cost. We have estimated the financial costs associated with the data collection based on 32 participants per sample. We carried out 32 experimental lab sessions totalling 8 h. Paying participants £2.50 per session and costing a research assistant's time at £11.40 per hour (the lowest agreed rate of pay for graduate students at Anonymous for peer review University for the academic year 2018–2019) leads to an overall cost of 32*2.50 + £11.40*8 = £171.20. For the CS sample, we paid, £0.80 per participant, and data collection took roughly 2 h. Including taxes, the additional fee to Prolific is 36%: 32*£0.75*1.36 + 2*£11.40 = £57.62. It is more difficult to estimate the cost of the Web sample. In total, the web version of the study was online for over 2 weeks, during which time it was necessary to occasionally repost the study on Reddit and check the number of responses. Furthermore, completing studies on SurveyTandem accounted for around 6 h of researcher time (costed as 6*£11.40 = £68.40). There is also, however, an important trade-off to consider: although the cost of the data was significantly lower than for the Lab sample and comparable to the CS sample, the quality of the data is somewhat poorer in terms of its agreement with the Lab data, data wastage and visibility of the hypothesized effect.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>13991</offset><text>Interpretation and Usage</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14016</offset><text>The aim of this Data Report is to provide support for the concept of online collection of reaction time data. Additionally, the authors are able to point out some limitations and benefits of the three types of data collection. Researchers might also find it useful to compare the three data sets using specific measures of importance in their research.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14369</offset><text>One of the most striking differences is the difference in attrition rates between the Lab and CS samples and the convenience web sample. Data from all of the participants in the Lab sample and from 94.5% of the CS sample was viable, whereas in the Web sample data from 84.6% of participants was considered viable. It is, however, difficult to know why this may be the case. One possibility is that web participants were less motivated in the absence of a concrete financial incentive. Another is that participants in the web sample may have felt less invested in the research as they were taking part remotely and had not met the researcher in person. Another option is that error rates were higher because participants were taking part in sub-optimal conditions, so there could have been environmental distractors that influenced the error rates. A final option is that one of the sites used for recruitment operates a system whereby researchers exchange participation in surveys; researchers acquire points by participating in other researchers' studies. When they have accrued enough points, their study is in turn circulated to other researchers enrolled with the website. This comes with the risk that some researchers may have little intrinsic motivation to complete the tasks properly and allow the task to time out whilst still accruing points to allow for circulation of their own studies.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15768</offset><text>The results of the KS comparisons and visual inspection of the cumulative RT distributions suggest that, in principle, online collection of response time data can yield RT distributions that are comparable to those collected in a lab. However, much depends on the sample. In particular, the degree of alignment between the CS and Lab samples was much better than the alignment between the Web and Lab samples. It seems reasonable to assume that participants in the prolific sample were more motivated to complete the study than participants recruited via more traditional web methods, although it is not known whether this is a consequence of the fee paid to the CS sample or other factors such as curiosity or personality.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>16492</offset><text>The per-target/prime pairing distributions from the Web sample differ significantly from the distributions recorded in the Lab. Given the significantly better agreement between the Lab and CS samples, it seems likely that this difference is a result of environmental or participant variables rather than browser or hardware differences.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>16829</offset><text>Importantly, the hypothesized priming effect was present in all three data sets, with the caveat that the effect was much more visible in the Lab and CS samples as compared to the Web sample. Indeed, the Lab and CS samples resulted in almost identical  effect sizes ( and ) in the Lab and CS samples respectively, with a smaller effect size in the Web sample (): it is noteworthy that it was still present despite the significant binomial test. One implication is that researchers who lack access to funding may still be able to collect usable data via a convenience web sample.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>17408</offset><text>Overall, the data set presented here provides support for the use of web-based reaction time protocols. Researchers should, however, exercise care in their choice of participant pool. Where possible, researchers should opt for participant pools where they can be confident in the degree of motivation and engagement on the part of the participants. Moreover, researchers may wish to carry out confirmatory lab studies. The benefits of this approach extended also to faster data collection than was the case with the Web sample whilst being more cost effective than Lab data. The data presented here align with Hilbig's findings that, in principle, RT phenomena can be captured successfully online and that online RT methods can be used successfully in music cognition.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title_1</infon><offset>18177</offset><text>Data Availability Statement</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>18205</offset><text>The raw data, stimuli, PsyToolkit code and R scripts used to analyse the RT data can be found at https://osf.io/yhsqv/?view_only=87ae6378312c4a539fd6a5316c983afb. A copy of the priming task is available at https://www.psytoolkit.org/cgi-bin/psy2.5.4/survey?s=MBxuc.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title_1</infon><offset>18471</offset><text>Ethics Statement</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>18488</offset><text>This study was carried out in accordance with the recommendations of the Music Department Ethics Committee and approved by the same committee. In the case of the lab study, informed consent was given in writing; in the case of the online studies, informed consent was given via an online checkbox.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title_1</infon><offset>18786</offset><text>Author Contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>18807</offset><text>JA wrote the PsyToolkit code, oversaw the Lab and Web data collection, carried out the data analysis, and wrote the first draft of the manuscript. TE proposed the concept of comparing the three datasets, oversaw the CS data collection, and contributed to the authorship of the manuscript.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title_2</infon><offset>19096</offset><text>Conflict of Interest</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>19117</offset><text>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">footnote</infon><offset>19290</offset><text>Funding. This research was funded Faculty Pro Vice Chancellor's Head of Department fund.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title_1</infon><offset>19379</offset><text>Supplementary Material</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>19402</offset><text>The Supplementary Material for this article can be found online at: https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02883/full#supplementary-material</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>19560</offset><text>More precise details regarding the selection of prime stimuli and procedure for the RT task are included as supplemental materials. Although strictly outside of the scope of this data report, we have reported the results of the congruency effects of interest in the priming task.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>19840</offset><text>References</text></passage><passage><infon key="name_0">surname:Aarden;given-names:B. J.</infon><infon key="section_type">REF</infon><infon key="source">Dynamic melodic expectancy</infon><infon key="type">ref</infon><infon key="year">2003</infon><offset>19851</offset></passage><passage><infon key="fpage">747</infon><infon key="lpage">751</infon><infon key="name_0">surname:Ando;given-names:S.</infon><infon key="name_1">surname:Kida;given-names:N.</infon><infon key="name_2">surname:Oda;given-names:S.</infon><infon key="pub-id_doi">10.2466/pms.2002.95.3.747</infon><infon key="pub-id_pmid">12509170</infon><infon key="section_type">REF</infon><infon key="source">Percept. Motor Skills</infon><infon key="type">ref</infon><infon key="volume">95</infon><infon key="year">2002</infon><offset>19852</offset><text>Practice effects on reaction time for peripheral and central visual fields</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">20</infon><infon key="name_0">surname:Anwyl-Irvine;given-names:A. L.</infon><infon key="name_1">surname:Massonnié;given-names:J.</infon><infon key="name_2">surname:Flitton;given-names:A.</infon><infon key="name_3">surname:Kirkham;given-names:N.</infon><infon key="name_4">surname:Evershed;given-names:J. K.</infon><infon key="pub-id_doi">10.3758/s13428-019-01237-x</infon><infon key="pub-id_pmid">29967978</infon><infon key="section_type">REF</infon><infon key="source">Behav. Res. Methods</infon><infon key="type">ref</infon><infon key="year">2019</infon><offset>19927</offset><text>Gorilla in our midst: an online behavioral experiment builder</text></passage><passage><infon key="fpage">918</infon><infon key="lpage">929</infon><infon key="name_0">surname:Barnhoorn;given-names:J. S.</infon><infon key="name_1">surname:Haasnoot;given-names:E.</infon><infon key="name_2">surname:Bocanegra;given-names:B. R.</infon><infon key="name_3">surname:van Steenbergen;given-names:H.</infon><infon key="pub-id_doi">10.3758/s13428-014-0530-7</infon><infon key="pub-id_pmid">25407763</infon><infon key="section_type">REF</infon><infon key="source">Behav. Res. Methods</infon><infon key="type">ref</infon><infon key="volume">47</infon><infon key="year">2015</infon><offset>19989</offset><text>QRTEngine: an easy solution for running online reaction time experiments using qualtrics</text></passage><passage><infon key="fpage">89</infon><infon key="lpage">101</infon><infon key="name_0">surname:Bermudez;given-names:P.</infon><infon key="name_1">surname:Zatorre;given-names:R. J.</infon><infon key="pub-id_doi">10.1525/mp.2009.27.2.89</infon><infon key="section_type">REF</infon><infon key="source">Music Percept.</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2009</infon><offset>20078</offset><text>A distribution of absolute pitch ability as revealed by computerized testing</text></passage><passage><infon key="fpage">403</infon><infon key="lpage">410</infon><infon key="name_0">surname:Bharucha;given-names:J. J.</infon><infon key="name_1">surname:Stoeckig;given-names:K.</infon><infon key="pub-id_doi">10.1037//0096-1523.12.4.403</infon><infon key="pub-id_pmid">2946797</infon><infon key="section_type">REF</infon><infon key="source">J. Exp. Psychol. Hum. Percept. Perform.</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">1986</infon><offset>20155</offset><text>Reaction time and musical expectancy: priming of chords</text></passage><passage><infon key="fpage">59</infon><infon key="lpage">76</infon><infon key="name_0">surname:Bishop;given-names:D. T.</infon><infon key="name_1">surname:Karageorghis;given-names:C. I.</infon><infon key="name_2">surname:Kinrade;given-names:N. P.</infon><infon key="pub-id_doi">10.1123/tsp.23.1.59</infon><infon key="section_type">REF</infon><infon key="source">Sport Psychol.</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2009</infon><offset>20211</offset><text>Effects of musically-induced emotions on choice reaction time performance</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">12</infon><infon key="name_0">surname:de Leeuw;given-names:J. R.</infon><infon key="name_1">surname:Motz;given-names:B. A.</infon><infon key="pub-id_doi">10.3758/s13428-015-0567-2</infon><infon key="pub-id_pmid">25761390</infon><infon key="section_type">REF</infon><infon key="source">Behav. Res. Methods</infon><infon key="type">ref</infon><infon key="volume">48</infon><infon key="year">2016</infon><offset>20285</offset><text>Psychophysics in a web browser? Comparing response times collected with javascript and psychophysics toolbox in a visual search task</text></passage><passage><infon key="fpage">513</infon><infon key="lpage">519</infon><infon key="name_0">surname:Duckworth;given-names:K. L.</infon><infon key="name_1">surname:Bargh;given-names:J. A.</infon><infon key="name_2">surname:Garcia;given-names:M.</infon><infon key="name_3">surname:Chaiken;given-names:S.</infon><infon key="pub-id_doi">10.1111/1467-9280.00490</infon><infon key="pub-id_pmid">12430834</infon><infon key="section_type">REF</infon><infon key="source">Psychol. Sci.</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2002</infon><offset>20418</offset><text>The automatic evaluation of novel stimuli</text></passage><passage><infon key="fpage">18</infon><infon key="lpage">49</infon><infon key="name_0">surname:Eerola;given-names:T.</infon><infon key="name_1">surname:Vuoskoski;given-names:J. K.</infon><infon key="pub-id_doi">10.1177/0305735610362821</infon><infon key="section_type">REF</infon><infon key="source">Psychol. Music</infon><infon key="type">ref</infon><infon key="volume">39</infon><infon key="year">2011</infon><offset>20460</offset><text>A comparison of the discrete and dimensional models of emotion in music</text></passage><passage><infon key="fpage">1725</infon><infon key="lpage">1741</infon><infon key="name_0">surname:Goerlich;given-names:K. S.</infon><infon key="name_1">surname:Witteman;given-names:J.</infon><infon key="name_2">surname:Schiller;given-names:N. O.</infon><infon key="name_3">surname:Van Heuven;given-names:V. J.</infon><infon key="name_4">surname:Aleman;given-names:A.</infon><infon key="name_5">surname:Martens;given-names:S.</infon><infon key="pub-id_doi">10.1162/jocn_a_00213</infon><infon key="pub-id_pmid">22360592</infon><infon key="section_type">REF</infon><infon key="source">J. Cogn. Neurosci.</infon><infon key="type">ref</infon><infon key="volume">24</infon><infon key="year">2012</infon><offset>20532</offset><text>The nature of affective priming in music and speech</text></passage><passage><infon key="fpage">134</infon><infon key="name_0">surname:Hardie;given-names:S. M.</infon><infon key="name_1">surname:Wright;given-names:L.</infon><infon key="pub-id_doi">10.3389/fpsyg.2014.00134</infon><infon key="pub-id_pmid">24600426</infon><infon key="section_type">REF</infon><infon key="source">Front. Psychol.</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2014</infon><offset>20584</offset><text>Differences between left-and right-handers in approach/avoidance motivation: influence of consistency of handedness measures</text></passage><passage><infon key="fpage">1718</infon><infon key="lpage">1724</infon><infon key="name_0">surname:Hilbig;given-names:B. E.</infon><infon key="pub-id_doi">10.3758/s13428-015-0678-9</infon><infon key="pub-id_pmid">26542972</infon><infon key="section_type">REF</infon><infon key="source">Behav. Res. Methods</infon><infon key="type">ref</infon><infon key="volume">48</infon><infon key="year">2016</infon><offset>20709</offset><text>Reaction time effects in lab-versus web-based research: experimental evidence</text></passage><passage><infon key="fpage">278</infon><infon key="lpage">280</infon><infon key="name_0">surname:Kalyanshetti;given-names:S. B.</infon><infon key="name_1">surname:Vastrad;given-names:B.</infon><infon key="section_type">REF</infon><infon key="source">Al Ameen J. Med. Sci.</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2013</infon><offset>20787</offset><text>Effect of handedness on visual, auditory and cutaneous reaction times in normal subjects</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">14</infon><infon key="name_0">surname:Miyazaki;given-names:K.</infon><infon key="pub-id_doi">10.2307/40285445</infon><infon key="section_type">REF</infon><infon key="source">Music Percept.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">1989</infon><offset>20876</offset><text>Absolute pitch identification: effects of timbre and pitch region</text></passage><passage><infon key="fpage">195</infon><infon key="lpage">203</infon><infon key="name_0">surname:Peirce;given-names:J.</infon><infon key="name_1">surname:Gray;given-names:J. R.</infon><infon key="name_2">surname:Simpson;given-names:S.</infon><infon key="name_3">surname:MacAskill;given-names:M.</infon><infon key="name_4">surname:Höchenberger;given-names:R.</infon><infon key="name_5">surname:Sogo;given-names:H.</infon><infon key="pub-id_doi">10.3758/s13428-018-01193-y</infon><infon key="pub-id_pmid">30734206</infon><infon key="section_type">REF</infon><infon key="source">Behav. Res. Methods</infon><infon key="type">ref</infon><infon key="volume">51</infon><infon key="year">2019</infon><offset>20942</offset><text>Psychopy2: experiments in behavior made easy</text></passage><passage><infon key="fpage">510</infon><infon key="lpage">532</infon><infon key="name_0">surname:Ratcliff;given-names:R.</infon><infon key="pub-id_doi">10.1037//0033-2909.114.3.510</infon><infon key="pub-id_pmid">8272468</infon><infon key="section_type">REF</infon><infon key="source">Psychol. Bull.</infon><infon key="type">ref</infon><infon key="volume">114</infon><infon key="year">1993</infon><offset>20987</offset><text>Methods for dealing with reaction time outliers</text></passage><passage><infon key="fpage">107</infon><infon key="lpage">114</infon><infon key="name_0">surname:Robinson;given-names:M. D.</infon><infon key="name_1">surname:Tamir;given-names:M.</infon><infon key="pub-id_doi">10.1037/0022-3514.89.1.107</infon><infon key="pub-id_pmid">16060749</infon><infon key="section_type">REF</infon><infon key="source">J. Pers. Soc. Psychol.</infon><infon key="type">ref</infon><infon key="volume">89</infon><infon key="year">2005</infon><offset>21035</offset><text>Neuroticism as mental noise: a relation between neuroticism and reaction time standard deviations</text></passage><passage><infon key="fpage">736</infon><infon key="lpage">748</infon><infon key="name_0">surname:Stewart;given-names:N.</infon><infon key="name_1">surname:Chandler;given-names:J.</infon><infon key="name_2">surname:Paolacci;given-names:G.</infon><infon key="pub-id_doi">10.1016/j.tics.2017.06.007</infon><infon key="pub-id_pmid">28803699</infon><infon key="section_type">REF</infon><infon key="source">Trends Cogn. Sci.</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2017</infon><offset>21133</offset><text>Crowdsourcing samples in cognitive science</text></passage><passage><infon key="fpage">1096</infon><infon key="lpage">1104</infon><infon key="name_0">surname:Stoet;given-names:G.</infon><infon key="pub-id_doi">10.3758/BRM.42.4.1096</infon><infon key="pub-id_pmid">21139177</infon><infon key="section_type">REF</infon><infon key="source">Behav. Res. Methods</infon><infon key="type">ref</infon><infon key="volume">42</infon><infon key="year">2010</infon><offset>21176</offset><text>PsyToolkit: a software package for programming psychological experiments using Linux</text></passage><passage><infon key="fpage">24</infon><infon key="lpage">31</infon><infon key="name_0">surname:Stoet;given-names:G.</infon><infon key="pub-id_doi">10.1177/0098628316677643</infon><infon key="section_type">REF</infon><infon key="source">Teach. Psychol.</infon><infon key="type">ref</infon><infon key="volume">44</infon><infon key="year">2017</infon><offset>21261</offset><text>Psytoolkit: a novel web-based method for running online questionnaires and reaction-time experiments</text></passage><passage><infon key="fpage">173</infon><infon key="issue">1_Suppl.</infon><infon key="lpage">211</infon><infon key="name_0">surname:Västfjäll;given-names:D.</infon><infon key="pub-id_doi">10.1177/10298649020050S107</infon><infon key="section_type">REF</infon><infon key="source">Music. Sci.</infon><infon key="type">ref</infon><infon key="volume">5</infon><infon key="year">2001</infon><offset>21362</offset><text>Emotion induction through music: a review of the musical mood induction procedure</text></passage><passage><infon key="fpage">536</infon><infon key="lpage">559</infon><infon key="name_0">surname:Voss;given-names:A.</infon><infon key="name_1">surname:Rothermund;given-names:K.</infon><infon key="name_2">surname:Gast;given-names:A.</infon><infon key="name_3">surname:Wentura;given-names:D.</infon><infon key="pub-id_doi">10.1037/a0029459</infon><infon key="pub-id_pmid">22866687</infon><infon key="section_type">REF</infon><infon key="source">J. Exp. Psychol. Gen.</infon><infon key="type">ref</infon><infon key="volume">142</infon><infon key="year">2013</infon><offset>21444</offset><text>Cognitive processes in associative and categorical priming: a diffusion model analysis</text></passage><passage><infon key="fpage">39827</infon><infon key="name_0">surname:Wang;given-names:Y.</infon><infon key="name_1">surname:Zhang;given-names:Z.</infon><infon key="name_2">surname:Bai;given-names:L.</infon><infon key="name_3">surname:Lin;given-names:C.</infon><infon key="name_4">surname:Osinsky;given-names:R.</infon><infon key="name_5">surname:Hewig;given-names:J.</infon><infon key="pub-id_doi">10.1038/srep39827</infon><infon key="pub-id_pmid">28051156</infon><infon key="section_type">REF</infon><infon key="source">Sci. Rep.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2017</infon><offset>21531</offset><text>Ingroup/outgroup membership modulates fairness consideration: neural signatures from ERPs and EEG oscillations</text></passage><passage><infon key="fpage">1191</infon><infon key="lpage">1207</infon><infon key="name_0">surname:Warriner;given-names:A. B.</infon><infon key="name_1">surname:Kuperman;given-names:V.</infon><infon key="name_2">surname:Brysbaert;given-names:M.</infon><infon key="pub-id_doi">10.3758/s13428-012-0314-x</infon><infon key="pub-id_pmid">23404613</infon><infon key="section_type">REF</infon><infon key="source">Behav. Res. Methods</infon><infon key="type">ref</infon><infon key="volume">45</infon><infon key="year">2013</infon><offset>21642</offset><text>Norms of valence, arousal, and dominance for 13,915 English lemmas</text></passage><passage><infon key="fpage">475</infon><infon key="lpage">482</infon><infon key="name_0">surname:Whelan;given-names:R.</infon><infon key="pub-id_doi">10.1007/BF03395630</infon><infon key="section_type">REF</infon><infon key="source">Psychol. Rec.</infon><infon key="type">ref</infon><infon key="volume">58</infon><infon key="year">2008</infon><offset>21709</offset><text>Effective analysis of reaction time data</text></passage></document></collection>
