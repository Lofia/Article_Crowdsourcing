<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20210520</date><key>pmc.key</key><document><id>8122952</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.3390/s21092964</infon><infon key="article-id_pmc">8122952</infon><infon key="article-id_pmid">33922627</infon><infon key="article-id_publisher-id">sensors-21-02964</infon><infon key="elocation-id">2964</infon><infon key="issue">9</infon><infon key="kwd">volunteered geographic information crowdsourcing spatiotemporal analysis support vector regression geographic information system twitter</infon><infon key="license">Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).</infon><infon key="name_0">surname:Salazar-Carrillo;given-names:Juan</infon><infon key="name_1">surname:Torres-Ruiz;given-names:Miguel</infon><infon key="name_2">surname:Davis;given-names:Clodoveu A.;suffix:Jr.</infon><infon key="name_3">surname:Quintero;given-names:Rolando</infon><infon key="name_4">surname:Moreno-Ibarra;given-names:Marco</infon><infon key="name_5">surname:Guzmán;given-names:Giovanni</infon><infon key="name_6">surname:Martinez;given-names:Francisco J.</infon><infon key="section_type">TITLE</infon><infon key="type">front</infon><infon key="volume">21</infon><infon key="year">2021</infon><offset>0</offset><text>Traffic Congestion Analysis Based on a Web-GIS and Data Mining of Traffic Events from Twitter †</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>98</offset><text>Smart cities are characterized by the use of massive information and digital communication technologies as well as sensor networks where the Internet and smart data are the core. This paper proposes a methodology to geocode traffic-related events that are collected from Twitter and how to use geocoded information to gather a training dataset, apply a Support Vector Machine method, and build a prediction model. This model produces spatiotemporal information regarding traffic congestions with a spatiotemporal analysis. Furthermore, a spatial distribution represented by heat maps is proposed to describe the traffic behavior of specific and sensed areas of Mexico City in a Web-GIS application. This work demonstrates that social media are a good alternative that can be leveraged to gather collaboratively Volunteered Geographic Information for sensing the dynamic of a city in which citizens act as sensors. </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1013</offset><text>1. Introduction</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1029</offset><text>Nowadays, mobile computing plays an important role to characterize the behavior, relationships, and dynamics of human being activities in big cities. Particularly, the development of applications oriented towards sensing specific tasks with the use of smartphones is increasing day-by-day to improve the well-being of the citizens. Different techniques to sensing human activity in the geospatial context have been proposed. Those present a shared and collaborative approach, using communication networks to collect data about diverse phenomena in a relatively short time and saving resources in specialized infrastructure. </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>1654</offset><text>Nowadays, user-generated content is one of the most common and powerful sources to compile spatially referenced data as taking people as sensors worldwide. Thus, there are different platforms, websites, social networks that are used to comment or post activities, situations, or feelings, share multimedia, and use location-based services to inform and influence everyday life. New tools to gain insight into different forms of data that are themselves the result of the digital revolution, the growth of the Internet, and, significantly, mobile devices.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2209</offset><text>The approach coined as Volunteered Geographic Information (VGI) is intended to generate geospatial data in which human beings are conceived as “sensors”, and they are the main generation source. Thus, various public and open online applications, publications on social networks, as well as specific sensors embedded into mobile devices are used to create and share these compiled geospatial data by the citizens. VGI has changed paradigms in which information is created, shared, used, and experienced, with important implications for geospatial data applications, including emergency management, traffic congestion, air pollution, energy consumption, urban planning, crime rate, climate change, and energy consumption, among others. Thus, citizen-sensors were defined by in order to compare humans to “intelligent, mobile sensors”, related directly to VGI for highlighting the concept of user-generated content attached with geospatial information (e.g., location, place names) in the form of geo-tags or coordinates. No matter what people, services, devices, and sensors are sensing (e.g., noise, air quality), the spatiotemporal context helps in the understanding and interpretation of the collected data. The term geocrowdsourcing, or simply crowdsourcing, is widely used in Geographic Information Systems (GIS) for urban computing, which involves the collection of geospatial information performed by an undefined network of people.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>3655</offset><text>Many platforms and systems have been designed to collect big datasets to represent the behavior and particular characteristics from different phenomena of diverse contexts. Pervasive systems are oriented towards improving sensing approaches, providing more descriptive geospatial information that can be collected by streaming in real-time. In this position, dwellers of urban spaces play a fundamental position to sense the pulse of the cities. Thus, there is a widespread state-of-the-art to comprehend different relationships and behaviors associated with human beings to describe the urban dynamics. User-generated traffic information in mobile communication networks is frequently used as a data source. This information content can be used to generate better models of activity and mobility.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4453</offset><text>According to, traffic congestion is a problem that directly affects big cities. Different approaches to describe this state have been deeply analyzed. For instance, information obtained from mobile devices to characterize the traffic congestion based on clustering the road flow, according to different values and considering the human judgment is described in; other approaches are focused on digital image processing, physical sensors installed in the streets, and pattern recognition techniques.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4952</offset><text>On the other hand, social media is a type of VGI platform, with fast information sharing facilities and a fast speed of online communication, as well as a large volume of people engaged with social networks such as Facebook and Twitter, enabling further communication and providing alternative means for information dissemination. Studies have demonstrated that there is a strong connection between social relationships and geography, considering the data from Facebook. Thus, people that interact daily almost always live near each other, and each user has at least 10 friends with shared locations.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5553</offset><text>In this paper, a methodology to geocode traffic-related events from the Twitter streaming, as well as how to use the geocoded information in order to gather a training dataset for applying a Support Vector Machine method and build a prediction model, is proposed. This model provides spatiotemporal information on traffic congestions with a spatiotemporal analysis. Moreover, the spatial distribution of the traffic-related events is represented by heat maps, which describe the concentration or density of the traffic congestion in a Web-GIS application. The results have been evaluated by applying precision and recall measures.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6184</offset><text>The paper is organized as follows: Section 2 presents the state-of-the-art in this field. Section 3 describes the methods and materials that comprise the proposed methodology to analyze traffic congestion and the behavior characterization by traffic-related events. Section 4 depicts the experimental results, applying the proposed methodology, and the evaluation of the proposed prediction model. Thus, Section 5 presents a discussion concerning the analysis of the results and performance of the methodology. Finally, Section 6 outlines the conclusion and future work.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>6755</offset><text>2. Related Work</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>6771</offset><text>In the state-of-the-art, there are several approaches oriented towards obtaining georeferenced information from social media to process and visualize geographic in-formation on the Web, as well as applying Machine Learning algorithms to build prediction models that describe the behavior of different phenomena that impact cities.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7102</offset><text>For example, in a model to predict traffic congestion is proposed. This approach consists of applying a deep learning technique, which compounds extracted data from Twitter with climate and transit data. It supports a Long Short-Term Memory, which is a deep bidirectional method to predict data. Thus, the model is trained by applying a stacked autoencoder architecture, generating test and training data sets with data regarding Twitter, traffic congestion, and climate. Moreover, a case study of Saudi Arabia to detect event-related to traffic congestion was proposed. The approach is based on the Apache Spark system and clustering methods to generate eight classes that represent different states or events.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>7814</offset><text>On the other hand, a case study of Washington DC to model the traffic phenomenon was presented in. This approach consists of establishing keywords, considering “traffic safety” data, which were obtained from Twitter for the last four years. Sentiment analysis was implemented over the tweets’ corpus, in which an extraction–transformation–cleaning (ETL) process was applied. Thus, some citizens’ faiths and moods were computed to determine the importance to reduce the deadliness, vehicular security issues, and the application of transit and official policies. Moreover, six high profiles were established such as drivers without seat belts, spoiled control, top speedup limits, distracted conduction, younger chauffeurs, and very mature drivers.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>8574</offset><text>A technique to analyze different patterns associated to work and rest activities and how traffic congestion influences these states during different moments of the day is described in. The authors proposed to determine these patterns by extracting information from Twitter. Later, sentiment analysis was also applied taking into consideration tweets that reflected the moods of the citizens. The study demonstrated that the activity of the dwellers during the day determines the traffic flow to the next day. In other words, depending on their rest or activity in the previous night, the traffic flow is represented in the roads. Thus, proposed an application to sense traffic congestion by mining continuously the Twitter streaming. The collected tweets are clustered by applying a feature-extraction algorithm, considering the occurrence and frequency of the traffic congestion in specific areas. This research work realized a comparative analysis to assess different clustering techniques regarding the application performance.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>9605</offset><text>On the other hand, an analysis performed in Valencia, Spain to determine the spatial traffic dispersion is presented in. The analysis consisted of classifying diverse avenues over the city, defining the congestion flows with spatiotemporal data, and taking into consideration trips in rush hours, and the number of lanes per street. The outcomes demonstrated that both variables impact only in certain segments of streets, and only an adjustment in the real conditions determines the vehicular flows to specific areas within the city.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10140</offset><text>According to, traffic states are usually not perfectly measured and are everywhere. Thus, an estimation is required from local and noisy sensor data. One of the most widely applied estimation methods is the Lighthill–Whitham and Richards (LWR) model with an extended Kalman filter (EKF). An important disadvantage of the EKF is that the method is too slow to perform in real-time on large networks. To overcome this issue, the authors proposed a novel localized EKF (L-EKF) algorithm. The logic of the traffic network is used to correct only the state in the vicinity of a detector.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>10725</offset><text>According to the state-of-the-art, public and open applications, as well as centrally devoted platforms focused on collecting, storing, and sharing VGI, have been proposed. In this context, collaborative applications oriented towards improving the social civic participation in activities associated with compiling data to enhance diverse electronic services and generate diverse data repositories for the well-being of big cities were proposed in. Moreover, presents a good comparative and analysis concerning VGI products that have been created with the design of systems focused on processing and assessing user-generated data.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>11356</offset><text>Many works related to obtaining VGI from social networks have been proposed. In other cases, approaches to recognize geospatial facts that occur in certain locations are presented in. A methodology for geocoding tweets to develop a map based on these given geographic references is described in. Moreover, an approach in which citizens were adopted as “human-sensors” to detect earthquakes based on publications of Twitter that reflected this phenomenon is proposed in. According to, human mobility plays an important role in the study of traffic forecasting and the engineering of smart cities. Approaches to face how to model traffic flows in big cities, as well as the development of transportation infrastructure for the citizens and visitors, is a very timely challenge. The flow or congestion is classified into two types: continuous or discontinuous. Thus, the usual traces of the citizens describe a natural behavior with repetitive patterns, which describe a continuous flow. The discontinuous flow is defined by random events such as vehicular accidents, climate situations, among others. In this context, insights to handle discontinuous flows are very important as well as the detection of these kinds of events allows us to determine efficient manners to control traffic congestion.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>12656</offset><text>In, an approach to mine tweet texts for extracting incident information on highways as an efficient and cost-effective alternative to existing data sources is proposed. It consists of a crawling process and filtering tweets that are freely accessible by citizens. So, keywords’ thesaurus and the combinations of these terms allow determining traffic events from the data acquisition process. Therefore, a post is handled as an n-dimensional vector according to the characteristic slot that is built by the thesaurus and clustered into traffic-related events or not. In this stage, the corpus of tweets was previously georeferenced to find the geospatial position. In the same context, the problem of interpreting tweets that describe traffic-related events, which are distributed by government agencies in charge of road networks or by news agencies is presented in. The contribution is an automatic tweet interpretation tool, based on Machine Learning techniques, achieving good performance for traffic-related tweets that are distributed by traffic authorities and news agencies. Ref. proposed a methodology based on user relationships to infer the location of messages on Twitter. A network is created considering the follower–following relationships, starting from the known locations of users in the network and inferring the location of others.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14011</offset><text>Research proposals to determine the performance of traffic models have been deeply studied. For instance, comparisons and tests regarding optimization techniques such as the analysis of genetic algorithms are presented in. The authors proposed the deterministic Nelder-Mead method, with the application of a stochastic algorithm, and the computation of the entropy to determine values of real traffic flows in different roads. The assessment of the model was carried out considering different transit data sets to evaluate the precision of the results, and how the time to resolve is optimized. Moreover, a traffic simulator application to reproduce traffic information behavior was proposed in to evaluate usual areas with a high density of vehicular traffic.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>14772</offset><text>The advances in mobile computing and social networking services enable people to probe the dynamics of a city. In, a method based on crowdsensing mixed with information on human mobility and social media to detect and describe traffic anomalies is presented. The detection of events was modeled by a sub-graph, which represents a road network, where drivers’ routing behaviors significantly differ from their original patterns.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>15202</offset><text>Other approaches are focused on identifying geographic features from the text, without using Natural Language Processing (NLP). In, a method to identify traffic events and conditions in Twitter, geocode them by using a GEODICT gazetteer, and display them on the Web in real-time was proposed. The GEODICT gazetteer is a data source where toponyms (place names) are associated with concepts and their geographic footprint. Thus, it is a free repository that contains basic yet precise information such as multilingual labels, and administrative boundaries polygons, among others, that can be customized. Preliminary results showed that the method is able to detect neighborhoods and thoroughfares with a precision that varies from 50 to 90%, depending on the number of places mentioned in the tweets. </text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>16003</offset><text>Traffic prediction models, transportation planning, and services centered on smart cities are deeply aligned with human mobility. In a design to implement an application of automatically catch citizen perceptions is proposed. The main conception is focused on generating a mobile space to compile user-generated content. Assumptions concerning the feasible information and the qualitative data value were analyzed. The approach was intended for urban practitioners and how to exploit these human mobility data. Twitter was used to mine messages, taking into consideration those that describe traffic situations. Subsequently, a natural language method to classify the tweets automatically was implemented.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>16709</offset><text>Machine Learning and probabilistic techniques have been also used in network traffic analysis. In, a statistical approach based on R software and GPS traces of vehicles was proposed. The traces were mined to extract the outlier traffic pattern. The urban was divided into a grid, and the road infrastructure was organized as segments of a graph. The congestion level was determined by analyzing the visits for each vehicle using the GPS trace data. Moreover, introduced a traffic model based on the probabilistic topic method to describe the traffic states for a variety of roads. Thus, a technique for detecting traffic incidents from probe-cars by identifying unusual events that distinguish incidents from spontaneous congestion was presented. The approach detected successfully between anomalous car trajectories and the more usual, slowly moving traffic patterns. In, a fast, non-convex multi-task sparse feature-based learning method to define a set of shared features in traffic data was proposed. The method can learn features belonging to each task as well as the common features shared among tasks. In, various models and approaches using soft computing techniques to tackle the problem have been developed. Major soft computing approaches for this purpose are Fuzzy Approaches, Neural Network and Genetic Algorithms, Petri Nets, and so on. Moreover, multi-agent systems were highly applicable in this approach. Ref. proposed a system for individual trip planning that incorporates future traffic hazards in routing. The traffic conditions were computed by spatiotemporal random field on a stream of sensor readings. The traffic flow in areas with low sensor coverage was estimated by Gaussian Process Regression. Moreover, presented an application based on a supervised statistical learning technique, which consists of a prediction model implemented in a Support Vector Regression (SVR) to predict freeway traffic flow under both typical and atypical conditions.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>18684</offset><text>3. Method and Materials</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>18708</offset><text>The proposed approach provides a general framework, which is composed of the following stages: (1) data acquisition and information analysis, (2) the creation of dictionaries and equivalents, (3) gazetteer division, (4) standardization, (5) the identification and location of traffic-related events, (6) the generation of a prediction model, and (7) the visualization of traffic-related event prediction.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19113</offset><text>The geocoding process is embedded from stage 1 to stage 6. The following stages are in charge of generating the prediction model and the visualization of traffic-related events that were predicted by the model. Figure 1 depicts the main phases that compose the general framework. This research work is oriented towards initiating from the data acquisition to the visualization of the prediction of traffic-related events. Thus, this Figure offers a general conceptualization of the work proposal.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19610</offset><text>Thus, the data acquisition and its geocoding process with the prediction model related to traffic events, as well as the visualization of results, are described in detail in the following Sections.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>19808</offset><text>3.1. Geocoding Traffic-Related Events from Tweets</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>19858</offset><text>In this stage, both automatic and manual steps are required with the purpose to search the following geographic elements on Twitter: streets, public transportation stations, local areas, among others. Thus, the GeoNames gazetteer and a tweet dataset were used to initiate this process.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20144</offset><text>GeoNames is a dataset that contains 36,236 streets from Mexico City and a minimum of 150,000 street segments. It describes the features of geographic objects that contain information in the Spanish language. For this reason, any field could contain an empty value, or, the label “NO NAME”, starts with one of the next abbreviations: ‘rd, ‘st’, ‘ave’ (road, street, and avenue); and finally, the charset includes low and upper case and special characters (á, é, í, ó, ú). </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>20635</offset><text>3.1.1. Data Acquisition and Information Analysis</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20684</offset><text>Read a tweet (t) from the tweet dataset (TD).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20730</offset><text>Define the value of N for the N-gram computing process.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20786</offset><text>Compute the occurrence of each N-gram.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20825</offset><text>Apply a sort descending algorithm.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20860</offset><text>Select the most repetitive N-grams according to a threshold.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>20921</offset><text>An analysis to select particular accounts from the tweet stream was made. Many tweets talk about traffic-related events, but it is important to determine and identify tweets that could describe an event using the information of crowded streets, common nicknames, short names, famous places, and historical monuments. With this dataset, an algorithm for computing the most common words was implemented, the output of this algorithm is a list of the most common N-grams. Thus, the operation of the algorithm is described as follows: </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21453</offset><text>A practical value for this threshold is 100. So, to reduce the computational complexity of this process, a restriction was established so that only continuous slices of N-words can be valid. In Figure 2 we illustrate the operation of this algorithm:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>21703</offset><text>The results obtained from the N-grams are the following: 150 common traffic-related events, 69 common nicknames; 34 common abbreviations; 456 common streets,135 common hashtags; 65 common buildings, places and, monuments; and 26 similar combinations of prepositions that were identified by hand. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>22000</offset><text>3.1.2. Creation of the Dictionaries and Equivalents</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22052</offset><text>By considering information hold of the preceding stage, figures the National Institute of Statistics and Geography (INEGI) of Mexico were used to bring about and enrich some glossaries and the bulletin (see Figure 3). The proposed glossaries are the next ones: short forms, alias, octothorps, movements, urban transportation service, main roads (those that show up in tweets and are present in the bulletin), locations, constructions, and markers, and areas. Some dictionaries have a geographical feature, that is required to dimensionally sketch earthly elements. Thus, these glossaries are identified by the letter “G” in the blocks of Figure 3, and they were called dictionaries of geographic elements. On the other hand, a glossary of geographical relationships might have been set up; however, in this method, the traffic-related events are classified by using the number of geographic elements that were identified in the tweets.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>22992</offset><text>Regarding the equivalents, it is habitual that avenues shall be signed for over more than one known name. In brief, Mexico City has 31 artery cuts and two peripheries covering over more than 10 thousand kilometers all around the city. Cuts and peripheries modify their names as they reach different streets and crossed roads. Thus, they are occasionally known with their most known name, or with the name of a specific segment (popular name), or just by putting names together (principal name + second name). Yet, all these different names are accepted; for this reason, all the different options have to be explored in the tweets. With the idea of looking for heterogeneity regarding the names, a glossary of equivalent artery cut names was considered to clarify the named collection.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>23778</offset><text>3.1.3. Gazetteer Division</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23804</offset><text>One of them contains the known streets frequently mentioned in tweets that exist in the bulletin (some ways shafted in tweets are in the suburbs of Mexico City, so they were left out).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>23989</offset><text>The second one contains the rest of the streets. Although the cut did not make the precision better and recall of geocoding, the achievement of the identification as well as the location steps had an increase by using this division.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24222</offset><text>According to information analysis, commonly a few streets have the most influx-related events. With the N-gram densities, just 19 percent of the roads that show up in tweets of the whole bulletin was actually localized. Thus, the bulletin is divided into two parts:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>24488</offset><text>3.1.4. Standardization</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24511</offset><text>The standardization process was improved by considering dictionaries of non-geographic elements, such as abbreviations, nicknames, and hashtags. In the proposed gazetteer, the names of streets contained in the geographic dictionaries present abbreviations, capitalized names, with stressed marks on the names, gaps between rows, etc. For this reason, changes each street name to lowercase, and the accent marks are removed (TALISMÁN to talisman). Additionally, the glossary of common short forms is used to substitute the complete sentence (talisman St.—talisman street). At last, blank gaps and ways with default values are eliminated.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25151</offset><text>Other issues that arose in tweets are related to chains and referents to other versions, alias, misplaces, and, octothorps (e.g.,  (accessed on 27 July 2020), @OVIALCDMX, “The angel”, “circuito interior street”, #insurgentesavenue). Thus, with the idea to solve these new features, the glossary of alias, and octothorps were intended to substitute those with the name given by the government in tweets (for instance, “The angel”—“angel of independence” and #insurgentesavenue—“insurgentes avenue”). Chains and referents to other versions were removed. The misplaces topic is never treated in this work.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>25778</offset><text>Additionally, in posts as well as in gazetteers, the stop words have to be factored out. These words do not give additional meaning to the sentence. Moreover, these words are very common in a language (articles, pronouns, and prepositions). As we do not have a list of stop words for using in Natural Language Processing. This is why the stop word list has been sketched by the Natural Language Toolkit Library.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>26190</offset><text>3.1.5. Identification and Location of Traffic-Related Events</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>26251</offset><text>It has been carried out the identification of geographic elements only by using all the glossaries of geographic elements. Accidents, traffic-related tweets from chosen accounts often describe either bad or good traffic conditions. As an example, incidents like accidents are known as “car crashes”, “rollovers”, “emergency services”; bad conditions are “slow displacement”, “blocked roads”, “settlements”, etc.; and good conditions are denoted as “yet moving”, “fluid displacement”, etc.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>26772</offset><text>Even when there is a good quantity of signs, inquiries, and safety suggestions, they are easily factored out due to the fact of lack of any geographical information as well as the short length of posted tweets.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>26983</offset><text>When we consider an amount of a tweet corpus and the N-gram frequency analysis, a vehicle incident is contemplated as a collision or incident on the public road a specific punctual location involving at least one geospatial object. For instance, “a road traffic accident at x street and z street”, “a broken traffic light at crossroads the intersection of x street and y street”, “overturn vehicles in front of x subway station”, etc. The explanation of a false or true state is set by the verified state of affairs of a road portion. The aforementioned descriptions, often one, two, or three or n geospatial objects are taken into account. For instance, “a traffic jam on x street between y street and z street”, “a good circulation of cars on x street from y street to z locality”, “rush hour in x street on z locality”, “rainfall over x neighborhood”, among others.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>27880</offset><text>A fragment of the list of accidents and conditions that were identified with the proposed method is presented in Table 1. Since tweets can only contain 140 characters, it is difficult to post a mention, a link, a traffic-related event, and more than three geographic elements. Therefore, the number of geographic elements included in the tweet has a strong relationship with the kind of traffic-related event (see Figure 4).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>28305</offset><text>Instead, each glossary of geospatial objects has a basic geographic depiction (punctual, arc, area). Therefore, the glossary of mass transit is rounded out by a set of punctual objects; the glossary of streets is distinguished by a set of arcs, and the glossaries of districts, sites, buildings, and memorials are illustrated by areas. Therefore, a collection of geographic primitives was obtained by searching for geographic elements from dictionaries in tweets.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>28769</offset><text>Taking for granted that there are not 1, 2, or 3 testimonials to places in a tweet, the number of correlations (relationships) that can occur amid them is calculated by Equation (1).  where q is the number of possible objects to be chosen; in this respect, punctual, arc, or area, and p is the number of objects that were retrieved. Hence, for one object: [(punctual), (arc), (area)], with two-spotted components: [(punctual, punctual), (punctual, arc), (punctual, area), (arc, arc), (arc, area), (area, area)], and three spotted components: [(punctual, punctual, punctual), (punctual, punctual, arc), (punctual, punctual, area), (punctual, arc, arc), (punctual, arc, area), (punctual, area, area), (arc, arc, arc), (arc, arc, area), (arc, area, area), (area, area, area)]. A lot of these connections of the geospatial basics are not exact regarding the location or prevalence in tweets is not excessive; therefore, they can be thrown away.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>29710</offset><text>(pt) describes an event in an urban transportation or service station.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>29781</offset><text>(pt, l) is an arterial road segment restriction in front of an urban transportation service station.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>29882</offset><text>(l, l) describes an event in an arterial road crossing point.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>29944</offset><text>(pt, pt, l) describes an arterial road segment restriction outlined by two urban transportation service stations.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30058</offset><text>(pt, l, l) describes an arterial road segment restriction outlined by other artery and urban transportation service station.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30183</offset><text>(l, l, l) describes an arterial road segment restriction delimited by two arteries.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30267</offset><text>(l, l, p) describes an arterial road segment delimited by an artery and place, building, or historical monument.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30380</offset><text>In this approach, the relationships that were considered are the following: [(pt, l), (l, l), (pt, pt, l), (pt, l, l), (l, l, l), (l, l, p)], where pt, l, and p represents a point, line, and polygon respectively. These relationships were recognized in the corpus obtained from the dataset; the hypothesis of each relationship is conceived as follows:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30731</offset><text>Determine the arterial road intersection;</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30773</offset><text>Determine the polygon, or the line, that is closest to the point of interest;</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30851</offset><text>Determine the bounding box of the line portion.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>30899</offset><text>On the other hand, it is important to define a set of three spatial operations to compute the final result of applying these assumptions. The spatial operations are described as follows:</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>31086</offset><text>To apply these spatial operations, we implemented scripts using the PostGIS spatial functions: ST_Intersection, ST_ClosestPoint, ST_Envelope, and ST_ConvexHull. Thus, the final result represents the location of the traffic-related event. In Table 2, the procedure to determine an (l, l, l) relationship is described.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>31403</offset><text>3.2. Generation of the Prediction Model</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>31443</offset><text>From the geocoding method that was described in Section 3, a collection of geocoded tweets was obtained. This collection is used to generate a training dataset for the Machine Learning method (Support Vector Machine). There are some features that were considered for this collection. Moreover, the selection of features in a Support Vector Machine determines the success of the learning approach. However, the best way to select the most relevant features is manually, based on the deep knowledge about the learning problem and the meaning of each feature.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>32000</offset><text>A training dataset is composed of an input that is an n-dimensional vector and the output that is a real number. In this case, the n-dimensional vector contains the features that better represent the collection of tweets, and the output is the location where the geocoding method found the traffic-related event. Due to the tweet restriction regarding 140 characters, it is difficult to obtain a vector with multiple features to create a training dataset. Thus, only features of traffic-related events that happened in the analysis were taken into consideration. Table 3 presents the spatiotemporal features and the possible values that these events could take for the training dataset.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>32687</offset><text>On the other hand, some features were discarded because they added noise to the results. In addition, geographic features over tweets are not usual; only a small quantity of tweets contains the neighborhood, zip code, or nearby places. Therefore, a supervised method cannot use information from the output for inferring the values of the selected features.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>33044</offset><text>Thus, the traffic-related events were classified according to their district in which a prediction was correlated with each district. In this case, the precision and recall measures increase considerably because the division of the training dataset per district reduces the possibility of finding vectors with similar values that belong to distant locations. Thus, Mexico City is composed of 16 districts; consequently, there are 16 training datasets, which define 16 prediction models.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>33531</offset><text>3.2.1. The Support Vector Regression Method</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>33575</offset><text>The aim of the following mathematical presentation is only to clarify some of the concepts used in the work, how they are computed, and where they come from.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>33733</offset><text>Thus, consider a training dataset of size n, denoted {(x1, y1),…, (xn, yn)}, where xi ∈ Rk is the input space of the sample, and yi ∈ R is a related numerical value that represents the output of each sample. The purpose of the regression problem is to determine future values with precision by means of a function modeled. The general function of SVR takes the form of Equation (2).  where ω ∈ Rk, b ∈ R, and Φ are the non-linear transformation from Rk to high dimensional space. Φ transformation is a primary characteristic of Support Vector Machines (SVM), it is called kernel trick. The main idea of this transformation is to move to another higher dimensional space when the samples are non-linearly separable. Therefore, the goal is to find the values of ω and b determining the values of x, minimizing the regression risk (see Equation (3)).  where Eε is a cost function, and C is a penalization constant. The value of the cost function (Equation (4)) is zero if the absolute difference between the prediction y(x) and the target t is less than ε, where ε &gt; 0. Otherwise, the cost is |y(x) − t| − ε. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>34878</offset><text>The optimization problem embedded in SVR needs slack variables in order to improve the accuracy of the model. In SVM, even if a linear separation is achieved in the feature space Φ(x), this separation of the training data can lead to a poor generalization; therefore, it is necessary to find a way to modify the SVM so as to allow some of the training points to be misclassified. Thus, slack variables modify the approach allowing points to be on the wrong side of the margin boundary, but with a penalty that increases with the distance from that boundary.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>35438</offset><text>In SVR, for each data point xn two slack variables are added, ξ ≥ 0 and  ≥ 0. The first one where ξ &gt; 0 corresponds to a point for which tn &gt; y(xn) + ε. In the second,  &gt; 0 corresponds to a point for which tn &lt; y(xn) − ε.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>35676</offset><text>The introduction of slack variables in the case of SVR allows points to lie outside the ε-insensitive region that is commonly called ε-tube, and the corresponding conditions are defined in Equations (5) and (6).  </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>35902</offset><text>The error function for SVR can now be defined as in Equation (7). </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>35969</offset><text>This error must be minimized subject to the constraints ξ &gt; 0,  &gt; 0 defined in Equations (5) and (6). Thus, the Lagrange multipliers (ε + ξn + yn − tn) ≥ 0, and  (ε + n − yn + tn) ≥ 0 are used to compute the optimization.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36207</offset><text>Now, the value of ω in terms of the Lagrange multipliers is described by Equation (8). </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36299</offset><text>The b variable is computed by applying Karush–Kuhn-Tucker (KKT) conditions, and Φ is the kernel trick value. It implies that the product of the Lagrange multipliers and constraints must be equal to zero (see Equations (9)–(12)).    </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36537</offset><text>In this case, b is computed by applying Equation (13). </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_3</infon><offset>36593</offset><text>3.2.2. The SVR Library</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36616</offset><text>The Scikit-learn framework was used to compute these Equations. It is an open-source Machine Learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, predicting, cross-validation, data preprocessing, model selection and evaluation, and many other utilities.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>36936</offset><text>The selection of this framework obeys the feasible mechanisms to introduce different programming languages. In this study, Python language was used to implement different algorithms, using different components embedded into the library such as regression and clustering algorithms, diverse classification techniques, and statistical methods. Moreover, the programs implemented into the Scikit-learn are suitable with the NumPy and ScyPy, which are scientific libraries of Python.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>37416</offset><text>The most important methods and algorithms of the Scikit-learn as well as some libraries such as NumPy were programmed in Python language. The kernel of the techniques and Machine Learning algorithms were also programmed in Cython, in order to enhance the performance for the users. Moreover, the libsvm package contains the main regression algorithms such as Support Vector Machines. In the same case, the liblinear package stores the Logistic Regression and Linear Techniques. Other packages programmed in Python have also been integrated into the Scikit-Learn, for example, NumPy and SciPy oriented towards handling array vectorization, Pandas to control dataframes’ structures, and matplotlib and plotly to plotting and edition.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>38150</offset><text>Regarding the conception of Python language, its conceptualization is focused on reusing code, with specific characteristics such as interoperability, readability, easy syntax, and definitions of concepts with simple code lines. It is considered as a high-level language, with a diverse mechanism to simplify the programming building in different development scales. Besides, Python is the most important language to develop fundamental applications oriented to data science.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>38626</offset><text>Thus, SVR is used to obtain a reliable prediction model, and it requires two processes: training and testing. The first one uses a mandatory training for the SVR method in order to make future predictions using the training dataset. The second uses a test dataset to validate the prediction model; this dataset was taken from the training dataset.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>38974</offset><text>The SVR library requires several parameters to establish the prediction model. The value of these parameters varies depending on the learning problem. The list of parameters is defined in Table 4. </text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>39172</offset><text>The parameters that were used to build the prediction model of traffic-related events with the highest precision are C = 1000, gamma = 0.04, and epsilon = 0.0004. These values were chosen manually by making k-fold cross-validation tests in order to ensure that the training dataset and the test dataset are isolated from the results.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>39506</offset><text>The implementation of the prediction model and the simulations of the obtained predicted data were developed in Python language under the version 3.8.8, using Anaconda, which is a package management service. Additionally, it can be used to facilitate a development cycle and organize the code that is in development, in testing, and in production, without affecting non-development users. With labels, one can upload a file to a specific label so only users who put that label in the URL that they search are able to find it.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>40032</offset><text>The training dataset was divided into input and output in order to use the SVR library and generate the prediction model. When the model is trained, the following process in the prediction model was tested using the test dataset.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>40262</offset><text>svr_rbf.fit(input_train, output_train);</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>40302</offset><text>svr_rbf.predict(input_test).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>40331</offset><text>4. Experimental Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>40355</offset><text>This section presents different results related to the proposed methodology in order to assess each stage by applying the methods to a particular case study.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>40513</offset><text>4.1. The Empirical Data</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>40537</offset><text>After the cleaning process, the corpus has 65,250 posts on Twitter. This collection was performed from 7 July 2020 until 22 December 2020, and each tweet is “original”. It means that the corpus does not contain retweets, favorite marks, and tweets with blank spaces. The sources to collect each tweet of the corpus come from trustworthy Twitter accounts, which are related to official institutions and certificate communication services (see Table 5). The criteria that were used to select those accounts accomplish the following issues: account reputation, number of followers, tweets per day, date of creation, geographic location of the account, website of the account, government account.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>41234</offset><text>Thus, the @Supervia_CDMX and @072AvialCDMX are Twitter accounts that correspond to government institutions. They are the accounts that more tweets provide to the corpus. There are important characteristics that allow us to validate the reputation of the account such as the description of traffic events is well-structured, good comprehension to post incidents, the number of followers is increasing, and the majority of its tweets can be georeferenced with good accuracy. Regarding @Trafico889 and @RedVialRC accounts, they are associated with radio broadcasting; so, data of climate conditions and traffic congestion are posted in their timelines, with the advantage that these tweets are also presented on their websites. Finally, @Alertux and @PolloVial accounts represent the user-generated content approach because they collect collaboratively volunteered data and make retweets from other Twitter profiles.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>42148</offset><text>These empirical data have been preprocessing with natural language techniques, and the tweet dataset is volunteered information. In background mode, the collection is continuously sensed and stored in a spatial database within PostGIS in order to obtain more general information that in the future can help other projects to determine rates of air pollution, crime rates in particular areas, energy consumption, and environmental pollution, among others.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>42603</offset><text>In addition, it is important to mention that the official government of Mexico City does not have any traffic information collection directly related to social networks in order to characterize and analyze the behavior of the traffic situation by means of a spatiotemporal approach. Thus, the empirical data collection was generated in order to represent traffic information provided by Twitter in which this phenomenon is not depicted in a map. Furthermore, the updating of this information is faster than classic cartographic techniques, and the integration with other Volunteered Geographic Information such as OpenStreetMaps and GeoWiki is feasible.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>43257</offset><text>The novel contribution focuses on developing an approach with low cost in which the main collected information is provided by Twitter. Thus, the proposed empirical dataset makes a big difference from the conventional traffic data collection methods, which are based on roadside inductive loop detectors that are costly to deploy and maintain. Thus, social media is an alternative that can be leveraged to gather collaboratively Volunteered Geographic Information about the conditions of roads, streets, and avenues.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>43773</offset><text>4.2. Evaluation of the Geocoding Method</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>43813</offset><text>In order to evaluate the accuracy of the geocoding method, a test dataset was put together using 652 geocoded tweets by hand. Thus, streets, public transportation stations, neighborhoods, places, buildings, and monuments were identified.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>44051</offset><text>Moreover, the test dataset was compared with elements identified by the proposed methodology, and the precision and recall measures were also computed. The first evaluation consisted of comparing the baseline with only the gazetteer with part of the standardization, using only lowercase (see Section 3.1.4). The second one was compared with the baseline plus the full standardization. Finally, the third one used the baseline plus the standardization process plus the equivalent axis names.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>44543</offset><text>Thus, the true-positive, true-negative, and false-negative values were used as parameters to compute the accuracy of the geocoding method, according to the proposed measures. In this case, true-positive values represent geospatial objects that were detected by the algorithm and these objects were also established as the gold standard metric in the design of the evaluation task. Concerning the true-negative values, they describe the geospatial objects that were detected by the algorithm; however, these objects are outside of the metric. Finally, the false-negative values represent the geospatial objects that correspond to the gold standard metric but they could not detect by the method. These calculations were realized to each tweet into the corpus and the mean was also determined. The outcomes regarding the evaluation measures are described in Table 6.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>45408</offset><text>According to Table 6, it is appreciated that the proposed methodology has a precision and recall of 85% and 83, respectively, which is higher than the 39% and 31% obtained from the baseline. Thus, the best results were obtained with the definition of a dictionary of equivalent axes to identify geographic objects. Therefore, it implies a novel contribution to refine the performance regarding precision and recall.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>45824</offset><text>From a temporal perspective, these results describe the relationship of traffic-related events in the real-world with Twitter. The number of tweets posted at 18, 19, and 20 h is higher. This is the time of the day with the highest level of participation that was found. Another relevant period is in the morning around 8 AM, with another important participation. Thus, this behavior corresponds to the rush hours in Mexico City (see Figure 5).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>46268</offset><text>4.3. Visualization of Geocoded Tweets and the Prediction Data</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>46330</offset><text>In particular, the SVR method was implemented to define the prediction model, which requires two well-defined processes: training and testing. The first one uses a mandatory training dataset for the SVR method in order to make future predictions. The second uses the test dataset to validate the prediction model; this dataset was taken from the training dataset. Thus, the training dataset was divided into input and output in order to use the SVR library and generate the prediction model. Figure 6 shows a spatial comparison between the traffic-related events that were geocoded by the proposed method defined in Section 3.1 that are represented by the Twitter image with squares in blue color, and the predicted data that were directly generated by the prediction model based on the SVR, represented by triangles in red color. </text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>47162</offset><text>Concerning the spatiotemporal analysis of traffic-related events, it was generated by a collection of n-dimensional vectors with the same features of the training dataset input. This information was gathered by using a new prediction model with a training dataset that contains the district, month, day, day of the week, and hour. The characteristics are defined by vectors with the same structure that compose the input of the training dataset. The number of vectors that are sent to the training dataset varies for the regression analysis applying the SVR method in which the input of the training dataset is composed of the characteristics of the hour and day of the week, adding the spatial district characteristic that are represented as a categorized form.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>47925</offset><text>The result of the output is the prediction model, which represents the number of accidents that could happen. With this number and the number of given constraints such as hour, day of the week, and month, a collection of n-dimensional vectors is obtained to send the traffic-related event to the prediction model.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>48239</offset><text>The values of the hour, day, and day of the week on each vector vary from the threshold from −1 to 1 to represent traffic values near the given constraint. Figure 7 depicts points in black color that represent the spatiotemporal analysis in which such points are traffic-related events. Thus, each vector that was sent to the prediction model is composed of the characteristics of time and space previously selected. Moreover, Figure 7 represents an example of the spatiotemporal analysis, taking into consideration the two components such as time and spatial location.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>48811</offset><text>On the other hand, it is important to clarify that it is not possible to obtain the streets associated with traffic-related events because the general framework was intended to locate, analyze, and predict geospatial information that is represented by geographic points. After all, the geocoding process was designed to operate and validate only this type of geospatial representation. The methodology is not focused on retrieving linear geospatial objects, although this representation is used and defined in the dictionaries and equivalents, as well as the gazetteer division, only to adjust and refine the geocoding process.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>49439</offset><text>In other words, a result is a number of locations where accidents could be placed. Figure 8 shows a representation of correlational traffic events by means of a heat map. This raster representation shows a spatial distribution, which defines the concentration or density of traffic-related events from a specific and sensed area of the Cuauhtémoc District in Mexico City. Additionally, Figure 8 depicts the range of concentration values of the traffic events. These values were obtained by computing all the predictions in rush hours.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>49975</offset><text>4.4. Evaluation and Results of the Prediction Model</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>50027</offset><text>The regression method works with numeric values that are in the set R. Thus, a variation between the predictive locations and the real locations that were used to test the model is proposed. The threshold has been established at 100 m in order to work with coordinates that contain latitude and longitude, which are required to establish how to consider true positives, true negatives, and false negatives values.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>50441</offset><text>In the case of predictions, a true positive is considered when an element of the test dataset (gold standard) is inside the threshold of a predicted element by the model. A true negative is a predicted element by the model, which is inside the threshold and there is any element of the test dataset. A false negative is an element of the test dataset that never was touched by the threshold of any predicted element by the model.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>50871</offset><text>The precision and recall measures were computed as follows. The test dataset is provided from the training dataset and it is not used to create the model. It is used with the input of the test dataset; the result was compared with the output of the test dataset by using the criterion below in order to consider true positive, true negative, and false negative values.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>51240</offset><text>In Figure 9, a general schema to process the empirical data is presented. Thus, the collection to generate and test the prediction model was divided into two sets called training and test. First, the training set was used to generate the prediction model, considering the empirical data. Moreover, the test set was divided again into inputs (subsets of characteristics vector), and outputs (the obtained coordinates from the geocoding process). The inputs were sent to the SVR model and the obtained output from this model was compared with the output of the test set in order to obtain the true positive (TP), true negative (TN), false positive (FP), and false negative (FN) items.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>51923</offset><text>The first experiment consisted of determining the relationship between the size of the training dataset and the precision and recall of the created models. By using one district of Mexico City and a threshold of 100 m, several increments were made starting with 500 elements. The precision and recall increased considerably while adding elements, but the generation of the model increased too; thus, when the training dataset has around 3000 elements, the precision is close to 80% and the time to generate the model is around 1.57 h (see Figure 10).</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>52474</offset><text>The second experiment consisted of selecting features, by adding time features such as a minute and second to the initial vector (hour, day, day of the week, month). The results showed that precision and recall fell considerably, from a precision and recall of 70% and 65%, respectively. In addition, they decreased to 47% and 42%, respectively, using a training dataset of 2500 elements. The reason was that by adding these variables, the vector generation was very similar at distant places with others; thus, it produced noise for the model creation.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>53028</offset><text>In fact, the values of the parameters required by the SVR library need to be tested. These values are very relevant to generate the traffic prediction model. Thus, an experiment switching the kernels was carried out. With a linear kernel, there was no solution because it is a non-linear regression problem. Although a polynomial kernel is very useful for Natural Language Processing, it tends to infinity in this kind of problem when the training datasets with more than 20 elements produce a memory overflow. By testing the penalty parameter (C), when it has a small value between 0 and 100, the models have low precision and recall values because the function presents many mistakes in the calibration. Otherwise, with high values of more than 10,000, good results were obtained. However, this fact increased considerably the time to generate the model. Something similar happened with epsilon (ε-tube) because it represents a radius that covers the function, such as a tube; thus, all elements that fell inside this tube were not considered for the learning process. Low values of epsilon ended up overfitting, and high values produced a lack of learning because the radius was very high with respect to the function in which any element did not have the capacity to learn.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>54312</offset><text>5. General Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>54334</offset><text>The precision and credibility of the geographic information posted on Twitter can be assessed by three different perspectives. The first one is given by the number of people that can participate in the generation of this information. This effect is also visible in social networks; when an event is exposed by a user account, it is generally accompanied by confirmations made by other followers of the Twitter account without a relationship between them. Thus, if the quantity of users that indicates an event in an isolated way is greater, then this isolated event has a higher weight, and the credibility of that event is real. Regarding the second perspective, it is carried out through the creation of a hierarchy of users and the assignment of roles within the group of users that generate the geographic content. Ref. endorsed that geographic information generation by user accounts follows a distribution with respect to generated information and the number of user accounts; that is, a small group of people generates a large amount of information, and the rest of the user accounts generate moderate information. Thus, to this small group of people a higher role is assigned, which implies additional responsibilities such as information assessment and edition capacity, and among others. The geographic proximity is related to the third approach. Basically, it is the first law of geography “All things are related to each other, but things that are closer in space have a greater relationship than those that are distant”. The approach is used to assign a probabilistic value if the exposed event can be true or false. An example is the knowledge of high levels of vehicular traffic on a given avenue; it is highly probable that some record of a vehicular accident is true, and even more so if there have already been records of previous vehicular accidents on this avenue. Thus, these approaches ensure that geographic information generated by users is consistent and with gradual increases in accuracy due to continuous reviews and assessments by the community.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>56413</offset><text>Moreover, a study carried out to assess information on Twitter demonstrated that true information behaves differently from false information. The study identified seven false events, and a tracing of the information behavior on the social network was performed. The results showed that true information is confirmed by 95.5% by the Twitter community and rejected by only 0.3%. On the other hand, false information is rejected by 50% in addition to being questioned by a percentage greater than the confirmation of the event. The study affirms that the Twitter community works as a collaborative filter of information. On the other hand, verified that when Twitter is used during an emergency, other users are not mentioned in the text of the messages. Thus, the percentage varies between 6% and 8% against 22% in a normal situation. Conversely, tweets that include Internet site addresses are higher in an emergency, ranging from 40% to 50% versus 25% in a daily situation. Thus, it is possible to infer that emergencies also follow a pattern that largely validates the veracity of the information.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>57512</offset><text>On the other hand, the generated corpus that represents the new tweet dataset is composed of 65,250 tweets, which were collected over a period of approximately six months, from 7 July 2020 to 22 December 2020. These tweets were cleaning and preprocessing according to the methods described in Section 3.1. Regarding the initial gazetteer, the dataset is composed of 36,236 different streets (more than 150,000 street segments) from Mexico City. It is important to emphasize that the estimation of traffic-related events improves with more collected tweets. Thus, there is no direct relationship among the number of collected data to generate the predictions.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>58171</offset><text>Concerning the case that the prediction model does not receive information from the Twitter stream, the model only generates the computation for the historic and collected data that is stored in the corpus; obviously, the input of the model depends directly on the collected tweet data to increase its precision. However, there is no constraint that the model can continue generating spatiotemporal predictions, but the accuracy of the outcomes could not be appropriate due to the Twitter data stream that is stopped.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>58689</offset><text>6. Conclusions and Future Works</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>58721</offset><text>Smart cities applications are oriented towards providing better public services and making the use and integration of different computing technology more efficient, such as the Internet of Things, telecommunication networks, wearable sensors, Volunteered Geographic Information, and Machine Learning approaches, among others. Thus, the essential components for urban development in a smart city include smart technology, smart industry, smart services, smart management, and smart life that can be modeled by smart systems or applications.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>59261</offset><text>Many smart city applications have been developed to share road network information. A popular example is Waze, which is a community-based traffic and navigation application. Another example is Traffic Pulse, a participatory mobile sensor web platform that relies on the voluntary use of smartphones to report on road conditions. Thus, the proposed framework could be very useful for mixing and integrating more variables and empirical data from those applications in order to enrich the tweet collection. Thus, the prediction models will improve the precision, analysis, and characterization of the traffic behavior, and other kinds of traffic-related events will be classified efficiently.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>59952</offset><text>The contribution or strengths of the proposed methodology are centered on developing an approach with low cost in which the main collected information is provided by Twitter with an assessment realized by the users of this social network. Thus, the proposed empirical dataset makes a big difference from the conventional traffic data collection methods, which are based on roadside inductive loop detectors that are costly to deploy and maintain. Thus, social media are an alternative that can be leveraged to gather collaboratively Volunteered Geographic Information about the conditions of roads, streets, and avenues. In this direction, this work was intended to design a novel framework to geolocate traffic-related events from the Twitter stream. Thus, the proposed research work is addressed to influence in the crowdsensing field because the benefits not only are focused on developing a methodology to generate prediction models to analyze the traffic congestion, but the geocoding process is also an important key to enrich other contexts and various datasets from different scopes such as air pollution, crime incidence, and human mobility, among others. This takes into consideration human beings as sensors, which represents important opportunities for user-generated content and for facing challenges associated with the dynamic-sensing of cities. </text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>61314</offset><text>Moreover, the geocoding method improved considerably by using a gazetteer enriched with information from the Twitter stream. Moreover, an approach to discover how to divide traffic-related events to give more accurate representations is proposed. With this division, it was possible to find the number of geographic elements in a tweet, which could have a relationship with the kind of traffic-related event. It is significantly important to highlight that this research demonstrated that there exists a relationship between Twitter participation and the rush hours in the Mexico City.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>61900</offset><text>According to the predictions, an approach to create training and test datasets from geocoded information is presented. These collections generated a traffic road prediction model as well as an evaluation technique to estimate the model. SVR demonstrated that it is capable to create reliable prediction models regarding traffic-related events. The considerations to keep in mind are the number of elements in the training dataset and the selected features, which are related to the precision and recall of the model. The SVR parameters are fundamental to create a reliable prediction model in order to avoid overfitting or learning lack.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>62538</offset><text>The geocoding of traffic-related events with training datasets based on an SVR method for making spatiotemporal predictions about the traffic congestions in a specific time is a useful resource to characterize the behavior of the traffic city conditions, such as to how to avoid crowded areas, assign traffic polices, or detect broken traffic lights.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>62889</offset><text>Regarding the weaknesses of the proposed methodology, both the geocoding process and the prediction model present limitations. They are restricted by the conception of their functionality. For example, the weakness of the geocoding process is conceived from the constitution of the gazetteer and the natural conception of the posted tweets. The approach of this methodology does not consider the direction of each event that has occurred due to the gazetteer not containing information related to the direction of the streets. Moreover, many of the tweets do not mention the direction where the traffic event has occurred. For the prediction model, the conceptualization of the Machine Learning method could be imprecise in considering road conditions due to a condition being composed of a coordinate sequence, which would have assigned the same vector of temporal characteristics. This affects considerably the creation of the regression model. Another issue not taken into account is the possible impact of each event on the street, that is, how long an event can affect a road as a baseline; a duration of time t is assigned to each accident when it is predicted or visualized. The amount of information to create the prediction model plays an important role in the implementation because districts that contain few recorded events from the Twitter stream produce poor predictions, but this is not only a limitation of the methodology but also a lack of data that prevents better predictions.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>64386</offset><text>On the other hand, there are applications such as SenseCity that can share open data related to urban participatory and tourist information. It offers an Application Programming Interface (API) for building mobile applications. Thus, smart city systems such as Smart City Vadodara, Enevo, Streetline, Anagog, EverImpact, and TZOA can exchange their sensed information with the proposed framework as an important insight to make predictions that consider traffic-related events, analyzing variables associated with the weather, human mobility, and public transportation networks.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>64965</offset><text>Moreover, many research directions are focused on developing new protocols, architectures, and services that will be devoted to the domain of smart cities. Thus, future works will be oriented towards integrating the information provided from wearable sensors in the context of healthcare applications to measure and analyze people’s stress, glucose level, and assistance for Parkinson’s Disease. Moreover, emergency management, risk mitigation, citizen election engagement, the management of energy consumption, urban public facilities, law enforcement, and air pollution are open issues that big cities are currently facing, and they represent big challenges for the research community.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>65657</offset><text>Regarding improving the geocoding approach, it is important to focus on discovering further relationships among geographic elements and finding other cases that can occur independently of the assumptions established in the present research. At this time, the proposed geocoding method of traffic-related events does not consider the direction of the event. Thus, it is necessary to define an algorithm for inferring the direction where the event is located. The nearest areas outside Mexico City present a lot of urban mobility; thus, expanding this methodology to the nearest areas beyond city boundaries would be a wellness initiative. In fact, a temporal analysis is required to establish a reasonable time duration for an accident or condition, and a baseline could be set up for each traffic-related event.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>66469</offset><text>Moreover, Twitter accounts always post with the same structure; thus, a Machine Learning method could be implemented to learn features, which can be related to the creation of the training dataset, the traffic road congestion model, and its predictions require improvement in different aspects such as the training dataset needing more features to increase the accurate model; a traffic-related event having many relationships, not only temporal but also descriptive attributes such as lane numbers; the number of traffic lights along the way; buildings; and public transportation stations and the neighborhoods near them. By adding these relationships to the training dataset, a better representation of the learning issue could be obtained. The model creation would add a geographic restriction in the SVR method, which handles in a better way the locations that contain the training dataset. Indeed, the precision of results is directly related to the accuracy of the traffic-related events that were previously geocoded; thus, it implies that better geocoded events can produce better predictions.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">footnote</infon><offset>67571</offset><text>Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title</infon><offset>67697</offset><text>Author Contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>67718</offset><text>J.S.-C.: investigation, approach development, and software; M.T.-R.: conceptualization, funding acquisition, and formal analysis; C.A.D.J.: formal analysis, state-of-the-art, and supervision; R.Q.: dataset integration and software; M.M.-I.: evaluation of the experiments, draft preparation, and writing; G.G.: software modeling, discussion and conclusion, review and editing. All authors have read and agreed to the published version of the manuscript.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>68171</offset><text>Funding</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>68179</offset><text>This research was funded by Instituto Politécnico Nacional and the Secretaría de Investigación y Posgrado, grant numbers 20201863, 20210162, and the CONACyT PN-2016/2110.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>68353</offset><text>Institutional Review Board Statement</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>68390</offset><text>Not applicable.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>68406</offset><text>Informed Consent Statement</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>68433</offset><text>Not applicable.</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">title</infon><offset>68449</offset><text>Data Availability Statement</text></passage><passage><infon key="section_type">SUPPL</infon><infon key="type">paragraph</infon><offset>68477</offset><text>Not applicable.</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title</infon><offset>68493</offset><text>Conflicts of Interest</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>68515</offset><text>The authors declare no conflict of interest.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>68560</offset><text>References</text></passage><passage><infon key="fpage">113</infon><infon key="lpage">119</infon><infon key="name_0">surname:Torres-Ruiz;given-names:M.J.</infon><infon key="name_1">surname:Lytras;given-names:M.D.</infon><infon key="pub-id_doi">10.4018/IJKSR.2016010108</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Knowl. Soc. Res. (IJKSR)</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2016</infon><offset>68571</offset><text>Urban computing and smart cities applications for the knowledge society</text></passage><passage><infon key="fpage">3</infon><infon key="lpage">9</infon><infon key="name_0">surname:Goodchild;given-names:M.F.</infon><infon key="pub-id_doi">10.1080/19475680903250715</infon><infon key="section_type">REF</infon><infon key="source">Ann. GIS</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2009</infon><offset>68643</offset><text>Geographic information systems and science: Today and tomorrow</text></passage><passage><infon key="fpage">212</infon><infon key="lpage">214</infon><infon key="name_0">surname:Cope;given-names:M.</infon><infon key="pub-id_doi">10.1016/j.landurbplan.2015.08.009</infon><infon key="section_type">REF</infon><infon key="source">Landsc. Urban Plan.</infon><infon key="type">ref</infon><infon key="volume">142</infon><infon key="year">2015</infon><offset>68706</offset><text>Commentary: Geographies of digital lives: Trajectories in the production of knowledge with user-generated content</text></passage><passage><infon key="fpage">211</infon><infon key="lpage">221</infon><infon key="name_0">surname:Goodchild;given-names:M.F.</infon><infon key="pub-id_doi">10.1007/s10708-007-9111-y</infon><infon key="section_type">REF</infon><infon key="source">GeoJournal</infon><infon key="type">ref</infon><infon key="volume">69</infon><infon key="year">2007</infon><offset>68820</offset><text>Citizens as sensors: The world of volunteered geography</text></passage><passage><infon key="fpage">231</infon><infon key="lpage">243</infon><infon key="name_0">surname:Granell;given-names:C.</infon><infon key="name_1">surname:Ostermann;given-names:F.O.</infon><infon key="pub-id_doi">10.1016/j.compenvurbsys.2016.01.006</infon><infon key="section_type">REF</infon><infon key="source">Comput. Environ. Urban Syst.</infon><infon key="type">ref</infon><infon key="volume">59</infon><infon key="year">2016</infon><offset>68876</offset><text>Beyond data collection: Objectives and methods of research using vgi and geo-social media for disaster management</text></passage><passage><infon key="fpage">139</infon><infon key="lpage">159</infon><infon key="name_0">surname:Goetz;given-names:M.</infon><infon key="name_1">surname:Zipf;given-names:A.</infon><infon key="section_type">REF</infon><infon key="source">Crowdsourcing Geographic Knowledge</infon><infon key="type">ref</infon><infon key="year">2013</infon><offset>68990</offset><text>The evolution of geo-crowdsourcing: Bringing volunteered geographic information to the third dimension</text></passage><passage><infon key="fpage">524</infon><infon key="lpage">538</infon><infon key="name_0">surname:Hudson-Smith;given-names:A.</infon><infon key="name_1">surname:Batty;given-names:M.</infon><infon key="name_2">surname:Crooks;given-names:A.</infon><infon key="name_3">surname:Milton;given-names:R.</infon><infon key="pub-id_doi">10.1177/0894439309332299</infon><infon key="section_type">REF</infon><infon key="source">Soc. Sci. Comput. Rev.</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2009</infon><offset>69093</offset><text>Mapping for the masses accessing web 2.0 through crowdsourcing</text></passage><passage><infon key="fpage">9800</infon><infon key="lpage">9822</infon><infon key="name_0">surname:Sagl;given-names:G.</infon><infon key="name_1">surname:Blaschke;given-names:T.</infon><infon key="name_2">surname:Beinat;given-names:E.</infon><infon key="name_3">surname:Resch;given-names:B.</infon><infon key="pub-id_doi">10.3390/s120709800</infon><infon key="pub-id_pmid">23012571</infon><infon key="section_type">REF</infon><infon key="source">Sensor</infon><infon key="type">ref</infon><infon key="volume">12</infon><infon key="year">2012</infon><offset>69156</offset><text>Ubiquitous geo-sensing for context-aware analysis: Exploring relationships between environmental and human dynamics</text></passage><passage><infon key="fpage">224015</infon><infon key="name_0">surname:Candia;given-names:J.</infon><infon key="name_1">surname:González;given-names:M.C.</infon><infon key="name_2">surname:Wang;given-names:P.</infon><infon key="name_3">surname:Schoenharl;given-names:T.</infon><infon key="name_4">surname:Madey;given-names:G.</infon><infon key="name_5">surname:Barabási;given-names:A.-L.</infon><infon key="pub-id_doi">10.1088/1751-8113/41/22/224015</infon><infon key="section_type">REF</infon><infon key="source">J. Phys. A Math. Theor.</infon><infon key="type">ref</infon><infon key="volume">41</infon><infon key="year">2008</infon><offset>69272</offset><text>Uncovering individual and collective human dynamics from mobile phone records</text></passage><passage><infon key="fpage">177376</infon><infon key="lpage">177386</infon><infon key="name_0">surname:Saldana-Perez;given-names:M.</infon><infon key="name_1">surname:Torres-Ruiz;given-names:M.</infon><infon key="name_2">surname:Moreno-Ibarra;given-names:M.</infon><infon key="pub-id_doi">10.1109/ACCESS.2019.2942586</infon><infon key="section_type">REF</infon><infon key="source">IEEE Access.</infon><infon key="type">ref</infon><infon key="volume">7</infon><infon key="year">2019</infon><offset>69350</offset><text>Geospatial Modeling of Road Traffic Using a Semi-Supervised Regression Algorithm</text></passage><passage><infon key="fpage">5586</infon><infon key="lpage">5590</infon><infon key="name_0">surname:Zhao;given-names:Q.</infon><infon key="name_1">surname:Kong;given-names:Q.</infon><infon key="name_2">surname:Xia;given-names:Y.</infon><infon key="name_3">surname:Liu;given-names:Y.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 30th Chinese Control Conference</infon><infon key="type">ref</infon><offset>69431</offset><text>An Improved Method for Estimating Urban Traffic State via Probe Vehicle Tracking</text></passage><passage><infon key="fpage">878</infon><infon key="lpage">892</infon><infon key="name_0">surname:Ramachandran;given-names:U.</infon><infon key="name_1">surname:Hong;given-names:K.</infon><infon key="name_2">surname:Iftode;given-names:L.</infon><infon key="name_3">surname:Jain;given-names:R.</infon><infon key="name_4">surname:Kumar;given-names:R.</infon><infon key="name_5">surname:Rothermel;given-names:K.</infon><infon key="name_6">surname:Shin;given-names:J.</infon><infon key="name_7">surname:Sivakumar;given-names:R.</infon><infon key="pub-id_doi">10.1109/JPROC.2011.2182093</infon><infon key="section_type">REF</infon><infon key="source">Proc. IEEE</infon><infon key="type">ref</infon><infon key="volume">100</infon><infon key="year">2012</infon><offset>69512</offset><text>Large-scale situation awareness with camera networks and multimodal sensing</text></passage><passage><infon key="fpage">93</infon><infon key="lpage">117</infon><infon key="name_0">surname:Bacon;given-names:J.</infon><infon key="name_1">surname:Bejan;given-names:A.I.</infon><infon key="name_2">surname:Beresford;given-names:A.R.</infon><infon key="name_3">surname:Evans;given-names:D.</infon><infon key="name_4">surname:Gibbens;given-names:R.J.</infon><infon key="name_5">surname:Moody;given-names:K.</infon><infon key="section_type">REF</infon><infon key="source">Dependable and Historic Computing</infon><infon key="type">ref</infon><infon key="year">2011</infon><offset>69588</offset><text>Using Real-time Road Traffic Data to Evaluate Congestion</text></passage><passage><infon key="fpage">130</infon><infon key="lpage">136</infon><infon key="name_0">surname:Rong;given-names:Y.</infon><infon key="name_1">surname:Guoxiang;given-names:W.</infon><infon key="name_2">surname:Zheng;given-names:J.</infon><infon key="name_3">surname:Haiyan;given-names:W.</infon><infon key="section_type">REF</infon><infon key="source">J. Transp. Syst. Eng. Inf. Technol.</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2013</infon><offset>69645</offset><text>Urban road traffic condition pattern recognition based on support vector machine</text></passage><passage><infon key="fpage">189</infon><infon key="lpage">198</infon><infon key="name_0">surname:Haworth;given-names:B.</infon><infon key="pub-id_doi">10.1016/j.compenvurbsys.2016.02.009</infon><infon key="section_type">REF</infon><infon key="source">Comput. Environ. Urban Syst.</infon><infon key="type">ref</infon><infon key="volume">57</infon><infon key="year">2016</infon><offset>69726</offset><text>Emergency management perspectives on volunteered geographic information: Opportunities, challenges and change</text></passage><passage><infon key="fpage">61</infon><infon key="lpage">70</infon><infon key="name_0">surname:Backstrom;given-names:L.</infon><infon key="name_1">surname:Sun;given-names:E.</infon><infon key="name_2">surname:Marlow;given-names:C.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 19th International Conference on World Wide Web</infon><infon key="type">ref</infon><offset>69836</offset><text>Find Me If You Can: Improving Geographical Prediction with Social and Spatial Proximity</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">24</infon><infon key="name_0">surname:Essien;given-names:A.</infon><infon key="name_1">surname:Petrounias;given-names:I.</infon><infon key="name_2">surname:Sampaio;given-names:P.</infon><infon key="name_3">surname:Sampaio;given-names:S.</infon><infon key="pub-id_doi">10.1007/s11280-020-00800-3</infon><infon key="section_type">REF</infon><infon key="source">World Wide Web.</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>69924</offset><text>A deep-learning model for urban traffic flow prediction with traffic events mined from twitter</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">16</infon><infon key="name_0">surname:Alomari;given-names:E.</infon><infon key="name_1">surname:Katib;given-names:I.</infon><infon key="name_2">surname:Mehmood;given-names:R.</infon><infon key="pub-id_doi">10.1007/s11036-020-01635-y</infon><infon key="section_type">REF</infon><infon key="source">Mob. Netw. Appl.</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>70019</offset><text>Iktishaf: A big data road-traffic event detection tool using Twitter and spark machine learning</text></passage><passage><infon key="fpage">04020059</infon><infon key="name_0">surname:Sujon;given-names:M.</infon><infon key="name_1">surname:Dai;given-names:F.</infon><infon key="pub-id_doi">10.1061/(ASCE)CP.1943-5487.0000943</infon><infon key="section_type">REF</infon><infon key="source">J. Comput. Civ. Eng.</infon><infon key="type">ref</infon><infon key="volume">35</infon><infon key="year">2021</infon><offset>70115</offset><text>Social Media Mining for Understanding Traffic Safety Culture in Washington State Using Twitter Data</text></passage><passage><infon key="fpage">102938</infon><infon key="name_0">surname:Yao;given-names:W.</infon><infon key="name_1">surname:Qian;given-names:S.</infon><infon key="pub-id_doi">10.1016/j.trc.2020.102938</infon><infon key="section_type">REF</infon><infon key="source">Transp. Res. Part C Emerg. Technol.</infon><infon key="type">ref</infon><infon key="volume">124</infon><infon key="year">2021</infon><offset>70215</offset><text>From Twitter to traffic predictor: Next-day morning traffic prediction using social media data</text></passage><passage><infon key="fpage">527</infon><infon key="lpage">534</infon><infon key="name_0">surname:Noori;given-names:M.A.R.</infon><infon key="name_1">surname:Mehra;given-names:R.</infon><infon key="section_type">REF</infon><infon key="source">ICT Analysis and Applications</infon><infon key="type">ref</infon><infon key="year">2021</infon><offset>70310</offset><text>Traffic Congestion Detection from Twitter Using word2vec</text></passage><passage><infon key="elocation-id">2020</infon><infon key="name_0">surname:Zambrano-Martinez;given-names:J.L.</infon><infon key="name_1">surname:Calafate;given-names:C.T.</infon><infon key="name_2">surname:Soler;given-names:D.</infon><infon key="name_3">surname:Cano;given-names:J.C.</infon><infon key="name_4">surname:Manzoni;given-names:P.</infon><infon key="pub-id_doi">10.3390/s18072020</infon><infon key="section_type">REF</infon><infon key="source">Sensors</infon><infon key="type">ref</infon><infon key="volume">18</infon><infon key="year">2018</infon><offset>70367</offset><text>Modeling and characterization of traffic flows in urban environments</text></passage><passage><infon key="fpage">385</infon><infon key="lpage">394</infon><infon key="name_0">surname:Van Hinsbergen;given-names:C.P.</infon><infon key="name_1">surname:Schreiter;given-names:T.</infon><infon key="name_2">surname:Zuurbier;given-names:F.S.</infon><infon key="name_3">surname:Van Lint;given-names:J.W.C.</infon><infon key="name_4">surname:Van Zuylen;given-names:H.J.</infon><infon key="pub-id_doi">10.1109/TITS.2011.2175728</infon><infon key="section_type">REF</infon><infon key="source">Ieee Trans. Intell. Transp. Syst.</infon><infon key="type">ref</infon><infon key="volume">13</infon><infon key="year">2012</infon><offset>70436</offset><text>Localized extended kalman filter for scalable real-time traffic state estimation</text></passage><passage><infon key="fpage">62</infon><infon key="lpage">69</infon><infon key="name_0">surname:Sheppard;given-names:S.A.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 1st ACM SIGSPATIAL International Workshop on Crowdsourced and Volunteered Geographic Information</infon><infon key="type">ref</infon><offset>70517</offset><text>Wq: A Modular Framework for Collecting, Storing, and Utilizing Experiential VGI</text></passage><passage><infon key="fpage">217</infon><infon key="lpage">227</infon><infon key="name_0">surname:Newman;given-names:G.</infon><infon key="name_1">surname:Graham;given-names:J.</infon><infon key="name_2">surname:Crall;given-names:A.</infon><infon key="name_3">surname:Laituri;given-names:M.</infon><infon key="pub-id_doi">10.1016/j.ecoinf.2011.03.002</infon><infon key="section_type">REF</infon><infon key="source">Ecol. Inform.</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2011</infon><offset>70597</offset><text>The art and science of multi-scale citizen science support</text></passage><passage><infon key="fpage">1928</infon><infon key="lpage">1946</infon><infon key="name_0">surname:Christin;given-names:D.</infon><infon key="name_1">surname:Reinhardt;given-names:A.</infon><infon key="name_2">surname:Kanhere;given-names:S.S.</infon><infon key="name_3">surname:Hollick;given-names:M.</infon><infon key="pub-id_doi">10.1016/j.jss.2011.06.073</infon><infon key="section_type">REF</infon><infon key="source">J. Syst. Softw.</infon><infon key="type">ref</infon><infon key="volume">84</infon><infon key="year">2011</infon><offset>70656</offset><text>A survey on privacy in mobile participatory sensing applications</text></passage><passage><infon key="fpage">248</infon><infon key="lpage">260</infon><infon key="name_0">surname:Hughes;given-names:A.L.</infon><infon key="name_1">surname:Palen;given-names:L.</infon><infon key="pub-id_doi">10.1504/IJEM.2009.031564</infon><infon key="section_type">REF</infon><infon key="source">Int. J. Emerg. Manag.</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2009</infon><offset>70721</offset><text>Twitter adoption and use in mass convergence and emergency events</text></passage><passage><infon key="fpage">105</infon><infon key="lpage">120</infon><infon key="name_0">surname:Oussalah;given-names:M.</infon><infon key="name_1">surname:Bhat;given-names:F.</infon><infon key="name_2">surname:Challis;given-names:K.</infon><infon key="name_3">surname:Schnier;given-names:T.</infon><infon key="pub-id_doi">10.1016/j.knosys.2012.07.017</infon><infon key="section_type">REF</infon><infon key="source">Knowl. Based Syst.</infon><infon key="type">ref</infon><infon key="volume">37</infon><infon key="year">2013</infon><offset>70787</offset><text>A software architecture for twitter collection, search and geolocation services</text></passage><passage><infon key="fpage">851</infon><infon key="lpage">860</infon><infon key="name_0">surname:Sakaki;given-names:T.</infon><infon key="name_1">surname:Okazaki;given-names:M.</infon><infon key="name_2">surname:Matsuo;given-names:Y.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 19th International Conference on World Wide Web</infon><infon key="type">ref</infon><offset>70867</offset><text>Earthquake Shakes Twitter Users: Real-time Event Detection by Social Sensors</text></passage><passage><infon key="fpage">25</infon><infon key="lpage">51</infon><infon key="name_0">surname:Kitamura;given-names:R.</infon><infon key="name_1">surname:Chen;given-names:C.</infon><infon key="name_2">surname:Pendyala;given-names:R.M.</infon><infon key="name_3">surname:Narayanan;given-names:R.</infon><infon key="pub-id_doi">10.1023/A:1005259324588</infon><infon key="section_type">REF</infon><infon key="source">Transportation</infon><infon key="type">ref</infon><infon key="volume">27</infon><infon key="year">2000</infon><offset>70944</offset><text>Micro-simulation of daily activity-travel patterns for travel demand forecasting</text></passage><passage><infon key="fpage">321</infon><infon key="lpage">342</infon><infon key="name_0">surname:Gu;given-names:Y.</infon><infon key="name_1">surname:Qian;given-names:Z.S.</infon><infon key="name_2">surname:Chen;given-names:F.</infon><infon key="pub-id_doi">10.1016/j.trc.2016.02.011</infon><infon key="section_type">REF</infon><infon key="source">Transp. Res. Part C Emerg. Technol.</infon><infon key="type">ref</infon><infon key="volume">67</infon><infon key="year">2016</infon><offset>71025</offset><text>From Twitter to detector: Real-time traffic incident detection using social media data</text></passage><passage><infon key="fpage">57</infon><infon key="lpage">69</infon><infon key="name_0">surname:Albuquerque;given-names:F.C.</infon><infon key="name_1">surname:Casanova;given-names:M.A.</infon><infon key="name_2">surname:Lopes;given-names:H.</infon><infon key="name_3">surname:Redlich;given-names:L.R.</infon><infon key="name_4">surname:de Macedo;given-names:J.A.F.</infon><infon key="name_5">surname:Lemos;given-names:M.</infon><infon key="name_6">surname:Renso;given-names:C.</infon><infon key="pub-id_doi">10.1016/j.compind.2015.10.005</infon><infon key="section_type">REF</infon><infon key="source">Comput. Ind.</infon><infon key="type">ref</infon><infon key="volume">78</infon><infon key="year">2016</infon><offset>71112</offset><text>A methodology for traffic-related Twitter messages interpretation</text></passage><passage><infon key="fpage">735</infon><infon key="lpage">751</infon><infon key="name_0">surname:Davis;given-names:C.A.;suffix:Jr.</infon><infon key="name_1">surname:Pappa;given-names:G.L.</infon><infon key="name_2">surname:de Oliveira;given-names:D.R.R.</infon><infon key="name_3">surname:de L Arcanjo;given-names:F.</infon><infon key="pub-id_doi">10.1111/j.1467-9671.2011.01297.x</infon><infon key="section_type">REF</infon><infon key="source">Trans. Gis</infon><infon key="type">ref</infon><infon key="volume">15</infon><infon key="year">2011</infon><offset>71178</offset><text>Inferring the location of twitter messages based on user relationships</text></passage><passage><infon key="fpage">144</infon><infon key="lpage">157</infon><infon key="name_0">surname:Spiliopoulou;given-names:A.</infon><infon key="name_1">surname:Papamichail;given-names:I.</infon><infon key="name_2">surname:Papageorgiou;given-names:M.</infon><infon key="name_3">surname:Tyrinopoulos;given-names:I.</infon><infon key="name_4">surname:Chrysoulakis;given-names:J.</infon><infon key="pub-id_doi">10.1016/j.trpro.2015.03.012</infon><infon key="section_type">REF</infon><infon key="source">Transp. Res. Procedia</infon><infon key="type">ref</infon><infon key="volume">6</infon><infon key="year">2015</infon><offset>71249</offset><text>Macroscopic traffic flow model calibration using different optimization algorithms</text></passage><passage><infon key="fpage">29</infon><infon key="lpage">55</infon><infon key="name_0">surname:Geisler;given-names:S.</infon><infon key="name_1">surname:Quix;given-names:C.</infon><infon key="name_2">surname:Schiffer;given-names:S.</infon><infon key="name_3">surname:Jarke;given-names:M.</infon><infon key="pub-id_doi">10.1016/j.trc.2011.08.003</infon><infon key="section_type">REF</infon><infon key="source">Transp. Res. Part C Emerg. Technol.</infon><infon key="type">ref</infon><infon key="volume">23</infon><infon key="year">2012</infon><offset>71332</offset><text>An evaluation frame- work for traffic information systems based on data streams</text></passage><passage><infon key="fpage">344</infon><infon key="lpage">353</infon><infon key="name_0">surname:Pan;given-names:B.</infon><infon key="name_1">surname:Zheng;given-names:Y.</infon><infon key="name_2">surname:Wilkie;given-names:D.</infon><infon key="name_3">surname:Shahabi;given-names:C.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 21st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems</infon><infon key="type">ref</infon><offset>71412</offset><text>Crowd Sensing of Traffic Anomalies Based on Human Mobility and Social Media</text></passage><passage><infon key="fpage">5</infon><infon key="lpage">11</infon><infon key="name_0">surname:Ribeiro;given-names:S.S.;suffix:Jr.</infon><infon key="name_1">surname:Davis;given-names:C.A.;suffix:Jr.</infon><infon key="name_2">surname:Oliveira;given-names:D.R.R.</infon><infon key="name_3">surname:Meira;given-names:W.;suffix:Jr.</infon><infon key="name_4">surname:Gonçalves;given-names:T.S.</infon><infon key="name_5">surname:Pappa;given-names:G.L.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the 5th ACM SIGSPATIAL International Workshop on Location-Based Social Networks</infon><infon key="type">ref</infon><offset>71488</offset><text>Traffic Observatory: A System to Detect and Locate Traffic Events and Conditions Using Twitter</text></passage><passage><infon key="fpage">219</infon><infon key="lpage">234</infon><infon key="name_0">surname:Kokkinogenis;given-names:Z.</infon><infon key="name_1">surname:Filguieras;given-names:J.</infon><infon key="name_2">surname:Carvalho;given-names:S.</infon><infon key="name_3">surname:Sarmento;given-names:L.</infon><infon key="name_4">surname:Rossetti;given-names:R.J.</infon><infon key="section_type">REF</infon><infon key="source">Advances in Artificial Transportation Systems and Simulation</infon><infon key="type">ref</infon><infon key="year">2015</infon><offset>71583</offset><text>Mobility Network Evaluation in the User Perspective: Real-time Sensing of Traffic Information in Twitter Messages</text></passage><passage><infon key="fpage">276</infon><infon key="lpage">285</infon><infon key="name_0">surname:Necula;given-names:E.</infon><infon key="pub-id_doi">10.1016/j.trpro.2015.09.077</infon><infon key="section_type">REF</infon><infon key="source">Transp. Res. Procedia</infon><infon key="type">ref</infon><infon key="volume">10</infon><infon key="year">2015</infon><offset>71697</offset><text>Analyzing traffic patterns on street segments based on GPS data using R</text></passage><passage><infon key="fpage">169</infon><infon key="lpage">188</infon><infon key="name_0">surname:Kinoshita;given-names:A.</infon><infon key="name_1">surname:Takasu;given-names:A.</infon><infon key="name_2">surname:Adachi;given-names:J.</infon><infon key="pub-id_doi">10.1016/j.is.2015.07.002</infon><infon key="section_type">REF</infon><infon key="source">Inf. Syst.</infon><infon key="type">ref</infon><infon key="volume">54</infon><infon key="year">2015</infon><offset>71769</offset><text>Real-time traffic incident detection using a probabilistic topic model</text></passage><passage><infon key="fpage">322</infon><infon key="lpage">332</infon><infon key="name_0">surname:Li;given-names:D.</infon><infon key="name_1">surname:Hu;given-names:G.</infon><infon key="name_2">surname:Wang;given-names:Y.</infon><infon key="name_3">surname:Pan;given-names:Z.</infon><infon key="pub-id_doi">10.1016/j.neucom.2014.10.061</infon><infon key="section_type">REF</infon><infon key="source">Neurocomputing</infon><infon key="type">ref</infon><infon key="volume">152</infon><infon key="year">2015</infon><offset>71840</offset><text>Network traffic classification via non-convex multi-task feature learning</text></passage><passage><infon key="fpage">206</infon><infon key="lpage">211</infon><infon key="name_0">surname:Tahilyani;given-names:S.</infon><infon key="name_1">surname:Darbari;given-names:M.</infon><infon key="name_2">surname:Shukla;given-names:P.K.</infon><infon key="pub-id_doi">10.1016/j.aasri.2013.10.032</infon><infon key="section_type">REF</infon><infon key="source">Aasri Procedia</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2013</infon><offset>71914</offset><text>Soft computing approaches in traffic control systems: A review</text></passage><passage><infon key="fpage">258</infon><infon key="lpage">265</infon><infon key="name_0">surname:Liebig;given-names:T.</infon><infon key="name_1">surname:Piatkowski;given-names:N.</infon><infon key="name_2">surname:Bockermann;given-names:C.</infon><infon key="name_3">surname:Morik;given-names:K.</infon><infon key="pub-id_doi">10.1016/j.is.2016.01.007</infon><infon key="section_type">REF</infon><infon key="source">Inf. Syst.</infon><infon key="type">ref</infon><infon key="volume">64</infon><infon key="year">2017</infon><offset>71977</offset><text>Dynamic route planning with real-time traffic predictions</text></passage><passage><infon key="fpage">6164</infon><infon key="lpage">6173</infon><infon key="name_0">surname:Castro-Neto;given-names:M.</infon><infon key="name_1">surname:Jeong;given-names:Y.-S.</infon><infon key="name_2">surname:Jeong;given-names:M.-K.</infon><infon key="name_3">surname:Han;given-names:L.D.</infon><infon key="pub-id_doi">10.1016/j.eswa.2008.07.069</infon><infon key="section_type">REF</infon><infon key="source">Expert Syst. Appl.</infon><infon key="type">ref</infon><infon key="volume">36</infon><infon key="year">2009</infon><offset>72035</offset><text>Online-svr for short-term traffic flow prediction under typical and atypical traffic conditions</text></passage><passage><infon key="fpage">69</infon><infon key="lpage">72</infon><infon key="name_0">surname:Bird;given-names:S.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions</infon><infon key="type">ref</infon><offset>72131</offset><text>NLTK: The Natural Language Toolkit. 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</text></passage><passage><infon key="fpage">14</infon><infon key="lpage">25</infon><infon key="name_0">surname:Salazar;given-names:J.C.</infon><infon key="name_1">surname:Torres-Ruiz;given-names:M.</infon><infon key="name_2">surname:Davis;given-names:C.A.;suffix:Jr.</infon><infon key="name_3">surname:Moreno-Ibarra;given-names:M.</infon><infon key="section_type">REF</infon><infon key="series">GEOINFO Series</infon><infon key="source">Proceedings of the XVI Brazilian Symposium of Geoinformatics GEOINFO</infon><infon key="type">ref</infon><offset>72299</offset><text>Geocoding of Traffic-related Events from Twitter</text></passage><passage><infon key="fpage">1</infon><infon key="lpage">27</infon><infon key="name_0">surname:Chang;given-names:C.C.</infon><infon key="name_1">surname:Lin;given-names:C.J.</infon><infon key="pub-id_doi">10.1145/1961189.1961199</infon><infon key="section_type">REF</infon><infon key="source">Acm Trans. Intell. Syst. Technol. (Tist)</infon><infon key="type">ref</infon><infon key="volume">2</infon><infon key="year">2011</infon><offset>72348</offset><text>LIBSVM: A library for support vector machines</text></passage><passage><infon key="fpage">110</infon><infon key="lpage">120</infon><infon key="name_0">surname:Goodchild;given-names:M.F.</infon><infon key="name_1">surname:Li;given-names:L.</infon><infon key="pub-id_doi">10.1016/j.spasta.2012.03.002</infon><infon key="section_type">REF</infon><infon key="source">Spat. Stat.</infon><infon key="type">ref</infon><infon key="volume">1</infon><infon key="year">2012</infon><offset>72394</offset><text>Assuring the quality of volunteered geographic information</text></passage><passage><infon key="fpage">234</infon><infon key="issue">Suppl. 1</infon><infon key="lpage">240</infon><infon key="name_0">surname:Tobler;given-names:W.R.</infon><infon key="pub-id_doi">10.2307/143141</infon><infon key="section_type">REF</infon><infon key="source">Econ. Geogr.</infon><infon key="type">ref</infon><infon key="volume">46</infon><infon key="year">1970</infon><offset>72453</offset><text>A computer movie simulating urban growth in the Detroit region</text></passage><passage><infon key="fpage">71</infon><infon key="lpage">79</infon><infon key="name_0">surname:Mendoza;given-names:M.</infon><infon key="name_1">surname:Poblete;given-names:B.</infon><infon key="name_2">surname:Castillo;given-names:C.</infon><infon key="section_type">REF</infon><infon key="source">Proceedings of the First Workshop on Social Media Analytics</infon><infon key="type">ref</infon><offset>72516</offset><text>Twitter Under Crisis: Can We Trust What We RT?</text></passage><passage><infon key="file">sensors-21-02964-g001.jpg</infon><infon key="id">sensors-21-02964-f001</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>72563</offset><text>The general framework of the proposed approach.</text></passage><passage><infon key="file">sensors-21-02964-g002.jpg</infon><infon key="id">sensors-21-02964-f002</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>72611</offset><text>Computing of the lists with most frequent N-grams by the script.</text></passage><passage><infon key="file">sensors-21-02964-g003.jpg</infon><infon key="id">sensors-21-02964-f003</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>72676</offset><text>Creation of dictionaries based on information analysis.</text></passage><passage><infon key="file">sensors-21-02964-g004.jpg</infon><infon key="id">sensors-21-02964-f004</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>72732</offset><text>Examples of common traffic-related events that appear in tweets and the number of geographic elements detected with the proposed approach.</text></passage><passage><infon key="file">sensors-21-02964-g005.jpg</infon><infon key="id">sensors-21-02964-f005</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>72871</offset><text>Relation of traffic-related events with Twitter.</text></passage><passage><infon key="file">sensors-21-02964-g006.jpg</infon><infon key="id">sensors-21-02964-f006</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>72920</offset><text>Comparison between predicted and geocoded traffic-related events.</text></passage><passage><infon key="file">sensors-21-02964-g007.jpg</infon><infon key="id">sensors-21-02964-f007</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>72986</offset><text>Traffic-related events that were obtained from the spatiotemporal analysis.</text></passage><passage><infon key="file">sensors-21-02964-g008.jpg</infon><infon key="id">sensors-21-02964-f008</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>73062</offset><text>Traffic events represented by a heat map.</text></passage><passage><infon key="file">sensors-21-02964-g009.jpg</infon><infon key="id">sensors-21-02964-f009</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>73104</offset><text>A general schema for the empirical testing of the prediction model.</text></passage><passage><infon key="file">sensors-21-02964-g010.jpg</infon><infon key="id">sensors-21-02964-f010</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>73172</offset><text>Relationship between the size of the training dataset and the precision, recall, and F-measure.</text></passage><passage><infon key="file">sensors-21-02964-t001.xml</infon><infon key="id">sensors-21-02964-t001</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>73268</offset><text>Common traffic conditions and events mentioned in the tweet dataset.</text></passage><passage><infon key="file">sensors-21-02964-t001.xml</infon><infon key="id">sensors-21-02964-t001</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Traffic Condition and Event&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Number of Occurrences/Count&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Emergency service&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;378&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Rollover&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;612&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Accident&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1162&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Flooding&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;432&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Car crash&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1312&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Emergency in place&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;508&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Broken car&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1002&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Vehicular congestion&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;570&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Traffic signals out of service&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;241&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Blocked road&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;4377&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Still close&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1053&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Heavy traffic&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1423&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Slow displacement&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2779&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Road work&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1225&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Road close&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2521&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Traffic jam&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1423&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Bumper to bumper&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;2246&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Gridlock&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1101&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>73337</offset><text>Traffic Condition and Event	Number of Occurrences/Count	 	Emergency service	378	 	Rollover	612	 	Accident	1162	 	Flooding	432	 	Car crash	1312	 	Emergency in place	508	 	Broken car	1002	 	Vehicular congestion	570	 	Traffic signals out of service	241	 	Blocked road	4377	 	Still close	1053	 	Heavy traffic	1423	 	Slow displacement	2779	 	Road work	1225	 	Road close	2521	 	Traffic jam	1423	 	Bumper to bumper	2246	 	Gridlock	1101	 	</text></passage><passage><infon key="file">sensors-21-02964-t002.xml</infon><infon key="id">sensors-21-02964-t002</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>73769</offset><text>The process to find traffic-related events with the relationship (line, line, line).</text></passage><passage><infon key="file">sensors-21-02964-t002.xml</infon><infon key="id">sensors-21-02964-t002</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Pseudocode to Find the Relationship&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;&amp;gt; While all the possible combinations of elements are not tested:&lt;break/&gt;&amp;gt; Is there intersection of &lt;italic&gt;A&lt;/italic&gt; element and &lt;italic&gt;B&lt;/italic&gt; element: (operation 1)&lt;break/&gt;&amp;gt; Save it.&lt;break/&gt;&amp;gt; Are there two intersections?&lt;break/&gt;&amp;gt; Yes: Is there an element in common from the two intersections?&lt;break/&gt;&amp;gt; Yes: Find the bounding box (or convex hull) of the element in common delimited by the&lt;break/&gt; two intersections. (operation 3)&lt;break/&gt;&amp;gt; No: Check (line, line) relationship.&lt;break/&gt;&amp;gt; No: Check (line, line) relationship.&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>73854</offset><text>Pseudocode to Find the Relationship	 	&gt; While all the possible combinations of elements are not tested:&gt; Is there intersection of A element and B element: (operation 1)&gt; Save it.&gt; Are there two intersections?&gt; Yes: Is there an element in common from the two intersections?&gt; Yes: Find the bounding box (or convex hull) of the element in common delimited by the two intersections. (operation 3)&gt; No: Check (line, line) relationship.&gt; No: Check (line, line) relationship.	 	</text></passage><passage><infon key="file">sensors-21-02964-t003.xml</infon><infon key="id">sensors-21-02964-t003</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>74326</offset><text>Selected features and possible values.</text></passage><passage><infon key="file">sensors-21-02964-t003.xml</infon><infon key="id">sensors-21-02964-t003</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Feature&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Possible Value&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Description&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Month&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[1,…,12]&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Month of the year when a tweet was posted&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Day of month&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[1,…,31]&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Day of the month when a tweet was posted&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Day of week&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0,…,6]&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Day of the week when the tweet was posted. 0 is for Sunday and 6 for Saturday&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Hour of the day&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;[0,…,23]&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Hour of the day when a tweet was posted&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>74365</offset><text>Feature	Possible Value	Description	 	Month	[1,…,12]	Month of the year when a tweet was posted	 	Day of month	[1,…,31]	Day of the month when a tweet was posted	 	Day of week	[0,…,6]	Day of the week when the tweet was posted. 0 is for Sunday and 6 for Saturday	 	Hour of the day	[0,…,23]	Hour of the day when a tweet was posted	 	</text></passage><passage><infon key="file">sensors-21-02964-t004.xml</infon><infon key="id">sensors-21-02964-t004</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>74702</offset><text>Defined parameters in the SVR library in order to characterize the prediction model.</text></passage><passage><infon key="file">sensors-21-02964-t004.xml</infon><infon key="id">sensors-21-02964-t004</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Parameter&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Description&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Value&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;italic&gt;C&lt;/italic&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Penalty parameter &lt;italic&gt;C&lt;/italic&gt; of the error term.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;italic&gt;Epsilon&lt;/italic&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;It specifies the ε-tube within no penalty and is associated in the training loss function with points predicted within a distance &lt;italic&gt;epsilon&lt;/italic&gt; from the actual value.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;italic&gt;Kernel&lt;/italic&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;It specifies the kernel type to be used in the algorithm. It must be &lt;italic&gt;linear&lt;/italic&gt;, &lt;italic&gt;poly&lt;/italic&gt;, &lt;italic&gt;rbf&lt;/italic&gt;, &lt;italic&gt;sigmoid&lt;/italic&gt;, &lt;italic&gt;precomputed&lt;/italic&gt;, or &lt;italic&gt;callable.&lt;/italic&gt;&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;rbf&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;italic&gt;Gamma&lt;/italic&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Kernel coefficient for &lt;italic&gt;rbf&lt;/italic&gt;, &lt;italic&gt;poly&lt;/italic&gt;, and &lt;italic&gt;sigmoid&lt;/italic&gt;. If &lt;italic&gt;gamma&lt;/italic&gt; is automatic, then 1/n features will be used instead.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;auto&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;italic&gt;Shrinking&lt;/italic&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Whether to use the shrinking heuristic.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;true&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;italic&gt;Tol&lt;/italic&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Tolerance for stopping criterion.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1&lt;italic&gt;e&lt;/italic&gt;−∍&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;
&lt;italic&gt;Max_iter&lt;/italic&gt;
&lt;/td&gt;&lt;td align=&quot;left&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;rd limit on iterations within solver, or −1 for no limit.&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;−1&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>74787</offset><text>Parameter	Description	Value	 	C	Penalty parameter C of the error term.	1.0	 	Epsilon	It specifies the ε-tube within no penalty and is associated in the training loss function with points predicted within a distance epsilon from the actual value.	0.1	 	Kernel	It specifies the kernel type to be used in the algorithm. It must be linear, poly, rbf, sigmoid, precomputed, or callable.	rbf	 	Gamma	Kernel coefficient for rbf, poly, and sigmoid. If gamma is automatic, then 1/n features will be used instead.	auto	 	Shrinking	Whether to use the shrinking heuristic.	true	 	Tol	Tolerance for stopping criterion.	1e−∍	 	Max_iter	rd limit on iterations within solver, or −1 for no limit.	−1	 	</text></passage><passage><infon key="file">sensors-21-02964-t005.xml</infon><infon key="id">sensors-21-02964-t005</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>75482</offset><text>Traffic-related Twitter accounts covering Mexico City.</text></passage><passage><infon key="file">sensors-21-02964-t005.xml</infon><infon key="id">sensors-21-02964-t005</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Twitter &lt;break/&gt;Account&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Geographic Location&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Creation Date&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Number of Followers&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Number of Tweets&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Government&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Supervia_CDMX&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mexico City&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;07.14.2010&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;19,900&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;29.6 K&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;PolloVial&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mexico City&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;01.31.2013&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;719&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;376.6 K&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Trafico889&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mexico City&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;05.14.2009&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;864,500&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;638.1 K&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;AlerTux&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mexico City&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10.16.2012&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;482,500&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;623.3 K&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;072AvialCDMX&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mexico City&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;10.20.2010&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;221,700&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1.5 M&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Yes&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;RedVialRC&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mexico City&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;03.09.2010&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;186,500&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;201.2 K&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;No&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>75537</offset><text>Twitter Account	Geographic Location	Creation Date	Number of Followers	Number of Tweets	Government	 	Supervia_CDMX	Mexico City	07.14.2010	19,900	29.6 K	Yes	 	PolloVial	Mexico City	01.31.2013	719	376.6 K	No	 	Trafico889	Mexico City	05.14.2009	864,500	638.1 K	No	 	AlerTux	Mexico City	10.16.2012	482,500	623.3 K	No	 	072AvialCDMX	Mexico City	10.20.2010	221,700	1.5 M	Yes	 	RedVialRC	Mexico City	03.09.2010	186,500	201.2 K	No	 	</text></passage><passage><infon key="file">sensors-21-02964-t006.xml</infon><infon key="id">sensors-21-02964-t006</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>75962</offset><text>Results of the evaluation task, applying precision and recall measures.</text></passage><passage><infon key="file">sensors-21-02964-t006.xml</infon><infon key="id">sensors-21-02964-t006</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Description of Elements&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Baseline&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;First &lt;break/&gt;Evaluation&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Second Evaluation&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Third &lt;break/&gt;Evaluation&lt;/th&gt;&lt;th align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-top:solid thin;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Test Dataset&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;All elements found&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;152&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;152&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;427&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;456&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;652&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;At least one element found&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;289&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;388&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;599&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;608&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;652&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Mistakes&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;363&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;264&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;53&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;44&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Precision&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.39&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.43&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.83&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.85&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;Recall&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.31&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.39&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.80&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;0.83&lt;/td&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; style=&quot;border-bottom:solid thin&quot; rowspan=&quot;1&quot; colspan=&quot;1&quot;&gt;1.0&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>76034</offset><text>Description of Elements	Baseline	First Evaluation	Second Evaluation	Third Evaluation	Test Dataset	 	All elements found	152	152	427	456	652	 	At least one element found	289	388	599	608	652	 	Mistakes	363	264	53	44	0.0	 	Precision	0.39	0.43	0.83	0.85	1.0	 	Recall	0.31	0.39	0.80	0.83	1.0	 	</text></passage></document></collection>
