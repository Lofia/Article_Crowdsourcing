<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE collection SYSTEM "BioC.dtd">
<collection><source>PMC</source><date>20220201</date><key>pmc.key</key><document><id>8783177</id><infon key="license">CC BY</infon><passage><infon key="article-id_doi">10.1186/s13643-021-01880-6</infon><infon key="article-id_pmc">8783177</infon><infon key="article-id_pmid">35065679</infon><infon key="article-id_publisher-id">1880</infon><infon key="elocation-id">15</infon><infon key="kwd">Machine learning Study classifiers Searching Information retrieval Methods/methodology Systematic reviews Automation Crowdsourcing Cochrane Library COVID-19</infon><infon key="license">Open AccessThis article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</infon><infon key="name_0">surname:Shemilt;given-names:Ian</infon><infon key="name_1">surname:Noel-Storr;given-names:Anna</infon><infon key="name_2">surname:Thomas;given-names:James</infon><infon key="name_3">surname:Featherstone;given-names:Robin</infon><infon key="name_4">surname:Mavergames;given-names:Chris</infon><infon key="section_type">TITLE</infon><infon key="title">Keywords</infon><infon key="type">front</infon><infon key="volume">11</infon><infon key="year">2022</infon><offset>0</offset><text>Machine learning reduced workload for the Cochrane COVID-19 Study Register: development and evaluation of the Cochrane COVID-19 Study Classifier</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>145</offset><text>Background</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>156</offset><text>This study developed, calibrated and evaluated a machine learning (ML) classifier designed to reduce study identification workload in maintaining the Cochrane COVID-19 Study Register (CCSR), a continuously updated register of COVID-19 research studies.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>409</offset><text>Methods</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>417</offset><text>A ML classifier for retrieving COVID-19 research studies (the ‘Cochrane COVID-19 Study Classifier’) was developed using a data set of title-abstract records ‘included’ in, or ‘excluded’ from, the CCSR up to 18th October 2020, manually labelled by information and data curation specialists or the Cochrane Crowd. The classifier was then calibrated using a second data set of similar records ‘included’ in, or ‘excluded’ from, the CCSR between October 19 and December 2, 2020, aiming for 99% recall. Finally, the calibrated classifier was evaluated using a third data set of similar records ‘included’ in, or ‘excluded’ from, the CCSR between the 4th and 19th of January 2021.</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>1120</offset><text>Results</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>1128</offset><text>The Cochrane COVID-19 Study Classifier was trained using 59,513 records (20,878 of which were ‘included’ in the CCSR). A classification threshold was set using 16,123 calibration records (6005 of which were ‘included’ in the CCSR) and the classifier had a precision of 0.52 in this data set at the target threshold recall &gt;0.99. The final, calibrated COVID-19 classifier correctly retrieved 2285 (98.9%) of 2310 eligible records but missed 25 (1%), with a precision of 0.638 and a net screening workload reduction of 24.1% (1113 records correctly excluded).</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract_title_1</infon><offset>1694</offset><text>Conclusions</text></passage><passage><infon key="section_type">ABSTRACT</infon><infon key="type">abstract</infon><offset>1706</offset><text>The Cochrane COVID-19 Study Classifier reduces manual screening workload for identifying COVID-19 research studies, with a very low and acceptable risk of missing eligible studies. It is now deployed in the live study identification workflow for the Cochrane COVID-19 Study Register.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">title_1</infon><offset>1990</offset><text>Background</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2001</offset><text>The COVID-19 pandemic has resulted in an unprecedented level of article publications of which only a small percentage report study data or analytics. This presented the systematic review community with significant challenges to identify and classify relevant study evidence reliably, accurately, and efficiently, to enable the rapid synthesis and use of cumulative bodies of evidence to inform international, national and local responses to the evolving global health crisis.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>2477</offset><text>As the pandemic took hold, a number of initiatives were started with the aim of identifying and classifying COVID-19 research. Two such initiatives are the COVID-19 Open Research Dataset (CORD-19) developed by the Semantic Scholar Team at the Allen Institute and COVID-19 L·OVE by Epistemonikos. Each initiative had variable aims and different approaches to collating the required information; but, to our knowledge, the Cochrane COVID-19 Study Register (CCSR) was the only product designed to support rapid evidence synthesis through the identification and classification of ongoing and completed primary studies. Cochrane was able to utilise existing technical infrastructure, processes and human resource to create an open access register of COVID-19 studies. The Cochrane COVID-19 Study Register (CCSR) includes primary, human studies across a broad range of areas relevant to COVID-19, including the treatment and management of the virus, diagnosis, prognosis, transmission and prevention, mechanism, epidemiology and the wider impact of the pandemic on populations and health services. The CCSR study records are validated and maintained by a team of Cochrane information and data curation specialists. Automated searches retrieve results via daily or weekly API calls across a range of sources. The results are then de-duplicated and screened. A sub-set of results (those retrieved from Embase) are sent to Cochrane Crowd, Cochrane’s citizen science platform; the rest are screened by the core register team. The screening process involves an assessment of record eligibility based on titles and abstracts. For records without abstracts, more information is sought before a judgement is made. Eligible studies are then tagged by the team or by the Crowd according to study type, study design and study aims. Intervention studies are also annotated according to their PICO (population, intervention, comparator and outcome) components. These tagging and annotation activities, together with the largely manual process of linking related reports together, are resource intensive.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>4565</offset><text>In July 2020, we convened a series of meetings between the CCSR team and the team from the EPPI Centre (UCL) and Centre for Reviews and Dissemination (University of York), which has been maintaining a living map of COVID-19 research evidence (the ‘C-19 living map’) commissioned by the UK Department of Health and Social Care. The purpose of these meetings was to share best practice and reduce duplication of effort between the respective workflows being used to keep these two overlapping resources up to date; and we have initially focused on strategies to reduce manual screening burden in the selection of eligible articles.</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5199</offset><text>As the rate of COVID-19 publishing shows little sign of slowing, introducing machine learning (ML) into COVID-19 study identification workflows could offer important gains in terms of workload reduction so long as the corollary risk of ‘missing’ (or ‘losing’) relevant research studies is acceptably low. The C-19 living map team had recently developed and deployed a ML classifier for this purpose, and similar classifiers have previously been deployed in Cochrane’s Centralised Search Service and Screen4Me workflows, to support efficient identification of randomised controlled trials (RCTs).</text></passage><passage><infon key="section_type">INTRO</infon><infon key="type">paragraph</infon><offset>5805</offset><text>For both the CCSR and the C-19 living map, we decided to deploy a ML classifier to discard records scoring below an identified threshold score, calibrated to minimise the risk of ‘missing’ eligible articles. However, given differences between the respective scopes and eligibility criteria of these two resources, we decided that a new binary ML classifier should be specifically developed for the CCSR workflow.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_1</infon><offset>6222</offset><text>Methods</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>6230</offset><text>In this study, we aimed to train (Stage 1), calibrate (Stage 2) and evaluate (Stage 3) a binary ML classifier (‘the classifier’) designed to reduce study identification workload in maintaining the CCSR, with an acceptably low corollary risk of ‘missing’ records of ‘included’ (eligible) studies. We therefore needed to assemble three separate data sets from the CCSR screening workflows (see below and ‘Availability of data and materials’).</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>6687</offset><text>Training (Stage 1)</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>6706</offset><text>In Stage 1, we assembled a training data set containing bibliographic title-abstract records of all articles manually screened for eligibility for the CCSR from its first search date (March 20, 2020) up until October 18, 2020. Embase.com records had only been recently added to the CCSR’s sources by mid-October, and a backlog of medRxiv preprints was still being processed. As the CCSR’s other sources were trial registers (not bibliographic title-abstract records), most of the training set records were from PubMed. These records had originally been identified using conventional Boolean searches of selected electronic bibliographic databases and trials registries, before being manually screened and labelled as either ‘included’ (eligible for the CCSR) or ‘excluded’ (ineligible) by Cochrane information specialists or the Cochrane Crowd. The search strategies used can be seen on the About page of the CCSR. After removing trials registry records, we were left 59,513 records, of which 20,878 were labelled as ‘included’ in the CCSR, and 38,635 were ‘excluded’. These records were imported into EPPI-Reviewer, assigned to code sets and used to train a logistic regression classifier using tri-gram ‘bag of words’ features, implemented in the SciKit-Learn python library, with ‘included’ records designated as the positive class (class of interest) and ‘excluded’ records as the negative class.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>8139</offset><text>Calibration (Stage 2)</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>8161</offset><text>In Stage 2, we assembled a calibration data set containing 16,123 similar records manually screened for eligibility for the CCSR between the 19th October and 2nd of December 2020, again labelled as ‘included’ (6005 eligible records) or ‘excluded’ (10,118 ineligible records) by the same people and process, and with trials registry records having again been removed. The records were imported into EPPI-Reviewer, assigned to code sets and used to calibrate the classifier developed in Stage 1. Specifically, we applied the classifier to 16,123 calibration records, which automatically assigned a score (0–100) to each record. We then computed the threshold score that captured &gt;99% of the ‘included’ records in this data set (i.e. recall &gt;0.99). 0.99 is the threshold level of recall that is currently required for ML classifiers to be deployed in Cochrane systems and workflows. We also computed standard performance metrics, namely: (cumulative) recall, (cumulative) precision and net workload reduction.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title_2</infon><offset>9182</offset><text>Evaluation (Stage 3)</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>9203</offset><text>In Stage 3, we assembled an evaluation data set of similar records containing 4722 records manually screened for eligibility for the CCSR between the 4th and 19th of January 2021, once again labelled as ‘included’ (2310 eligible records) or ‘excluded’ (2412 ineligible records), with trials registry records removed. The records were imported into EPPI-Reviewer, assigned to code sets, and used to evaluate the classifier developed in Stage 1. Specifically, we applied the classifier to 4722 evaluation records, identified ‘included’ and ‘excluded’ records scoring above and below the threshold score we had computed in Stage 2, and then, we computed (cumulative) recall, (cumulative) precision and net workload reduction. We also analysed characteristics of ‘included’ articles that would have been ‘missed’ by the workflow if the classifier had been implemented.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>10092</offset><text>Finally, we compared key characteristics of articles between the three study data sets described above in this section (training, calibration, evaluation), to check post hoc that they comprised similar enough sets of records to validate our results from calibrating and evaluating the classifier.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_1</infon><offset>10389</offset><text>Results</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>10397</offset><text>Calibration</text></passage><passage><infon key="file">13643_2021_1880_Fig1_HTML.jpg</infon><infon key="id">Fig1</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>10409</offset><text>Distribution of classifier scores among ‘included’ and ‘excluded’ calibration records (N=16,123) and related performance metrics</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>10546</offset><text>Distribution of classifier scores among ‘included’ and ‘excluded’ calibration records and related performance metrics</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Classifier score&lt;/th&gt;&lt;th&gt;90–99&lt;/th&gt;&lt;th&gt;80–89&lt;/th&gt;&lt;th&gt;70–79&lt;/th&gt;&lt;th&gt;60–69&lt;/th&gt;&lt;th&gt;50–59&lt;/th&gt;&lt;th&gt;40–49&lt;/th&gt;&lt;th&gt;30–39&lt;/th&gt;&lt;th&gt;20–29&lt;/th&gt;&lt;th&gt;10–19&lt;/th&gt;&lt;th&gt;0–9&lt;/th&gt;&lt;th&gt;Totals&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Included&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;2853&lt;/td&gt;&lt;td&gt;1059&lt;/td&gt;&lt;td&gt;610&lt;/td&gt;&lt;td&gt;402&lt;/td&gt;&lt;td&gt;284&lt;/td&gt;&lt;td&gt;202&lt;/td&gt;&lt;td&gt;195&lt;/td&gt;&lt;td&gt;180&lt;/td&gt;&lt;td&gt;129&lt;/td&gt;&lt;td&gt;91&lt;/td&gt;&lt;td&gt;6005&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Excluded&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;83&lt;/td&gt;&lt;td&gt;156&lt;/td&gt;&lt;td&gt;190&lt;/td&gt;&lt;td&gt;237&lt;/td&gt;&lt;td&gt;290&lt;/td&gt;&lt;td&gt;364&lt;/td&gt;&lt;td&gt;578&lt;/td&gt;&lt;td&gt;885&lt;/td&gt;&lt;td&gt;1736&lt;/td&gt;&lt;td&gt;5599&lt;/td&gt;&lt;td&gt;10,118&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Totals&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;2936&lt;/td&gt;&lt;td&gt;1215&lt;/td&gt;&lt;td&gt;800&lt;/td&gt;&lt;td&gt;639&lt;/td&gt;&lt;td&gt;574&lt;/td&gt;&lt;td&gt;566&lt;/td&gt;&lt;td&gt;773&lt;/td&gt;&lt;td&gt;1065&lt;/td&gt;&lt;td&gt;1865&lt;/td&gt;&lt;td&gt;5690&lt;/td&gt;&lt;td&gt;16,123&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Precision&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;0.97&lt;/td&gt;&lt;td&gt;0.87&lt;/td&gt;&lt;td&gt;0.76&lt;/td&gt;&lt;td&gt;0.63&lt;/td&gt;&lt;td&gt;0.49&lt;/td&gt;&lt;td&gt;0.36&lt;/td&gt;&lt;td&gt;0.25&lt;/td&gt;&lt;td&gt;0.17&lt;/td&gt;&lt;td&gt;0.07&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;0.02&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Cumulative recall&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;0.48&lt;/td&gt;&lt;td&gt;0.65&lt;/td&gt;&lt;td&gt;0.75&lt;/td&gt;&lt;td&gt;0.82&lt;/td&gt;&lt;td&gt;0.87&lt;/td&gt;&lt;td&gt;0.90&lt;/td&gt;&lt;td&gt;0.93&lt;/td&gt;&lt;td&gt;0.96&lt;/td&gt;&lt;td&gt;0.98&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;1.00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Cumulative precision&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;0.97&lt;/td&gt;&lt;td&gt;0.94&lt;/td&gt;&lt;td&gt;0.91&lt;/td&gt;&lt;td&gt;0.88&lt;/td&gt;&lt;td&gt;0.84&lt;/td&gt;&lt;td&gt;0.80&lt;/td&gt;&lt;td&gt;0.75&lt;/td&gt;&lt;td&gt;0.68&lt;/td&gt;&lt;td&gt;0.57&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;0.37&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Threshold classifier score (recall &amp;gt;0.99)&lt;/bold&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Screened included&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;5950&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Screened excluded&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;5487&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Precision&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;0.52&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Discarded (‘Lost’) included&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;55&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Discarded excluded&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;4631&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Net workload reduction&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;4686&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Net workload reduction %&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;29.1%&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>10672</offset><text>Classifier score	90–99	80–89	70–79	60–69	50–59	40–49	30–39	20–29	10–19	0–9	Totals	 	IncludedN	2853	1059	610	402	284	202	195	180	129	91	6005	 	ExcludedN	83	156	190	237	290	364	578	885	1736	5599	10,118	 	Totals	2936	1215	800	639	574	566	773	1065	1865	5690	16,123	 	Precision	0.97	0.87	0.76	0.63	0.49	0.36	0.25	0.17	0.07	0.02	 	Cumulative recall	0.48	0.65	0.75	0.82	0.87	0.90	0.93	0.96	0.98	1.00	 	Cumulative precision	0.97	0.94	0.91	0.88	0.84	0.80	0.75	0.68	0.57	0.37	 	Threshold classifier score (recall &gt;0.99)	7	 	Screened includedNa	5950	 	Screened excludedNa	5487	 	Precisiona	0.52	 	Discarded (‘Lost’) includedNa	55	 	Discarded excludedNa	4631	 	Net workload reductionNa	4686	 	Net workload reduction %a	29.1%	 	</text></passage><passage><infon key="file">Tab1.xml</infon><infon key="id">Tab1</infon><infon key="section_type">TABLE</infon><infon key="type">table_foot</infon><offset>11412</offset><text>aAt threshold score = 7 (recall &gt;0.99)</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>11451</offset><text>Results from calibrating the Cochrane COVID-19 Study Classifier (Stage 2) are shown in Fig. 1 and Table 1. The threshold classifier score at target recall &gt;0.99 was identified as 7 (Table 1), which means that &gt;99% of ‘included’ records in the calibration set scored 7 or above. In this data set, retaining records scoring 7 or above, to achieve target recall &gt;0.99 among ‘included’ records, would have resulted in an overall workflow precision of 0.52, with a corollary 29.1% reduction in manual screening workload.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>11975</offset><text>Evaluation</text></passage><passage><infon key="file">13643_2021_1880_Fig2_HTML.jpg</infon><infon key="id">Fig2</infon><infon key="section_type">FIG</infon><infon key="type">fig_caption</infon><offset>11986</offset><text>Distribution of classifier scores among ‘included’ and ‘excluded’ evaluation records (N=4722) and related performance metrics</text></passage><passage><infon key="file">Tab2.xml</infon><infon key="id">Tab2</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>12120</offset><text>Distribution of classifier scores among ‘included’ and ‘excluded’ evaluation records and related performance metrics</text></passage><passage><infon key="file">Tab2.xml</infon><infon key="id">Tab2</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Classifier Score&lt;/th&gt;&lt;th&gt;90–99&lt;/th&gt;&lt;th&gt;80–89&lt;/th&gt;&lt;th&gt;70–79&lt;/th&gt;&lt;th&gt;60–69&lt;/th&gt;&lt;th&gt;50–59&lt;/th&gt;&lt;th&gt;40–49&lt;/th&gt;&lt;th&gt;30–39&lt;/th&gt;&lt;th&gt;20–29&lt;/th&gt;&lt;th&gt;10–19&lt;/th&gt;&lt;th&gt;0–9&lt;/th&gt;&lt;th&gt;Totals&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Included&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;1037&lt;/td&gt;&lt;td&gt;417&lt;/td&gt;&lt;td&gt;256&lt;/td&gt;&lt;td&gt;157&lt;/td&gt;&lt;td&gt;122&lt;/td&gt;&lt;td&gt;85&lt;/td&gt;&lt;td&gt;74&lt;/td&gt;&lt;td&gt;66&lt;/td&gt;&lt;td&gt;63&lt;/td&gt;&lt;td&gt;33&lt;/td&gt;&lt;td&gt;2310&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Excluded&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;23&lt;/td&gt;&lt;td&gt;39&lt;/td&gt;&lt;td&gt;62&lt;/td&gt;&lt;td&gt;62&lt;/td&gt;&lt;td&gt;69&lt;/td&gt;&lt;td&gt;87&lt;/td&gt;&lt;td&gt;149&lt;/td&gt;&lt;td&gt;188&lt;/td&gt;&lt;td&gt;395&lt;/td&gt;&lt;td&gt;1338&lt;/td&gt;&lt;td&gt;2412&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Totals&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;1060&lt;/td&gt;&lt;td&gt;456&lt;/td&gt;&lt;td&gt;318&lt;/td&gt;&lt;td&gt;219&lt;/td&gt;&lt;td&gt;191&lt;/td&gt;&lt;td&gt;172&lt;/td&gt;&lt;td&gt;223&lt;/td&gt;&lt;td&gt;254&lt;/td&gt;&lt;td&gt;458&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;1371&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Precision&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;0.98&lt;/td&gt;&lt;td&gt;0.91&lt;/td&gt;&lt;td&gt;0.81&lt;/td&gt;&lt;td&gt;0.72&lt;/td&gt;&lt;td&gt;0.64&lt;/td&gt;&lt;td&gt;0.49&lt;/td&gt;&lt;td&gt;0.33&lt;/td&gt;&lt;td&gt;0.26&lt;/td&gt;&lt;td&gt;0.14&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;0.02&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Cumulative recall&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;0.45&lt;/td&gt;&lt;td&gt;0.63&lt;/td&gt;&lt;td&gt;0.74&lt;/td&gt;&lt;td&gt;0.81&lt;/td&gt;&lt;td&gt;0.86&lt;/td&gt;&lt;td&gt;0.90&lt;/td&gt;&lt;td&gt;0.93&lt;/td&gt;&lt;td&gt;0.96&lt;/td&gt;&lt;td&gt;0.99&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;1.00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Cumulative precision&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;0.98&lt;/td&gt;&lt;td&gt;0.96&lt;/td&gt;&lt;td&gt;0.93&lt;/td&gt;&lt;td&gt;0.91&lt;/td&gt;&lt;td&gt;0.89&lt;/td&gt;&lt;td&gt;0.86&lt;/td&gt;&lt;td&gt;0.81&lt;/td&gt;&lt;td&gt;0.77&lt;/td&gt;&lt;td&gt;0.68&lt;/td&gt;&lt;td&gt;0.49&lt;/td&gt;&lt;td&gt;0.98&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Threshold classifier score&lt;/bold&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Screened included&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;2285&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Screened excluded&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;1299&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Precision&lt;/bold&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;0.64&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Discarded (‘Lost’) included&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;25&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Discarded excluded&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;1113&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Recall&lt;/bold&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;0.99&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Net workload reduction&lt;/bold&gt;
&lt;bold&gt;&lt;italic&gt;N&lt;/italic&gt;&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;1138&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Net workload reduction %&lt;/bold&gt;&lt;sup&gt;a&lt;/sup&gt;&lt;/td&gt;&lt;td colspan=&quot;11&quot;&gt;24.1%&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>12245</offset><text>Classifier Score	90–99	80–89	70–79	60–69	50–59	40–49	30–39	20–29	10–19	0–9	Totals	 	IncludedN	1037	417	256	157	122	85	74	66	63	33	2310	 	ExcludedN	23	39	62	62	69	87	149	188	395	1338	2412	 	Totals	1060	456	318	219	191	172	223	254	458	1371	 	Precision	0.98	0.91	0.81	0.72	0.64	0.49	0.33	0.26	0.14	0.02	 	Cumulative recall	0.45	0.63	0.74	0.81	0.86	0.90	0.93	0.96	0.99	1.00	 	Cumulative precision	0.98	0.96	0.93	0.91	0.89	0.86	0.81	0.77	0.68	0.49	0.98	 	Threshold classifier score	7	 	Screened includedNa	2285	 	Screened excludedNa	1299	 	Precision	0.64	 	Discarded (‘Lost’) includedNa	25	 	Discarded excludedNa	1113	 	Recall	0.99	 	Net workload reductionNa	1138	 	Net workload reduction %a	24.1%	 	</text></passage><passage><infon key="file">Tab2.xml</infon><infon key="id">Tab2</infon><infon key="section_type">TABLE</infon><infon key="type">table_foot</infon><offset>12965</offset><text>aAt threshold score = 7</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>12989</offset><text>Evaluation results for the classifier are shown in Fig. 2 and Table 2. In the evaluation data set, retaining records scoring at or above the calibrated threshold score would have resulted in 0.99 recall among ‘included’ records, with an overall workflow precision of 0.64 and a corollary 24.1% reduction in manual screening workload.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>13328</offset><text>In our analysis of the 25 (1%) ‘missed’(discarded) ‘included’ records, we found that 12 were title-only records. Of these, four were errata or replies to studies already included in the CCSR and were therefore not the primary reference to the study. All but one of the ‘missed includes’ had been sourced from PubMed. Only two were records of interventional studies, the rest were records of observational studies. One ‘missed’ interventional study was an RCT, but it was not reporting the results of the RCT. The other one was a single-arm study that was not about COVID-19 patients, but the broader impact of the pandemic on the mental health of students, and the effects of a mindfulness component of the intervention described. Of the remaining ‘missed’ observational studies, most were studies looking at the broader impact of the pandemic on health services or selected populations. Three were small case-control or cohort studies that were diagnostic or prognostic in their aims. The remining three ‘missed’ records were all studies concerned with virus mutations. It is likely that this kind of study was not part of our stage 1 (training) data set, which contains studies from the first few months of the pandemic.</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">title_2</infon><offset>14575</offset><text>Post hoc analysis of data set key characteristics</text></passage><passage><infon key="file">Tab3.xml</infon><infon key="id">Tab3</infon><infon key="section_type">TABLE</infon><infon key="type">table_caption</infon><offset>14625</offset><text>Key characteristics of development, calibration and evaluation data sets</text></passage><passage><infon key="file">Tab3.xml</infon><infon key="id">Tab3</infon><infon key="section_type">TABLE</infon><infon key="type">table</infon><infon key="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;table frame=&quot;hsides&quot; rules=&quot;groups&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Data set (classifier development stage)&lt;/th&gt;&lt;th&gt;Size&lt;/th&gt;&lt;th&gt;Number of eligible records (%)&lt;/th&gt;&lt;th&gt;Number of title-only records (%)&lt;/th&gt;&lt;th&gt;Number of title-only records that were eligible (%)&lt;/th&gt;&lt;th&gt;Provenance of records&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Data set 1 (Training)&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;59,513&lt;/td&gt;&lt;td&gt;20,878 (35.1%)&lt;/td&gt;&lt;td&gt;18,669 (31.4%)&lt;/td&gt;&lt;td&gt;4495 (21.5%)&lt;/td&gt;&lt;td&gt;&lt;p&gt;3229 (5.4%)—Embase&lt;/p&gt;&lt;p&gt;2083 (3.5%)—preprint&lt;/p&gt;&lt;p&gt;54201 (91.1%)—PubMed&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Data set 2 (Calibration)&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;16,123&lt;/td&gt;&lt;td&gt;6005 (37.2%)&lt;/td&gt;&lt;td&gt;3626 (22.5%)&lt;/td&gt;&lt;td&gt;821 (13.7%)&lt;/td&gt;&lt;td&gt;&lt;p&gt;1994 (12.4%)—Embase&lt;/p&gt;&lt;p&gt;287 (1.8%)—pre-print&lt;/p&gt;&lt;p&gt;13842 (85.8%)—PubMed&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;bold&gt;Data set 3 (Evaluation)&lt;/bold&gt;&lt;/td&gt;&lt;td&gt;4722&lt;/td&gt;&lt;td&gt;2310 (48.9%)&lt;/td&gt;&lt;td&gt;896 (19.0%)&lt;/td&gt;&lt;td&gt;285 (12.3%)&lt;/td&gt;&lt;td&gt;&lt;p&gt;89 (1.9%)—Embase&lt;/p&gt;&lt;p&gt;202 (4.3%)—pre-print&lt;/p&gt;&lt;p&gt;4431 (93.8%)—PubMed&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</infon><offset>14698</offset><text>Data set (classifier development stage)	Size	Number of eligible records (%)	Number of title-only records (%)	Number of title-only records that were eligible (%)	Provenance of records	 	Data set 1 (Training)	59,513	20,878 (35.1%)	18,669 (31.4%)	4495 (21.5%)	3229 (5.4%)—Embase2083 (3.5%)—preprint54201 (91.1%)—PubMed	 	Data set 2 (Calibration)	16,123	6005 (37.2%)	3626 (22.5%)	821 (13.7%)	1994 (12.4%)—Embase287 (1.8%)—pre-print13842 (85.8%)—PubMed	 	Data set 3 (Evaluation)	4722	2310 (48.9%)	896 (19.0%)	285 (12.3%)	89 (1.9%)—Embase202 (4.3%)—pre-print4431 (93.8%)—PubMed	 	</text></passage><passage><infon key="section_type">RESULTS</infon><infon key="type">paragraph</infon><offset>15291</offset><text>Results from comparing key characteristics between data sets used in the training, calibration and evaluation of the COVID-19 Study Classifier are shown in Table 3. Stage 1 (training) and Stage 2 (calibration) data sets were very similar in terms of the proportion of ‘included’ records in each set (35% and 37%, respectively). The Stage 3 (evaluation) data set, compiled of records manually screened for the CCSR during January 2021, had a higher proportion of ‘included’ records, at almost 50%. Each data set included a substantial proportion of title-only records (i.e. records without abstracts). The Stage 1 data set had the largest proportion of such records: 18,669 records (31%), of which 4495 were includes. Datasets 2 and 3 and a lower, but similar, proportion of title-only records: 23% and 19%, respectively.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_1</infon><offset>16120</offset><text>Discussion</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>16131</offset><text>We developed a binary ML classifier with the aim of reducing screening workload for the CCSR. Calibrated to achieve 99% recall, the classifier reduced screening workload by 24.1% in the evaluation data set. This finding was especially encouraging given the proportion of eligible records in this data set was close to 50%; and almost one in five of the records were ‘title-only’, with relatively few text features for classification, compared to records with accompanying abstracts. Title-only records in the context of the COVID pandemic can be resource- and time-intensive to manually assess. For many, more information will need to be found before a judgement on whether the record is eligible can be made. Having a classifier able to reliably reject ineligible title-only records is valuable and will free up human resource to assess the more unclear title-only records.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>17011</offset><text>One of the main strengths of this study is the quality of the three data sets. We were able to use highly representative records for each stage, with a high level of confidence in the quality of each, derived as they were from the Cochrane Centralised Search Service team and Cochrane Crowd. In addition, the training data set was fairly large (n=59,513), made up of both the class of interest (‘included’) and non-eligible records (‘excluded’). Records within the class of interest set encompassed all eligible study types (observational, interventional, qualitative and modelling studies) and designs and had good coverage across the range of possible study aims.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>17686</offset><text>A potential limitation is that most records comprising each of the three study data sets were sourced from PubMed (of which a large proportion are also likely to have been indexed in Embase). This is unlikely to be an issue when applying the classifier to bibliographic records of journal articles identified from other database sources; but caution would be needed when applying the classifier to records with a different structure, for example, trial registry records. While many trial registry records contain similar information to a standard bibliographic record that could, in principle, be parsed and added to the title-abstract records prior to their classification, it is important to be aware of which fields map well to each other across the different record types, and in some cases to exclude certain fields of information that might confuse the classifier—such as trial exclusion criteria. As such, further work would be needed to evaluate the performance of this classifier when applied to records incorporating selected text from trial registry records. We could also investigate the potential to incorporate such records into sets used to retrain and recalibrate periodically updated versions of this classifier.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>18918</offset><text>In this paper, we have focused on reporting the deployment of a machine learning classifier in a real-world scenario over a short period of time. The method employed, using train, test and calibration data sets and easily interpretable probabilities from a logistic regression classifier, provides a robust basis for future work and has proved acceptable to Cochrane. A workload reduction of ~25% is substantial given the high recall that must be achieved. However, we do not rule out that deployment of more sophisticated machine learning classification algorithms may be able to push the reported savings in workload marginally higher.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>19557</offset><text>Evolution in the scope, aims and topics and text features of COVID-19 research over time suggest that ML classifiers which, like this one, that have been prospectively developed, are likely to need to be periodically retrained, recalibrated and re-evaluated, in order to minimise the risk of ‘losing’ (or ‘missing’) new bodies (or ‘strands’) of relevant research, with new ‘previously unseen’ text features, that are likely to emerge as the pandemic continues to unfold. Periodically updated training, calibration and evaluation data sets should be prospectively assembled to comprise records from three consecutive time periods, as we have done in the current study. This approach is robust in terms of its external validity, as it is consistent with the real-world use scenario in which such classifiers are deployed, where we do not know in advance how the research literature will evolve following their (re-) deployment. (Re-)calibrating and (re-)evaluating the classifier using records from consecutive time periods immediately succeeding the one covered by records in the</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>20653</offset><text>(re-)training dataset therefore confers further confidence (alongside the size and breadth of our study datasets) that any subtle evolution or ‘shifts’ in the scope and text features of bibliographic records of published COVID-19 research over time are unlikely to adversely impact on the performance of the deployed classifier in the short-term.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21004</offset><text>In late January 2021, the classifier developed in this study was deployed in the Cochrane COVID-19 register workflow, with records retrieved from PubMed and Embase.com being run through it. Workload reduction in terms of screening effort has been reduced in practice by approximately 20–25%, which is in line with the expected reduction based on this study. The classifier is also being used to help prioritise screening by ordering the records that score above the cut-point from highest to lowest score. Feedback from the screening team has indicated that records that receives high scores are almost always eligible studies, but they are often not the higher priority interventional studies. This is very likely due to the high prevalence of observational studies in the data sets used.</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">title_2</infon><offset>21796</offset><text>Next steps</text></passage><passage><infon key="section_type">DISCUSS</infon><infon key="type">paragraph</infon><offset>21807</offset><text>The Cochrane COVID-19 Study Classifier reduces screening burden by cutting the number of excludes to assess by approximately half. This is a helpful start but with the proportion of records eligible being around 50% (as it has been for the last 6 months for the CCSR), an ‘exclusion’ classifier can only do so much. In addition, the rate of publication on COVID-19 shows no sign of slowing with the number of new studies identified for the CCSR averaging 4600 per month over the last 6 months. Therefore, we are now developing additional automated approaches to maintain the CCSR. With over 60,000 COVID-19-related studies identified and tagged in the register, we are developing additional ML classifiers that will assign or suggest both study design characteristics and study aims to potentially eligible studies. We are also developing automated approaches to assigning PICO characteristics to interventional studies. Here, we will use crowd and ML capabilities in a hybrid approach to keeping up with the deluge of publications on COVID-19.</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">title_1</infon><offset>22856</offset><text>Conclusions</text></passage><passage><infon key="section_type">CONCL</infon><infon key="type">paragraph</infon><offset>22868</offset><text>The Cochrane COVID-19 Study Classifier can reduce manual screening workload for identifying COVID-19 research studies, with a very low and acceptable risk of missing eligible studies. This classifier is now deployed in the study identification workflow for the Cochrane COVID-19 Study Register.</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">title</infon><offset>23163</offset><text>Abbreviations</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>23177</offset><text>CCSR</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>23182</offset><text>Cochrane COVID-19 Study Register</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>23215</offset><text>ML</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>23218</offset><text>Machine learning</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>23235</offset><text>RCT</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">paragraph</infon><offset>23239</offset><text>Randomised controlled trial</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">footnote</infon><offset>23267</offset><text>Publisher’s Note</text></passage><passage><infon key="section_type">ABBR</infon><infon key="type">footnote</infon><offset>23286</offset><text>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">title</infon><offset>23405</offset><text>Authors’ contributions</text></passage><passage><infon key="section_type">AUTH_CONT</infon><infon key="type">paragraph</infon><offset>23430</offset><text>IS: conceptualisation, methodology, investigation, data curation, visualisation, supervision, and writing—original draft preparation. ANS: conceptualisation, methodology, investigation, data curation, visualisation, supervision, and writing—original draft preparation. JT: conceptualisation, methodology, data curation, and writing—reviewing and editing. RF: conceptualisation, methodology, and writing—reviewing and editing. CM: conceptualisation, methodology, and writing—reviewing and editing. The authors read and approved the manuscript.</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">title</infon><offset>23983</offset><text>Funding</text></passage><passage><infon key="section_type">ACK_FUND</infon><infon key="type">paragraph</infon><offset>23991</offset><text>The Cochrane COVID-19 Study Register and the implementation of the COVID-19 classifier described in this methodological paper was funded by Cochrane.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title</infon><offset>24141</offset><text>Availability of data and materials</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24176</offset><text>All data used in this analysis are available here: https://github.com/EPPI-Centre/CochraneCOVID19Classifier</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title</infon><offset>24284</offset><text>Declarations</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title</infon><offset>24297</offset><text>Ethics approval and consent to participate</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24340</offset><text>Not applicable.</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">title</infon><offset>24356</offset><text>Consent for publication</text></passage><passage><infon key="section_type">METHODS</infon><infon key="type">paragraph</infon><offset>24380</offset><text>Not applicable.</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">title</infon><offset>24396</offset><text>Competing interests</text></passage><passage><infon key="section_type">COMP_INT</infon><infon key="type">paragraph</infon><offset>24416</offset><text>The authors declare that they have no competing interests.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">title</infon><offset>24475</offset><text>References</text></passage><passage><infon key="fpage">34</infon><infon key="issue">9-S</infon><infon key="lpage">39</infon><infon key="name_0">surname:Odone;given-names:A</infon><infon key="name_1">surname:Salvati;given-names:S</infon><infon key="name_2">surname:Bellini;given-names:L</infon><infon key="name_3">surname:Bucci;given-names:D</infon><infon key="name_4">surname:Capraro;given-names:M</infon><infon key="name_5">surname:Gaetti;given-names:G</infon><infon key="name_6">surname:Amerio;given-names:A</infon><infon key="name_7">surname:Signorelli;given-names:C</infon><infon key="pub-id_doi">10.23750/abm.v91i9-S.10121</infon><infon key="pub-id_pmid">32701915</infon><infon key="section_type">REF</infon><infon key="source">Acta Biomed</infon><infon key="type">ref</infon><infon key="volume">91</infon><infon key="year">2020</infon><offset>24486</offset><text>The runaway science: a bibliometric analysis of the COVID-19 scientific literature</text></passage><passage><infon key="fpage">553</infon><infon key="issue">7839</infon><infon key="name_0">surname:Else;given-names:H</infon><infon key="pub-id_doi">10.1038/d41586-020-03564-y</infon><infon key="pub-id_pmid">33328621</infon><infon key="section_type">REF</infon><infon key="source">Nature.</infon><infon key="type">ref</infon><infon key="volume">588</infon><infon key="year">2020</infon><offset>24569</offset><text>How a torrent of COVID science changed research publishing - in seven charts</text></passage><passage><infon key="fpage">1</infon><infon key="name_0">surname:Raynaud;given-names:M</infon><infon key="name_1">surname:Zhang;given-names:H</infon><infon key="name_2">surname:Louis;given-names:K</infon><infon key="pub-id_doi">10.1186/s12874-020-01190-w</infon><infon key="pub-id_pmid">33397292</infon><infon key="section_type">REF</infon><infon key="source">BMC Med Res Methodol</infon><infon key="type">ref</infon><infon key="volume">21</infon><infon key="year">2021</infon><offset>24646</offset><text>COVID-19-related medical research: a meta-research and critical appraisal</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>24720</offset><text>COVID-19 Open Research Dataset (CORD-19). https://www.semanticscholar.org/cord19. Accessed 24 October 2021</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>24827</offset><text>COVID-19 L·OVE. https://app.iloveevidence.com. Accessed 24 Oct 2021</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>24896</offset><text>Cochrane COVID-19 Study Register. https://covid-19.cochrane.org. Accessed 03 July 2021</text></passage><passage><infon key="fpage">00008</infon><infon key="issue">21</infon><infon key="lpage">00001</infon><infon key="name_0">surname:Noel-Storr;given-names:A</infon><infon key="name_1">surname:Dooley;given-names:G</infon><infon key="name_10">surname:Foxlee;given-names:R</infon><infon key="name_11">surname:Beecher;given-names:D</infon><infon key="name_12">surname:Ware;given-names:J</infon><infon key="name_13">surname:Thomas;given-names:J</infon><infon key="name_2">surname:Elliott;given-names:J</infon><infon key="name_3">surname:Steele;given-names:E</infon><infon key="name_4">surname:Shemilt;given-names:I</infon><infon key="name_5">surname:Mavergames;given-names:C</infon><infon key="name_6">surname:Wisniewski;given-names:S</infon><infon key="name_7">surname:McDonald;given-names:S</infon><infon key="name_8">surname:Murano;given-names:M</infon><infon key="name_9">surname:Glanville;given-names:J</infon><infon key="pub-id_doi">10.1016/j.jclinepi.2021.01.006</infon><infon key="section_type">REF</infon><infon key="source">J Clin Epidemiol</infon><infon key="type">ref</infon><infon key="volume">S0895-4356</infon><infon key="year">2021</infon><offset>24983</offset><text>An evaluation of Cochrane Crowd found that crowdsourcing produced accurate results in identifying randomized trials</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>25099</offset><text>Metzendorf MI, Featherstone RM. Evaluation of the comprehensiveness, accuracy and currency of the Cochrane COVID-19 Study Register for supporting rapid evidence synthesis production [published online ahead of print, 2021 Jun 5]. Res Synth Methods. 2021. 10.1002/jrsm.1501.</text></passage><passage><infon key="section_type">REF</infon><infon key="type">ref</infon><offset>25372</offset><text>Featherstone R, Last A, Becker L, Mavergames C. Rapid development of the Cochrane COVID-19 Study Register to support review production. Collaborating in response to COVID-19: editorial and methods initiatives across Cochrane. Cochrane Database Sys Rev. 2020;(12 Suppl 1):37–40. 10.1002/14651858.CD202002.</text></passage><passage><infon key="fpage">5</infon><infon key="name_0">surname:O’Mara-Eves;given-names:A</infon><infon key="name_1">surname:Thomas;given-names:J</infon><infon key="name_2">surname:McNaught;given-names:J</infon><infon key="name_3">surname:Miwa;given-names:M</infon><infon key="name_4">surname:Ananiadou;given-names:S</infon><infon key="pub-id_doi">10.1186/2046-4053-4-5</infon><infon key="pub-id_pmid">25588314</infon><infon key="section_type">REF</infon><infon key="source">Systematic Reviews</infon><infon key="type">ref</infon><infon key="volume">4</infon><infon key="year">2015</infon><offset>25679</offset><text>Using text mining for study identification in systematic reviews: a systematic review of current approaches</text></passage><passage><infon key="fpage">142</infon><infon key="lpage">150</infon><infon key="name_0">surname:Noel-Storr;given-names:AH</infon><infon key="name_1">surname:Dooley;given-names:G</infon><infon key="name_2">surname:Wisniewski;given-names:S</infon><infon key="name_3">surname:Glanville;given-names:J</infon><infon key="name_4">surname:Thomas;given-names:J</infon><infon key="name_5">surname:Cox;given-names:S</infon><infon key="name_6">surname:Featherstone;given-names:R</infon><infon key="name_7">surname:Foxlee;given-names:R</infon><infon key="pub-id_doi">10.1016/j.jclinepi.2020.08.008</infon><infon key="pub-id_pmid">32798713</infon><infon key="section_type">REF</infon><infon key="source">J Clin Epidemiol.</infon><infon key="type">ref</infon><infon key="volume">127</infon><infon key="year">2020</infon><offset>25787</offset><text>Cochrane Centralised Search Service showed high sensitivity identifying randomized controlled trials: a retrospective analysis</text></passage><passage><infon key="name_0">surname:Thomas;given-names:J</infon><infon key="name_1">surname:Graziosi;given-names:S</infon><infon key="name_2">surname:Brunton;given-names:J</infon><infon key="name_3">surname:Ghouze;given-names:Z</infon><infon key="name_4">surname:O’Driscoll;given-names:P</infon><infon key="name_5">surname:Bond;given-names:M</infon><infon key="section_type">REF</infon><infon key="source">EPPI-Reviewer: advanced software for systematic reviews, maps and evidence synthesis</infon><infon key="type">ref</infon><infon key="year">2020</infon><offset>25914</offset></passage><passage><infon key="fpage">140</infon><infon key="lpage">151</infon><infon key="name_0">surname:Thomas;given-names:J</infon><infon key="name_1">surname:McDonald;given-names:S</infon><infon key="name_2">surname:Noel-Storr;given-names:A</infon><infon key="name_3">surname:Shemilt;given-names:I</infon><infon key="name_4">surname:Elliott;given-names:J</infon><infon key="name_5">surname:Mavergames;given-names:C</infon><infon key="name_6">surname:Marshall;given-names:IJ</infon><infon key="pub-id_doi">10.1016/j.jclinepi.2020.11.003</infon><infon key="pub-id_pmid">33171275</infon><infon key="section_type">REF</infon><infon key="source">J Clin Epidemiol.</infon><infon key="type">ref</infon><infon key="volume">133</infon><infon key="year">2021</infon><offset>25915</offset><text>Machine learning reduced workload with minimal risk of missing studies: development and evaluation of a randomized controlled trial classifier for Cochrane Reviews</text></passage></document></collection>
