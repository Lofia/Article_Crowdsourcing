Evaluation of Pharmaceutical Pictograms by Older “Turkers”: A Cross-Sectional Crowdsourced Study
Background:
Well-designed pharmaceutical pictograms may improve patients’ understanding of medication instructions. However, the iterative participatory design process required to produce effective pictograms can be costly in terms of money, time, and effort. Crowdsourcing has been applied to bring down the costs of the participatory design process, but the feasibility of using this approach with older adults remains largely unknown.
Objectives:
To evaluate the feasibility of using Amazon Mechanical Turk (MTurk), a leading crowdsourcing platform, for participatory pictogram evaluation with older adults (55+) and to evaluate the comprehensibility of USP pictogram, identify common misinterpretations, and explore the relationship between selected participant characteristics and their pictogram comprehension performance.
Methods:
108 older adults (56.5% female; 57–80 years of age) were recruited via MTurk to complete a cross-sectional online survey that asked them to interpret 15 USP pictograms and answer questions about their health and health literacy.
Results:
It was feasible to perform pictogram evaluation with older adults on MTurk, as shown by ease of recruitment and high data quality. Of the 15 pictograms tested, seven (46.7%) resulted in a comprehensibility score below the threshold established by the American National Standards Institute (ANSI), eight (53.3%) elicited common misinterpretations, and two (13.3%) resulted in ANSI-defined “critical confusion.” Age (P = 0.04) was associated with pictogram comprehension performance. Certain issues with the pictogram subtitles emerged during the evaluation.
Conclusions:
MTurk is a feasible platform for participatory pictogram evaluation, even for a sole target of older adults. The USP should develop a pictogram user manual, redesign pictograms confusing to older adults, and establish policies and procedures to ensure that pictogram subtitles conform to evidence-based best practices and standards for patient-centered written drug information.
Introduction
In the US, more than 85% of community-dwelling older adults take at least one prescription medication and 36% take at least five concurrently. The high prevalence of medication use, combined with aging-related declines in health literacy, places older adults at greater risk of misunderstanding medication instructions. These factors may subsequently lead to unintentional medication misuse and adverse health outcomes. Pictograms—graphic symbols of objects, actions, and concepts to convey specific meanings—may help improve older adults’ comprehension and recall of medication instructions. This is because well-designed pictograms are more compact than written descriptions, can stimulate the imagination and be understood faster than text, improve the readability of more complex drug information, and provide a visual overview of patient information leaflets. Additionally, research suggests that the so-called pictorial superiority effect — namely, the phenomenon of greater recognition and recall of pictures relative to their verbal and textual labels — holds true in older adults.
The United States Pharmacopeial Convention (USP) created 81 standardized pictograms to convey medication instructions and cautionary statements to patients, which are free of charge to use and are publicly accessible from the USP website (https://www.usp.org/download-pictograms). The USP pictograms have been the most widely evaluated pharmaceutical pictograms and the most frequently modified and applied to the international audiences and settings. The USP pictograms are also recommended by the National Health Law Program, American Association of Colleges of Pharmacy, and National Alliance of State Pharmacy Associations in their Language Services Resource Guide for Pharmacists. According to the USP, its pictograms are particularly helpful for patients with lower literacy levels and those who speak English as a second language. However, the USP provides no information regarding the utility of its pictograms for older adults, which is surprising as most older adults are medication users. Furthermore, although older adults tend to recognize and recall pictures better than verbal and textual labels (i.e., pictorial superiority effect), research shows that the ability to comprehend pictograms may be age-dependent. For instance, Beaufils et al. found that older adults had lower pictogram comprehension scores than young adults. Therefore, pictograms found to be effective for general adults may not be as effective, or even appropriate, for older adults without modification or redesign. Fortunately, research shows that testing and redesign can improve pictogram comprehension for older adults.
For effective pictograms, an iterative participatory design process that repeatedly involves end users is required. Such a process; however, tends to be costly in terms of money, time, and effort, including the need to recruit and train research personnel, payment for the research personnel to recruit, screen, and schedule participants and conduct the comprehension testing and participatory design sessions, rent of the testing locations, as well as compensation for representative target users’ repeated engagements and their transportation expenses. According to Wolff and Wogalter, “one of the major costs of testing pictorials is the collection of data from the relevant target populations” and one way to reduce this cost is “by performing preliminary iterative cycles of testing and redesign using easily obtainable participants… in advance of more formal test procedures involving higher-cost representative sample of the target population(s).” To reduce high costs, several research groups explored the possibility of performing participatory evaluation of medical/pharmaceutical pictograms on crowdsourcing platforms, but none of these groups have targeted older adults. Therefore, the feasibility of engaging solely older adults in crowdsourced pictogram evaluation remains largely unknown. It is important to assess the feasibility of recruiting a sole older adult sample because as discussed above, age is an important predictor of one’s ability to comprehend pictograms. The older Turker recommended preliminary iterative cycles of testing and redesign to help bring down costs.
Crowdsourcing is a powerful problem-solving and task realization model that leverages human intelligence. The term of “crowdsourcing” was first coined by Jeff Howe and he defined it as:
the act of a company or institution taking a function once performed by employees and outsourcing it to an undefined (and general large) network of people in the form of an open call. This can take the form of peer-production (when the job is performed collaborative), but is also often undertaken by sole individual.
The definition of crowdsourcing has evolved ever since, but scholars agree that “crowdsourcing” has to involve a crowd and a specific task. Examples of crowdsourcing platforms include Amazon Mechanical Turk (MTurk), CrowdFlower, Freelancer, and Microworkers. For research and reviews of crowdsourcing typology and projects, see e.g., Estellés-Arolas and González-Ladrón-de-Guevara, Estellés-Arolas et al., and Assis Neto and Santos.
For this study, MTurk was selected because the literature suggests that it is the leading platform, a valid, inexpensive, and time-efficient data collection tool, and it has been successfully used by various disciplines, including consumer research, psychology, political science, public health, medicine, and more recently, dental research.
MTurk is a crowdsourcing web service and “an online labor market where employees (called workers) are recruited by employers (called requester) for the execution of tasks (called HITs, acronym for Human Intelligence Tasks) in exchange for a wage (called a reward)”. MTurk was first introduced by Amazon in 2005, named after an 18th century “automatic” chess-playing machine operated by a hidden person that handily beat humans in chess games; and it began to gain popularity as a source of subjects for experimental research since 2010. Human Intelligence Tasks (HITs) are tasks that humans can perform more efficiently than computers, such as describing a photograph. Workers who perform such HITs are called “Turkers.” Each Turker is assigned a unique worker ID by Amazon but remains anonymous otherwise. When Turkers log in to the MTurk worker website, they see a dashboard with a list of HITs. For each HIT, the Turkers can see a brief description of the task, the amount of the reward, how long the task has been created, the maximum time allotted to completion, the expiration date of the task, the number of assignments remaining for each task (the minimum number of assignments for each HIT required by MTurk is 10), and a preview of each HIT, before they decide whether to accept the HIT. As of June 2020, the minimum reward for each HIT assignment remains as low as $0.01, though requesters can provide additional bonus. It is estimated that there are at least 250,000 Turkers worldwide and approximately 75% of the Turkers are from the US. For demographic estimates of Turkers, see e.g., Difallah et al., Huff and Tingley, Levay et al., Paolacci and Chandler, and Hitlin. Real-time demographic and activity estimates of Turkers can be found on a free dashboard called MTurk Tracker developed by Ipeirotis and colleagues (see Djellel et al. and Ipeirotis for the underlying methodologies).
The purpose of this study is two-fold: (1) to pilot test the use of MTurk for participatory pictogram evaluation with older Turkers (55+); and (2) to examine the comprehensibility of USP pictograms among older Turkers in order to identify pictograms that are not well-understood, pinpoint common misinterpretations, and explore whether older Turkers’ demographic characteristics (i.e., age, sex, education, and medication usage) and health literacy are associated with their pictogram comprehension performance. It was hypothesized that the target number of older Turkers would be reached within a pre-specified timeframe and produce high quality data for pictogram evaluation (see the feasibility measures section).
Methods
Design and setting
A cross-sectional pilot study with a convenience sample of older Turkers recruited via MTurk was conducted between February and March 2018 to evaluate 15 selected USP pictograms presented in an online survey format. Pictogram selection was based on their relevance to the US National Library of Medicine Medline Plus (https://medlineplus.gov/) medication information for the 4 most commonly prescribed drugs among older Americans – namely, simvastatin, lisinopril, hydrochlorothiazide, and levothyroxine. This study was intended to serve as the first step of a larger research project involving an iterative participatory design process (see Figure 1). The Institutional Review Board (IRB) approved this study (IRB ID: STUDY00003899).
Participants
To participate, an individual had to be 55 years old or older, an existing MTurk account user, able to read and write in English, and residing in the US. The age criterion was chosen based on the oldest age group available through MTurk’s worker cohort filters called Premium Qualifications. Even though MTurk is an international platform, this study was limited to US-based Turkers to reduce potential confounding effect of the country because research shows that respondents in other countries prefer and understand their locally developed pictograms better than the USP pictograms. The target sample size was set at 100, which was informed by an existing crowdsourced pictogram evaluation study. This also fulfilled the American National Standards Institute’s (ANSI) recommendation of a minimum of 50 respondents for reliable pictogram comprehension testing results.
Conceptual framework
This study was informed by the Communication-Human Information Processing (C-HIP) model. The C-HIP model has been applied by the authors of the model to studying human information processing of pharmaceutical labeling including pictograms specifically; see Wogalter and Sojourner. According to this model, once information is delivered by the source (e.g., USP) via some channel (e.g., pictograms), the information receiver must sustain attention for sufficient time to process and understand the information. Once comprehended, the extent to which the information aligns with (or is convincing enough to alter) the receiver’s beliefs and attitudes subsequently influences whether the receiver decides to perform the target behavior (e.g., taking medication as directed). (For those familiar with the information, once comprehended, the pictogram can serve as a reminder to cue relevant information or knowledge in long-term memory.) Each of these stages can produce a bottleneck that prevents information from flowing to the subsequent stage(s). Notably, later stages can also influence whether and how information is processed at earlier stages. For instance, an individual may decide not to attend to the instructions of a particular medication (earlier stage) because the individual believes he or she knows the medication well (later stage). Figure 1 depicts the adaptation of the C-HIP model in the context of this study.
According to the authors of the C-HIP model, it can serve as an investigative tool in helping determine the reason(s) why a warning (in the context of this study, the intended message of a given pictogram) failed to be effective. In this study, the authors took a pragmatic stance, using publicly available pictogram resources from a credible organization (i.e., USP pictograms) in the hopes that the study findings would more readily inform real-world practices. Therefore, there was no manipulation of the source (USP) or the channel (pictograms) of information. Moreover, it has been well-documented that pictograms, including USP pictograms, enhance attention to written instructions, whereas a lack of comprehension can create a bottleneck for subsequent information processing stages. Consequently, this study targeted the comprehension stage and three inter-related concepts that need to be considered simultaneously at the comprehension stage when studying human information processing of pictograms specifically: comprehensibility, common misinterpretation, and comprehension performance.
Comprehensibility is an important concept that is part of the comprehension stage of the C-HIP model when it is applied to pharmaceutical labeling including pictograms. In the context of pictogram research, comprehensibility refers to the extent to which the intended message of a pictogram is interpreted correctly by a group of respondents. The comprehensibility score is the percentage of users who understand the intended message of a pictogram (the correct interpretation rate). For example, if 85% of the respondents interpret the meaning of a given pictogram correctly, the comprehensibility score of this pictogram would be 85%. However, a low comprehensibility score only suggests that the pictogram is ineffective at communicating its intended message to the intended audience; it provides no information on which specific design elements confuse the end users. Therefore, in order to pinpoint the problematic design elements in a pictogram that likely interfere with comprehension of the intended message at the comprehension stage, it is imperative to identify common misinterpretations. On the other hand, pictograms with high comprehensibility scores likely would result in few or no common misinterpretations. In this study, a common misinterpretation is defined as an erroneous interpretation made by at least 5% of respondents. Comprehension performance, in contrast, refers to the performance level of the respondent during comprehension testing. In this study, comprehension performance is measured by the total number of pictograms correctly interpreted by a respondent. It is important to assess comprehension performance along with pictogram comprehensibility and common misinterpretations at the comprehension stage. This is because in the context of pictogram research, whether the information received is successfully processed and passed on to the next stage of human information processing is determined by at least both the design of the pictogram itself (measured by comprehensibility and common interpretations) and the information receiver’s general ability to understand pictograms (measured by comprehension performance). Pictograms tested in a group of users with a high level of comprehension performance likely will result in higher comprehensibility scores than the same pictograms tested in a group of uses with a low level of comprehension performance. In addition, certain demographic characteristics (age, sex education, medication usage, health literacy) of the information receiver may affect comprehension performance and; therefore, are added in the adapted C-HIP model.
In future research, the study team plans to also examine the later stages of the C-HIP model including Attitudes and Beliefs, Motivation, and Behavior, as well as the feedback loops, illustrated as the arrows connecting each stage of the model, to more fully examine how human information processing of pictograms affect patients’ actual medication-taking behaviors.
Data collection
To recruit older Turkers, the research team created an MTurk requester account to deploy a HIT titled “Guess What the Picture Tries to Tell You” with a link to an online pictogram evaluation survey (Catalyst Tools, University of Washington, Seattle, WA). On MTurk, the task requester is required to specify the number of assignments to be collected for each HIT. The research team published a HIT requesting 100 assignments on February 23, 2018. This HIT was made visible only to Turkers who met the pre-specified age and location criteria. Following recommendations of existing research, an additional filter was applied to require potential participants’ prior HIT approval rate to be greater than 95% to avoid spammers and ensure data quality. The online survey consisted of (1) a consent page; (2) an English screening question; (3) pictogram images and comprehension-testing questions (see Figure 2 for an example); (4) demographic and health-related questions including medication usage; (5) the 4-item Brief Health Literacy Screening Tool (known as BRIEF; Haun et al., 2009); and (6) the Newest Vital Sign (NVS; Weiss et al., 2005). The BRIEF scale measures subjective health literacy through four 5-point Likert type scales (e.g. “How often do you have someone help you read hospital materials? 1. Always; 2. Often; 3. Sometimes; 4. Occasionally; 5. Never”), and has been validated in a sample of predominately older adults. The possible BRIEF scores range from 4 to 20; a score between 4 and 12 indicates “limited” health literacy, between 13 and 16 “marginal”, and between 17 and 20 “adequate”. The NVS is an objective health literacy test, consisting of one ice-cream nutrition label and 6 questions (e.g. “If you eat the entire container, how many calories will you eat?”). The possible NVS scores range from 0 to 6, with 0 to 1 suggesting high likelihood (50% or more) of limited literacy”, 2 to 3 “the possibility of limited literacy”, and 4 to 6 “almost always indicates adequate literacy.” The NVS has been validated in English and Spanish-speaking samples. Each pictogram image (without displaying its USP subtitle, the official textual description of the pictogram) was accompanied by 3 open-ended comprehension-testing questions adapted from the ANSI comprehension testing template: (1) Exactly what do you think this picture means?; (2) What action should you take in response to this picture?; and (3) What might happen if the instruction is not followed? In order to reduce potential information bias (measurement errors) caused by unclear survey questions and instructions, before deploying the HIT, the online survey was first piloted within the research team and then with 4 additional graduate students including non-English native speakers who were naive to this study. In addition, the online anonymous survey format prevented interviewer bias that could occur during in-person comprehension testing sessions. Participants who completed the survey were paid U.S. $1.00 through their MTurk account.
Feasibility measures
The feasibility of using MTurk for participatory pictogram evaluation with older Turkers was assessed by ease of recruitment and data quality. Ease of recruitment was measured by whether the target sample size of 100 was reached within a pre-specified time frame of 21 days. The 21-day timeframe was estimated based on a prior study that aimed to recruit 100 Turkers with no age limits to evaluate USP pictograms. In that study, the target sample size was reached within 3 days, but only 16% of their respondents were older adults (defined as > = 56 years in their study). Given their recruitment rate, it would have taken approximately 19 days to recruit a sample of 100 older Turkers (3 days divided by 0.16 equals to 18.8 days). Based on this estimate, plus a 10% grace period (1.9 days) in case unexpected issues would occur with the platform, a maximum recruitment period of 21 days was used as an indicator for ease of recruitment in this study. Data quality was assessed by the percentage of missing data and the number of valid surveys received.
Pictogram scoring
Three judges, a provider (MF), a pharmacist (LH), and an allied health professional (SL), independently scored all pictogram interpretations from all respondents using “1” for correct, “0” for incorrect, and “−1” for “critical confusion”. Critical confusion is a special case of incorrect interpretation. As defined by the ANSI, it refers to “the opposite, or prohibited action” elicited by a symbol (e.g., “do not chew” versus “chew”).
The 3 judges were from 3 different disciplines since the USP pictograms can be used by different health care professionals. According to the USP, pictograms are “Available for use by health care professionals and others to reinforce printed or oral instructions”. In addition to the scoring rules for correct, incorrect, and critical confusion, the 3 judges were only given the official subtitle of each USP pictogram to use as the answer key. This was because the USP only made available the pictograms and did not provide any user manuals or a range of acceptable interpretations for each pictogram. After all judges had completed their independent scoring, they reviewed each other’s scoring and discussed the results together. The final score of each interpretation was determined by consensus among the judges.
Data analysis
For qualitative data, after the final score of each pictogram interpretation was assigned, the first author grouped all incorrect interpretations into preliminary themes. The research team reviewed and discussed all preliminary themes and corresponding incorrect interpretations during team meetings to finalize the themes. Quantitative data analysis was performed in Stata/IC 15.1 (StataCorp LLC, USA). Descriptive statistics were calculated for participant demographics, health information, medication usage, subjective and objective health literacies, pictogram comprehensibility, and pictogram comprehension performance. Simple linear regression using the Huber-White sandwich estimator was performed to examine the association between participants’ pictogram comprehension performance (dependent variable) and each of the following variables as the independent variable: age, sex, education attainment in the US, medication usage, subjective health literacy, and objective health literacy. Complete-case analysis approach was used to deal with missing data. The percentage agreement and Fleiss’ kappa were calculated using the original scoring assigned by the 3 judges to assess inter-rater reliability.
Results
Ease of recruitment, data quality, and costs
The target sample size of 100 was reached within 15 days (February 23, 2018 to March 10, 2018), which was within the pre-specified period of 21 days, suggesting adequate ease of recruitment. However, the research team had to publish the HIT more than once. Over the first 7 days, the research team received 94 surveys—89 submissions within the first 24 hours, 1 additional submission on the 3rd day, 2 more submissions on the 5th day, and another 2 on the 7th day. Between Day 8 and Day 13; however, no new submissions were received, which was likely because the study HIT was buried by other HITs published on later dates on MTurk. Since there were still 6 more surveys needed in order to reach the target sample size, the research team decided to publish another HIT of the same content, requesting 10 assignments (MTurk requires that each HIT contains a minimum of 10 assignments). The 10 assignments requested by this new HIT were completed within 24 hours (and still no new submissions from the original HIT published 2 week ago). This further supported the speculation that the slowed recruitment rate after the first day was likely due to the HIT being buried by newly published ones. However, of the 10 submissions collected by the 2nd HIT, 5 were submitted by existing respondents from the first HIT, as indicated by their unique Amazon Worker ID associated with their MTurk account. These 5 submissions were removed, resulting in a total of 99 valid surveys. Since it was still a week from the recruitment deadline and one more survey to go, the research team decided to publish another HIT requseting10 assignments on Day 14. But this time, before publishing the HIT, the research team created a new customized qualification type (through functionality freely available under the Management tab of the requester account) and named it “existing respondent”, manually assigned this qualification to all existing respondents, and then limited the new HIT to be visible only to Turkers whose “existing respondent” qualification has not been granted by the research team. This time, the research team received 9 new submissions within a day; all from new respondents. Since the target sample size was reached, the research team canceled this new HIT and the original HIT to stop them from collecting more submissions. No action was required for the 2nd HIT since 10 out of the 10 assignments requested had been fulfilled. The overall cost to reach the target sample size was $214.70. MTurk charged a 20% fee on the reward and bonus paid to the Turkers ($1 in this study) and another 20% on the reward and bonus paid for a HIT with 10 or more assignments. For each Premium Qualification used, it also incurred an additional fee. For the Premium Qualification of age 55+ used in this study, the fee was $0.5 per assignment. Therefore, for each submission received (including the second submission from the 5 Turkers), the research team paid $1.9 ($1 reward to the participant + $0.2 reward fee to MTurk + $0.2 assignment fee to MTurk + $0.5 Premium Qualification fee to MTurk). Since there were 5 second submissions that had to be excluded, the average cost for each of the 108 unique surveys was $1.99 ($214.7 ÷ 108 = approximately $1.99).
The final sample included 108 surveys completed by 108 unique Turkers as indicated by their Amazon Worker ID. Table 1 provides a summary of the participant characteristics. The overall survey data quality was good: All 108 surveys were deemed valid because there were no signs of lack of effort. The average completion time of these 108 surveys was 39.6 minutes (range: 14.5–86.5 minutes) and the medium was 35.5 minutes (interquartile range: 29–48 minutes). The percentage of missing data was small across all survey items, ranging from 0 to 3.7%.
Comprehensibility and common misinterpretations
According to ANSI (2017), an acceptable symbol needs to fulfill two criteria: (1) a minimum comprehensibility score of 85% and (2) a maximum of 5% critical confusions (i.e., no more than 5% of respondents provided an opposite interpretation). The mean comprehensibility score of the 15 pictograms tested was 70.4% (SD: 28.6%; range: 3.7%–99.1%). Seven of the 15 pictograms (46.7%) had a comprehensibility score below the ANSI threshold of 85% correct: “For hypertension (high blood pressure)”; “For heart problems”; “Do not use additional salt”; “Do not store near heat or in sunlight”; “Do not share your medicine with others”; “Take 2 times a day”; and “Take by mouth.” Two pictograms, “For hypertension” and “For heart problems,” not only failed the 85% correct interpretation criterion, but also exceeded the maximum 5% level of critical confusions. Furthermore, eight of the 15 pictograms (53.3%) elicited common misinterpretations, suggesting underlying design issues. See Table 2 for the comprehensibility score, the critical confusion rate, and common misinterpretations for each of the 15 pictograms tested.
Inter-rater reliability
The percentage agreements of all pictograms included at least 1 high percentage agreement (>80%) between 2 of the 3 judges. However, the provider and the pharmacist pair (Rater 2 vs Rater 3) surprisingly had lower percentage agreement (<80%) for more pictograms than the other parings. According to the ANSI, “If there is low inter-rater reliability (the judges do not agree), either the correct meaning is unclear, or the respondent’s language is ambiguous”. Both seemed to be true for certain pictograms evaluated in this study. Another explanation is that different disciplines are more sensitive to the accuracy of different types of minor details in the same interpretation. For instance, when the 3 judges were discussing the rating results, it became evident that, the provider paid more attention to the additional minor details provided along with the main message “Call your doctor” in participants’ interpretations and made judgement based on whether the reason to call the doctor provided in the interpretation was reasonable based on her insider knowledge.
See Table 3.
Respondent characteristics and comprehension performance
On average, older Turkers correctly interpreted 10.6 out of the 15 pictograms (SD: 1.9; range: 5–14). Univariate analysis results of the association between pictogram comprehension performance and age, sex, US education attainment, medication usage, subjective health literacy, and objective health literacy are provided in Table 4. Among all respondent characteristics evaluated in this study, only age is significantly associated with pictogram comprehension performance.
Discussion and Implications
Feasibility
The aims of this study were to examine the feasibility of MTurk by ease of recruitment and data quality, as well as the comprehensibility of 15 USP pictograms, selected based on their relevance to commonly prescribed medications for older Americans, among US-based older Turkers. Similar to studies conducted with adult Turkers, findings of this study suggest that MTurk is a feasible, inexpensive, time-efficient platform for evaluating pharmaceutical pictograms and revealing underlying design issues, even when the age group is limited to older adults. On the other hand, even though it was within the estimated timeframe, it took longer to reach the same target number of Turkers for similar tasks when limited to older adults. Publishing more batches of the same HIT or increasing the reward to Turkers might help speed up the recruitment rate. On the other hand, when more than one batch of the same HIT is published, it is important to implement redundancy control strategies such as creating an additional qualification to keep the same Turker from completing the same task twice, unless multiple submissions from the same individual is not of concern. By default, each Turker can only submit one assignment for each batch of the HIT. This feature, however, does not keep Turkers from submitting another assignment to another batch of the HIT of identical content published by the same requester. Consistent with existing literature, we found that greater age was significantly associated with poorer pictogram comprehension performance.
Confusing pictogram design elements
Nearly half of the pictograms (46%) tested here failed to meet the ANSI criteria. Among these less-understood pictograms, “For heart problems” and “For hypertension” were the most problematic because both led to alarmingly high critical confusion rates of 21.3% and 61.1%, respectively. Many participants misinterpreted “For heart problems” as causing heart problems (e.g., “May cause an arrhythmia”) and mistook “For hypertension” as causing high blood pressure. This difficulty in conveying the positive versus negative direction of the drug effect in pictograms was also reported by van Beusekom et al., who noted that “whether the medicine should or should not be taken with heart problems and if it helps against high or low blood pressure was difficult to infer from the pictograms” (p. 969). Consistent with a previous adult Turker study, the concept of additional in the “Do not use additional salt” pictogram was difficult for older Turker participants in this study to comprehend; many misinterpreted it as “Do not use salt.” The main issue found in the pictogram of “Do not share your medicine with others” was that many participants were distracted by the four pills depicted in the pictogram image, associating this with the concept of many (“Don’t take multiple pills”) or more (“Don’t take more than prescribed”), while overlooking the concepts of (not) sharing and others. Similar to prior studies using US and non-US samples, the “Do not store near heat or in sunlight” pictogram confused respondents in this study. Many older Turkers identified the prohibiting concept of the image, but did not recognize the flames design element; even participants who identified the flames tended to overlook the concept of storage, misinterpreting “Do not store near heat or in sunlight” as “Do not burn” or “Do not dispose in fire.”
The main reason that the pictograms for “Take by mouth” and “Take 2 times a day” did not pass the ANSI criteria was that some participants over-interpreted them, including extra information such as the dosage form (e.g., “The pill must be swallowed whole”) or drug quantity (e.g., “Take one pill by mouth” or “Take one pill twice daily”). Such interpretations were rated as incorrect in this study because the additional information inferred from these pictograms (both the “Take by mouth” and “Take 2 times a day” pictograms include an icon of a single pill, which is not part of the intended message and should not be interpreted literally as “one pill”) could lead to unintended consequences. For instance, a patient prescribed to take two pills by mouth but who misinterprets the “Take by mouth” pictogram as “Take one pill by mouth” might underdose themselves by taking only one pill orally. Similarly, those prescribed to take two pills twice a day but misinterpreting the “Take 2 times a day” pictogram as “Take one pill twice a day” might end up taking only half of the prescription. To resolve this issue, customizing these pictograms to match the exact dosage and drug form as specified in each prescription or limiting the use of these pictograms to prescriptions that call for exactly one pill when counseling patients who tend to interpret pictograms literally should be considered.
Furthermore, one controversy concerns the acceptable interpretation for the “Take 2 times a day” pictogram. A majority of the older Turker participants interpreted this pictogram as “Take it in the morning and at night.” Similarly, when Soares tested this pictogram with community pharmacy clients, many misinterpreted it as “Take two times a day, in the morning and evening” or “Take when waking and at bedtime.” In another study aimed at validating the Brazilian Portuguese version of the USP pictogram subtitles, 74% of participants suggested changing the Brazilian Portuguese translation of this pictogram from “Take twice a day” to “Take in the morning and in the evening,”, however, the authors decided not to apply this change as these suggested time points might not apply for all treatments. In the current study, a research team member also voiced a similar concern, cautioning that “Take 2 times a day” and “Take it in the morning and at night” are not necessarily interchangeable depending on the drug in question. However, after discussing the issue, the consensus was that “Take it in the morning and at night” was an acceptable interpretation because the “Take 2 times a day” USP pictogram presents icons of the sun and moon to indicate two different time points in one day. Nevertheless, we agreed that the current sun and moon design of the “Take 2 times a day” pictogram is only appropriate for drugs that are meant to be taken specifically once in the morning and once at night; it is inappropriate for medication that is prescribed twice a day at other times.
Additional issue: vague pictogram subtitles
Apart from these design issues in pictogram images, some of the USP pictogram subtitles seem to be problematically vague. For instance, the “Take with glass of water” subtitle does not specify the amount of water. It is likely that one health provider pairs this pictogram with any medication that should be taken with water, whereas another might use it specifically for those that require a full glass (e.g., levothyroxine). Similarly, although the “Do not use additional salt” pictogram may be useful for medications often prescribed alongside a low sodium diet (e.g., lisinopril), it is unclear whether “additional salt” simply means “added salt” or it has a specific reference value (e.g., any additional salt intake beyond 2,000 milligrams/day). If the former, then “Do not add salt to your food/when cooking” would be a more explicit subtitle than “Do not use additional salt.” If the latter, where “additional” is relative to an established threshold, then the USP should provide such a standardized counseling point to ensure that different providers teach it consistently. Although “Do not use additional salt” is seemingly a simple subtitle, when the three independent judges in this study were grading this pictogram, they interpreted this subtitle (used as the answer key) differently. Both the pharmacist and the allied health professional originally graded “Do not use salt” as an acceptable answer, whereas the provider maintained that since the official subtitle retains the term “additional,” only interpretations indicating a reduction in salt intake but not in an absolute sense should be considered correct. The latter became the grading criteria after discussion. In the real world, however, practicing health professionals are unlikely to spend time discussing vague pictogram subtitles among themselves to ensure that they interpret and teach these pictograms to patients in a consistent manner. Therefore, to improve the utility of USP pictograms, apart from testing pictogram images for comprehensibility, the USP should perform additional testing on pictogram subtitles to ensure that the wording is precise and explicit, as well as provide an official user manual that clarifies the subtitle/intended message of each pictogram. Additional research should also further examine whether different health professionals interpret and teach the intended meaning of each USP pictogram similarly or differently to their patients if they were only given the subtitle of each pictogram, as well as whether they grade pictogram interpretations from the same group of patients similarly or differently.
Additional issue: a lack of currency
Another issue concerning the USP pictogram subtitles is a lack of currency. The USP launched its initiative for developing standardized pharmaceutical pictograms in 1987 and developed the current set of 81 pictograms in 1997. Since the USP pictogram subtitles are textual, they should conform to the current evidence-based best practices and standards for patient-centered written drug information. Nonetheless, we observed otherwise. For instance, USP pictogram subtitles such as “Take 2 times a day” and other similar subtitles (e.g., “Take 3 times a day”) do not fully conform to the Universal Medication Schedule (UMS), a system to standardize the times at which one takes medication using 4 standard time periods (morning, noon, evening, and bedtime) to streamline prescription and dispensation practices, simplify drug labeling, and increase the understandability of directions for patients. Following the UMS guidelines, an instruction to take 2 tablets twice daily, for example, should be paraphrased as “Take 2 tablets in the morning and 2 tablets in the evening” (using numeric rather than alpha characters is another best practice principle related to the UMS. The UMS was proposed more than a decade ago in the Institute of Medicine (IOM) report Standardizing Medication Labels: Confusing Patients Less. The UMS has accumulated a strong evidence base since then and has been endorsed by many organizations, including the IOM, the American College of Physicians, the National Council for Prescription Drug Programs, and the USP itself. It is surprising that the USP endorsed the UMS and incorporated it into its Prescription Container Labeling standards in 2012, but its current pictogram subtitles remain inconsistent with the UMS.
Strengths and Limitations
This study utilized an open-ended comprehension test procedure which, according to the ANSI, is the most reliable method of determining symbol comprehensibility. Moreover, and to the best of our knowledge, this is the first pictogram study to specifically target older Turkers and report feasibility results and the first pictogram study to measure subjective health literacy. Another strength of this study is the use of 3 open-ended questions per pictogram rather than a single question asking participants what they thought the pictogram meant, as is commonly found in other USP pictogram evaluation studies. The inclusion of all 3 questions adapted from the ANSI template allowed for better judgment of participants’ understanding, which was of particular importance given that the evaluation was performed by an anonymous online crowd and the research team would not have had the chance to probe for additional details if a vague response was received. The inclusion of independent judges from three different health disciplines to rate pictograms using the official USP pictogram subtitles without giving them a range of acceptable interpretations or training them to grade participants’ interpretations in a similar manner beforehand helped reveal an important utility issue of USP pictograms that would not have otherwise been exposed—that is, the subtitle and intended meaning of some USP pictograms are confusing, even to health professionals. This challenges the assumption that if USP pictograms are used by health professionals there is no need to provide additional training or information about each individual pictogram. However, additional research with larger samples of health professionals from different disciplines is needed to confirm or reject this observation from the current study.
This study, however, has several limitations. First, the study was conducted with an online convenience sample instead of a representative sample of older adults. Therefore, potential self-selection bias could not be ruled out. Moreover, the majority of participants were White and highly educated, which is a common issue reported in studies sampling MTurk users. Finally, older adults with a low health literacy level were not adequately represented in the study sample. These limitations can affect the generalizability of our findings.
Conclusions
This study piloted the use of MTurk, a leading crowdsourcing platform, to recruit a target of 100 older adults to participate in pharmaceutical pictogram evaluation within a pre-specified timeline. The results showed that MTurk is a feasible platform for screening confusing pictograms and the most obvious design issues, although follow-up testing and design iterations with more representative older adult samples will still be necessary. When incorporating USP pictograms in patient counseling, health professionals should be aware that (1) it is important to clarify the direction of drug effect when using the “For heart problems” and “For hypertension” pictograms with older adults; and (2) due to the large proportion of USP pictograms that failed against ANSI criteria, it is important to ensure that older adults fully understand and can recall the meaning of each pictogram after patient counseling. The USP pictograms that do not meet the ANSI criteria should be prioritized for design modifications. Alternatively, the USP should consider developing a separate, older adult-friendly pictogram set. Furthermore, to increase the general utility of its pictograms, the USP should (1) establish policies and procedures (e.g., methods to select best practice guidelines for pictogram subtitles and the interval between periodic reviews of pictogram subtitles) to ensure that its pictogram subtitles conform to the current evidence-based best practices and standards for patient-centered written drug information, including the UMS; and (2) create a user manual that provides standardized counseling points, explanations for each pictogram image and subtitle, and common misinterpretations reported in published studies by patient group (e.g., children, adult, older adults). Finally, future research is needed to compare the pictogram comprehensibility, comprehension performance, and common misinterpretation results between older Turkers, representative older adult samples, and older adults with limited English literacy and/or health literacy.
This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final form. Please note that during the production process errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain.
References
Changes in prescription and over-the-counter medication and dietary supplement use among older adults in the United States, 2005 vs 2011
Cognition and health literacy in older adults’ recall of self-care Information
Low literacy impairs comprehension of prescription drug warning labels
Aging and functional health literacy: A systematic review and meta-analysis
Medication use leading to emergency department visits for adverse drug events in older adults
Health literacy and older Adults: A systematic review
The evaluation of pharmaceutical pictograms in a low-literate South African population
Effect of pictograms on readability of patient information materials
Low literacy and written drug information: Information-seeking, leaflet evaluation and preferences, and roles for images
Aging memory for pictures: Using high-density event-related potentials to understand the effect of aging on the picture superiority effect
The extent and effects of patient involvement in pictogram design for written drug information: A short systematic review
The effect of age and educational level on the cognitive processes used to comprehend the meaning of pictograms
Interpretation of medication pictograms by adults in the UK
Pharmaceutical pictograms: A model for development and testing for comprehension and utility
Crowdsourcing participatory evaluation of medical pictograms using Amazon Mechanical Turk
Assessing pictograph recognition: A comparison of crowdsourcing and traditional survey approaches
Understanding crowdsourcing projects: A systematic review of tendencies, workflow, and quality management
The rise of crowdsourcing
Towards an integrated crowdsourcing definition
Amazon’s Mechanical Turk: A new source of inexpensive, yet high-quality, data?
Using Amazon’s Mechanical Turk to recruit older adults: Easy and cheap, but is it valid?
Comparing Amazon’s Mechanical Turk platform to conventional data collection methods in the health and medical research literature
MTurk Character Misrepresentation: Assessment and Solutions
Inside the Turk: Understanding Mechanical Turk as a participant pool
Recruiting large online samples in the United States and India: Facebook, Mechanical Turk, and Qualtrics
The demographic and political composition of Mechanical Turk samples
Online reporting for malaria surveillance using micro-monetary incentives, in urban India 2010–2011
Using crowdsourcing technology for testing multilingual public health promotion materials
Crowdsourcing—Harnessing the masses to advance health and medicine: A systematic review
Are dental patients able to perceive erosive tooth wear on anterior teeth?: An internet-based survey assessing awareness and related action
Patient preferences on sharing private information in dental settings
Orthognathic surgery has a significant effect on perceived personality traits and emotions
Patient perceptions of new robotic technologies in clinical restorative dentistry
Running experiments on Amazon Mechanical Turk
Analyzing the Amazon Mechanical Turk marketplace
An evaluation of Amazon’s Mechanical Turk, its rapid rise, and its effective use
Tapped out or barely tapped? Recommendations for how to harness the vast and largely unused potential of the Mechanical Turk participant pool
“Who are these people?” Evaluating the demographic characteristics and political preferences of MTurk survey respondents
The role of pictures in improving health communication: A review of research on attention, comprehension, recall, and adherence
Pharmaceutical container labels: Enhancing preference perceptions with alternative designs and pictorials
Improving visual search in instruction manuals using pictograms
Reputation as a sufficient condition for data quality on Amazon Mechanical Turk
Testing the BRIEF Health Literacy Screening Tool
Quick assessment of literacy in primary care: The Newest Vital Sign
Health literacy measurement: An inventory and descriptive summary of 51 instruments
Evaluating online labor markets for experimental research: Amazon.com’s Mechanical Turk
Pharmaceutical pictograms for low-literate patients: Understanding, risk of false confidence, and evidence-based design strategies
Understanding of pictograms from the United States Pharmacopeia Dispensing Information (USP-DI) among elderly Brazilians
Effects of prospective-user factors and sign design features on guessability of pharmaceutical pictograms
Pictograms for conveying medicine instructions: Comprehension in various South African language groups
Evaluating pictograms as an aid for counseling elderly and low-literate patients
The evaluation of pharmaceutical pictograms among elderly patients in community pharmacy settings – a multicenter pilot study
Legibility of USP pictograms by clients of community pharmacies in Portugal
Semantic validation of subtitles and analysis of understanding of pictograms taken from the United States Pharmacopeia Dispensing Information (USP-DI)
Pictograms in pharmacy
Rationale and design of a randomized trial to evaluate an evidence-based prescription drug label on actual medication use
Expanding the Universal Medication Schedule: A patient-centred approach
The potential for using a Universal Medication Schedule (UMS) to improve adherence in patients taking multiple medications in the UK: a qualitative evaluation
An adapted Communication-Human Information Processing (C-HIP) model for pictogram evaluation.
Interface of pictogram evaluation survey
Characteristics of the participants (n = 108).
Characteristic		 	Agea, medium, IQR/range	63, 59–67/57–80	 	Female, n (%)	61 (56.5%)	 	White, n (%)	98 (91.6%)	 	Born in the United States, n (%)	105 (97.2%)	 	Education, n (%)	 	 Secondary (grades 9–12)	15 (13.9%)	 	 Vocational (post-secondary)	17 (15.7%)	 	 College/university	72 (66.7%)	 	 Advanced degree	4 (3.7%)	 	English as first language, n (%)	106 (98.2%)	 	Self-reported overall health, n (%)	 	 Excellent	14 (13.0%)	 	 Very good	30 (27.8%)	 	 Good	45 (41.7%)	 	 Fair	16 (14.8%)	 	 Poor	3 (2.8%)	 	Number of medications takena, medium, IQR/range	1, 0–4/0–11	 	Background in healthcare, n (%)	15 (13.9%)	 	Significant past illnesses, injuries, or health issues, n (%)	40 (37.4%)	 	Exposure to health conditions, n (%)	 	 Arthritis	42 (39.3%)	 	 Heart disease	30 (28.0%)	 	 Chronic obstructive pulmonary disease	13 (12.1%)	 	 Cancer	33 (30.8%)	 	 Depression	43 (40.2%)	 	 Diabetes	27 (25.2%)	 	 Hyperlipidemia	28 (26.2%)	 	 Hypertension	57 (53.3%)	 	 Stroke	11 (10.3%)	 	 Other	30 (28.0%)	 	BRIEF score, medium, IQR/range	20, 19–20/12–20	 	BRIEF category, n (%)	 	 Limited health literacy (score: 4–12)	1 (0.9%)	 	 Marginal health literacy (13–16)	7 (6.5%)	 	 Adequate health literacy (17–20)	100 (92.6%)	 	NVS score, medium, IQR/range	5, 4–6/1–6)	 	NVS category, n (%)	 	 High likelihood of limited literacy (score: 0–1)	2 (1.9%)	 	 Possibility of limited literacy (2–3)	14 (13.0%)	 	 Almost always indicates adequate literacy (4–6)	92 (85.2%)
BRIEF = four-item Brief Health Literacy Screening Tool; Education = Highest level of education completed in the US; IQR = interquartile range; NVS = Newest Vital Sign.
Medium/IQR instead of mean/standard deviation are used as the measures of central tendency and spread because this variable has a skewed distribution.
Missing data: Three participants provided incomplete dates of birth. Consequently, n = 105 is the denominator for the age variable. For each of the following questions, one participant chose “I prefer not to answer”: race/ethnicity; past major health event (“Have you had significant illness, injuries, or other health issues requiring extended medical care?”); and exposure to health conditions (“Have you either been diagnosed with or cared for someone with any of the following conditions?). Consequently, n = 107 is the denominator for these questions.
Pictogram comprehensibility, critical confusion, and common misinterpretations (n = 108).
Pictogram	Pictogram subtitle: comprehensibility (%); critical confusion rate (%)	Common misinterpretationa (frequency)	Example response	 		Take by mouth: 75; 0	a. Extra information about the form of medication (9) b. Extra information about the number of pills (5)	“The pill must be swallowed whole” “Take one pill orally”	 		Take two times a day: 59.3; 4.6	a. Extra information about the number of pills (34) b. Either day or night (5)	“Take one pill in the morning and one pill at night” “The pill can be taken in the morning or the evening”	 		Do not store near heat or in sunlight: 48.2; 0	a. Do not take or use (25) b. Do not burn, put near an open flame, or dispose in fire (7) c. Not medication or prescription drug (6) d. Dangerous or harmful (5)	“Do not take this medication” “Do not dispose of unused medication by fire” “This is not medicine” “Poison, dangerous, do not touch”	 		Do not store medicine where children can get it: 98.2; 0	No common misinterpretations	N/A	 		This medicine may make you drowsy: 85.2; 0	Take at bedtime or before going to sleep (5)	“Take the medicine by mouth at night before bedtime”	 		Do not break or crush tablets or open capsules: 88.0; 1.9	No common misinterpretations	N/A	 		Take with glass of water: 99.1; 0	No common misinterpretations	N/A	 		Call your doctor: 87.0; 0	No common misinterpretations	N/A	 		This medicine may make you dizzy: 93.5; 0.9	No common misinterpretations	N/A	 		Do not share your medicine with others: 58.3; 0	a. Do not take more than prescribed or directed (15) b. Do not take more than one tablet or one dose/Do not take multiple pills or doses (8) c. Take only as prescribed (7)	“Don’t take more medication than is prescribed” “Don’t take multiple pills at one time.” “Take only the amount prescribed”	 		Get emergency help: 95.4; 0	No common misinterpretations	N/A	 		For hypertension (high blood pressure): 3.7; 61.1	a. May increase blood pressure or cause high blood pressure (66) b. Take your blood pressure (11) c. Monitor your blood pressure (11)	“May cause high blood pressure” “Take your blood pressure while sitting up” “Monitor your blood pressure after taking this medication”	 		Do not use additional salt: 45.4; 0.9	a. Do not use or eat salt/Avoid (eating) salt/No salt allowed (36) b. Do not take medication with salt or salty food (17)	“Do not use salt when taking this medication” “Do not take this medication with salty food”	 		Avoid too much sun or use of sunlamp: 89.8; 0.9	No common misinterpretations	N/A	 		For heart problems: 29.6; 21.3	a. Causes heart problems, irregular heartbeat, or chest pain (21) b. Affects or alters heart rate or heart rhythm (14) c. Affects the heart or unspecified functions of the heart (7) d. Have your heart checked/monitor your heart/EKG (7) e. For a specific heart condition (5)	“May cause an arrhythmia” “Medicine may affect heartbeat” “This medication may affect the function of the heart” “Have your heart checked by a physician” “This medicine is for heart attacks”
Common misinterpretation = an error made by at least 5% of participants or in at least 5 responses (108 responses × 5% = 5.4 responses).
Inter-rater reliability
Pictogram: Comprehensibility (%) /critical confusion (%)	Percentage agreement	Fleiss’ kappa	 	R1 vs R2	R2 vs R3	R1 vs R3	 	#1 Take by mouth: 75/0	93.5	87.0	86.1	0.65	 	#2 Take 2 times a day: 59.3/4.6	95.4	22.2	25.0	−0.01	 	#3 Do not store near heat or in sunlight: 48.2/0	99.1	94.4	93.5	0.91	 	#4 Do not store medicine where children can get it: 98.2/0	96.3	97.2	97.2	0.27	 	#5 This medicine may make you drowsy: 85.2/0	95.4	95.4	98.2	0.84	 	#6 Do not break or crush tablets or open capsules: 88.0/1.9	95.4	98.2	95.4	0.82	 	#7 Take with glass of water: 99.1/0	97.2	96.3	99.1	0.19	 	#8 Call your doctor: 87.0/0	50.9	46.3	88.0	0.02	 	#9 This medicine may make you dizzy: 93.5/0.9	90.7	98.2	90.7	0.51	 	#10 Do not share your medicine with others: 58.3/0	93.5	90.7	95.4	0.86	 	#11 Get emergency help: 95.4/0	81.5	78.7	93.5	0.27	 	#12 For hypertension (high blood pressure): 3.7/61.1	97.2	34.3	33.3	−0.11	 	#13 Do not use additional salt: 45.4/0.9	39.8	37.0	95.4	−0.13	 	#14 Avoid too much sun or use of sunlamp: 89.8/0.9	92.6	91.7	94.4	0.52	 	#15 For heart problems: 29.6/21.3	89.8	79.6	82.4	0.66
Bolded means percentage agreement below 80% or Fleiss kappa < 0.41.
Interpretation of kappa values: < 0 “poor agreement”; 0.01–0.20 “slight agreement”; 0.21–0.40 “fair agreement”; 0.41-0.60 “moderate agreement”; 0.61-0.80 “substantial agreement”; 0.81–1.00 “almost perfect agreement”.
Univariate linear regression results (n =108)
Dependent variable: Pictogram comprehension performance (the total number of pictograms interpreted correctly)	 	Independent variable	Coefficient (β)	Robust Standard Error	P-value	95% Confidence Interval for β	 	Lower bound	Upper bound	 	Age (in years)	−0.07	0.03	0.04*	−0.136	−0.002	 	Sex						 	 Male	−0.04	0.37	0.91	−0.773	0.689	 	Educationa						 	 Vocational	0.95	0.72	0.19	−0.476	2.374	 	 College/university	0.71	0.60	0.24	−0.480	1.891	 	 Advanced degree	0.07	0.91	0.94	−1.738	1.871	 	Medication (binary)						 	 Yes	−0.02	0.36	0.96	−0.734	0.698	 	Subjective health literacy (binary)						 	 Adequate literacy	1.01	0.71	0.16	−0.412	2.422	 	Objective health literacy (binary)						 	 Adequate literacy	0.73	0.61	0.24	−0.486	1.937
reference group=Secondary Education
P-value < 0.05
Medication usage was treated as a binary variable (Yes/No) due to a proportion of respondents not taking any medications (34%).
Subjective health literacy and objective health literacy were both treated as binary variables (the two lower levels were combined due to few observations available in the lowest level).
Missing data: Three participants provided incomplete dates of birth. Consequently, only 105 observations were available when age was the independent variable.
