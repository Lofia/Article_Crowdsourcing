Vayu: An Open-Source Toolbox for Visualization and Analysis of Crowd-Sourced Sensor Data
Recent advances in sensor technology and the availability of low-cost and low-power sensors have changed the air quality monitoring paradigm. These sensors are being widely used by scientists and citizens for monitoring air quality at finer spatial-temporal resolution. Such practices are opening up opportunities to enhance the traditional monitoring networks, but at the same time, these sensors are producing large data sets that can become overwhelming and challenging when it comes to the scientific tools and skills required to analyze the data. To address this challenge, an open-source, robust, and cross-platform sensor data analysis toolbox called Vayu is developed that allows researchers and citizens to do detailed and reproducible analyses of air quality data. Vayu combines the power of visualization and statistical analysis using a simple and intuitive graphical user interface. Additionally, it offers a comprehensive set of tools for systematic analysis such as data conversion, interpolation, aggregation, and prediction. Even though Vayu was developed with air quality research in mind, it can be used to analyze different kinds of time-series data.
1. Introduction
In recent years, the air quality monitoring paradigm has rapidly changed due to the use of the Internet of Things (IoT) and participatory sensing methods. These developments have allowed researchers to use low-cost sensing solutions to monitor the environment at a finer spatial and temporal scale. To complement the official air quality monitoring systems, citizen-driven air quality monitoring networks have also been created all over the world. These networks are mainly run by Citizen Scientists who are community members involved in scientific research. As citizen science grows bigger, more ambitious projects are undertaken by the scientists in collaboration with the citizens. To promote inclusiveness, transparency, and open data, researchers have been developing co-creation studies where citizens are actively involved in large-scale deployment of low-cost air quality sensors to create air quality maps and tools not just for one city, but for an entire region. This has led to an increase in the availability of air quality data as well as interest from multiple stakeholders who want to explore the real-time data to extract locally relevant information. However, processing, aggregation, analysis, and visualization of low-cost sensor data is a formidable task that requires a comprehensive computational framework and expert knowledge of different programming languages and data analysis tools. In most air quality participatory sensing studies, citizen scientists, and other stakeholders depend on computational researchers to process and analyze the data to unravel meaningful insights. In many cases, commercial packages like SPSS Statistics from IBM, Statistica from Statsoft, or open-source professional software like R Studio are used. Most of the citizen-driven environment monitoring networks have dedicated applications and platforms for data visualization and analysis. For example, Purple Air PA-II sensors have a map-based visualization and the AirSensor R package; AirBox has chatbot, Grafana based visualization, pollution maps, route finding application; Luftdaten has a network map and AirBeam has AirCasting map. However, all these applications and resources are sensor-specific. So, for analyzing data from different sensor networks, the user would have to do it separately on a sensor-specific platform. In addition to these sensor-specific platforms, there are several R packages like OpenAir and PWFSLSmoke that can be used for visualizing and analyzing air quality data. But to work with these packages, users would need basic programming skills. Despite the availability of sensor-specific tools and programming libraries, exploration, statistical analysis, and visualization of sensor data sets can still be challenging for citizen scientists and the majority of researchers who don’t have training in programming and data science. Also, many of the commercial applications are black-box algorithms, which is problematic in terms of transparency and open science.
One way to address these challenges is to create appropriate and open-source tools that can reduce technical barriers especially related to programming, and allow experts as well as non-experts to analyze and interpret data in a meaningful way. In this work, an open-source toolbox Vayu is presented that enables researchers as well as citizen scientists independent of their computational skills to analyze their air quality data. Vayu is a Sanskrit word that means “air” in English. The current version of Vayu addresses the challenges and concerns mentioned above by (i) Creating an open, free, and ready to use a toolbox that can process data from different air quality sensor networks, as well as complex time-series data from other sources, (ii) Providing an intuitive graphical user interface (GUI) that allows users to easily visualize and analyze their data, (iii) Offering a variety of options to plot data (line plots, scatter plots and, bar plots) and statistically analyze the data using functions like data interpolation, summarization, aggregation, correlation, linear regression, and naïve Bayes classification to analyze complex data, and (iv) Facilitating easy export of charts, figures, and information-rich statistical analyses that can be used for reporting/publication with little post-processing. Furthermore, Vayu is distributed as an open-source toolbox that allows advanced users to create custom functions and add new features to enhance the toolbox.
In what follows, I first present the system architecture of Vayu. That is followed by a detailed description of the analysis workflow where Vayu is tested with different air quality sensor data sets. I subsequently present the results of a series of tests that were performed to understand how different statistical analysis methods work. The features of Vayu are then compared with existing state-of-the-art air quality sensor data analysis tools and libraries. The final section discusses some future directions.
2. Methods
2.1. Toolbox Design
Vayu is a Python (>3.7) based toolbox that takes advantage of well documented Python packages. The reason behind choosing Python for writing this toolbox was the availability of a wide range of open-source data analysis libraries, and user-specific code adjustments that can be achieved by researchers from different backgrounds. Vayu is an open-source toolbox and relies on the following Python modules: (i) PyQt5 —set of Python bindings for C++ widget library Qt v5 are used to build the GUI. (ii) Pandas —library for data manipulation and analysis. (iii) Scikit-learn —library to implement machine learning in Python. (iv) Matplotlib —library for generating plots that are embedded in PyQt widgets.
All these four modules are well documented and actively used by the open-source developer community. The GUI built with PyQt5 puts together different windows, widgets, and elements of the toolbox. While designing this toolbox, the main objective was to develop an intuitive application that would facilitate usability for people with different skill levels. Different levels of interaction with the data allow the user to uncover meaningful insights without using coding or any query language. Figure 1 gives an overview of the different workflows of Vayu.
2.2. Reporting, Maintenance and Community-Driven Development
As this is an open-source toolbox, users would be encouraged to report issues and unexpected behaviour via GitHub.
2.3. Example Data
Several example data sets have been included in the dataset folder of the GitHub repository. This will facilitate an easy start for the users who want to use this toolbox. A fully documented and easy to follow step-by-step guide is also included that will allow users to perform data analysis using different data sets: (i) PurpleAir: PurpleAir sensors network includes thousands of air quality monitors mainly deployed around North America. The data is regularly used by citizen scientists as well as local and regional environmental monitoring agencies. (ii) AirBox: AirBox sensors are widely deployed around the world specifically in South-East Asia. At present, there are more than 20,000 plus devices deployed in 59 countries. The data is regularly used by scientists, citizens, and policymakers. (iii) Luftdaten: Luftdaten is a citizen science project that runs a global network of air quality monitors to obtain fine-grained air quality data. (iv) A custom data set is also created and tested to show users how they can analyze custom data from IoT devices. The step-by-step guide will be extended regularly by adding example data from more sensor networks.
3. Results and Discussion
The idea behind the development of this toolbox is to simplify the process of analysis of air quality data. A simplified workflow is created for data pre-processing, analysis, prediction, and visualization. This allows the users to interpret the data, analyze the patterns, perform visual data inspection, as well as have reusable results for sharing within the research or citizen science community. The following paragraphs discuss the general aspects of the toolbox and give an overview of different features related to data organization and plotting, data analysis, and data prediction. The example data sets used for testing different features are available in the GitHub repository.
3.1. Data Organization and Plotting
The current version of the toolbox accepts data in different file types including comma-separated values (CSV) files and Excel. As most of the citizen science air quality monitoring projects allow you to download the data as a CSV file, it is set as the default file type the user should upload to perform different actions on the data. If the user has the data in Excel file format, the toolbox allows the user to convert it into CSV format for further analysis. The next step of data organization includes cleaning the data set by removing missing values. Low-cost sensors occasionally show missing data that is usually due to loss of transmission power or device failure. From the quality control perspective, it is important to clean the missing data before the data analysis. The data interpolation feature of the toolbox removes the missing data and uses linear interpolation to estimate the missing data. The linear interpolation method has been widely used for air quality data sets. Linear interpolation estimates the missing values by fitting a straight line between the two data points. The missing values are calculated using the line equation.
In Equation (1), X is the known data point, Y is the value to be determined,  and  are the coordinates that are below the known X value, and  and  are the coordinates that are above the x value. The interpolated data is saved as a CSV file locally and can be used to initiate data visualization and analysis.
Plots can be created instantaneously by selecting the column headers in the X and Y axis boxes, and choosing the plot type (scatter, line and bar). For example, Figure 2 shows the output of the data visualization function. The data from “Tutorial_PurpleAir.csv” is used to create a scatter, bar, and line plot. The plots are generated using Plotly which is an interactive browser-based graphing library for Python. The generated plots are saved in two file formats, .html and .png. This gives the user flexibility to use the plots for different purposes, for example, .html files can be easily shared and embedded within a web page and .png files can be used for reports, publications, etc.
3.2. Data Analysis
Vayu offers a choice of computational functions to analyze and explore sensor data. The functions can be applied to the columns in the data set. Figure 3 gives an overview of different features of the data analysis function. Data processing and statistical analysis are the key tasks of sensor data analysis. The aim of the data analysis workflow is to provide users with the options to recompile the data in the required format, understand the relationship between different variables in the data set, and provides a descriptive analysis of the data set.
Data Aggregation: Different sensors record measurements at different sampling frequencies. In many cases, either the data is too granular or not granular enough. Having an imbalanced time-series is a common problem and it often needs resampling solutions. In scenarios such as comparing data sets from different sensors or comparing the data with regulatory monitors that have a different sampling frequency, the sensor data needs to be resampled. Also, in the case of doing a forecast at a different frequency, resampling may be required. Most of the widely used sensors have a sampling frequency in minutes. In such cases, it is important to downsample the frequency, such as from minutes to hours, days, or months. The data aggregation function allows the user to downsample the data to hourly, daily, or monthly data. It uses the Pandas library to resample the data. A key requirement of using this function is that the data should have a DateTime type index. The users can use different methods like mean, median, sum, and standard deviation to perform data aggregation. The aggregated data is saved as a CSV file.
Data Summarization: Data summarization is often needed to simplify the data interpretation and to understand the distribution of a variable within a data set. Some of the common ways to understand the data distribution are to look at the mean, mode, and median. These values are typically used to understand where the central part of the data is located. Another method is to look at the standard deviation, which acts as an index of variability. If the sensor data are widely scattered, the standard deviation would be larger, and if the data are clustered together, the standard deviation would be smaller. The data summarization function of the toolbox allows the user to look at the column statistics and download the result as a CSV file.
Data Correlation: Looking at the correlation is an effective way to understand the relationship between different variables within a data set. For air quality data, it has been often observed that there is a correlation between air pollution concentration and meteorological factors. Air pollution is negatively correlated with humidity, wind speed, and precipitation, and positively correlated with atmospheric pressure. Correlation allows the user to understand the strength of a relationship between two variables. Such information is useful when building models for calibration or forecasting. The data correlation function allows the user to perform data correlation. Vayu allows a user to calculate different correlation coefficients that are widely used in air quality research: Pearson’s correlation, Kendall Tau’s Correlation, and Spearman correlation. Figure 4 shows the output of the data correlation function. The data from “Tutorial_PurpleAir.csv” is used to find the correlation coefficient. The output is a CSV file with correlation coefficients (Figure 4b) and a correlation heatmap (Figure 4c).
3.3. Data Prediction
Vayu promotes the visual interpretation of data, but it also offers several techniques to perform supervised learning. Supervised learning is a Machine Learning technique in which a model is trained on labeled data. Such methods can be used for the prediction and classification problems.
Linear Regression: The data prediction workflow allows the user to perform linear regression. A linear regression model finds the relationship between the independent and dependent variables. It is a relatively simple method but has been widely used for calibration studies as well as for prediction tasks. Vayu allows a user to use the linear regression function to build a model. It can be useful for citizen scientists as well as researchers who want to start with simple models to perform predictive analysis. Figure 5 shows an example of how the output of linear regression function looks. The data from “Tutorial_Custom1.csv” is used to build a regression model. This example data set contains two variables: data from a reference station, and data from a sensor. A linear regression model is developed to find the correction factor for the sensor. The GUI (as shown in Figure 5a) allows the user to upload the data, and select the dependent and independent variable. The output is a regression plot that shows the relationship between the independent and dependent variables. The plot is also saved as a .png file. A text file (as shown in Figure 5b) is also generated that shows the algorithm details and the model accuracy.
Naïve Bayes Classifier: Methods like linear regression are efficient and useful when we are dealing with numeric data. But in some cases, the problem can be categorized as a classification problem. For example, a user wants to predict whether the Air Quality Index (AQI) would be “High” or “Low” based on different features. In such a case, a classification algorithm would have to be applied. Vayu toolbox allows the users to implement the Naive Bayes (NB) Classification algorithm to perform the classification tasks. NB is one of the most straightforward and fast classification algorithms, and is often used for air quality prediction. NB is a supervised learning algorithm based on Bayes Theorem. In simple words, generating a model using NB classifier includes creating the NB classifier, fitting the data set on the classifier, and performing prediction. The data prediction function allows the users to perform NB classification with binary labels. NB classification has several types and in the case of Vayu, Gaussian NB is used. “Tutorial_Custom2.csv” has been used to test the method, and the results are shown in Figure 6 and Figure 7. The user can use the GUI to select the target variable and the independent variables (as shown in Figure 6a). The data is split between train and test set. The default setting has to be kept to 75% of data for training and the remaining 25% data for testing. This is followed by generating a model. The model is then evaluated by checking the accuracy of the model. The results are in the form of model accuracy, confusion matrix (Figure 6), and a receiver operating characteristic (ROC) curve (Figure 7). The confusion matrix summarizes the performance of the classification model on the test data. The ROC curve is created by plotting the true positive rate against the false-positive rate. The ROC curve shows the area under the curve (AUC) that provides an aggregate measure of performance. The output also includes an ROC curve (Figure 7b) that compares the performance of Gaussian NB to Logistic Regression. This provides a user with an additional way of understanding the performance of different models. The ROC curves and the confusion matrix are saved as .png files, and the algorithm details are saved as a text file.
3.4. Comparison with Existing Tools
Table 1 compares Vayu with other air quality sensors analysis toolkits and software. Each toolkit and software has its strengths and weaknesses as they were designed for different user groups. The issue with sensor-specific software is that they might not work well in case the data from a different sensor is in a different format. With open-source libraries (for example, R packages), the user needs to be experienced in programming to analyze the data. Vayu provides a combination of features in one application that works for different sensor data as well as allows users from different backgrounds to analyze and visualize data without any need for programming. The open-source nature of the toolbox allows users with training in programming to add more functionalities as well as improve the existing features.
4. Conclusions and Future Directions
With citizen science and community-driven air quality monitoring becoming a common practice around the globe, it is important to find user-friendly and intuitive ways to analyze massive streams of sensor data. Vayu aims to support easy analysis and interpretation of air quality sensor data. Developed as a desktop-based, and non-sensor-specific data analysis and visualization toolbox, it equips the users to perform fast and comprehensive analysis of air quality data sets. The open-source nature of the proposed toolbox allows the developer community to build on the existing framework, collaborate, and add to and improve the features of Vayu.
The work discussed in the paper focused on the initial version of Vayu and explained its data processing, analysis, and visualization capabilities. Future work will include adding more functionalities related to outlier detection and time-series forecasting. Additional enhancements may include improvement in the user interface.
Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Funding
The author acknowledges support through the project “CoCi: Co-Evolving City Life”, which has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme under grant agreement No. 833168.
Institutional Review Board Statement
Not applicable.
Informed Consent Statement
Not applicable.
Data Availability Statement
The source code of Vayu and all the data sets that are used in this paper are available on GitHub ( (accessed on 16 October 2021)).
Conflicts of Interest
The author declares no conflict of interest.
References
ADF: An anomaly detection framework for large-scale PM2.5 sensing systems
Community-based participatory research for the study of air pollution: A review of motivations, approaches, and outcomes
Internet of environmental things: A human centered approach
No PhDs needed: How citizen science is transforming research
From Do-It-Yourself (DIY) to Do-It-Together (DIT): Reflections on designing a citizen-driven air quality monitoring framework in Taiwan
A citizen science and government collaboration: Developing tools to facilitate community air monitoring
The AirSensor open-source R-package and DataViewer web application for interpreting community data collected by low-cost sensor networks
Design and implementation of IoT-enabled personal air quality assistant on instant messenger
Particles Matter: A Case Study on How Civic IoT Can Contribute to Sustainable Communities
AirBeam2 Technical Specifications, Operation & Performance
Openair—An R package for air quality data analysis
PWFSLSmoke: Utilities for Working with Air Quality Monitoring Data
Water, water, but not everywhere: Analysis of shrinking water bodies using open access satellite data
Data structures for statistical computing in python
Scikit-learn: Machine learning in Python
Matplotlib: A 2D graphics environment
Vayu Github Repository
Purple Air Monitor
PM2.5 Open Data Portal
Luftdaten Website
Low-cost sensors and crowd-sourced data: Observations of siting impacts on a network of air-quality instruments
Source attribution of air pollution by spatial scale separation using high spatial density networks of low cost air quality sensors
Methods for imputation of missing values in air quality data sets
Impact of outdoor air quality on the natural ventilation usage of commercial buildings in the US
Plotly
Resampling strategies for imbalanced time series forecasting
A fast PM2.5 forecast approach based on time-series data analysis, regression and regularization
Exploring the relationship between air pollution and meteorological conditions in China under environmental governance
An efficient spatiotemporal data calibration approach for the low-cost PM2.5 sensing network: A case study in Taiwan
Why Is Short-Time PM2.5 Forecast Difficult? The Effects of Sudden Events
Indoor air quality differences between urban and rural preschools in Korea
Impact of urbanization level on urban air quality: A case of fine particles (PM2.5) in Chinese cities
AirKit: A Citizen-Sensing Toolkit for Monitoring Air Quality
Air quality warning system based on a localized PM2.5 soft sensor using a novel approach of Bayesian regularized neural network via forward feature selection
Overview of supervised learning
Field calibration of a cluster of low-cost available sensors for air quality monitoring. Part A: Ozone and nitrogen dioxide
Forecasting fine-grained air quality based on big data
Time series prediction based on linear regression and SVR
Estimating Continuous Distributions in Bayesian Classifiers
Air pollution prediction via multi-label classification
Bayes’ theorem and naive Bayes classifier
A non-parametric mixture of Gaussian naive Bayes classifiers based on local independent features
Comparing performances of logistic regression, classification and regression tree, and neural networks for predicting coronary artery disease
Vayu workflows: The toolbox supports the analysis of sensor data by including four workflows. The toolbox accepts external inputs for different workflows and produces output that is stored locally.
Data visualization example: (a) Snapshot of data visualization GUI, (b) scatter plot, (c) line plot, and (d) bar plot.
Data analysis workflow showing different functions, options, and outputs.
Data correlation example: (a) Snapshot of data correlation GUI, (b) output as a CSV file, and (c) correlation heatmap.
Linear regression example: (a) Snapshot of linear regression GUI with regression plot and (b) snapshot of the text file showing regression model details.
NB Classifier example with outputs: (a) Snapshot of NB classifier GUI and (b) confusion matrix.
NB Classifier output: (a) ROC curve showing AUC for NB and (b) plot comparing AUC for NB and logistic regression.
Comparison of Vayu with other tools.
Name	Open	 	Source	Sensor 	 	Specific	GUI	Programming	 	Requirement	 	AirSensor 	Yes	Yes	-	Yes	 	OpenAir 	Yes	No	-	Yes	 	DataViewer 	Yes	Yes	Web-based	No	 	PWFSLSmoke 	Yes	No	-	Yes	 	Vayu	Yes	No	Desktop App	No
